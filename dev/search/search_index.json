{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pydantic","text":"<p>Documentation for development version: 91a4993.</p> <p>Pydantic is the most widely used data validation library for Python.</p> <p>Fast and extensible, Pydantic plays nicely with your linters/IDE/brain. Define how data should be in pure, canonical Python 3.8+; validate it with Pydantic.</p> <p>Migrating to Pydantic V2</p> <p>Using Pydantic V1? See the Migration Guide for notes on upgrading to Pydantic V2 in your applications!</p> Pydantic Example<pre><code>from datetime import datetime\nfrom typing import Tuple\n\nfrom pydantic import BaseModel\n\n\nclass Delivery(BaseModel):\n    timestamp: datetime\n    dimensions: Tuple[int, int]\n\n\nm = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10', '20'])\nprint(repr(m.timestamp))\n#&gt; datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))\nprint(m.dimensions)\n#&gt; (10, 20)\n</code></pre> <p>Why is Pydantic named the way it is?</p> <p>The name \"Pydantic\" is a portmanteau of \"Py\" and \"pedantic.\" The \"Py\" part indicates that the library is associated with Python, and \"pedantic\" refers to the library's meticulous approach to data validation and type enforcement.</p> <p>Combining these elements, \"Pydantic\" describes our Python library that provides detail-oriented, rigorous data validation.</p> <p>We\u2019re aware of the irony that Pydantic V1 was not strict in its validation, so if we're being pedantic, \"Pydantic\" was a misnomer until V2 \ud83d\ude09.</p>"},{"location":"#why-use-pydantic","title":"Why use Pydantic?","text":"<ul> <li>Powered by type hints \u2014 with Pydantic, schema validation and serialization are controlled by type annotations; less to learn, less code to write, and integration with your IDE and static analysis tools. Learn more\u2026</li> <li>Speed \u2014 Pydantic's core validation logic is written in Rust. As a result, Pydantic is among the fastest data validation libraries for Python. Learn more\u2026</li> <li>JSON Schema \u2014 Pydantic models can emit JSON Schema, allowing for easy integration with other tools. Learn more\u2026</li> <li>Strict and Lax mode \u2014 Pydantic can run in either strict mode (where data is not converted) or lax mode where Pydantic tries to coerce data to the correct type where appropriate. Learn more\u2026</li> <li>Dataclasses, TypedDicts and more \u2014 Pydantic supports validation of many standard library types including <code>dataclass</code> and <code>TypedDict</code>. Learn more\u2026</li> <li>Customisation \u2014 Pydantic allows custom validators and serializers to alter how data is processed in many powerful ways. Learn more\u2026</li> <li>Ecosystem \u2014 around 8,000 packages on PyPI use Pydantic, including massively popular libraries like   FastAPI, huggingface, Django Ninja, SQLModel, &amp; LangChain. Learn more\u2026</li> <li>Battle tested \u2014 Pydantic is downloaded over 70M times/month and is used by all FAANG companies and 20 of the 25 largest companies on NASDAQ. If you're trying to do something with Pydantic, someone else has probably already done it. Learn more\u2026</li> </ul> <p>Installing Pydantic is as simple as: <code>pip install pydantic</code></p>"},{"location":"#pydantic-examples","title":"Pydantic examples","text":"<p>To see Pydantic at work, let's start with a simple example, creating a custom class that inherits from <code>BaseModel</code>:</p> Validation Successful<pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, PositiveInt\n\n\nclass User(BaseModel):\n    id: int  # (1)!\n    name: str = 'John Doe'  # (2)!\n    signup_ts: datetime | None  # (3)!\n    tastes: dict[str, PositiveInt]  # (4)!\n\n\nexternal_data = {\n    'id': 123,\n    'signup_ts': '2019-06-01 12:22',  # (5)!\n    'tastes': {\n        'wine': 9,\n        b'cheese': 7,  # (6)!\n        'cabbage': '1',  # (7)!\n    },\n}\n\nuser = User(**external_data)  # (8)!\n\nprint(user.id)  # (9)!\n#&gt; 123\nprint(user.model_dump())  # (10)!\n\"\"\"\n{\n    'id': 123,\n    'name': 'John Doe',\n    'signup_ts': datetime.datetime(2019, 6, 1, 12, 22),\n    'tastes': {'wine': 9, 'cheese': 7, 'cabbage': 1},\n}\n\"\"\"\n</code></pre> <ol> <li><code>id</code> is of type <code>int</code>; the annotation-only declaration tells Pydantic that this field is required. Strings,    bytes, or floats will be coerced to integers if possible; otherwise an exception will be raised.</li> <li><code>name</code> is a string; because it has a default, it is not required.</li> <li><code>signup_ts</code> is a <code>datetime</code> field that is required, but the value <code>None</code> may be provided;    Pydantic will process either a Unix timestamp integer (e.g. <code>1496498400</code>)    or a string representing the date and time.</li> <li><code>tastes</code> is a dictionary with string keys and positive integer values. The <code>PositiveInt</code> type is    shorthand for <code>Annotated[int, annotated_types.Gt(0)]</code>.</li> <li>The input here is an ISO 8601 formatted datetime, but Pydantic will    convert it to a <code>datetime</code> object.</li> <li>The key here is <code>bytes</code>, but Pydantic will take care of coercing it to a string.</li> <li>Similarly, Pydantic will coerce the string <code>'1'</code> to the integer <code>1</code>.</li> <li>We create instance of <code>User</code> by passing our external data to <code>User</code> as keyword arguments.</li> <li>We can access fields as attributes of the model.</li> <li>We can convert the model to a dictionary with <code>model_dump()</code>.</li> </ol> <p>If validation fails, Pydantic will raise an error with a breakdown of what was wrong:</p> Validation Error<pre><code># continuing the above example...\n\nfrom datetime import datetime\nfrom pydantic import BaseModel, PositiveInt, ValidationError\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime | None\n    tastes: dict[str, PositiveInt]\n\n\nexternal_data = {'id': 'not an int', 'tastes': {}}  # (1)!\n\ntry:\n    User(**external_data)  # (2)!\nexcept ValidationError as e:\n    print(e.errors())\n    \"\"\"\n    [\n        {\n            'type': 'int_parsing',\n            'loc': ('id',),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'not an int',\n            'url': 'https://errors.pydantic.dev/2/v/int_parsing',\n        },\n        {\n            'type': 'missing',\n            'loc': ('signup_ts',),\n            'msg': 'Field required',\n            'input': {'id': 'not an int', 'tastes': {}},\n            'url': 'https://errors.pydantic.dev/2/v/missing',\n        },\n    ]\n    \"\"\"\n</code></pre> <ol> <li>The input data is wrong here \u2014 <code>id</code> is not a valid integer, and <code>signup_ts</code> is missing.</li> <li>Trying to instantiate <code>User</code> will raise a <code>ValidationError</code> with a list of errors.</li> </ol>"},{"location":"#who-is-using-pydantic","title":"Who is using Pydantic?","text":"<p>Hundreds of organisations and packages are using Pydantic. Some of the prominent companies and organizations around the world who are using Pydantic include:</p> <p>For a more comprehensive list of open-source projects using Pydantic see the list of dependents on github, or you can find some awesome projects using Pydantic in awesome-pydantic.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>\ud83d\udea7 Work in Progress</p> <p>This page is a work in progress.</p> <p>Starting with Pydantic V2, part of the codebase is written in Rust in a separate package called <code>pydantic-core</code>. This was done partly in order to improve validation and serialization performance (with the cost of limited customization and extendibility of the internal logic).</p> <p>This architecture documentation will first cover how the two <code>pydantic</code> and <code>pydantic-core</code> packages interact together, then will go through the architecture specifics for various patterns (model definition, validation, serialization, JSON Schema).</p> <p>Usage of the Pydantic library can be divided into two parts:</p> <ul> <li>Model definition, done in the <code>pydantic</code> package.</li> <li>Model validation and serialization, done in the <code>pydantic-core</code> package.</li> </ul>"},{"location":"architecture/#model-definition","title":"Model definition","text":"<p>Whenever a Pydantic <code>BaseModel</code> is defined, the metaclass will analyze the body of the model to collect a number of elements:</p> <ul> <li>Defined annotations to build model fields (collected in the <code>model_fields</code> attribute).</li> <li>Model configuration, set with <code>model_config</code>.</li> <li>Additional validators/serializers.</li> <li>Private attributes, class variables, identification of generic parametrization, etc.</li> </ul>"},{"location":"architecture/#communicating-between-pydantic-and-pydantic-core-the-core-schema","title":"Communicating between <code>pydantic</code> and <code>pydantic-core</code>: the core schema","text":"<p>We then need a way to communicate the collected information from the model definition to <code>pydantic-core</code>, so that validation and serialization is performed accordingly. To do so, Pydantic uses the concept of a core schema: a structured (and serializable) Python dictionary (represented using <code>TypedDict</code> definitions) describing a specific validation and serialization logic. It is the core data structure used to communicate between the <code>pydantic</code> and <code>pydantic-core</code> packages. Every core schema has a required <code>type</code> key, and extra properties depending on this <code>type</code>.</p> <p>The generation of a core schema is handled in a single place, by the <code>GenerateSchema</code> class (no matter if it is for a Pydantic model or anything else).</p> <p>Note</p> <p>It is not possible to define a custom core schema. A core schema needs to be understood by the <code>pydantic-core</code> package, and as such we only support a fixed number of core schema types. This is also part of the reason why the <code>GenerateSchema</code> isn't truly exposed and properly documented.</p> <p>The core schema definitions can be found in the <code>pydantic_core.core_schema</code> module.</p> <p>In the case of a Pydantic model, a core schema will be constructed and set as the <code>__pydantic_core_schema__</code> attribute.</p> <p>To illustrate what a core schema looks like, we will take the example of the <code>bool</code> core schema:</p> <pre><code>class BoolSchema(TypedDict, total=False):\n    type: Required[Literal['bool']]\n    strict: bool\n    ref: str\n    metadata: Any\n    serialization: SerSchema\n</code></pre> <p>When defining a Pydantic model with a boolean field:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Model(BaseModel):\n    foo: bool = Field(strict=True)\n</code></pre> <p>The core schema for the <code>foo</code> field will look like:</p> <pre><code>{\n    'type': 'bool',\n    'strict': True,\n}\n</code></pre> <p>As seen in the <code>BoolSchema</code> definition, the serialization logic is also defined in the core schema. If we were to define a custom serialization function for <code>foo</code> (1), the <code>serialization</code> key would look like:</p> <ol> <li> <p>For example using the <code>field_serializer</code> decorator:</p> <pre><code>class Model(BaseModel):\n    foo: bool = Field(strict=True)\n\n    @field_serializer('foo', mode='plain')\n    def serialize_foo(self, value: bool) -&gt; Any:\n        ...\n</code></pre> </li> </ol> <pre><code>{\n    'type': 'function-plain',\n    'function': &lt;function Model.serialize_foo at 0x111&gt;,\n    'is_field_serializer': True,\n    'info_arg': False,\n    'return_schema': {'type': 'int'},\n}\n</code></pre> <p>Note that this is also a core schema definition, just that it is only relevant for <code>pydantic-core</code> during serialization.</p> <p>Core schemas cover a broad scope, and are used whenever we want to communicate between the Python and Rust side. While the previous examples were related to validation and serialization, it could in theory be used for anything: error management, extra metadata, etc.</p>"},{"location":"architecture/#json-schema-generation","title":"JSON Schema generation","text":"<p>You may have noticed that the previous serialization core schema has a <code>return_schema</code> key. This is because the core schema is also used to generate the corresponding JSON Schema.</p> <p>Similar to how the core schema is generated, the JSON Schema generation is handled by the <code>GenerateJsonSchema</code> class. The <code>generate</code> method is the main entry point and is given the core schema of that model.</p> <p>Coming back to our <code>bool</code> field example, the <code>bool_schema</code> method will be given the previously generated boolean core schema and will return the following JSON Schema:</p> <pre><code>{\n    {\"type\": \"boolean\"}\n}\n</code></pre>"},{"location":"architecture/#customizing-the-core-schema-and-json-schema","title":"Customizing the core schema and JSON schema","text":"<p>Usage Documentation</p> <p>Custom types</p> <p>Implementing <code>__get_pydantic_core_schema__</code></p> <p>Implementing <code>__get_pydantic_json_schema__</code></p> <p>While the <code>GenerateSchema</code> and <code>GenerateJsonSchema</code> classes handle the creation of the corresponding schemas, Pydantic offers a way to customize them in some cases, following a wrapper pattern. This customization is done through the <code>__get_pydantic_core_schema__</code> and <code>__get_pydantic_json_schema__</code> methods.</p> <p>To understand this wrapper pattern, we will take the example of metadata classes used with <code>Annotated</code>, where the <code>__get_pydantic_core_schema__</code> method can be used:</p> <pre><code>from typing import Any\n\nfrom pydantic_core import CoreSchema\nfrom typing_extensions import Annotated\n\nfrom pydantic import GetCoreSchemaHandler, TypeAdapter\n\n\nclass MyStrict:\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: Any, handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        schema = handler(source)  # (1)!\n        schema['strict'] = True\n        return schema\n\n\nclass MyGt:\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: Any, handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        schema = handler(source)  # (2)!\n        schema['gt'] = 1\n        return schema\n\n\nta = TypeAdapter(Annotated[int, MyStrict(), MyGt()])\n</code></pre> <ol> <li><code>MyStrict</code> is the first annotation to be applied. At this point, <code>schema = {'type': 'int'}</code>.</li> <li><code>MyGt</code> is the last annotation to be applied. At this point, <code>schema = {'type': 'int', 'strict': True}</code>.</li> </ol> <p>When the <code>GenerateSchema</code> class builds the core schema for <code>Annotated[int, MyStrict(), MyGt()]</code>, it will create an instance of a <code>GetCoreSchemaHandler</code> to be passed to the <code>MyGt.__get_pydantic_core_schema__</code> method. (1)</p> <ol> <li>In the case of our <code>Annotated</code> pattern, the <code>GetCoreSchemaHandler</code> is defined in a nested way.     Calling it will recursively call the other <code>__get_pydantic_core_schema__</code> methods until it reaches the <code>int</code> annotation,     where a simple <code>{'type': 'int'}</code> schema is returned.</li> </ol> <p>The <code>source</code> argument depends on the core schema generation pattern. In the case of <code>Annotated</code>, the <code>source</code> will be the type being annotated. When defining a custom type, the <code>source</code> will be the actual class where <code>__get_pydantic_core_schema__</code> is defined.</p>"},{"location":"architecture/#model-validation-and-serialization","title":"Model validation and serialization","text":"<p>While model definition was scoped to the class level (i.e. when defining your model), model validation and serialization happens at the instance level. Both these concepts are handled in <code>pydantic-core</code> (providing a 5 to 20 performance increase compared to Pydantic V1), by using the previously built core schema.</p> <p><code>pydantic-core</code> exposes a <code>SchemaValidator</code> and <code>SchemaSerializer</code> class to perform these tasks:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    foo: int\n\n\nmodel = Model.model_validate({'foo': 1})  # (1)!\ndumped = model.model_dump()  # (2)!\n</code></pre> <ol> <li>The provided data is sent to <code>pydantic-core</code> by using the    <code>SchemaValidator.validate_python</code> method.    <code>pydantic-core</code> will validate (following the core schema of the model) the data and populate    the model's <code>__dict__</code> attribute.</li> <li>The <code>model</code> instance is sent to <code>pydantic-core</code> by using the    <code>SchemaSerializer.to_python</code> method.    <code>pydantic-core</code> will read the instance's <code>__dict__</code> attribute and built the appropriate result    (again, following the core schema of the model).</li> </ol>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v290b2-2024-08-30","title":"v2.9.0b2 (2024-08-30)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed","title":"What's Changed","text":""},{"location":"changelog/#packaging","title":"Packaging","text":"<ul> <li>Bump <code>pydantic-core</code> to <code>v2.23.1</code> and other minor version bumps by @sydney-runkle in #10269</li> </ul>"},{"location":"changelog/#changes","title":"Changes","text":"<ul> <li>Raise helpful warning when <code>self</code> isn't returned from model validator by @sydney-runkle in #10255</li> </ul>"},{"location":"changelog/#performance","title":"Performance","text":"<ul> <li>Update ns stack with already copied ns by @sydney-runkle in #10267</li> </ul>"},{"location":"changelog/#fixes","title":"Fixes","text":"<ul> <li>Fix new warnings assertions to use <code>pytest.warns()</code> by @mgorny in #10241</li> <li>Fix a crash when cleaning the namespace in <code>ModelMetaclass</code> by @Viicos in #10242</li> <li>Fix parent namespace issue with model rebuilds by @sydney-runkle in #10257</li> <li>Remove defaults filter for namespace by @sydney-runkle in #10261</li> <li>Use identity instead of equality after validating model in <code>__init__</code> by @Viicos in #10264</li> <li>Support <code>BigInt</code> serialization for <code>int</code> subclasses by @kxx317 in pydantic/pydantic-core#1417</li> </ul>"},{"location":"changelog/#new-contributors","title":"New Contributors","text":"<ul> <li>@AdolfoVillalobos made their first contribution in #10240</li> <li>@bllchmbrs made their first contribution in #10270</li> </ul>"},{"location":"changelog/#v290b1-2024-08-26","title":"v2.9.0b1 (2024-08-26)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_1","title":"What's Changed","text":""},{"location":"changelog/#packaging_1","title":"Packaging","text":"<ul> <li>Bump <code>ruff</code> to <code>v0.5.0</code> and <code>pyright</code> to <code>v1.1.369</code> by @sydney-runkle in #9801</li> <li>Bump <code>pydantic-extra-types</code> to <code>v2.9.0</code> by @sydney-runkle in #9832</li> <li>Support compatibility with <code>pdm v2.18.1</code> by @Viicos in #10138</li> <li>Bump <code>pydantic-core</code> to v2.23.0 by @sydney-runkle in #10180</li> <li>Bump <code>v1</code> version stub to <code>v1.10.18</code> by @sydney-runkle in #10214</li> </ul>"},{"location":"changelog/#new-features","title":"New Features","text":"<ul> <li>Add support for <code>ZoneInfo</code> by @Youssefares in #9896</li> <li>Add <code>Config.val_json_bytes</code> by @josh-newman in #9770</li> <li>Add DSN for Snowflake by @aditkumar72 in #10128</li> <li>Support <code>complex</code> number by @changhc in #9654</li> <li>Add support for <code>annotated_types.Not</code> by @aditkumar72 in #10210</li> <li>Allow <code>WithJsonSchema</code> to inject <code>$ref</code>s w/ <code>http</code> or <code>https</code> links by @dAIsySHEng1 in #9863</li> <li>Allow validators to customize validation JSON schema by @Viicos in #10094</li> <li>Support parametrized <code>PathLike</code> types by @nix010 in #9764</li> <li>Add tagged union serializer that attempts to use <code>str</code> or <code>callable</code> discriminators to select the correct serializer by @sydney-runkle in in pydantic/pydantic-core#1397</li> </ul>"},{"location":"changelog/#changes_1","title":"Changes","text":"<ul> <li>Breaking Change: Merge <code>dict</code> type <code>json_schema_extra</code> by @sydney-runkle in #9792</li> <li>For more info (how to replicate old behavior) on this change, see here</li> <li>Refactor annotation injection for known (often generic) types by @sydney-runkle in #9979</li> <li>Move annotation compatibility errors to validation phase by @sydney-runkle in #9999</li> <li>Improve runtime errors for string constraints like <code>pattern</code> for incompatible types by @sydney-runkle in #10158</li> <li>Remove <code>'allOf'</code> JSON schema workarounds by @dpeachey in #10029</li> <li>Remove <code>typed_dict_cls</code> data from <code>CoreMetadata</code> by @sydney-runkle in #10180</li> <li>Deprecate passing a dict to the <code>Examples</code> class by @Viicos in #10181</li> <li>Remove <code>initial_metadata</code> from internal metadata construct by @sydney-runkle in #10194</li> <li>Use <code>re.Pattern.search</code> instead of <code>re.Pattern.match</code> for consistency with <code>rust</code> behavior by @tinez in pydantic/pydantic-core#1368</li> <li>Show value of wrongly typed data in <code>pydantic-core</code> serialization warning by @BoxyUwU in pydantic/pydantic-core#1377</li> <li>Breaking Change: in <code>pydantic-core</code>, change <code>metadata</code> type hint in core schemas from <code>Any</code> -&gt; <code>Dict[str, Any] | None</code> by @sydney-runkle in pydantic/pydantic-core#1411</li> </ul>"},{"location":"changelog/#performance_1","title":"Performance","text":"<ul> <li>Initial start at improving import times for modules, using caching primarily by @sydney-runkle in #10009</li> <li>Using cached internal import for <code>BaseModel</code> by @sydney-runkle in #10013</li> <li>Simplify internal generics logic - remove generator overhead by @sydney-runkle in #10059</li> <li>Remove default module globals from types namespace by @sydney-runkle in #10123</li> <li>Performance boost: skip caching parent namespaces in most cases by @sydney-runkle in #10113</li> </ul>"},{"location":"changelog/#minor-internal-improvements","title":"Minor Internal Improvements","text":"<ul> <li>\u26a1\ufe0f Speed up <code>multiple_of_validator()</code> by 31% in <code>pydantic/_internal/_validators.py</code> by @misrasaurabh1 in #9839</li> <li>\u26a1\ufe0f Speed up <code>ModelPrivateAttr.__set_name__()</code> by 18% in <code>pydantic/fields.py</code> by @misrasaurabh1 in #9841</li> <li>\u26a1\ufe0f Speed up <code>dataclass()</code> by 7% in <code>pydantic/dataclasses.py</code> by @misrasaurabh1 in #9843</li> <li>\u26a1\ufe0f Speed up function <code>_field_name_for_signature</code> by 37% in <code>pydantic/_internal/_signature.py</code> by @misrasaurabh1 in #9951</li> <li>\u26a1\ufe0f Speed up method <code>GenerateSchema._unpack_refs_defs</code> by 26% in <code>pydantic/_internal/_generate_schema.py</code> by @misrasaurabh1 in #9949</li> <li>\u26a1\ufe0f Speed up function <code>apply_each_item_validators</code> by 100% in <code>pydantic/_internal/_generate_schema.py</code> by @misrasaurabh1 in #9950</li> <li>\u26a1\ufe0f Speed up method <code>ConfigWrapper.core_config</code> by 28% in <code>pydantic/_internal/_config.py</code> by @misrasaurabh1 in #9953</li> </ul>"},{"location":"changelog/#fixes_1","title":"Fixes","text":"<ul> <li>Respect <code>use_enum_values</code> on <code>Literal</code> types by @kwint in #9787</li> <li>Prevent type error for exotic <code>BaseModel/RootModel</code> inheritance by @dmontagu in #9913</li> <li>Fix typing issue with field_validator-decorated methods by @dmontagu in #9914</li> <li>Replace <code>str</code> type annotation with <code>Any</code> in validator factories in documentation on validators by @maximilianfellhuber in #9885</li> <li>Fix <code>ComputedFieldInfo.wrapped_property</code> pointer when a property setter is assigned by @tlambert03 in #9892</li> <li>Fix recursive typing of <code>main.IncEnx</code> by @tlambert03 in #9924</li> <li>Allow usage of <code>type[Annotated[...]]</code> by @Viicos in #9932</li> <li><code>mypy</code> plugin: handle frozen fields on a per-field basis by @dmontagu in #9935</li> <li>Fix typo in <code>invalid-annotated-type</code> error code by @sydney-runkle in #9948</li> <li>Simplify schema generation for <code>uuid</code>, <code>url</code>, and <code>ip</code> types by @sydney-runkle in #9975</li> <li>Move <code>date</code> schemas to <code>_generate_schema.py</code> by @sydney-runkle in #9976</li> <li>Move <code>decimal.Decimal</code> validation to <code>_generate_schema.py</code> by @sydney-runkle in #9977</li> <li>Simplify IP address schema in <code>_std_types_schema.py</code> by @sydney-runkle in #9959</li> <li>Fix type annotations for some potentially generic <code>GenerateSchema.match_type</code> options by @sydney-runkle in #9961</li> <li>Add class name to \"has conflict\" warnings by @msabramo in #9964</li> <li>Fix <code>dataclass</code> ignoring <code>default_factory</code> passed in Annotated by @kc0506 in #9971</li> <li>Fix <code>Sequence</code> ignoring <code>discriminator</code> by @kc0506 in #9980</li> <li>Fix typing for <code>IPvAnyAddress</code> and <code>IPvAnyInterface</code> by @haoyun in #9990</li> <li>Fix false positives on v1 models in <code>mypy</code> plugin for <code>from_orm</code> check requiring from_attributes=True config by @radekwlsk in #9938</li> <li>Apply <code>strict=True</code> to <code>__init__</code> in <code>mypy</code> plugin by @kc0506 in #9998</li> <li>Refactor application of <code>deque</code> annotations by @sydney-runkle in #10018</li> <li>Raise a better user error when failing to evaluate a forward reference by @Viicos in #10030</li> <li>Fix evaluation of <code>__pydantic_extra__</code> annotation in specific circumstances by @Viicos in #10070</li> <li>Fix <code>frozen</code> enforcement for <code>dataclasses</code> by @sydney-runkle in #10066</li> <li>Remove logic to handle unused <code>__get_pydantic_core_schema__</code> signature by @Viicos in #10075</li> <li>Use <code>is_annotated</code> consistently by @Viicos in #10095</li> <li>Fix <code>PydanticDeprecatedSince26</code> typo by @kc0506 in #10101</li> <li>Improve <code>pyright</code> tests, refactor model decorators signatures by @Viicos in #10092</li> <li>Fix <code>ip</code> serialization logic by @sydney-runkle in #10112</li> <li>Warn when frozen defined twice for <code>dataclasses</code> by @mochi22 in #10082</li> <li>Do not compute JSON Schema default when plain serializers are used with <code>when_used</code> set to <code>'json-unless-none'</code> and the default value is <code>None</code> by @Viicos in #10121</li> <li>Fix <code>ImportString</code> special cases by @sydney-runkle in #10137</li> <li>Blacklist default globals to support exotic user code with <code>__</code> prefixed annotations by @sydney-runkle in #10136</li> <li>Handle <code>nullable</code> schemas with <code>serialization</code> schema available during JSON Schema generation by @Viicos in #10132</li> <li>Reorganize <code>BaseModel</code> annotations by @kc0506 in #10110</li> <li>Fix core schema simplification when serialization schemas are involved in specific scenarios by @Viicos in #10155</li> <li>Add support for stringified annotations when using <code>PrivateAttr</code> with <code>Annotated</code> by @Viicos in #10157</li> <li>Fix JSON Schema <code>number</code> type for literal and enum schemas by @Viicos in #10172</li> <li>Fix JSON Schema generation of fields with plain validators in serialization mode by @Viicos in #10167</li> <li>Fix invalid JSON Schemas being generated for functions in certain scenarios by @Viicos in #10188</li> <li>Make sure generated JSON Schemas are valid in tests by @Viicos in #10182</li> <li>Fix key error with custom serializer by @sydney-runkle in #10200</li> <li>Add 'wss' for allowed schemes in NatsDsn by @swelborn in #10224</li> <li>Fix <code>Mapping</code> and <code>MutableMapping</code> annotations to use mapping schema instead of dict schema by @sydney-runkle in #10020</li> <li>Fix JSON Schema generation for constrained dates by @Viicos in #10185</li> <li>Fix discriminated union bug regression when using enums by @kfreezen in pydantic/pydantic-core#1286</li> <li>Fix <code>field_serializer</code> with computed field when using <code>*</code> by @nix010 in pydantic/pydantic-core#1349</li> <li>Try each option in <code>Union</code> serializer before inference by @sydney-runkle in pydantic/pydantic-core#1398</li> <li>Fix <code>float</code> serialization behavior in <code>strict</code> mode by @sydney-runkle in pydantic/pydantic-core#1400</li> <li>Introduce <code>exactness</code> into Decimal validation logic to improve union validation behavior by @sydney-runkle in in pydantic/pydantic-core#1405</li> </ul>"},{"location":"changelog/#new-contributors_1","title":"New Contributors","text":""},{"location":"changelog/#pydantic","title":"<code>pydantic</code>","text":"<ul> <li>@kwint made their first contribution in #9787</li> <li>@seekinginfiniteloop made their first contribution in #9822</li> <li>@a-alexander made their first contribution in #9848</li> <li>@maximilianfellhuber made their first contribution in #9885</li> <li>@karmaBonfire made their first contribution in #9945</li> <li>@s-rigaud made their first contribution in #9958</li> <li>@msabramo made their first contribution in #9964</li> <li>@DimaCybr made their first contribution in #9972</li> <li>@kc0506 made their first contribution in #9971</li> <li>@haoyun made their first contribution in #9990</li> <li>@radekwlsk made their first contribution in #9938</li> <li>@dpeachey made their first contribution in #10029</li> <li>@BoxyUwU made their first contribution in #10085</li> <li>@mochi22 made their first contribution in #10082</li> <li>@aditkumar72 made their first contribution in #10128</li> <li>@changhc made their first contribution in #9654</li> <li>@insumanth made their first contribution in #10229</li> </ul>"},{"location":"changelog/#pydantic-core","title":"<code>pydantic-core</code>","text":"<ul> <li>@kfreezen made their first contribution in pydantic/pydantic-core#1286</li> <li>@tinez made their first contribution in pydantic/pydantic-core#1368</li> <li>@fft001 made their first contribution in pydantic/pydantic-core#1362</li> <li>@nix010 made their first contribution in pydantic/pydantic-core#1349</li> <li>@BoxyUwU made their first contribution in pydantic/pydantic-core#1379</li> <li>@candleindark made their first contribution in pydantic/pydantic-core#1404</li> <li>@changhc made their first contribution in pydantic/pydantic-core#1331</li> </ul>"},{"location":"changelog/#v282-2024-07-03","title":"v2.8.2 (2024-07-03)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_2","title":"What's Changed","text":""},{"location":"changelog/#fixes_2","title":"Fixes","text":"<ul> <li>Fix issue with assertion caused by pluggable schema validator by @dmontagu in #9838</li> </ul>"},{"location":"changelog/#v281-2024-07-03","title":"v2.8.1 (2024-07-03)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_3","title":"What's Changed","text":""},{"location":"changelog/#packaging_2","title":"Packaging","text":"<ul> <li>Bump <code>ruff</code> to <code>v0.5.0</code> and <code>pyright</code> to <code>v1.1.369</code> by @sydney-runkle in #9801</li> <li>Bump <code>pydantic-core</code> to <code>v2.20.1</code>, <code>pydantic-extra-types</code> to <code>v2.9.0</code> by @sydney-runkle in #9832</li> </ul>"},{"location":"changelog/#fixes_3","title":"Fixes","text":"<ul> <li>Fix breaking change in <code>to_snake</code> from v2.7 -&gt; v2.8 by @sydney-runkle in #9812</li> <li>Fix list constraint json schema application by @sydney-runkle in #9818</li> <li>Support time duration more than 23 by @nix010 in pydantic/speedate#64</li> <li>Fix millisecond fraction being handled with the wrong scale by @davidhewitt in pydantic/speedate#65</li> <li>Handle negative fractional durations correctly by @sydney-runkle in pydantic/speedate#71</li> </ul>"},{"location":"changelog/#v280-2024-07-01","title":"v2.8.0 (2024-07-01)","text":"<p> GitHub release</p> <p>The code released in v2.8.0 is functionally identical to that of v2.8.0b1.</p>"},{"location":"changelog/#whats-changed_4","title":"What's Changed","text":""},{"location":"changelog/#packaging_3","title":"Packaging","text":"<ul> <li>Update citation version automatically with new releases by @sydney-runkle in #9673</li> <li>Bump pyright to <code>v1.1.367</code> and add type checking tests for pipeline API by @adriangb in #9674</li> <li>Update <code>pydantic.v1</code> stub to <code>v1.10.17</code> by @sydney-runkle in #9707</li> <li>General package updates to prep for <code>v2.8.0b1</code> by @sydney-runkle in #9741</li> <li>Bump <code>pydantic-core</code> to <code>v2.20.0</code> by @sydney-runkle in #9745</li> <li>Add support for Python 3.13 by @sydney-runkle in #9743</li> <li>Update <code>pdm</code> version used for <code>pdm.lock</code> to v2.16.1 by @sydney-runkle in #9761</li> <li>Update to <code>ruff</code> <code>v0.4.8</code> by @Viicos in #9585</li> </ul>"},{"location":"changelog/#new-features_1","title":"New Features","text":"<ul> <li>Experimental: support <code>defer_build</code> for <code>TypeAdapter</code> by @MarkusSintonen in #8939</li> <li>Implement <code>deprecated</code> field in json schema by @NeevCohen in #9298</li> <li>Experimental: Add pipeline API by @adriangb in #9459</li> <li>Add support for programmatic title generation by @NeevCohen in #9183</li> <li>Implement <code>fail_fast</code> feature by @uriyyo in #9708</li> <li>Add <code>ser_json_inf_nan='strings'</code> mode to produce valid JSON by @josh-newman in pydantic/pydantic-core#1307</li> </ul>"},{"location":"changelog/#changes_2","title":"Changes","text":"<ul> <li>Add warning when \"alias\" is set in ignored <code>Annotated</code> field by @nix010 in #9170</li> <li>Support serialization of some serializable defaults in JSON schema by @sydney-runkle in #9624</li> <li>Relax type specification for <code>__validators__</code> values in <code>create_model</code> by @sydney-runkle in #9697</li> <li>Breaking Change: Improve <code>smart</code> union matching logic by @sydney-runkle in pydantic/pydantic-core#1322 You can read more about our <code>smart</code> union matching logic here. In some cases, if the old behavior is desired, you can switch to <code>left-to-right</code> mode and change the order of your <code>Union</code> members.</li> </ul>"},{"location":"changelog/#performance_2","title":"Performance","text":""},{"location":"changelog/#internal-improvements","title":"Internal Improvements","text":"<ul> <li>\u26a1\ufe0f Speed up <code>_display_error_loc()</code> by 25% in <code>pydantic/v1/error_wrappers.py</code> by @misrasaurabh1 in #9653</li> <li>\u26a1\ufe0f Speed up <code>_get_all_json_refs()</code> by 34% in <code>pydantic/json_schema.py</code> by @misrasaurabh1 in #9650</li> <li>\u26a1\ufe0f Speed up <code>is_pydantic_dataclass()</code> by 41% in <code>pydantic/dataclasses.py</code> by @misrasaurabh1 in #9652</li> <li>\u26a1\ufe0f Speed up <code>to_snake()</code> by 27% in <code>pydantic/alias_generators.py</code> by @misrasaurabh1 in #9747</li> <li>\u26a1\ufe0f Speed up <code>unwrap_wrapped_function()</code> by 93% in <code>pydantic/_internal/_decorators.py</code> by @misrasaurabh1 in #9727</li> </ul>"},{"location":"changelog/#fixes_4","title":"Fixes","text":"<ul> <li>Replace <code>__spec__.parent</code> with <code>__package__</code> by @hramezani in #9331</li> <li>Fix Outputted Model JSON Schema for <code>Sequence</code> type by @anesmemisevic in #9303</li> <li>Fix typing of <code>_frame_depth</code> by @Viicos in #9353</li> <li>Make <code>ImportString</code> json schema compatible by @amitschang in #9344</li> <li>Hide private attributes (<code>PrivateAttr</code>) from <code>__init__</code> signature in type checkers by @idan22moral in #9293</li> <li>Make detection of <code>TypeVar</code> defaults robust to the CPython <code>PEP-696</code> implementation by @AlexWaygood in #9426</li> <li>Fix usage of <code>PlainSerializer</code> with builtin types by @Viicos in #9450</li> <li>Add more robust custom validation examples by @ChrisPappalardo in #9468</li> <li>Fix ignored <code>strict</code> specification for <code>StringConstraint(strict=False)</code> by @vbmendes in #9476</li> <li>Breaking Change: Use PEP 570 syntax by @Viicos in #9479</li> <li>Use <code>Self</code> where possible by @Viicos in #9479</li> <li>Do not alter <code>RootModel.model_construct</code> signature in the <code>mypy</code> plugin by @Viicos in #9480</li> <li>Fixed type hint of <code>validation_context</code> by @OhioDschungel6 in #9508</li> <li>Support context being passed to TypeAdapter's <code>dump_json</code>/<code>dump_python</code> by @alexcouper in #9495</li> <li>Updates type signature for <code>Field()</code> constructor by @bjmc in #9484</li> <li>Improve builtin alias generators by @sydney-runkle in #9561</li> <li>Fix typing of <code>TypeAdapter</code> by @Viicos in #9570</li> <li>Add fallback default value for private fields in <code>__setstate__</code> of BaseModel by @anhpham1509 in #9584</li> <li>Support <code>PEP 746</code> by @adriangb in #9587</li> <li>Allow validator and serializer functions to have default values by @Viicos in #9478</li> <li>Fix bug with mypy plugin's handling of covariant <code>TypeVar</code> fields by @dmontagu in #9606</li> <li>Fix multiple annotation / constraint application logic by @sydney-runkle in #9623</li> <li>Respect <code>regex</code> flags in validation and json schema by @sydney-runkle in #9591</li> <li>Fix type hint on <code>IpvAnyAddress</code> by @sydney-runkle in #9640</li> <li>Allow a field specifier on <code>__pydantic_extra__</code> by @dmontagu in #9659</li> <li>Use normalized case for file path comparison by @sydney-runkle in #9737</li> <li>Modify constraint application logic to allow field constraints on <code>Optional[Decimal]</code> by @lazyhope in #9754</li> <li><code>validate_call</code> type params fix by @sydney-runkle in #9760</li> <li>Check all warnings returned by pytest.warns() by @s-t-e-v-e-n-k in #9702</li> <li>Reuse <code>re.Pattern</code> object in regex patterns to allow for regex flags by @sydney-runkle in pydantic/pydantic-core#1318</li> </ul>"},{"location":"changelog/#new-contributors_2","title":"New Contributors","text":"<ul> <li>@idan22moral made their first contribution in #9294</li> <li>@anesmemisevic made their first contribution in #9303</li> <li>@max-muoto made their first contribution in #9338</li> <li>@amitschang made their first contribution in #9344</li> <li>@paulmartin91 made their first contribution in #9410</li> <li>@OhioDschungel6 made their first contribution in #9405</li> <li>@AlexWaygood made their first contribution in #9426</li> <li>@kinuax made their first contribution in #9433</li> <li>@antoni-jamiolkowski made their first contribution in #9431</li> <li>@candleindark made their first contribution in #9448</li> <li>@nix010 made their first contribution in #9170</li> <li>@tomy0000000 made their first contribution in #9457</li> <li>@vbmendes made their first contribution in #9470</li> <li>@micheleAlberto made their first contribution in #9471</li> <li>@ChrisPappalardo made their first contribution in #9468</li> <li>@blueTurtz made their first contribution in #9475</li> <li>@WinterBlue16 made their first contribution in #9477</li> <li>@bittner made their first contribution in #9500</li> <li>@alexcouper made their first contribution in #9495</li> <li>@bjmc made their first contribution in #9484</li> <li>@pjvv made their first contribution in #9529</li> <li>@nedbat made their first contribution in #9530</li> <li>@gunnellEvan made their first contribution in #9469</li> <li>@jaymbans made their first contribution in #9531</li> <li>@MarcBresson made their first contribution in #9534</li> <li>@anhpham1509 made their first contribution in #9584</li> <li>@K-dash made their first contribution in #9595</li> <li>@s-t-e-v-e-n-k made their first contribution in #9527</li> <li>@airwoodix made their first contribution in #9506</li> <li>@misrasaurabh1 made their first contribution in #9653</li> <li>@AlessandroMiola made their first contribution in #9740</li> <li>@mylapallilavanyaa made their first contribution in #9746</li> <li>@lazyhope made their first contribution in #9754</li> <li>@YassinNouh21 made their first contribution in #9759</li> </ul>"},{"location":"changelog/#v280b1-2024-06-27","title":"v2.8.0b1 (2024-06-27)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v274-2024-06-12","title":"v2.7.4 (2024-06-12)","text":"<p>Github release</p>"},{"location":"changelog/#whats-changed_5","title":"What's Changed","text":""},{"location":"changelog/#packaging_4","title":"Packaging","text":"<ul> <li>Bump <code>pydantic.v1</code> to <code>v1.10.16</code> reference by @sydney-runkle in #9639</li> </ul>"},{"location":"changelog/#fixes_5","title":"Fixes","text":"<ul> <li>Specify <code>recursive_guard</code> as kwarg in <code>FutureRef._evaluate</code> by @vfazio in #9612</li> </ul>"},{"location":"changelog/#v273-2024-06-03","title":"v2.7.3 (2024-06-03)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_6","title":"What's Changed","text":""},{"location":"changelog/#packaging_5","title":"Packaging","text":"<ul> <li>Bump <code>pydantic-core</code> to <code>v2.18.4</code> by @sydney-runkle in #9550</li> </ul>"},{"location":"changelog/#fixes_6","title":"Fixes","text":"<ul> <li>Fix u style unicode strings in python @samuelcolvin in pydantic/jiter#110</li> </ul>"},{"location":"changelog/#v272-2024-05-28","title":"v2.7.2 (2024-05-28)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_7","title":"What's Changed","text":""},{"location":"changelog/#packaging_6","title":"Packaging","text":"<ul> <li>Bump <code>pydantic-core</code> to <code>v2.18.3</code> by @sydney-runkle in #9515</li> </ul>"},{"location":"changelog/#fixes_7","title":"Fixes","text":"<ul> <li>Replace <code>__spec__.parent</code> with <code>__package__</code> by @hramezani in #9331</li> <li>Fix validation of <code>int</code>s with leading unary minus by @RajatRajdeep in pydantic/pydantic-core#1291</li> <li>Fix <code>str</code> subclass validation for enums by @sydney-runkle in pydantic/pydantic-core#1273</li> <li>Support <code>BigInt</code>s in <code>Literal</code>s and <code>Enum</code>s by @samuelcolvin in pydantic/pydantic-core#1297</li> <li>Fix: uuid - allow <code>str</code> subclass as input by @davidhewitt in pydantic/pydantic-core#1296</li> </ul>"},{"location":"changelog/#v271-2024-04-23","title":"v2.7.1 (2024-04-23)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_8","title":"What's Changed","text":""},{"location":"changelog/#packaging_7","title":"Packaging","text":"<ul> <li>Bump <code>pydantic-core</code> to <code>v2.18.2</code> by @sydney-runkle in #9307</li> </ul>"},{"location":"changelog/#new-features_2","title":"New Features","text":"<ul> <li>Ftp and Websocket connection strings support by @CherrySuryp in #9205</li> </ul>"},{"location":"changelog/#changes_3","title":"Changes","text":"<ul> <li>Use field description for RootModel schema description when there is <code>\u2026</code> by @LouisGobert in #9214</li> </ul>"},{"location":"changelog/#fixes_8","title":"Fixes","text":"<ul> <li>Fix <code>validation_alias</code> behavior with <code>model_construct</code> for <code>AliasChoices</code> and <code>AliasPath</code> by @sydney-runkle in #9223</li> <li>Revert <code>typing.Literal</code> and import it outside the TYPE_CHECKING block by @frost-nzcr4 in #9232</li> <li>Fix <code>Secret</code> serialization schema, applicable for unions by @sydney-runkle in #9240</li> <li>Fix <code>strict</code> application to <code>function-after</code> with <code>use_enum_values</code> by @sydney-runkle in #9279</li> <li>Address case where <code>model_construct</code> on a class which defines <code>model_post_init</code> fails with <code>AttributeError</code> by @babygrimes in #9168</li> <li>Fix <code>model_json_schema</code> with config types by @NeevCohen in #9287</li> <li>Support multiple zeros as an <code>int</code> by @samuelcolvin in pydantic/pydantic-core#1269</li> <li>Fix validation of <code>int</code>s with leading unary plus by @cknv in pydantic/pydantic-core#1272</li> <li>Fix interaction between <code>extra != 'ignore'</code> and <code>from_attributes=True</code> by @davidhewitt in pydantic/pydantic-core#1276</li> <li>Handle error from <code>Enum</code>'s <code>missing</code> function as <code>ValidationError</code> by @sydney-runkle in pydantic/pydantic-core#1274</li> <li>Fix memory leak with <code>Iterable</code> validation by @davidhewitt in pydantic/pydantic-core#1271</li> </ul>"},{"location":"changelog/#new-contributors_3","title":"New Contributors","text":"<ul> <li>@zzstoatzz made their first contribution in #9219</li> <li>@frost-nzcr4 made their first contribution in #9232</li> <li>@CherrySuryp made their first contribution in #9205</li> <li>@vagenas made their first contribution in #9268</li> <li>@ollz272 made their first contribution in #9262</li> <li>@babygrimes made their first contribution in #9168</li> <li>@swelborn made their first contribution in #9296</li> <li>@kf-novi made their first contribution in #9236</li> <li>@lgeiger made their first contribution in #9288</li> </ul>"},{"location":"changelog/#v270-2024-04-11","title":"v2.7.0 (2024-04-11)","text":"<p> GitHub release</p> <p>The code released in v2.7.0 is practically identical to that of v2.7.0b1.</p>"},{"location":"changelog/#whats-changed_9","title":"What's Changed","text":""},{"location":"changelog/#packaging_8","title":"Packaging","text":"<ul> <li>Reorganize <code>pyproject.toml</code> sections by @Viicos in #8899</li> <li>Bump <code>pydantic-core</code> to <code>v2.18.1</code> by @sydney-runkle in #9211</li> <li>Adopt <code>jiter</code> <code>v0.2.0</code> by @samuelcolvin in pydantic/pydantic-core#1250</li> </ul>"},{"location":"changelog/#new-features_3","title":"New Features","text":"<ul> <li>Extract attribute docstrings from <code>FieldInfo.description</code> by @Viicos in #6563</li> <li>Add a <code>with_config</code> decorator to comply with typing spec by @Viicos in #8611</li> <li>Allow an optional separator splitting the value and unit of the result of <code>ByteSize.human_readable</code> by @jks15satoshi in #8706</li> <li>Add generic <code>Secret</code> base type by @conradogarciaberrotaran in #8519</li> <li>Make use of <code>Sphinx</code> inventories for cross references in docs by @Viicos in #8682</li> <li>Add environment variable to disable plugins by @geospackle in #8767</li> <li>Add support for <code>deprecated</code> fields by @Viicos in #8237</li> <li>Allow <code>field_serializer('*')</code> by @ornariece in #9001</li> <li>Handle a case when <code>model_config</code> is defined as a model property by @alexeyt101 in #9004</li> <li>Update <code>create_model()</code> to support <code>typing.Annotated</code> as input by @wannieman98 in #8947</li> <li>Add <code>ClickhouseDsn</code> support by @solidguy7 in #9062</li> <li>Add support for <code>re.Pattern[str]</code> to <code>pattern</code> field by @jag-k in #9053</li> <li>Support for <code>serialize_as_any</code> runtime setting by @sydney-runkle in #8830</li> <li>Add support for <code>typing.Self</code> by @Youssefares in #9023</li> <li>Ability to pass <code>context</code> to serialization by @ornariece in #8965</li> <li>Add feedback widget to docs with flarelytics integration by @sydney-runkle in #9129</li> <li>Support for parsing partial JSON strings in Python by @samuelcolvin in pydantic/jiter#66</li> </ul> <p>Finalized in v2.7.0, rather than v2.7.0b1: * Add support for field level number to str coercion option by @NeevCohen in #9137 * Update <code>warnings</code> parameter for serialization utilities to allow raising a warning by @Lance-Drane in #9166</p>"},{"location":"changelog/#changes_4","title":"Changes","text":"<ul> <li>Correct docs, logic for <code>model_construct</code> behavior with <code>extra</code> by @sydney-runkle in #8807</li> <li>Improve error message for improper <code>RootModel</code> subclasses by @sydney-runkle in #8857</li> <li>Breaking Change: Use <code>PEP570</code> syntax by @Viicos in #8940</li> <li>Add <code>enum</code> and <code>type</code> to the JSON schema for single item literals by @dmontagu in #8944</li> <li>Deprecate <code>update_json_schema</code> internal function by @sydney-runkle in #9125</li> <li>Serialize duration to hour minute second, instead of just seconds by @kakilangit in pydantic/speedate#50</li> <li>Trimming str before parsing to int and float by @hungtsetse in pydantic/pydantic-core#1203</li> </ul>"},{"location":"changelog/#performance_3","title":"Performance","text":"<ul> <li><code>enum</code> validator improvements by @samuelcolvin in #9045</li> <li>Move <code>enum</code> validation and serialization to Rust by @samuelcolvin in #9064</li> <li>Improve schema generation for nested dataclasses by @sydney-runkle in #9114</li> <li>Fast path for ASCII python string creation in JSON by @samuelcolvin in in pydantic/jiter#72</li> <li>SIMD integer and string JSON parsing on <code>aarch64</code>(Note: SIMD on x86 will be implemented in a future release) by @samuelcolvin in in pydantic/jiter#65</li> <li>Support JSON <code>Cow&lt;str&gt;</code> from <code>jiter</code> by @davidhewitt in pydantic/pydantic-core#1231</li> <li>MAJOR performance improvement: update to PyO3 0.21 final by @davidhewitt in pydantic/pydantic-core#1248</li> <li>cache Python strings by @samuelcolvin in pydantic/pydantic-core#1240</li> </ul>"},{"location":"changelog/#fixes_9","title":"Fixes","text":"<ul> <li>Fix strict parsing for some <code>Sequence</code>s by @sydney-runkle in #8614</li> <li>Add a check on the existence of <code>__qualname__</code> by @anci3ntr0ck in #8642</li> <li>Handle <code>__pydantic_extra__</code> annotation being a string or inherited by @alexmojaki in #8659</li> <li>Fix json validation for <code>NameEmail</code> by @Holi0317 in #8650</li> <li>Fix type-safety of attribute access in <code>BaseModel</code> by @bluenote10 in #8651</li> <li>Fix bug with <code>mypy</code> plugin and <code>no_strict_optional = True</code> by @dmontagu in #8666</li> <li>Fix <code>ByteSize</code> error <code>type</code> change by @sydney-runkle in #8681</li> <li>Fix inheriting annotations in dataclasses by @sydney-runkle in #8679</li> <li>Fix regression in core schema generation for indirect definition references by @dmontagu in #8702</li> <li>Fix unsupported types bug with plain validator by @sydney-runkle in #8710</li> <li>Reverting problematic fix from 2.6 release, fixing schema building bug by @sydney-runkle in #8718</li> <li>fixes <code>__pydantic_config__</code> ignored for TypeDict by @13sin in #8734</li> <li>Fix test failures with <code>pytest v8.0.0</code> due to <code>pytest.warns()</code> starting to work inside <code>pytest.raises()</code> by @mgorny in #8678</li> <li>Use <code>is_valid_field</code> from 1.x for <code>mypy</code> plugin by @DanielNoord in #8738</li> <li>Better-support <code>mypy</code> strict equality flag by @dmontagu in #8799</li> <li>model_json_schema export with Annotated types misses 'required' parameters by @LouisGobert in #8793</li> <li>Fix default inclusion in <code>FieldInfo.__repr_args__</code> by @sydney-runkle in #8801</li> <li>Fix resolution of forward refs in dataclass base classes that are not present in the subclass module namespace by @matsjoyce-refeyn in #8751</li> <li>Fix <code>BaseModel</code> type annotations to be resolvable by <code>typing.get_type_hints</code> by @devmonkey22 in #7680</li> <li>Fix: allow empty string aliases with <code>AliasGenerator</code> by @sydney-runkle in #8810</li> <li>Fix test along with <code>date</code> -&gt; <code>datetime</code> timezone assumption fix by @sydney-runkle in #8823</li> <li>Fix deprecation warning with usage of <code>ast.Str</code> by @Viicos in #8837</li> <li>Add missing <code>deprecated</code> decorators by @Viicos in #8877</li> <li>Fix serialization of <code>NameEmail</code> if name includes an email address by @NeevCohen in #8860</li> <li>Add information about class in error message of schema generation by @Czaki in #8917</li> <li>Make <code>TypeAdapter</code>'s typing compatible with special forms by @adriangb in #8923</li> <li>Fix issue with config behavior being baked into the ref schema for <code>enum</code>s by @dmontagu in #8920</li> <li>More helpful error re wrong <code>model_json_schema</code> usage by @sydney-runkle in #8928</li> <li>Fix nested discriminated union schema gen, pt 2 by @sydney-runkle in #8932</li> <li>Fix schema build for nested dataclasses / TypedDicts with discriminators by @sydney-runkle in #8950</li> <li>Remove unnecessary logic for definitions schema gen with discriminated unions by @sydney-runkle in #8951</li> <li>Fix handling of optionals in <code>mypy</code> plugin by @dmontagu in #9008</li> <li>Fix <code>PlainSerializer</code> usage with std type constructor by @sydney-runkle in #9031</li> <li>Remove unnecessary warning for config in plugin by @dmontagu in #9039</li> <li>Fix default value serializing by @NeevCohen in #9066</li> <li>Fix extra fields check in <code>Model.__getattr__()</code> by @NeevCohen in #9082</li> <li>Fix <code>ClassVar</code> forward ref inherited from parent class by @alexmojaki in #9097</li> <li>fix sequence like validator with strict <code>True</code> by @andresliszt in #8977</li> <li>Improve warning message when a field name shadows a field in a parent model by @chan-vince in #9105</li> <li>Do not warn about shadowed fields if they are not redefined in a child class by @chan-vince in #9111</li> <li>Fix discriminated union bug with unsubstituted type var by @sydney-runkle in #9124</li> <li>Support serialization of <code>deque</code> when passed to <code>Sequence[blah blah blah]</code> by @sydney-runkle in #9128</li> <li>Init private attributes from super-types in <code>model_post_init</code> by @Viicos in #9134</li> <li>fix <code>model_construct</code> with <code>validation_alias</code> by @ornariece in #9144</li> <li>Ensure json-schema generator handles <code>Literal</code> <code>null</code> types by @bruno-f-cruz in #9135</li> <li>Fixed in v2.7.0: Fix allow extra generic by @dmontagu in #9193</li> </ul>"},{"location":"changelog/#new-contributors_4","title":"New Contributors","text":"<ul> <li>@hungtsetse made their first contribution in #8546</li> <li>@StrawHatDrag0n made their first contribution in #8583</li> <li>@anci3ntr0ck made their first contribution in #8642</li> <li>@Holi0317 made their first contribution in #8650</li> <li>@bluenote10 made their first contribution in #8651</li> <li>@ADSteele916 made their first contribution in #8703</li> <li>@musicinmybrain made their first contribution in #8731</li> <li>@jks15satoshi made their first contribution in #8706</li> <li>@13sin made their first contribution in #8734</li> <li>@DanielNoord made their first contribution in #8738</li> <li>@conradogarciaberrotaran made their first contribution in #8519</li> <li>@chris-griffin made their first contribution in #8775</li> <li>@LouisGobert made their first contribution in #8793</li> <li>@matsjoyce-refeyn made their first contribution in #8751</li> <li>@devmonkey22 made their first contribution in #7680</li> <li>@adamency made their first contribution in #8847</li> <li>@MamfTheKramf made their first contribution in #8851</li> <li>@ornariece made their first contribution in #9001</li> <li>@alexeyt101 made their first contribution in #9004</li> <li>@wannieman98 made their first contribution in #8947</li> <li>@solidguy7 made their first contribution in #9062</li> <li>@kloczek made their first contribution in #9047</li> <li>@jag-k made their first contribution in #9053</li> <li>@priya-gitTest made their first contribution in #9088</li> <li>@Youssefares made their first contribution in #9023</li> <li>@chan-vince made their first contribution in #9105</li> <li>@bruno-f-cruz made their first contribution in #9135</li> <li>@Lance-Drane made their first contribution in #9166</li> </ul>"},{"location":"changelog/#v270b1-2024-04-03","title":"v2.7.0b1 (2024-04-03)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v264-2024-03-12","title":"v2.6.4 (2024-03-12)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_10","title":"What's Changed","text":""},{"location":"changelog/#fixes_10","title":"Fixes","text":"<ul> <li>Fix usage of <code>AliasGenerator</code> with <code>computed_field</code> decorator by @sydney-runkle in #8806</li> <li>Fix nested discriminated union schema gen, pt 2 by @sydney-runkle in #8932</li> <li>Fix bug with no_strict_optional=True caused by API deferral by @dmontagu in #8826</li> </ul>"},{"location":"changelog/#v263-2024-02-27","title":"v2.6.3 (2024-02-27)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_11","title":"What's Changed","text":""},{"location":"changelog/#packaging_9","title":"Packaging","text":"<ul> <li>Update <code>pydantic-settings</code> version in the docs by @hramezani in #8906</li> </ul>"},{"location":"changelog/#fixes_11","title":"Fixes","text":"<ul> <li>Fix discriminated union schema gen bug by @sydney-runkle in #8904</li> </ul>"},{"location":"changelog/#v262-2024-02-23","title":"v2.6.2 (2024-02-23)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_12","title":"What's Changed","text":""},{"location":"changelog/#packaging_10","title":"Packaging","text":"<ul> <li>Upgrade to <code>pydantic-core</code> 2.16.3 by @sydney-runkle in #8879</li> </ul>"},{"location":"changelog/#fixes_12","title":"Fixes","text":"<ul> <li>'YYYY-MM-DD' date string coerced to datetime shouldn't infer timezone by @sydney-runkle in pydantic/pydantic-core#1193</li> </ul>"},{"location":"changelog/#v261-2024-02-05","title":"v2.6.1 (2024-02-05)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_13","title":"What's Changed","text":""},{"location":"changelog/#packaging_11","title":"Packaging","text":"<ul> <li>Upgrade to <code>pydantic-core</code> 2.16.2 by @sydney-runkle in #8717</li> </ul>"},{"location":"changelog/#fixes_13","title":"Fixes","text":"<ul> <li>Fix bug with <code>mypy</code> plugin and <code>no_strict_optional = True</code> by @dmontagu in #8666</li> <li>Fix <code>ByteSize</code> error <code>type</code> change by @sydney-runkle in #8681</li> <li>Fix inheriting <code>Field</code> annotations in dataclasses by @sydney-runkle in #8679</li> <li>Fix regression in core schema generation for indirect definition references by @dmontagu in #8702</li> <li>Fix unsupported types bug with <code>PlainValidator</code> by @sydney-runkle in #8710</li> <li>Reverting problematic fix from 2.6 release, fixing schema building bug by @sydney-runkle in #8718</li> <li>Fix warning for tuple of wrong size in <code>Union</code> by @davidhewitt in pydantic/pydantic-core#1174</li> <li>Fix <code>computed_field</code> JSON serializer <code>exclude_none</code> behavior by @sydney-runkle in pydantic/pydantic-core#1187</li> </ul>"},{"location":"changelog/#v260-2024-01-23","title":"v2.6.0 (2024-01-23)","text":"<p> GitHub release</p> <p>The code released in v2.6.0 is practically identical to that of v2.6.0b1.</p>"},{"location":"changelog/#whats-changed_14","title":"What's Changed","text":""},{"location":"changelog/#packaging_12","title":"Packaging","text":"<ul> <li>Check for <code>email-validator</code> version &gt;= 2.0 by @commonism in #6033</li> <li>Upgrade `ruff`` target version to Python 3.8 by @Elkiwa in #8341</li> <li>Update to <code>pydantic-extra-types==2.4.1</code> by @yezz123 in #8478</li> <li>Update to <code>pyright==1.1.345</code> by @Viicos in #8453</li> <li>Update pydantic-core from 2.14.6 to 2.16.1, significant changes from these updates are described below, full changelog here</li> </ul>"},{"location":"changelog/#new-features_4","title":"New Features","text":"<ul> <li>Add <code>NatsDsn</code> by @ekeew in #6874</li> <li>Add <code>ConfigDict.ser_json_inf_nan</code> by @davidhewitt in #8159</li> <li>Add <code>types.OnErrorOmit</code> by @adriangb in #8222</li> <li>Support <code>AliasGenerator</code> usage by @sydney-runkle in #8282</li> <li>Add Pydantic People Page to docs by @sydney-runkle in #8345</li> <li>Support <code>yyyy-MM-DD</code> datetime parsing by @sydney-runkle in #8404</li> <li>Added bits conversions to the <code>ByteSize</code> class #8415 by @luca-matei in #8507</li> <li>Enable json schema creation with type <code>ByteSize</code> by @geospackle in #8537</li> <li>Add <code>eval_type_backport</code> to handle union operator and builtin generic subscripting in older Pythons by @alexmojaki in #8209</li> <li>Add support for <code>dataclass</code> fields <code>init</code> by @dmontagu in #8552</li> <li>Implement pickling for <code>ValidationError</code> by @davidhewitt in pydantic/pydantic-core#1119</li> <li>Add unified tuple validator that can handle \"variadic\" tuples via PEP-646 by @dmontagu in pydantic/pydantic-core#865</li> </ul>"},{"location":"changelog/#changes_5","title":"Changes","text":"<ul> <li>Drop Python3.7 support by @hramezani in #7188</li> <li>Drop Python 3.7, and PyPy 3.7 and 3.8 by @davidhewitt in pydantic/pydantic-core#1129</li> <li>Use positional-only <code>self</code> in <code>BaseModel</code> constructor, so no field name can ever conflict with it by @ariebovenberg in #8072</li> <li>Make <code>@validate_call</code> return a function instead of a custom descriptor - fixes binding issue with inheritance and adds <code>self/cls</code> argument to validation errors by @alexmojaki in #8268</li> <li>Exclude <code>BaseModel</code> docstring from JSON schema description by @sydney-runkle in #8352</li> <li>Introducing <code>classproperty</code> decorator for <code>model_computed_fields</code> by @Jocelyn-Gas in #8437</li> <li>Explicitly raise an error if field names clashes with types by @Viicos in #8243</li> <li>Use stricter serializer for unions of simple types by @alexdrydew pydantic/pydantic-core#1132</li> </ul>"},{"location":"changelog/#performance_4","title":"Performance","text":"<ul> <li>Add Codspeed profiling Actions workflow  by @lambertsbennett in #8054</li> <li>Improve <code>int</code> extraction by @samuelcolvin in pydantic/pydantic-core#1155</li> <li>Improve performance of recursion guard by @samuelcolvin in pydantic/pydantic-core#1156</li> <li><code>dataclass</code> serialization speedups by @samuelcolvin in pydantic/pydantic-core#1162</li> <li>Avoid <code>HashMap</code> creation when looking up small JSON objects in <code>LazyIndexMaps</code> by @samuelcolvin in pydantic/jiter#55</li> <li>use hashbrown to speedup python string caching by @davidhewitt in pydantic/jiter#51</li> <li>Replace <code>Peak</code> with more efficient <code>Peek</code> by @davidhewitt in pydantic/jiter#48</li> </ul>"},{"location":"changelog/#fixes_14","title":"Fixes","text":"<ul> <li>Move <code>getattr</code> warning in deprecated <code>BaseConfig</code> by @tlambert03 in #7183</li> <li>Only hash <code>model_fields</code>, not whole <code>__dict__</code> by @alexmojaki in #7786</li> <li>Fix mishandling of unions while freezing types in the <code>mypy</code> plugin by @dmontagu in #7411</li> <li>Fix <code>mypy</code> error on untyped <code>ClassVar</code> by @vincent-hachin-wmx in #8138</li> <li>Only compare pydantic fields in <code>BaseModel.__eq__</code> instead of whole <code>__dict__</code> by @QuentinSoubeyranAqemia in #7825</li> <li>Update <code>strict</code> docstring in <code>model_validate</code> method. by @LukeTonin in #8223</li> <li>Fix overload position of <code>computed_field</code> by @Viicos in #8227</li> <li>Fix custom type type casting used in multiple attributes by @ianhfc in #8066</li> <li>Fix issue not allowing <code>validate_call</code> decorator to be dynamically assigned to a class method by @jusexton in #8249</li> <li>Fix issue <code>unittest.mock</code> deprecation warnings  by @ibleedicare in #8262</li> <li>Added tests for the case <code>JsonValue</code> contains subclassed primitive values by @jusexton in #8286</li> <li>Fix <code>mypy</code> error on free before validator (classmethod) by @sydney-runkle in #8285</li> <li>Fix <code>to_snake</code> conversion by @jevins09 in #8316</li> <li>Fix type annotation of <code>ModelMetaclass.__prepare__</code> by @slanzmich in #8305</li> <li>Disallow <code>config</code> specification when initializing a <code>TypeAdapter</code> when the annotated type has config already by @sydney-runkle in #8365</li> <li>Fix a naming issue with JSON schema for generics parametrized by recursive type aliases by @dmontagu in #8389</li> <li>Fix type annotation in pydantic people script by @shenxiangzhuang in #8402</li> <li>Add support for field <code>alias</code> in <code>dataclass</code> signature by @NeevCohen in #8387</li> <li>Fix bug with schema generation with <code>Field(...)</code> in a forward ref by @dmontagu in #8494</li> <li>Fix ordering of keys in <code>__dict__</code> with <code>model_construct</code> call by @sydney-runkle in #8500</li> <li>Fix module <code>path_type</code> creation when globals does not contain <code>__name__</code> by @hramezani in #8470</li> <li>Fix for namespace issue with dataclasses with <code>from __future__ import annotations</code> by @sydney-runkle in #8513</li> <li>Fix: make function validator types positional-only by @pmmmwh in #8479</li> <li>Fix usage of <code>@deprecated</code> by @Viicos in #8294</li> <li>Add more support for private attributes in <code>model_construct</code> call by @sydney-runkle in #8525</li> <li>Use a stack for the types namespace by @dmontagu in #8378</li> <li>Fix schema-building bug with <code>TypeAliasType</code> for types with refs by @dmontagu in #8526</li> <li>Support <code>pydantic.Field(repr=False)</code> in dataclasses by @tigeryy2 in #8511</li> <li>Override <code>dataclass_transform</code> behavior for <code>RootModel</code> by @Viicos in #8163</li> <li>Refactor signature generation for simplicity by @sydney-runkle in #8572</li> <li>Fix ordering bug of PlainValidator annotation by @Anvil in #8567</li> <li>Fix <code>exclude_none</code> for json serialization of <code>computed_field</code>s by @sydney-runkle in pydantic/pydantic-core#1098</li> <li>Support yyyy-MM-DD string for datetimes by @sydney-runkle in pydantic/pydantic-core#1124</li> <li>Tweak ordering of definitions in generated schemas by @StrawHatDrag0n in #8583</li> </ul>"},{"location":"changelog/#new-contributors_5","title":"New Contributors","text":""},{"location":"changelog/#pydantic_1","title":"<code>pydantic</code>","text":"<ul> <li>@ekeew made their first contribution in #6874</li> <li>@lambertsbennett made their first contribution in #8054</li> <li>@vincent-hachin-wmx made their first contribution in #8138</li> <li>@QuentinSoubeyranAqemia made their first contribution in #7825</li> <li>@ariebovenberg made their first contribution in #8072</li> <li>@LukeTonin made their first contribution in #8223</li> <li>@denisart made their first contribution in #8231</li> <li>@ianhfc made their first contribution in #8066</li> <li>@eonu made their first contribution in #8255</li> <li>@amandahla made their first contribution in #8263</li> <li>@ibleedicare made their first contribution in #8262</li> <li>@jevins09 made their first contribution in #8316</li> <li>@cuu508 made their first contribution in #8322</li> <li>@slanzmich made their first contribution in #8305</li> <li>@jensenbox made their first contribution in #8331</li> <li>@szepeviktor made their first contribution in #8356</li> <li>@Elkiwa made their first contribution in #8341</li> <li>@parhamfh made their first contribution in #8395</li> <li>@shenxiangzhuang made their first contribution in #8402</li> <li>@NeevCohen made their first contribution in #8387</li> <li>@zby made their first contribution in #8497</li> <li>@patelnets made their first contribution in #8491</li> <li>@edwardwli made their first contribution in #8503</li> <li>@luca-matei made their first contribution in #8507</li> <li>@Jocelyn-Gas made their first contribution in #8437</li> <li>@bL34cHig0 made their first contribution in #8501</li> <li>@tigeryy2 made their first contribution in #8511</li> <li>@geospackle made their first contribution in #8537</li> <li>@Anvil made their first contribution in #8567</li> <li>@hungtsetse made their first contribution in #8546</li> <li>@StrawHatDrag0n made their first contribution in #8583</li> </ul>"},{"location":"changelog/#pydantic-core_1","title":"<code>pydantic-core</code>","text":"<ul> <li>@mariuswinger made their first contribution in pydantic/pydantic-core#1087</li> <li>@adamchainz made their first contribution in pydantic/pydantic-core#1090</li> <li>@akx made their first contribution in pydantic/pydantic-core#1123</li> </ul>"},{"location":"changelog/#v260b1-2024-01-19","title":"v2.6.0b1 (2024-01-19)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v253-2023-12-22","title":"v2.5.3 (2023-12-22)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_15","title":"What's Changed","text":""},{"location":"changelog/#packaging_13","title":"Packaging","text":"<ul> <li>uprev <code>pydantic-core</code> to 2.14.6</li> </ul>"},{"location":"changelog/#fixes_15","title":"Fixes","text":"<ul> <li>Fix memory leak with recursive definitions creating reference cycles by @davidhewitt in pydantic/pydantic-core#1125</li> </ul>"},{"location":"changelog/#v252-2023-11-22","title":"v2.5.2 (2023-11-22)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_16","title":"What's Changed","text":""},{"location":"changelog/#packaging_14","title":"Packaging","text":"<ul> <li>uprev <code>pydantic-core</code> to 2.14.5</li> </ul>"},{"location":"changelog/#new-features_5","title":"New Features","text":"<ul> <li>Add <code>ConfigDict.ser_json_inf_nan</code> by @davidhewitt in #8159</li> </ul>"},{"location":"changelog/#fixes_16","title":"Fixes","text":"<ul> <li>Fix validation of <code>Literal</code> from JSON keys when used as <code>dict</code> key by @sydney-runkle in pydantic/pydantic-core#1075</li> <li>Fix bug re <code>custom_init</code> on members of <code>Union</code> by @sydney-runkle in pydantic/pydantic-core#1076</li> <li>Fix <code>JsonValue</code> <code>bool</code> serialization by @sydney-runkle in #8190</li> <li>Fix handling of unhashable inputs with <code>Literal</code> in <code>Union</code>s by @sydney-runkle in pydantic/pydantic-core#1089</li> </ul>"},{"location":"changelog/#v251-2023-11-15","title":"v2.5.1 (2023-11-15)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_17","title":"What's Changed","text":""},{"location":"changelog/#packaging_15","title":"Packaging","text":"<ul> <li>uprev pydantic-core to 2.14.3 by @samuelcolvin in #8120</li> </ul>"},{"location":"changelog/#fixes_17","title":"Fixes","text":"<ul> <li>Fix package description limit by @dmontagu in #8097</li> <li>Fix <code>ValidateCallWrapper</code> error when creating a model which has a @validate_call wrapped field annotation by @sydney-runkle in #8110</li> </ul>"},{"location":"changelog/#v250-2023-11-13","title":"v2.5.0 (2023-11-13)","text":"<p> GitHub release</p> <p>The code released in v2.5.0 is functionally identical to that of v2.5.0b1.</p>"},{"location":"changelog/#whats-changed_18","title":"What's Changed","text":""},{"location":"changelog/#packaging_16","title":"Packaging","text":"<ul> <li>Update pydantic-core from 2.10.1 to 2.14.1, significant changes from these updates are described below, full changelog here</li> <li>Update to <code>pyright==1.1.335</code> by @Viicos in #8075</li> </ul>"},{"location":"changelog/#new-features_6","title":"New Features","text":"<ul> <li>Allow plugins to catch non <code>ValidationError</code> errors by @adriangb in #7806</li> <li>Support <code>__doc__</code> argument in <code>create_model()</code> by @chris-spann in #7863</li> <li>Expose <code>regex_engine</code> flag - meaning you can use with the Rust or Python regex libraries in constraints by @utkini in #7768</li> <li>Save return type generated from type annotation in <code>ComputedFieldInfo</code> by @alexmojaki in #7889</li> <li>Adopting <code>ruff</code> formatter by @Luca-Blight in #7930</li> <li>Added <code>validation_error_cause</code> to config by @zakstucke in #7626</li> <li>Make path of the item to validate available in plugin by @hramezani in #7861</li> <li>Add <code>CallableDiscriminator</code> and <code>Tag</code> by @dmontagu in #7983</li> <li><code>CallableDiscriminator</code> renamed to <code>Discriminator</code> by @dmontagu in #8047</li> <li>Make union case tags affect union error messages by @dmontagu in #8001</li> <li>Add <code>examples</code> and <code>json_schema_extra</code> to <code>@computed_field</code> by @alexmojaki in #8013</li> <li>Add <code>JsonValue</code> type by @dmontagu in #7998</li> <li>Allow <code>str</code> as argument to <code>Discriminator</code> by @dmontagu in #8047</li> <li>Add <code>SchemaSerializer.__reduce__</code> method to enable pickle serialization by @edoakes in pydantic/pydantic-core#1006</li> </ul>"},{"location":"changelog/#changes_6","title":"Changes","text":"<ul> <li>Significant Change: replace <code>ultra_strict</code> with new smart union implementation, the way unions are validated has changed significantly to improve performance and correctness, we have worked hard to absolutely minimise the number of cases where behaviour has changed, see the PR for details - by @davidhewitt in pydantic/pydantic-core#867</li> <li>Add support for instance method reassignment when <code>extra='allow'</code> by @sydney-runkle in #7683</li> <li>Support JSON schema generation for <code>Enum</code> types with no cases by @sydney-runkle in #7927</li> <li>Warn if a class inherits from <code>Generic</code> before <code>BaseModel</code> by @alexmojaki in #7891</li> </ul>"},{"location":"changelog/#performance_5","title":"Performance","text":"<ul> <li>New custom JSON parser, <code>jiter</code> by @samuelcolvin in pydantic/pydantic-core#974</li> <li>PGO build for MacOS M1 by @samuelcolvin in pydantic/pydantic-core#1063</li> <li>Use <code>__getattr__</code> for all package imports, improve import time by @samuelcolvin in #7947</li> </ul>"},{"location":"changelog/#fixes_18","title":"Fixes","text":"<ul> <li>Fix <code>mypy</code> issue with subclasses of <code>RootModel</code> by @sydney-runkle in #7677</li> <li>Properly rebuild the <code>FieldInfo</code> when a forward ref gets evaluated by @dmontagu in #7698</li> <li>Fix failure to load <code>SecretStr</code> from JSON (regression in v2.4) by @sydney-runkle in #7729</li> <li>Fix <code>defer_build</code> behavior with <code>TypeAdapter</code> by @sydney-runkle in #7736</li> <li>Improve compatibility with legacy <code>mypy</code> versions by @dmontagu in #7742</li> <li>Fix: update <code>TypeVar</code> handling when default is not set by @pmmmwh in #7719</li> <li>Support specification of <code>strict</code> on <code>Enum</code> type fields by @sydney-runkle in #7761</li> <li>Wrap <code>weakref.ref</code> instead of subclassing to fix <code>cloudpickle</code> serialization by @edoakes in #7780</li> <li>Keep values of private attributes set within <code>model_post_init</code> in subclasses by @alexmojaki in #7775</li> <li>Add more specific type for non-callable <code>json_schema_extra</code> by @alexmojaki in #7803</li> <li>Raise an error when deleting frozen (model) fields by @alexmojaki in #7800</li> <li>Fix schema sorting bug with default values by @sydney-runkle in #7817</li> <li>Use generated alias for aliases that are not specified otherwise by @alexmojaki in #7802</li> <li>Support <code>strict</code> specification for <code>UUID</code> types by @sydney-runkle in #7865</li> <li>JSON schema: fix extra parameter handling by @me-and in #7810</li> <li>Fix: support <code>pydantic.Field(kw_only=True)</code> with inherited dataclasses by @PrettyWood in #7827</li> <li>Support <code>validate_call</code> decorator for methods in classes with <code>__slots__</code> by @sydney-runkle in #7883</li> <li>Fix pydantic dataclass problem with <code>dataclasses.field</code> default by @hramezani in #7898</li> <li>Fix schema generation for generics with union type bounds by @sydney-runkle in #7899</li> <li>Fix version for <code>importlib_metadata</code> on python 3.7 by @sydney-runkle in #7904</li> <li>Support <code>|</code> operator (Union) in PydanticRecursiveRef by @alexmojaki in #7892</li> <li>Fix <code>display_as_type</code> for <code>TypeAliasType</code> in python 3.12 by @dmontagu in #7929</li> <li>Add support for <code>NotRequired</code> generics in <code>TypedDict</code> by @sydney-runkle in #7932</li> <li>Make generic <code>TypeAliasType</code> specifications produce different schema definitions by @alexdrydew in #7893</li> <li>Added fix for signature of inherited dataclass by @howsunjow in #7925</li> <li>Make the model name generation more robust in JSON schema by @joakimnordling in #7881</li> <li>Fix plurals in validation error messages (in tests) by @Iipin in #7972</li> <li><code>PrivateAttr</code> is passed from <code>Annotated</code> default position by @tabassco in #8004</li> <li>Don't decode bytes (which may not be UTF8) when displaying SecretBytes by @alexmojaki in #8012</li> <li>Use <code>classmethod</code> instead of <code>classmethod[Any, Any, Any]</code> by @Mr-Pepe in #7979</li> <li>Clearer error on invalid Plugin by @samuelcolvin in #8023</li> <li>Correct pydantic dataclasses import by @samuelcolvin in #8027</li> <li>Fix misbehavior for models referencing redefined type aliases by @dmontagu in #8050</li> <li>Fix <code>Optional</code> field with <code>validate_default</code> only performing one field validation by @sydney-runkle in pydantic/pydantic-core#1002</li> <li>Fix <code>definition-ref</code> bug with <code>Dict</code> keys by @sydney-runkle in pydantic/pydantic-core#1014</li> <li>Fix bug allowing validation of <code>bool</code> types with <code>coerce_numbers_to_str=True</code> by @sydney-runkle in pydantic/pydantic-core#1017</li> <li>Don't accept <code>NaN</code> in float and decimal constraints by @davidhewitt in pydantic/pydantic-core#1037</li> <li>Add <code>lax_str</code> and <code>lax_int</code> support for enum values not inherited from str/int by @michaelhly in pydantic/pydantic-core#1015</li> <li>Support subclasses in lists in <code>Union</code> of <code>List</code> types by @sydney-runkle in pydantic/pydantic-core#1039</li> <li>Allow validation against <code>max_digits</code> and <code>decimals</code> to pass if normalized or non-normalized input is valid by @sydney-runkle in pydantic/pydantic-core#1049</li> <li>Fix: proper pluralization in <code>ValidationError</code> messages by @Iipin in pydantic/pydantic-core#1050</li> <li>Disallow the string <code>'-'</code> as <code>datetime</code> input by @davidhewitt in pydantic/speedate#52 &amp; pydantic/pydantic-core#1060</li> <li>Fix: NaN and Inf float serialization by @davidhewitt in pydantic/pydantic-core#1062</li> <li>Restore manylinux-compatible PGO builds by @davidhewitt in pydantic/pydantic-core#1068</li> </ul>"},{"location":"changelog/#new-contributors_6","title":"New Contributors","text":""},{"location":"changelog/#pydantic_2","title":"<code>pydantic</code>","text":"<ul> <li>@schneebuzz made their first contribution in #7699</li> <li>@edoakes made their first contribution in #7780</li> <li>@alexmojaki made their first contribution in #7775</li> <li>@NickG123 made their first contribution in #7751</li> <li>@gowthamgts made their first contribution in #7830</li> <li>@jamesbraza made their first contribution in #7848</li> <li>@laundmo made their first contribution in #7850</li> <li>@rahmatnazali made their first contribution in #7870</li> <li>@waterfountain1996 made their first contribution in #7878</li> <li>@chris-spann made their first contribution in #7863</li> <li>@me-and made their first contribution in #7810</li> <li>@utkini made their first contribution in #7768</li> <li>@bn-l made their first contribution in #7744</li> <li>@alexdrydew made their first contribution in #7893</li> <li>@Luca-Blight made their first contribution in #7930</li> <li>@howsunjow made their first contribution in #7925</li> <li>@joakimnordling made their first contribution in #7881</li> <li>@icfly2 made their first contribution in #7976</li> <li>@Yummy-Yums made their first contribution in #8003</li> <li>@Iipin made their first contribution in #7972</li> <li>@tabassco made their first contribution in #8004</li> <li>@Mr-Pepe made their first contribution in #7979</li> <li>@0x00cl made their first contribution in #8010</li> <li>@barraponto made their first contribution in #8032</li> </ul>"},{"location":"changelog/#pydantic-core_2","title":"<code>pydantic-core</code>","text":"<ul> <li>@sisp made their first contribution in pydantic/pydantic-core#995</li> <li>@michaelhly made their first contribution in pydantic/pydantic-core#1015</li> </ul>"},{"location":"changelog/#v250b1-2023-11-09","title":"v2.5.0b1 (2023-11-09)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v242-2023-09-27","title":"v2.4.2 (2023-09-27)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_19","title":"What's Changed","text":""},{"location":"changelog/#fixes_19","title":"Fixes","text":"<ul> <li>Fix bug with JSON schema for sequence of discriminated union by @dmontagu in #7647</li> <li>Fix schema references in discriminated unions by @adriangb in #7646</li> <li>Fix json schema generation for recursive models by @adriangb in #7653</li> <li>Fix <code>models_json_schema</code> for generic models by @adriangb in #7654</li> <li>Fix xfailed test for generic model signatures by @adriangb in #7658</li> </ul>"},{"location":"changelog/#new-contributors_7","title":"New Contributors","text":"<ul> <li>@austinorr made their first contribution in #7657</li> <li>@peterHoburg made their first contribution in #7670</li> </ul>"},{"location":"changelog/#v241-2023-09-26","title":"v2.4.1 (2023-09-26)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_20","title":"What's Changed","text":""},{"location":"changelog/#packaging_17","title":"Packaging","text":"<ul> <li>Update pydantic-core to 2.10.1 by @davidhewitt in #7633</li> </ul>"},{"location":"changelog/#fixes_20","title":"Fixes","text":"<ul> <li>Serialize unsubstituted type vars as <code>Any</code> by @adriangb in #7606</li> <li>Remove schema building caches by @adriangb in #7624</li> <li>Fix an issue where JSON schema extras weren't JSON encoded by @dmontagu in #7625</li> </ul>"},{"location":"changelog/#v240-2023-09-22","title":"v2.4.0 (2023-09-22)","text":"<p> GitHub release</p>"},{"location":"changelog/#whats-changed_21","title":"What's Changed","text":""},{"location":"changelog/#packaging_18","title":"Packaging","text":"<ul> <li>Update pydantic-core to 2.10.0 by @samuelcolvin in #7542</li> </ul>"},{"location":"changelog/#new-features_7","title":"New Features","text":"<ul> <li>Add <code>Base64Url</code> types by @dmontagu in #7286</li> <li>Implement optional <code>number</code> to <code>str</code> coercion by @lig in #7508</li> <li>Allow access to <code>field_name</code> and <code>data</code> in all validators if there is data and a field name by @samuelcolvin in #7542</li> <li>Add <code>BaseModel.model_validate_strings</code> and <code>TypeAdapter.validate_strings</code> by @hramezani in #7552</li> <li>Add Pydantic <code>plugins</code> experimental implementation by @lig @samuelcolvin and @Kludex in #6820</li> </ul>"},{"location":"changelog/#changes_7","title":"Changes","text":"<ul> <li>Do not override <code>model_post_init</code> in subclass with private attrs by @Viicos in #7302</li> <li>Make fields with defaults not required in the serialization schema by default by @dmontagu in #7275</li> <li>Mark <code>Extra</code> as deprecated by @disrupted in #7299</li> <li>Make <code>EncodedStr</code> a dataclass by @Kludex in #7396</li> <li>Move <code>annotated_handlers</code> to be public by @samuelcolvin in #7569</li> </ul>"},{"location":"changelog/#performance_6","title":"Performance","text":"<ul> <li>Simplify flattening and inlining of <code>CoreSchema</code> by @adriangb in #7523</li> <li>Remove unused copies in <code>CoreSchema</code> walking by @adriangb in #7528</li> <li>Add caches for collecting definitions and invalid schemas from a CoreSchema by @adriangb in #7527</li> <li>Eagerly resolve discriminated unions and cache cases where we can't by @adriangb in #7529</li> <li>Replace <code>dict.get</code> and <code>dict.setdefault</code> with more verbose versions in <code>CoreSchema</code> building hot paths by @adriangb in #7536</li> <li>Cache invalid <code>CoreSchema</code> discovery by @adriangb in #7535</li> <li>Allow disabling <code>CoreSchema</code> validation for faster startup times by @adriangb in #7565</li> </ul>"},{"location":"changelog/#fixes_21","title":"Fixes","text":"<ul> <li>Fix config detection for <code>TypedDict</code> from grandparent classes by @dmontagu in #7272</li> <li>Fix hash function generation for frozen models with unusual MRO by @dmontagu in #7274</li> <li>Make <code>strict</code> config overridable in field for Path by @hramezani in #7281</li> <li>Use <code>ser_json_&lt;timedelta|bytes&gt;</code> on default in <code>GenerateJsonSchema</code> by @Kludex in #7269</li> <li>Adding a check that alias is validated as an identifier for Python by @andree0 in #7319</li> <li>Raise an error when computed field overrides field by @sydney-runkle in #7346</li> <li>Fix applying <code>SkipValidation</code> to referenced schemas by @adriangb in #7381</li> <li>Enforce behavior of private attributes having double leading underscore by @lig in #7265</li> <li>Standardize <code>__get_pydantic_core_schema__</code> signature by @hramezani in #7415</li> <li>Fix generic dataclass fields mutation bug (when using <code>TypeAdapter</code>) by @sydney-runkle in #7435</li> <li>Fix <code>TypeError</code> on <code>model_validator</code> in <code>wrap</code> mode by @pmmmwh in #7496</li> <li>Improve enum error message by @hramezani in #7506</li> <li>Make <code>repr</code> work for instances that failed initialization when handling <code>ValidationError</code>s by @dmontagu in #7439</li> <li>Fixed a regular expression denial of service issue by limiting whitespaces by @prodigysml in #7360</li> <li>Fix handling of <code>UUID</code> values having <code>UUID.version=None</code> by @lig in #7566</li> <li>Fix <code>__iter__</code> returning private <code>cached_property</code> info by @sydney-runkle in #7570</li> <li>Improvements to version info message by @samuelcolvin in #7594</li> </ul>"},{"location":"changelog/#new-contributors_8","title":"New Contributors","text":"<ul> <li>@15498th made their first contribution in #7238</li> <li>@GabrielCappelli made their first contribution in #7213</li> <li>@tobni made their first contribution in #7184</li> <li>@redruin1 made their first contribution in #7282</li> <li>@FacerAin made their first contribution in #7288</li> <li>@acdha made their first contribution in #7297</li> <li>@andree0 made their first contribution in #7319</li> <li>@gordonhart made their first contribution in #7375</li> <li>@pmmmwh made their first contribution in #7496</li> <li>@disrupted made their first contribution in #7299</li> <li>@prodigysml made their first contribution in #7360</li> </ul>"},{"location":"changelog/#v230-2023-08-23","title":"v2.3.0 (2023-08-23)","text":"<p> GitHub release</p> <ul> <li>\ud83d\udd25 Remove orphaned changes file from repo by @lig in #7168</li> <li>Add copy button on documentation by @Kludex in #7190</li> <li>Fix docs on JSON type by @Kludex in #7189</li> <li>Update mypy 1.5.0 to 1.5.1 in CI by @hramezani in #7191</li> <li>fix download links badge by @samuelcolvin in #7200</li> <li>add 2.2.1 to changelog by @samuelcolvin in #7212</li> <li>Make ModelWrapValidator protocols generic by @dmontagu in #7154</li> <li>Correct <code>Field(..., exclude: bool)</code> docs by @samuelcolvin in #7214</li> <li>Make shadowing attributes a warning instead of an error by @adriangb in #7193</li> <li>Document <code>Base64Str</code> and <code>Base64Bytes</code> by @Kludex in #7192</li> <li>Fix <code>config.defer_build</code> for serialization first cases by @samuelcolvin in #7024</li> <li>clean Model docstrings in JSON Schema by @samuelcolvin in #7210</li> <li>fix #7228 (typo): docs in <code>validators.md</code> to correct <code>validate_default</code> kwarg by @lmmx in #7229</li> <li>\u2705 Implement <code>tzinfo.fromutc</code> method for <code>TzInfo</code> in <code>pydantic-core</code> by @lig in #7019</li> <li>Support <code>__get_validators__</code> by @hramezani in #7197</li> </ul>"},{"location":"changelog/#v221-2023-08-18","title":"v2.2.1 (2023-08-18)","text":"<p> GitHub release</p> <ul> <li>Make <code>xfail</code>ing test for root model extra stop <code>xfail</code>ing by @dmontagu in #6937</li> <li>Optimize recursion detection by stopping on the second visit for the same object by @mciucu in #7160</li> <li>fix link in docs by @tlambert03 in #7166</li> <li>Replace MiMalloc w/ default allocator by @adriangb in pydantic/pydantic-core#900</li> <li>Bump pydantic-core to 2.6.1 and prepare 2.2.1 release by @adriangb in #7176</li> </ul>"},{"location":"changelog/#v220-2023-08-17","title":"v2.2.0 (2023-08-17)","text":"<p> GitHub release</p> <ul> <li>Split \"pipx install\" setup command into two commands on the documentation site by @nomadmtb in #6869</li> <li>Deprecate <code>Field.include</code> by @hramezani in #6852</li> <li>Fix typo in default factory error msg by @hramezani in #6880</li> <li>Simplify handling of typing.Annotated in GenerateSchema by @dmontagu in #6887</li> <li>Re-enable fastapi tests in CI by @dmontagu in #6883</li> <li>Make it harder to hit collisions with json schema defrefs by @dmontagu in #6566</li> <li>Cleaner error for invalid input to <code>Path</code> fields by @samuelcolvin in #6903</li> <li> support Coordinate Type by @yezz123 in #6906</li> <li>Fix <code>ForwardRef</code> wrapper for py 3.10.0 (shim until bpo-45166) by @randomir in #6919</li> <li>Fix misbehavior related to copying of RootModel by @dmontagu in #6918</li> <li>Fix issue with recursion error caused by ParamSpec by @dmontagu in #6923</li> <li>Add section about Constrained classes to the Migration Guide by @Kludex in #6924</li> <li>Use <code>main</code> branch for badge links by @Viicos in #6925</li> <li>Add test for v1/v2 Annotated discrepancy by @carlbordum in #6926</li> <li>Make the v1 mypy plugin work with both v1 and v2 by @dmontagu in #6921</li> <li>Fix issue where generic models couldn't be parametrized with BaseModel by @dmontagu in #6933</li> <li>Remove xfail for discriminated union with alias by @dmontagu in #6938</li> <li>add field_serializer to computed_field by @andresliszt in #6965</li> <li>Use union_schema with Type[Union[...]] by @JeanArhancet in #6952</li> <li>Fix inherited typeddict attributes / config by @adriangb in #6981</li> <li>fix dataclass annotated before validator called twice by @davidhewitt in #6998</li> <li>Update test-fastapi deselected tests by @hramezani in #7014</li> <li>Fix validator doc format by @hramezani in #7015</li> <li>Fix typo in docstring of model_json_schema by @AdamVinch-Federated in #7032</li> <li>remove unused \"type ignores\" with pyright by @samuelcolvin in #7026</li> <li>Add benchmark representing FastAPI startup time by @adriangb in #7030</li> <li>Fix json_encoders for Enum subclasses by @adriangb in #7029</li> <li>Update docstring of <code>ser_json_bytes</code> regarding base64 encoding by @Viicos in #7052</li> <li>Allow <code>@validate_call</code> to work on async methods by @adriangb in #7046</li> <li>Fix: mypy error with <code>Settings</code> and <code>SettingsConfigDict</code> by @JeanArhancet in #7002</li> <li>Fix some typos (repeated words and it's/its) by @eumiro in #7063</li> <li>Fix the typo in docstring by @harunyasar in #7062</li> <li>Docs: Fix broken URL in the pydantic-settings package recommendation by @swetjen in #6995</li> <li>Handle constraints being applied to schemas that don't accept it by @adriangb in #6951</li> <li>Replace almost_equal_floats with math.isclose by @eumiro in #7082</li> <li>bump pydantic-core to 2.5.0 by @davidhewitt in #7077</li> <li>Add <code>short_version</code> and use it in links by @hramezani in #7115</li> <li>\ud83d\udcdd Add usage link to <code>RootModel</code> by @Kludex in #7113</li> <li>Revert \"Fix default port for mongosrv DSNs (#6827)\" by @Kludex in #7116</li> <li>Clarify validate_default and _Unset handling in usage docs and migration guide by @benbenbang in #6950</li> <li>Tweak documentation of <code>Field.exclude</code> by @Viicos in #7086</li> <li>Do not require <code>validate_assignment</code> to use <code>Field.frozen</code> by @Viicos in #7103</li> <li>tweaks to <code>_core_utils</code> by @samuelcolvin in #7040</li> <li>Make DefaultDict working with set by @hramezani in #7126</li> <li>Don't always require typing.Generic as a base for partially parametrized models by @dmontagu in #7119</li> <li>Fix issue with JSON schema incorrectly using parent class core schema by @dmontagu in #7020</li> <li>Fix xfailed test related to TypedDict and alias_generator by @dmontagu in #6940</li> <li>Improve error message for NameEmail by @dmontagu in #6939</li> <li>Fix generic computed fields by @dmontagu in #6988</li> <li>Reflect namedtuple default values during validation by @dmontagu in #7144</li> <li>Update dependencies, fix pydantic-core usage, fix CI issues by @dmontagu in #7150</li> <li>Add mypy 1.5.0 by @hramezani in #7118</li> <li>Handle non-json native enum values by @adriangb in #7056</li> <li>document <code>round_trip</code> in Json type documentation  by @jc-louis in #7137</li> <li>Relax signature checks to better support builtins and C extension functions as validators by @adriangb in #7101</li> <li>add union_mode='left_to_right' by @davidhewitt in #7151</li> <li>Include an error message hint for inherited ordering by @yvalencia91 in #7124</li> <li>Fix one docs link and resolve some warnings for two others by @dmontagu in #7153</li> <li>Include Field extra keys name in warning by @hramezani in #7136</li> </ul>"},{"location":"changelog/#v211-2023-07-25","title":"v2.1.1 (2023-07-25)","text":"<p> GitHub release</p> <ul> <li>Skip FieldInfo merging when unnecessary by @dmontagu in #6862</li> </ul>"},{"location":"changelog/#v210-2023-07-25","title":"v2.1.0 (2023-07-25)","text":"<p> GitHub release</p> <ul> <li>Add <code>StringConstraints</code> for use as Annotated metadata by @adriangb in #6605</li> <li>Try to fix intermittently failing CI by @adriangb in #6683</li> <li>Remove redundant example of optional vs default. by @ehiggs-deliverect in #6676</li> <li>Docs update by @samuelcolvin in #6692</li> <li>Remove the Validate always section in validator docs by @adriangb in #6679</li> <li>Fix recursion error in json schema generation by @adriangb in #6720</li> <li>Fix incorrect subclass check for secretstr by @AlexVndnblcke in #6730</li> <li>update pdm / pdm lockfile to 2.8.0 by @davidhewitt in #6714</li> <li>unpin pdm on more CI jobs by @davidhewitt in #6755</li> <li>improve source locations for auxiliary packages in docs by @davidhewitt in #6749</li> <li>Assume builtins don't accept an info argument by @adriangb in #6754</li> <li>Fix bug where calling <code>help(BaseModelSubclass)</code> raises errors by @hramezani in #6758</li> <li>Fix mypy plugin handling of <code>@model_validator(mode=\"after\")</code> by @ljodal in #6753</li> <li>update pydantic-core to 2.3.1 by @davidhewitt in #6756</li> <li>Mypy plugin for settings by @hramezani in #6760</li> <li>Use <code>contentSchema</code> keyword for JSON schema by @dmontagu in #6715</li> <li>fast-path checking finite decimals by @davidhewitt in #6769</li> <li>Docs update by @samuelcolvin in #6771</li> <li>Improve json schema doc by @hramezani in #6772</li> <li>Update validator docs by @adriangb in #6695</li> <li>Fix typehint for wrap validator by @dmontagu in #6788</li> <li>\ud83d\udc1b Fix validation warning for unions of Literal and other type by @lig in #6628</li> <li>Update documentation for generics support in V2 by @tpdorsey in #6685</li> <li>add pydantic-core build info to <code>version_info()</code> by @samuelcolvin in #6785</li> <li>Fix pydantic dataclasses that use slots with default values by @dmontagu in #6796</li> <li>Fix inheritance of hash function for frozen models by @dmontagu in #6789</li> <li>\u2728 Add <code>SkipJsonSchema</code> annotation by @Kludex in #6653</li> <li>Error if an invalid field name is used with Field by @dmontagu in #6797</li> <li>Add <code>GenericModel</code> to <code>MOVED_IN_V2</code> by @adriangb in #6776</li> <li>Remove unused code from <code>docs/usage/types/custom.md</code> by @hramezani in #6803</li> <li>Fix <code>float</code> -&gt; <code>Decimal</code> coercion precision loss by @adriangb in #6810</li> <li>remove email validation from the north star benchmark by @davidhewitt in #6816</li> <li>Fix link to mypy by @progsmile in #6824</li> <li>Improve initialization hooks example by @hramezani in #6822</li> <li>Fix default port for mongosrv DSNs by @dmontagu in #6827</li> <li>Improve API documentation, in particular more links between usage and API docs by @samuelcolvin in #6780</li> <li>update pydantic-core to 2.4.0 by @davidhewitt in #6831</li> <li>Fix <code>annotated_types.MaxLen</code> validator for custom sequence types by @ImogenBits in #6809</li> <li>Update V1 by @hramezani in #6833</li> <li>Make it so callable JSON schema extra works by @dmontagu in #6798</li> <li>Fix serialization issue with <code>InstanceOf</code> by @dmontagu in #6829</li> <li>Add back support for <code>json_encoders</code> by @adriangb in #6811</li> <li>Update field annotations when building the schema by @dmontagu in #6838</li> <li>Use <code>WeakValueDictionary</code> to fix generic memory leak by @dmontagu in #6681</li> <li>Add <code>config.defer_build</code> to optionally make model building lazy by @samuelcolvin in #6823</li> <li>delegate <code>UUID</code> serialization to pydantic-core by @davidhewitt in #6850</li> <li>Update <code>json_encoders</code> docs by @adriangb in #6848</li> <li>Fix error message for <code>staticmethod</code>/<code>classmethod</code> order with validate_call by @dmontagu in #6686</li> <li>Improve documentation for <code>Config</code> by @samuelcolvin in #6847</li> <li>Update serialization doc to mention <code>Field.exclude</code> takes priority over call-time <code>include/exclude</code> by @hramezani in #6851</li> <li>Allow customizing core schema generation by making <code>GenerateSchema</code> public by @adriangb in #6737</li> </ul>"},{"location":"changelog/#v203-2023-07-05","title":"v2.0.3 (2023-07-05)","text":"<p> GitHub release</p> <ul> <li>Mention PyObject (v1) moving to ImportString (v2) in migration doc by @slafs in #6456</li> <li>Fix release-tweet CI by @Kludex in #6461</li> <li>Revise the section on required / optional / nullable fields. by @ybressler in #6468</li> <li>Warn if a type hint is not in fact a type by @adriangb in #6479</li> <li>Replace TransformSchema with GetPydanticSchema by @dmontagu in #6484</li> <li>Fix the un-hashability of various annotation types, for use in caching generic containers by @dmontagu in #6480</li> <li>PYD-164: Rework custom types docs by @adriangb in #6490</li> <li>Fix ci by @adriangb in #6507</li> <li>Fix forward ref in generic by @adriangb in #6511</li> <li>Fix generation of serialization JSON schemas for core_schema.ChainSchema by @dmontagu in #6515</li> <li>Document the change in <code>Field.alias</code> behavior in Pydantic V2 by @hramezani in #6508</li> <li>Give better error message attempting to compute the json schema of a model with undefined fields by @dmontagu in #6519</li> <li>Document <code>alias_priority</code> by @tpdorsey in #6520</li> <li>Add redirect for types documentation by @tpdorsey in #6513</li> <li>Allow updating docs without release by @samuelcolvin in #6551</li> <li>Ensure docs tests always run in the right folder by @dmontagu in #6487</li> <li>Defer evaluation of return type hints for serializer functions by @dmontagu in #6516</li> <li>Disable E501 from Ruff and rely on just Black by @adriangb in #6552</li> <li>Update JSON Schema documentation for V2 by @tpdorsey in #6492</li> <li>Add documentation of cyclic reference handling by @dmontagu in #6493</li> <li>Remove the need for change files by @samuelcolvin in #6556</li> <li>add \"north star\" benchmark by @davidhewitt in #6547</li> <li>Update Dataclasses docs by @tpdorsey in #6470</li> <li>\u267b\ufe0f Use different error message on v1 redirects by @Kludex in #6595</li> <li>\u2b06 Upgrade <code>pydantic-core</code> to v2.2.0 by @lig in #6589</li> <li>Fix serialization for IPvAny by @dmontagu in #6572</li> <li>Improve CI by using PDM instead of pip to install typing-extensions by @adriangb in #6602</li> <li>Add <code>enum</code> error type docs  by @lig in #6603</li> <li>\ud83d\udc1b Fix <code>max_length</code> for unicode strings by @lig in #6559</li> <li>Add documentation for accessing features via <code>pydantic.v1</code> by @tpdorsey in #6604</li> <li>Include extra when iterating over a model by @adriangb in #6562</li> <li>Fix typing of model_validator by @adriangb in #6514</li> <li>Touch up Decimal validator by @adriangb in #6327</li> <li>Fix various docstrings using fixed pytest-examples by @dmontagu in #6607</li> <li>Handle function validators in a discriminated union by @dmontagu in #6570</li> <li>Review json_schema.md by @tpdorsey in #6608</li> <li>Make validate_call work on basemodel methods by @dmontagu in #6569</li> <li>add test for big int json serde by @davidhewitt in #6614</li> <li>Fix pydantic dataclass problem with dataclasses.field default_factory by @hramezani in #6616</li> <li>Fixed mypy type inference for TypeAdapter by @zakstucke in #6617</li> <li>Make it work to use None as a generic parameter by @dmontagu in #6609</li> <li>Make it work to use <code>$ref</code> as an alias by @dmontagu in #6568</li> <li>add note to migration guide about changes to <code>AnyUrl</code> etc by @davidhewitt in #6618</li> <li>\ud83d\udc1b Support defining <code>json_schema_extra</code> on <code>RootModel</code> using <code>Field</code> by @lig in #6622</li> <li>Update pre-commit to prevent commits to main branch on accident by @dmontagu in #6636</li> <li>Fix PDM CI for python 3.7 on MacOS/windows by @dmontagu in #6627</li> <li>Produce more accurate signatures for pydantic dataclasses by @dmontagu in #6633</li> <li>Updates to Url types for Pydantic V2 by @tpdorsey in #6638</li> <li>Fix list markdown in <code>transform</code> docstring by @StefanBRas in #6649</li> <li>simplify slots_dataclass construction to appease mypy by @davidhewitt in #6639</li> <li>Update TypedDict schema generation docstring by @adriangb in #6651</li> <li>Detect and lint-error for prints by @dmontagu in #6655</li> <li>Add xfailing test for pydantic-core PR 766 by @dmontagu in #6641</li> <li>Ignore unrecognized fields from dataclasses metadata by @dmontagu in #6634</li> <li>Make non-existent class getattr a mypy error by @dmontagu in #6658</li> <li>Update pydantic-core to 2.3.0 by @hramezani in #6648</li> <li>Use OrderedDict from typing_extensions by @dmontagu in #6664</li> <li>Fix typehint for JSON schema extra callable by @dmontagu in #6659</li> </ul>"},{"location":"changelog/#v202-2023-07-05","title":"v2.0.2 (2023-07-05)","text":"<p> GitHub release</p> <ul> <li>Fix bug where round-trip pickling/unpickling a <code>RootModel</code> would change the value of <code>__dict__</code>, #6457 by @dmontagu</li> <li>Allow single-item discriminated unions, #6405 by @dmontagu</li> <li>Fix issue with union parsing of enums, #6440 by @dmontagu</li> <li>Docs: Fixed <code>constr</code> documentation, renamed old <code>regex</code> to new <code>pattern</code>, #6452 by @miili</li> <li>Change <code>GenerateJsonSchema.generate_definitions</code> signature, #6436 by @dmontagu</li> </ul> <p>See the full changelog here</p>"},{"location":"changelog/#v201-2023-07-04","title":"v2.0.1 (2023-07-04)","text":"<p> GitHub release</p> <p>First patch release of Pydantic V2</p> <ul> <li>Extra fields added via <code>setattr</code> (i.e. <code>m.some_extra_field = 'extra_value'</code>)   are added to <code>.model_extra</code> if <code>model_config</code> <code>extra='allowed'</code>. Fixed #6333, #6365 by @aaraney</li> <li>Automatically unpack JSON schema '$ref' for custom types, #6343 by @adriangb</li> <li>Fix tagged unions multiple processing in submodels, #6340 by @suharnikov</li> </ul> <p>See the full changelog here</p>"},{"location":"changelog/#v20-2023-06-30","title":"v2.0 (2023-06-30)","text":"<p> GitHub release</p> <p>Pydantic V2 is here! </p> <p>See this post for more details.</p>"},{"location":"changelog/#v20b3-2023-06-16","title":"v2.0b3 (2023-06-16)","text":"<p>Third beta pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20b2-2023-06-03","title":"v2.0b2 (2023-06-03)","text":"<p>Add <code>from_attributes</code> runtime flag to <code>TypeAdapter.validate_python</code> and <code>BaseModel.model_validate</code>.</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20b1-2023-06-01","title":"v2.0b1 (2023-06-01)","text":"<p>First beta pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20a4-2023-05-05","title":"v2.0a4 (2023-05-05)","text":"<p>Fourth pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20a3-2023-04-20","title":"v2.0a3 (2023-04-20)","text":"<p>Third pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20a2-2023-04-12","title":"v2.0a2 (2023-04-12)","text":"<p>Second pre-release of Pydantic V2</p> <p>See the full changelog here</p>"},{"location":"changelog/#v20a1-2023-04-03","title":"v2.0a1 (2023-04-03)","text":"<p>First pre-release of Pydantic V2!</p> <p>See this post for more details.</p>"},{"location":"changelog/#v11018-2024-08-22","title":"v1.10.18 (2024-08-22)","text":"<ul> <li>Eval type fix in V1 by @sydney-runkle in https://github.com/pydantic/pydantic/pull/9751</li> <li>Add <code>to_lower_camel</code> to <code>__all__</code> in <code>utils.py</code> by @sydney-runkle (direct commit)</li> <li>Fix <code>mypy</code> v1 plugin for mypy 1.11 release by @flaeppe in https://github.com/pydantic/pydantic/pull/10139</li> <li>Fix discriminator key used when discriminator has alias and <code>.schema(by_alias=False)</code> by @exs-dwoodward in https://github.com/pydantic/pydantic/pull/10146</li> </ul>"},{"location":"changelog/#v11017-2024-06-20","title":"v1.10.17 (2024-06-20)","text":"<ul> <li>Advertise Python 3.12 for 1.10.x! Part Deux by @vfazio in https://github.com/pydantic/pydantic/pull/9644</li> <li>Mirrored modules in <code>v1</code> namespace to fix typing and object resolution in python&gt;3.11 by @exs-dwoodward in https://github.com/pydantic/pydantic/pull/9660</li> <li>setup: remove upper bound from python_requires by @vfazio in https://github.com/pydantic/pydantic/pull/9685</li> </ul>"},{"location":"changelog/#v11016-2024-06-11","title":"v1.10.16 (2024-06-11)","text":"<ul> <li>Specify recursive_guard as kwarg in FutureRef._evaluate by @vfazio in https://github.com/pydantic/pydantic/pull/9612</li> <li>Fix mypy v1 plugin for upcoming mypy release by @ cdce8p in https://github.com/pydantic/pydantic/pull/9586</li> <li>Import modules/objects directly from v1 namespace by @exs-dwoodward in https://github.com/pydantic/pydantic/pull/9162</li> </ul>"},{"location":"changelog/#v11015-2024-04-03","title":"v1.10.15 (2024-04-03)","text":"<ul> <li>Add pydantic.v1 namespace to Pydantic v1 by @exs-dmiketa in https://github.com/pydantic/pydantic/pull/9042</li> <li>Relax version of typing-extensions for V1 by @SonOfLilit in https://github.com/pydantic/pydantic/pull/8819</li> <li>patch fix for mypy by @sydney-runkle in https://github.com/pydantic/pydantic/pull/8765</li> </ul>"},{"location":"changelog/#v11014-2024-01-19","title":"v1.10.14 (2024-01-19)","text":"<ul> <li>Update install.md by @dmontagu in #7690</li> <li>Fix ci to only deploy docs on release by @sydney-runkle in #7740</li> <li>Ubuntu fixes for V1 by @sydney-runkle in #8540 and #8587</li> <li>Fix cached_property handling in dataclasses when copied by @rdbisme in #8407</li> </ul>"},{"location":"changelog/#v11013-2023-09-27","title":"v1.10.13 (2023-09-27)","text":"<ul> <li>Fix: Add max length check to <code>pydantic.validate_email</code>, #7673 by @hramezani</li> <li>Docs: Fix pip commands to install v1, #6930 by @chbndrhnns</li> </ul>"},{"location":"changelog/#v11012-2023-07-24","title":"v1.10.12 (2023-07-24)","text":"<ul> <li>Fixes the <code>maxlen</code> property being dropped on <code>deque</code> validation. Happened only if the deque item has been typed. Changes the <code>_validate_sequence_like</code> func, #6581 by @maciekglowka</li> </ul>"},{"location":"changelog/#v11011-2023-07-04","title":"v1.10.11 (2023-07-04)","text":"<ul> <li>Importing create_model in tools.py through relative path instead of absolute path - so that it doesn't import V2 code when copied over to V2 branch, #6361 by @SharathHuddar</li> </ul>"},{"location":"changelog/#v11010-2023-06-30","title":"v1.10.10 (2023-06-30)","text":"<ul> <li>Add Pydantic <code>Json</code> field support to settings management, #6250 by @hramezani</li> <li>Fixed literal validator errors for unhashable values, #6188 by @markus1978</li> <li>Fixed bug with generics receiving forward refs, #6130 by @mark-todd</li> <li>Update install method of FastAPI for internal tests in CI, #6117 by @Kludex</li> </ul>"},{"location":"changelog/#v1109-2023-06-07","title":"v1.10.9 (2023-06-07)","text":"<ul> <li>Fix trailing zeros not ignored in Decimal validation, #5968 by @hramezani</li> <li>Fix mypy plugin for v1.4.0, #5928 by @cdce8p</li> <li>Add future and past date hypothesis strategies, #5850 by @bschoenmaeckers</li> <li>Discourage usage of Cython 3 with Pydantic 1.x, #5845 by @lig</li> </ul>"},{"location":"changelog/#v1108-2023-05-23","title":"v1.10.8 (2023-05-23)","text":"<ul> <li>Fix a bug in <code>Literal</code> usage with <code>typing-extension==4.6.0</code>, #5826 by @hramezani</li> <li>This solves the (closed) issue #3849 where aliased fields that use discriminated union fail to validate when the data contains the non-aliased field name, #5736 by @benwah</li> <li>Update email-validator dependency to &gt;=2.0.0post2, #5627 by @adriangb</li> <li>update <code>AnyClassMethod</code> for changes in python/typeshed#9771, #5505 by @ITProKyle</li> </ul>"},{"location":"changelog/#v1107-2023-03-22","title":"v1.10.7 (2023-03-22)","text":"<ul> <li>Fix creating schema from model using <code>ConstrainedStr</code> with <code>regex</code> as dict key, #5223 by @matejetz</li> <li>Address bug in mypy plugin caused by explicit_package_bases=True, #5191 by @dmontagu</li> <li>Add implicit defaults in the mypy plugin for Field with no default argument, #5190 by @dmontagu</li> <li>Fix schema generated for Enum values used as Literals in discriminated unions, #5188 by @javibookline</li> <li>Fix mypy failures caused by the pydantic mypy plugin when users define <code>from_orm</code> in their own classes, #5187 by @dmontagu</li> <li>Fix <code>InitVar</code> usage with pydantic dataclasses, mypy version <code>1.1.1</code> and the custom mypy plugin, #5162 by @cdce8p</li> </ul>"},{"location":"changelog/#v1106-2023-03-08","title":"v1.10.6 (2023-03-08)","text":"<ul> <li>Implement logic to support creating validators from non standard callables by using defaults to identify them and unwrapping <code>functools.partial</code> and <code>functools.partialmethod</code> when checking the signature, #5126 by @JensHeinrich</li> <li>Fix mypy plugin for v1.1.1, and fix <code>dataclass_transform</code> decorator for pydantic dataclasses, #5111 by @cdce8p</li> <li>Raise <code>ValidationError</code>, not <code>ConfigError</code>, when a discriminator value is unhashable, #4773 by @kurtmckee</li> </ul>"},{"location":"changelog/#v1105-2023-02-15","title":"v1.10.5 (2023-02-15)","text":"<ul> <li>Fix broken parametrized bases handling with <code>GenericModel</code>s with complex sets of models, #5052 by @MarkusSintonen</li> <li>Invalidate mypy cache if plugin config changes, #5007 by @cdce8p</li> <li>Fix <code>RecursionError</code> when deep-copying dataclass types wrapped by pydantic, #4949 by @mbillingr</li> <li>Fix <code>X | Y</code> union syntax breaking <code>GenericModel</code>, #4146 by @thenx</li> <li>Switch coverage badge to show coverage for this branch/release, #5060 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1104-2022-12-30","title":"v1.10.4 (2022-12-30)","text":"<ul> <li>Change dependency to <code>typing-extensions&gt;=4.2.0</code>, #4885 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1103-2022-12-29","title":"v1.10.3 (2022-12-29)","text":"<p>NOTE: v1.10.3 was \"yanked\" from PyPI due to #4885 which is fixed in v1.10.4</p> <ul> <li>fix parsing of custom root models, #4883 by @gou177</li> <li>fix: use dataclass proxy for frozen or empty dataclasses, #4878 by @PrettyWood</li> <li>Fix <code>schema</code> and <code>schema_json</code> on models where a model instance is a one of default values, #4781 by @Bobronium</li> <li>Add Jina AI to sponsors on docs index page, #4767 by @samuelcolvin</li> <li>fix: support assignment on <code>DataclassProxy</code>, #4695 by @PrettyWood</li> <li>Add <code>postgresql+psycopg</code> as allowed scheme for <code>PostgreDsn</code> to make it usable with SQLAlchemy 2, #4689 by @morian</li> <li>Allow dict schemas to have both <code>patternProperties</code> and <code>additionalProperties</code>, #4641 by @jparise</li> <li>Fixes error passing None for optional lists with <code>unique_items</code>, #4568 by @mfulgo</li> <li>Fix <code>GenericModel</code> with <code>Callable</code> param raising a <code>TypeError</code>, #4551 by @mfulgo</li> <li>Fix field regex with <code>StrictStr</code> type annotation, #4538 by @sisp</li> <li>Correct <code>dataclass_transform</code> keyword argument name from <code>field_descriptors</code> to <code>field_specifiers</code>, #4500 by @samuelcolvin</li> <li>fix: avoid multiple calls of <code>__post_init__</code> when dataclasses are inherited, #4487 by @PrettyWood</li> <li>Reduce the size of binary wheels, #2276 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1102-2022-09-05","title":"v1.10.2 (2022-09-05)","text":"<ul> <li>Revert Change: Revert percent encoding of URL parts which was originally added in #4224, #4470 by @samuelcolvin</li> <li>Prevent long (length &gt; <code>4_300</code>) strings/bytes as input to int fields, see   python/cpython#95778 and   CVE-2020-10735, #1477 by @samuelcolvin</li> <li>fix: dataclass wrapper was not always called, #4477 by @PrettyWood</li> <li>Use <code>tomllib</code> on Python 3.11 when parsing <code>mypy</code> configuration, #4476 by @hauntsaninja</li> <li>Basic fix of <code>GenericModel</code> cache to detect order of arguments in <code>Union</code> models, #4474 by @sveinugu</li> <li>Fix mypy plugin when using bare types like <code>list</code> and <code>dict</code> as <code>default_factory</code>, #4457 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1101-2022-08-31","title":"v1.10.1 (2022-08-31)","text":"<ul> <li>Add <code>__hash__</code> method to <code>pydancic.color.Color</code> class, #4454 by @czaki</li> </ul>"},{"location":"changelog/#v1100-2022-08-30","title":"v1.10.0 (2022-08-30)","text":"<ul> <li>Refactor the whole pydantic <code>dataclass</code> decorator to really act like its standard lib equivalent.   It hence keeps <code>__eq__</code>, <code>__hash__</code>, ... and makes comparison with its non-validated version possible.   It also fixes usage of <code>frozen</code> dataclasses in fields and usage of <code>default_factory</code> in nested dataclasses.   The support of <code>Config.extra</code> has been added.   Finally, config customization directly via a <code>dict</code> is now possible, #2557 by @PrettyWood BREAKING CHANGES:</li> <li>The <code>compiled</code> boolean (whether pydantic is compiled with cython) has been moved from <code>main.py</code> to <code>version.py</code></li> <li>Now that <code>Config.extra</code> is supported, <code>dataclass</code> ignores by default extra arguments (like <code>BaseModel</code>)</li> <li>Fix PEP487 <code>__set_name__</code> protocol in <code>BaseModel</code> for PrivateAttrs, #4407 by @tlambert03</li> <li>Allow for custom parsing of environment variables via <code>parse_env_var</code> in <code>Config</code>, #4406 by @acmiyaguchi</li> <li>Rename <code>master</code> to <code>main</code>, #4405 by @hramezani</li> <li>Fix <code>StrictStr</code> does not raise <code>ValidationError</code> when <code>max_length</code> is present in <code>Field</code>, #4388 by @hramezani</li> <li>Make <code>SecretStr</code> and <code>SecretBytes</code> hashable, #4387 by @chbndrhnns</li> <li>Fix <code>StrictBytes</code> does not raise <code>ValidationError</code> when <code>max_length</code> is present in <code>Field</code>, #4380 by @JeanArhancet</li> <li>Add support for bare <code>type</code>, #4375 by @hramezani</li> <li>Support Python 3.11, including binaries for 3.11 in PyPI, #4374 by @samuelcolvin</li> <li>Add support for <code>re.Pattern</code>, #4366 by @hramezani</li> <li>Fix <code>__post_init_post_parse__</code> is incorrectly passed keyword arguments when no <code>__post_init__</code> is defined, #4361 by @hramezani</li> <li>Fix implicitly importing <code>ForwardRef</code> and <code>Callable</code> from <code>pydantic.typing</code> instead of <code>typing</code> and also expose <code>MappingIntStrAny</code>, #4358 by @aminalaee</li> <li>remove <code>Any</code> types from the <code>dataclass</code> decorator so it can be used with the <code>disallow_any_expr</code> mypy option, #4356 by @DetachHead</li> <li>moved repo to <code>pydantic/pydantic</code>, #4348 by @yezz123</li> <li>fix \"extra fields not permitted\" error when dataclass with <code>Extra.forbid</code> is validated multiple times, #4343 by @detachhead</li> <li>Add Python 3.9 and 3.10 examples to docs, #4339 by @Bobronium</li> <li>Discriminated union models now use <code>oneOf</code> instead of <code>anyOf</code> when generating OpenAPI schema definitions, #4335 by @MaxwellPayne</li> <li>Allow type checkers to infer inner type of <code>Json</code> type. <code>Json[list[str]]</code> will be now inferred as <code>list[str]</code>,   <code>Json[Any]</code> should be used instead of plain <code>Json</code>.   Runtime behaviour is not changed, #4332 by @Bobronium</li> <li>Allow empty string aliases by using a <code>alias is not None</code> check, rather than <code>bool(alias)</code>, #4253 by @sergeytsaplin</li> <li>Update <code>ForwardRef</code>s in <code>Field.outer_type_</code>, #4249 by @JacobHayes</li> <li>The use of <code>__dataclass_transform__</code> has been replaced by <code>typing_extensions.dataclass_transform</code>, which is the preferred way to mark pydantic models as a dataclass under PEP 681, #4241 by @multimeric</li> <li>Use parent model's <code>Config</code> when validating nested <code>NamedTuple</code> fields, #4219 by @synek</li> <li>Update <code>BaseModel.construct</code> to work with aliased Fields, #4192 by @kylebamos</li> <li>Catch certain raised errors in <code>smart_deepcopy</code> and revert to <code>deepcopy</code> if so, #4184 by @coneybeare</li> <li>Add <code>Config.anystr_upper</code> and <code>to_upper</code> kwarg to constr and conbytes, #4165 by @satheler</li> <li>Fix JSON schema for <code>set</code> and <code>frozenset</code> when they include default values, #4155 by @aminalaee</li> <li>Teach the mypy plugin that methods decorated by <code>@validator</code> are classmethods, #4102 by @DMRobertson</li> <li>Improve mypy plugin's ability to detect required fields, #4086 by @richardxia</li> <li>Support fields of type <code>Type[]</code> in schema, #4051 by @aminalaee</li> <li>Add <code>default</code> value in JSON Schema when <code>const=True</code>, #4031 by @aminalaee</li> <li>Adds reserved word check to signature generation logic, #4011 by @strue36</li> <li>Fix Json strategy failure for the complex nested field, #4005 by @sergiosim</li> <li>Add JSON-compatible float constraint <code>allow_inf_nan</code>, #3994 by @tiangolo</li> <li>Remove undefined behaviour when <code>env_prefix</code> had characters in common with <code>env_nested_delimiter</code>, #3975 by @arsenron</li> <li>Support generics model with <code>create_model</code>, #3945 by @hot123s</li> <li>allow submodels to overwrite extra field info, #3934 by @PrettyWood</li> <li>Document and test structural pattern matching (PEP 636) on <code>BaseModel</code>, #3920 by @irgolic</li> <li>Fix incorrect deserialization of python timedelta object to ISO 8601 for negative time deltas.   Minus was serialized in incorrect place (\"P-1DT23H59M59.888735S\" instead of correct \"-P1DT23H59M59.888735S\"), #3899 by @07pepa</li> <li>Fix validation of discriminated union fields with an alias when passing a model instance, #3846 by @chornsby</li> <li>Add a CockroachDsn type to validate CockroachDB connection strings. The type   supports the following schemes: <code>cockroachdb</code>, <code>cockroachdb+psycopg2</code> and <code>cockroachdb+asyncpg</code>, #3839 by @blubber</li> <li>Fix MyPy plugin to not override pre-existing <code>__init__</code> method in models, #3824 by @patrick91</li> <li>Fix mypy version checking, #3783 by @KotlinIsland</li> <li>support overwriting dunder attributes of <code>BaseModel</code> instances, #3777 by @PrettyWood</li> <li>Added <code>ConstrainedDate</code> and <code>condate</code>, #3740 by @hottwaj</li> <li>Support <code>kw_only</code> in dataclasses, #3670 by @detachhead</li> <li>Add comparison method for <code>Color</code> class, #3646 by @aminalaee</li> <li>Drop support for python3.6, associated cleanup, #3605 by @samuelcolvin</li> <li>created new function <code>to_lower_camel()</code> for \"non pascal case\" camel case, #3463 by @schlerp</li> <li>Add checks to <code>default</code> and <code>default_factory</code> arguments in Mypy plugin, #3430 by @klaa97</li> <li>fix mangling of <code>inspect.signature</code> for <code>BaseModel</code>, #3413 by @fix-inspect-signature</li> <li>Adds the <code>SecretField</code> abstract class so that all the current and future secret fields like <code>SecretStr</code> and <code>SecretBytes</code> will derive from it, #3409 by @expobrain</li> <li>Support multi hosts validation in <code>PostgresDsn</code>, #3337 by @rglsk</li> <li>Fix parsing of very small numeric timedelta values, #3315 by @samuelcolvin</li> <li>Update <code>SecretsSettingsSource</code> to respect <code>config.case_sensitive</code>, #3273 by @JeanArhancet</li> <li>Add MongoDB network data source name (DSN) schema, #3229 by @snosratiershad</li> <li>Add support for multiple dotenv files, #3222 by @rekyungmin</li> <li>Raise an explicit <code>ConfigError</code> when multiple fields are incorrectly set for a single validator, #3215 by @SunsetOrange</li> <li>Allow ellipsis on <code>Field</code>s inside <code>Annotated</code> for <code>TypedDicts</code> required, #3133 by @ezegomez</li> <li>Catch overflow errors in <code>int_validator</code>, #3112 by @ojii</li> <li>Adds a <code>__rich_repr__</code> method to <code>Representation</code> class which enables pretty printing with Rich, #3099 by @willmcgugan</li> <li>Add percent encoding in <code>AnyUrl</code> and descendent types, #3061 by @FaresAhmedb</li> <li><code>validate_arguments</code> decorator now supports <code>alias</code>, #3019 by @MAD-py</li> <li>Avoid <code>__dict__</code> and <code>__weakref__</code> attributes in <code>AnyUrl</code> and IP address fields, #2890 by @nuno-andre</li> <li>Add ability to use <code>Final</code> in a field type annotation, #2766 by @uriyyo</li> <li>Update requirement to <code>typing_extensions&gt;=4.1.0</code> to guarantee <code>dataclass_transform</code> is available, #4424 by @commonism</li> <li>Add Explosion and AWS to main sponsors, #4413 by @samuelcolvin</li> <li>Update documentation for <code>copy_on_model_validation</code> to reflect recent changes, #4369 by @samuelcolvin</li> <li>Runtime warning if <code>__slots__</code> is passed to <code>create_model</code>, <code>__slots__</code> is then ignored, #4432 by @samuelcolvin</li> <li>Add type hints to <code>BaseSettings.Config</code> to avoid mypy errors, also correct mypy version compatibility notice in docs, #4450 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v1100b1-2022-08-24","title":"v1.10.0b1 (2022-08-24)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v1100a2-2022-08-24","title":"v1.10.0a2 (2022-08-24)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v1100a1-2022-08-22","title":"v1.10.0a1 (2022-08-22)","text":"<p>Pre-release, see the GitHub release for details.</p>"},{"location":"changelog/#v192-2022-08-11","title":"v1.9.2 (2022-08-11)","text":"<p>Revert Breaking Change: v1.9.1 introduced a breaking change where model fields were deep copied by default, this release reverts the default behaviour to match v1.9.0 and before, while also allow deep-copy behaviour via <code>copy_on_model_validation = 'deep'</code>. See #4092 for more information.</p> <ul> <li>Allow for shallow copies of model fields, <code>Config.copy_on_model_validation</code> is now a str which must be   <code>'none'</code>, <code>'deep'</code>, or <code>'shallow'</code> corresponding to not copying, deep copy &amp; shallow copy; default <code>'shallow'</code>,   #4093 by @timkpaine</li> </ul>"},{"location":"changelog/#v191-2022-05-19","title":"v1.9.1 (2022-05-19)","text":"<p>Thank you to pydantic's sponsors: @tiangolo, @stellargraph, @JonasKs, @grillazz, @Mazyod, @kevinalh, @chdsbd, @povilasb, @povilasb, @jina-ai, @mainframeindustries, @robusta-dev, @SendCloud, @rszamszur, @jodal, @hardbyte, @corleyma, @daddycocoaman, @Rehket, @jokull, @reillysiemens, @westonsteimel, @primer-io, @koxudaxi, @browniebroke, @stradivari96, @adriangb, @kamalgill, @jqueguiner, @dev-zero, @datarootsio, @RedCarpetUp for their kind support.</p> <ul> <li>Limit the size of <code>generics._generic_types_cache</code> and <code>generics._assigned_parameters</code>   to avoid unlimited increase in memory usage, #4083 by @samuelcolvin</li> <li>Add Jupyverse and FPS as Jupyter projects using pydantic, #4082 by @davidbrochart</li> <li>Speedup <code>__isinstancecheck__</code> on pydantic models when the type is not a model, may also avoid memory \"leaks\", #4081 by @samuelcolvin</li> <li>Fix in-place modification of <code>FieldInfo</code> that caused problems with PEP 593 type aliases, #4067 by @adriangb</li> <li>Add support for autocomplete in VS Code via <code>__dataclass_transform__</code> when using <code>pydantic.dataclasses.dataclass</code>, #4006 by @giuliano-oliveira</li> <li>Remove benchmarks from codebase and docs, #3973 by @samuelcolvin</li> <li>Typing checking with pyright in CI, improve docs on vscode/pylance/pyright, #3972 by @samuelcolvin</li> <li>Fix nested Python dataclass schema regression, #3819 by @himbeles</li> <li>Update documentation about lazy evaluation of sources for Settings, #3806 by @garyd203</li> <li>Prevent subclasses of bytes being converted to bytes, #3706 by @samuelcolvin</li> <li>Fixed \"error checking inheritance of\" when using PEP585 and PEP604 type hints, #3681 by @aleksul</li> <li>Allow self referencing <code>ClassVar</code>s in models, #3679 by @samuelcolvin</li> <li>Breaking Change, see #4106: Fix issue with self-referencing dataclass, #3675 by @uriyyo</li> <li>Include non-standard port numbers in rendered URLs, #3652 by @dolfinus</li> <li><code>Config.copy_on_model_validation</code> does a deep copy and not a shallow one, #3641 by @PrettyWood</li> <li>fix: clarify that discriminated unions do not support singletons, #3636 by @tommilligan</li> <li>Add <code>read_text(encoding='utf-8')</code> for <code>setup.py</code>, #3625 by @hswong3i</li> <li>Fix JSON Schema generation for Discriminated Unions within lists, #3608 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v190-2021-12-31","title":"v1.9.0 (2021-12-31)","text":"<p>Thank you to pydantic's sponsors: @sthagen, @timdrijvers, @toinbis, @koxudaxi, @ginomempin, @primer-io, @and-semakin, @westonsteimel, @reillysiemens, @es3n1n, @jokull, @JonasKs, @Rehket, @corleyma, @daddycocoaman, @hardbyte, @datarootsio, @jodal, @aminalaee, @rafsaf, @jqueguiner, @chdsbd, @kevinalh, @Mazyod, @grillazz, @JonasKs, @simw, @leynier, @xfenix for their kind support.</p>"},{"location":"changelog/#highlights","title":"Highlights","text":"<ul> <li>add Python 3.10 support, #2885 by @PrettyWood</li> <li>Discriminated unions, #619 by @PrettyWood</li> <li><code>Config.smart_union</code> for better union logic, #2092 by @PrettyWood</li> <li>Binaries for Macos M1 CPUs, #3498 by @samuelcolvin</li> <li>Complex types can be set via nested environment variables, e.g. <code>foo___bar</code>, #3159 by @Air-Mark</li> <li>add a dark mode to pydantic documentation, #2913 by @gbdlin</li> <li>Add support for autocomplete in VS Code via <code>__dataclass_transform__</code>, #2721 by @tiangolo</li> <li>Add \"exclude\" as a field parameter so that it can be configured using model config, #660 by @daviskirk</li> </ul>"},{"location":"changelog/#v190-2021-12-31-changes","title":"v1.9.0 (2021-12-31) Changes","text":"<ul> <li>Apply <code>update_forward_refs</code> to <code>Config.json_encodes</code> prevent name clashes in types defined via strings, #3583 by @samuelcolvin</li> <li>Extend pydantic's mypy plugin to support mypy versions <code>0.910</code>, <code>0.920</code>, <code>0.921</code> &amp; <code>0.930</code>, #3573 &amp; #3594 by @PrettyWood, @christianbundy, @samuelcolvin</li> </ul>"},{"location":"changelog/#v190a2-2021-12-24-changes","title":"v1.9.0a2 (2021-12-24) Changes","text":"<ul> <li>support generic models with discriminated union, #3551 by @PrettyWood</li> <li>keep old behaviour of <code>json()</code> by default, #3542 by @PrettyWood</li> <li>Removed typing-only <code>__root__</code> attribute from <code>BaseModel</code>, #3540 by @layday</li> <li>Build Python 3.10 wheels, #3539 by @mbachry</li> <li>Fix display of <code>extra</code> fields with model <code>__repr__</code>, #3234 by @cocolman</li> <li>models copied via <code>Config.copy_on_model_validation</code> always have all fields, #3201 by @PrettyWood</li> <li>nested ORM from nested dictionaries, #3182 by @PrettyWood</li> <li>fix link to discriminated union section by @PrettyWood</li> </ul>"},{"location":"changelog/#v190a1-2021-12-18-changes","title":"v1.9.0a1 (2021-12-18) Changes","text":"<ul> <li>Add support for <code>Decimal</code>-specific validation configurations in <code>Field()</code>, additionally to using <code>condecimal()</code>,   to allow better support from editors and tooling, #3507 by @tiangolo</li> <li>Add <code>arm64</code> binaries suitable for MacOS with an M1 CPU to PyPI, #3498 by @samuelcolvin</li> <li>Fix issue where <code>None</code> was considered invalid when using a <code>Union</code> type containing <code>Any</code> or <code>object</code>, #3444 by @tharradine</li> <li>When generating field schema, pass optional <code>field</code> argument (of type   <code>pydantic.fields.ModelField</code>) to <code>__modify_schema__()</code> if present, #3434 by @jasujm</li> <li>Fix issue when pydantic fail to parse <code>typing.ClassVar</code> string type annotation, #3401 by @uriyyo</li> <li>Mention Python &gt;= 3.9.2 as an alternative to <code>typing_extensions.TypedDict</code>, #3374 by @BvB93</li> <li>Changed the validator method name in the Custom Errors example   to more accurately describe what the validator is doing; changed from <code>name_must_contain_space</code> to <code>value_must_equal_bar</code>, #3327 by @michaelrios28</li> <li>Add <code>AmqpDsn</code> class, #3254 by @kludex</li> <li>Always use <code>Enum</code> value as default in generated JSON schema, #3190 by @joaommartins</li> <li>Add support for Mypy 0.920, #3175 by @christianbundy</li> <li><code>validate_arguments</code> now supports <code>extra</code> customization (used to always be <code>Extra.forbid</code>), #3161 by @PrettyWood</li> <li>Complex types can be set by nested environment variables, #3159 by @Air-Mark</li> <li>Fix mypy plugin to collect fields based on <code>pydantic.utils.is_valid_field</code> so that it ignores untyped private variables, #3146 by @hi-ogawa</li> <li>fix <code>validate_arguments</code> issue with <code>Config.validate_all</code>, #3135 by @PrettyWood</li> <li>avoid dict coercion when using dict subclasses as field type, #3122 by @PrettyWood</li> <li>add support for <code>object</code> type, #3062 by @PrettyWood</li> <li>Updates pydantic dataclasses to keep <code>_special</code> properties on parent classes, #3043 by @zulrang</li> <li>Add a <code>TypedDict</code> class for error objects, #3038 by @matthewhughes934</li> <li>Fix support for using a subclass of an annotation as a default, #3018 by @JacobHayes</li> <li>make <code>create_model_from_typeddict</code> mypy compliant, #3008 by @PrettyWood</li> <li>Make multiple inheritance work when using <code>PrivateAttr</code>, #2989 by @hmvp</li> <li>Parse environment variables as JSON, if they have a <code>Union</code> type with a complex subfield, #2936 by @cbartz</li> <li>Prevent <code>StrictStr</code> permitting <code>Enum</code> values where the enum inherits from <code>str</code>, #2929 by @samuelcolvin</li> <li>Make <code>SecretsSettingsSource</code> parse values being assigned to fields of complex types when sourced from a secrets file,   just as when sourced from environment variables, #2917 by @davidmreed</li> <li>add a dark mode to pydantic documentation, #2913 by @gbdlin</li> <li>Make <code>pydantic-mypy</code> plugin compatible with <code>pyproject.toml</code> configuration, consistent with <code>mypy</code> changes.   See the doc for more information, #2908 by @jrwalk</li> <li>add Python 3.10 support, #2885 by @PrettyWood</li> <li>Correctly parse generic models with <code>Json[T]</code>, #2860 by @geekingfrog</li> <li>Update contrib docs re: Python version to use for building docs, #2856 by @paxcodes</li> <li>Clarify documentation about pydantic's support for custom validation and strict type checking,   despite pydantic being primarily a parsing library, #2855 by @paxcodes</li> <li>Fix schema generation for <code>Deque</code> fields, #2810 by @sergejkozin</li> <li>fix an edge case when mixing constraints and <code>Literal</code>, #2794 by @PrettyWood</li> <li>Fix postponed annotation resolution for <code>NamedTuple</code> and <code>TypedDict</code> when they're used directly as the type of fields   within Pydantic models, #2760 by @jameysharp</li> <li>Fix bug when <code>mypy</code> plugin fails on <code>construct</code> method call for <code>BaseSettings</code> derived classes, #2753 by @uriyyo</li> <li>Add function overloading for a <code>pydantic.create_model</code> function, #2748 by @uriyyo</li> <li>Fix mypy plugin issue with self field declaration, #2743 by @uriyyo</li> <li>The colon at the end of the line \"The fields which were supplied when user was initialised:\" suggests that the code following it is related.   Changed it to a period, #2733 by @krisaoe</li> <li>Renamed variable <code>schema</code> to <code>schema_</code> to avoid shadowing of global variable name, #2724 by @shahriyarr</li> <li>Add support for autocomplete in VS Code via <code>__dataclass_transform__</code>, #2721 by @tiangolo</li> <li>add missing type annotations in <code>BaseConfig</code> and handle <code>max_length = 0</code>, #2719 by @PrettyWood</li> <li>Change <code>orm_mode</code> checking to allow recursive ORM mode parsing with dicts, #2718 by @nuno-andre</li> <li>Add episode 313 of the Talk Python To Me podcast, where Michael Kennedy and Samuel Colvin discuss Pydantic, to the docs, #2712 by @RatulMaharaj</li> <li>fix JSON schema generation when a field is of type <code>NamedTuple</code> and has a default value, #2707 by @PrettyWood</li> <li><code>Enum</code> fields now properly support extra kwargs in schema generation, #2697 by @sammchardy</li> <li>Breaking Change, see #3780: Make serialization of referenced pydantic models possible, #2650 by @PrettyWood</li> <li>Add <code>uniqueItems</code> option to <code>ConstrainedList</code>, #2618 by @nuno-andre</li> <li>Try to evaluate forward refs automatically at model creation, #2588 by @uriyyo</li> <li>Switch docs preview and coverage display to use smokeshow, #2580 by @samuelcolvin</li> <li>Add <code>__version__</code> attribute to pydantic module, #2572 by @paxcodes</li> <li>Add <code>postgresql+asyncpg</code>, <code>postgresql+pg8000</code>, <code>postgresql+psycopg2</code>, <code>postgresql+psycopg2cffi</code>, <code>postgresql+py-postgresql</code>   and <code>postgresql+pygresql</code> schemes for <code>PostgresDsn</code>, #2567 by @postgres-asyncpg</li> <li>Enable the Hypothesis plugin to generate a constrained decimal when the <code>decimal_places</code> argument is specified, #2524 by @cwe5590</li> <li>Allow <code>collections.abc.Callable</code> to be used as type in Python 3.9, #2519 by @daviskirk</li> <li>Documentation update how to custom compile pydantic when using pip install, small change in <code>setup.py</code>   to allow for custom CFLAGS when compiling, #2517 by @peterroelants</li> <li>remove side effect of <code>default_factory</code> to run it only once even if <code>Config.validate_all</code> is set, #2515 by @PrettyWood</li> <li>Add lookahead to ip regexes for <code>AnyUrl</code> hosts. This allows urls with DNS labels   looking like IPs to validate as they are perfectly valid host names, #2512 by @sbv-csis</li> <li>Set <code>minItems</code> and <code>maxItems</code> in generated JSON schema for fixed-length tuples, #2497 by @PrettyWood</li> <li>Add <code>strict</code> argument to <code>conbytes</code>, #2489 by @koxudaxi</li> <li>Support user defined generic field types in generic models, #2465 by @daviskirk</li> <li>Add an example and a short explanation of subclassing <code>GetterDict</code> to docs, #2463 by @nuno-andre</li> <li>add <code>KafkaDsn</code> type, <code>HttpUrl</code> now has default port 80 for http and 443 for https, #2447 by @MihanixA</li> <li>Add <code>PastDate</code> and <code>FutureDate</code> types, #2425 by @Kludex</li> <li>Support generating schema for <code>Generic</code> fields with subtypes, #2375 by @maximberg</li> <li>fix(encoder): serialize <code>NameEmail</code> to str, #2341 by @alecgerona</li> <li>add <code>Config.smart_union</code> to prevent coercion in <code>Union</code> if possible, see  the doc for more information, #2092 by @PrettyWood</li> <li>Add ability to use <code>typing.Counter</code> as a model field type, #2060 by @uriyyo</li> <li>Add parameterised subclasses to <code>__bases__</code> when constructing new parameterised classes, so that <code>A &lt;: B =&gt; A[int] &lt;: B[int]</code>, #2007 by @diabolo-dan</li> <li>Create <code>FileUrl</code> type that allows URLs that conform to RFC 8089.   Add <code>host_required</code> parameter, which is <code>True</code> by default (<code>AnyUrl</code> and subclasses), <code>False</code> in <code>RedisDsn</code>, <code>FileUrl</code>, #1983 by @vgerak</li> <li>add <code>confrozenset()</code>, analogous to <code>conset()</code> and <code>conlist()</code>, #1897 by @PrettyWood</li> <li>stop calling parent class <code>root_validator</code> if overridden, #1895 by @PrettyWood</li> <li>Add <code>repr</code> (defaults to <code>True</code>) parameter to <code>Field</code>, to hide it from the default representation of the <code>BaseModel</code>, #1831 by @fnep</li> <li>Accept empty query/fragment URL parts, #1807 by @xavier</li> </ul>"},{"location":"changelog/#v182-2021-05-11","title":"v1.8.2 (2021-05-11)","text":"<p>Warning</p> <p>A security vulnerability, level \"moderate\" is fixed in v1.8.2. Please upgrade ASAP. See security advisory CVE-2021-29510</p> <ul> <li>Security fix: Fix <code>date</code> and <code>datetime</code> parsing so passing either <code>'infinity'</code> or <code>float('inf')</code>   (or their negative values) does not cause an infinite loop,   see security advisory CVE-2021-29510</li> <li>fix schema generation with Enum by generating a valid name, #2575 by @PrettyWood</li> <li>fix JSON schema generation with a <code>Literal</code> of an enum member, #2536 by @PrettyWood</li> <li>Fix bug with configurations declarations that are passed as   keyword arguments during class creation, #2532 by @uriyyo</li> <li>Allow passing <code>json_encoders</code> in class kwargs, #2521 by @layday</li> <li>support arbitrary types with custom <code>__eq__</code>, #2483 by @PrettyWood</li> <li>support <code>Annotated</code> in <code>validate_arguments</code> and in generic models with Python 3.9, #2483 by @PrettyWood</li> </ul>"},{"location":"changelog/#v181-2021-03-03","title":"v1.8.1 (2021-03-03)","text":"<p>Bug fixes for regressions and new features from <code>v1.8</code></p> <ul> <li>allow elements of <code>Config.field</code> to update elements of a <code>Field</code>, #2461 by @samuelcolvin</li> <li>fix validation with a <code>BaseModel</code> field and a custom root type, #2449 by @PrettyWood</li> <li>expose <code>Pattern</code> encoder to <code>fastapi</code>, #2444 by @PrettyWood</li> <li>enable the Hypothesis plugin to generate a constrained float when the <code>multiple_of</code> argument is specified, #2442 by @tobi-lipede-oodle</li> <li>Avoid <code>RecursionError</code> when using some types like <code>Enum</code> or <code>Literal</code> with generic models, #2436 by @PrettyWood</li> <li>do not overwrite declared <code>__hash__</code> in subclasses of a model, #2422 by @PrettyWood</li> <li>fix <code>mypy</code> complaints on <code>Path</code> and <code>UUID</code> related custom types, #2418 by @PrettyWood</li> <li>Support properly variable length tuples of compound types, #2416 by @PrettyWood</li> </ul>"},{"location":"changelog/#v18-2021-02-26","title":"v1.8 (2021-02-26)","text":"<p>Thank you to pydantic's sponsors: @jorgecarleitao, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @koxudaxi, @timdrijvers, @mkeen, @meadsteve, @ginomempin, @primer-io, @and-semakin, @tomthorogood, @AjitZK, @westonsteimel, @Mazyod, @christippett, @CarlosDomingues, @Kludex, @r-m-n for their kind support.</p>"},{"location":"changelog/#highlights_1","title":"Highlights","text":"<ul> <li>Hypothesis plugin for testing, #2097 by @Zac-HD</li> <li>support for <code>NamedTuple</code> and <code>TypedDict</code>, #2216 by @PrettyWood</li> <li>Support <code>Annotated</code> hints on model fields, #2147 by @JacobHayes</li> <li><code>frozen</code> parameter on <code>Config</code> to allow models to be hashed, #1880 by @rhuille</li> </ul>"},{"location":"changelog/#changes_8","title":"Changes","text":"<ul> <li>Breaking Change, remove old deprecation aliases from v1, #2415 by @samuelcolvin:</li> <li>remove notes on migrating to v1 in docs</li> <li>remove <code>Schema</code> which was replaced by <code>Field</code></li> <li>remove <code>Config.case_insensitive</code> which was replaced by <code>Config.case_sensitive</code> (default <code>False</code>)</li> <li>remove <code>Config.allow_population_by_alias</code> which was replaced by <code>Config.allow_population_by_field_name</code></li> <li>remove <code>model.fields</code> which was replaced by <code>model.__fields__</code></li> <li>remove <code>model.to_string()</code> which was replaced by <code>str(model)</code></li> <li>remove <code>model.__values__</code> which was replaced by <code>model.__dict__</code></li> <li>Breaking Change: always validate only first sublevel items with <code>each_item</code>.   There were indeed some edge cases with some compound types where the validated items were the last sublevel ones, #1933 by @PrettyWood</li> <li>Update docs extensions to fix local syntax highlighting, #2400 by @daviskirk</li> <li>fix: allow <code>utils.lenient_issubclass</code> to handle <code>typing.GenericAlias</code> objects like <code>list[str]</code> in Python &gt;= 3.9, #2399 by @daviskirk</li> <li>Improve field declaration for pydantic <code>dataclass</code> by allowing the usage of pydantic <code>Field</code> or <code>'metadata'</code> kwarg of <code>dataclasses.field</code>, #2384 by @PrettyWood</li> <li>Making <code>typing-extensions</code> a required dependency, #2368 by @samuelcolvin</li> <li>Make <code>resolve_annotations</code> more lenient, allowing for missing modules, #2363 by @samuelcolvin</li> <li>Allow configuring models through class kwargs, #2356 by @Bobronium</li> <li>Prevent <code>Mapping</code> subclasses from always being coerced to <code>dict</code>, #2325 by @ofek</li> <li>fix: allow <code>None</code> for type <code>Optional[conset / conlist]</code>, #2320 by @PrettyWood</li> <li>Support empty tuple type, #2318 by @PrettyWood</li> <li>fix: <code>python_requires</code> metadata to require &gt;=3.6.1, #2306 by @hukkinj1</li> <li>Properly encode <code>Decimal</code> with, or without any decimal places, #2293 by @hultner</li> <li>fix: update <code>__fields_set__</code> in <code>BaseModel.copy(update=\u2026)</code>, #2290 by @PrettyWood</li> <li>fix: keep order of fields with <code>BaseModel.construct()</code>, #2281 by @PrettyWood</li> <li>Support generating schema for Generic fields, #2262 by @maximberg</li> <li>Fix <code>validate_decorator</code> so <code>**kwargs</code> doesn't exclude values when the keyword   has the same name as the <code>*args</code> or <code>**kwargs</code> names, #2251 by @cybojenix</li> <li>Prevent overriding positional arguments with keyword arguments in   <code>validate_arguments</code>, as per behaviour with native functions, #2249 by @cybojenix</li> <li>add documentation for <code>con*</code> type functions, #2242 by @tayoogunbiyi</li> <li>Support custom root type (aka <code>__root__</code>) when using <code>parse_obj()</code> with nested models, #2238 by @PrettyWood</li> <li>Support custom root type (aka <code>__root__</code>) with <code>from_orm()</code>, #2237 by @PrettyWood</li> <li>ensure cythonized functions are left untouched when creating models, based on #1944 by @kollmats, #2228 by @samuelcolvin</li> <li>Resolve forward refs for stdlib dataclasses converted into pydantic ones, #2220 by @PrettyWood</li> <li>Add support for <code>NamedTuple</code> and <code>TypedDict</code> types.   Those two types are now handled and validated when used inside <code>BaseModel</code> or pydantic <code>dataclass</code>.   Two utils are also added <code>create_model_from_namedtuple</code> and <code>create_model_from_typeddict</code>, #2216 by @PrettyWood</li> <li>Do not ignore annotated fields when type is <code>Union[Type[...], ...]</code>, #2213 by @PrettyWood</li> <li>Raise a user-friendly <code>TypeError</code> when a <code>root_validator</code> does not return a <code>dict</code> (e.g. <code>None</code>), #2209 by @masalim2</li> <li>Add a <code>FrozenSet[str]</code> type annotation to the <code>allowed_schemes</code> argument on the <code>strict_url</code> field type, #2198 by @Midnighter</li> <li>add <code>allow_mutation</code> constraint to <code>Field</code>, #2195 by @sblack-usu</li> <li>Allow <code>Field</code> with a <code>default_factory</code> to be used as an argument to a function   decorated with <code>validate_arguments</code>, #2176 by @thomascobb</li> <li>Allow non-existent secrets directory by only issuing a warning, #2175 by @davidolrik</li> <li>fix URL regex to parse fragment without query string, #2168 by @andrewmwhite</li> <li>fix: ensure to always return one of the values in <code>Literal</code> field type, #2166 by @PrettyWood</li> <li>Support <code>typing.Annotated</code> hints on model fields. A <code>Field</code> may now be set in the type hint with <code>Annotated[..., Field(...)</code>; all other annotations are ignored but still visible with <code>get_type_hints(..., include_extras=True)</code>, #2147 by @JacobHayes</li> <li>Added <code>StrictBytes</code> type as well as <code>strict=False</code> option to <code>ConstrainedBytes</code>, #2136 by @rlizzo</li> <li>added <code>Config.anystr_lower</code> and <code>to_lower</code> kwarg to <code>constr</code> and <code>conbytes</code>, #2134 by @tayoogunbiyi</li> <li>Support plain <code>typing.Tuple</code> type, #2132 by @PrettyWood</li> <li>Add a bound method <code>validate</code> to functions decorated with <code>validate_arguments</code>   to validate parameters without actually calling the function, #2127 by @PrettyWood</li> <li>Add the ability to customize settings sources (add / disable / change priority order), #2107 by @kozlek</li> <li>Fix mypy complaints about most custom pydantic types, #2098 by @PrettyWood</li> <li>Add a Hypothesis plugin for easier property-based testing with Pydantic's custom types - usage details here, #2097 by @Zac-HD</li> <li>add validator for <code>None</code>, <code>NoneType</code> or <code>Literal[None]</code>, #2095 by @PrettyWood</li> <li>Handle properly fields of type <code>Callable</code> with a default value, #2094 by @PrettyWood</li> <li>Updated <code>create_model</code> return type annotation to return type which inherits from <code>__base__</code> argument, #2071 by @uriyyo</li> <li>Add merged <code>json_encoders</code> inheritance, #2064 by @art049</li> <li>allow overwriting <code>ClassVar</code>s in sub-models without having to re-annotate them, #2061 by @layday</li> <li>add default encoder for <code>Pattern</code> type, #2045 by @PrettyWood</li> <li>Add <code>NonNegativeInt</code>, <code>NonPositiveInt</code>, <code>NonNegativeFloat</code>, <code>NonPositiveFloat</code>, #1975 by @mdavis-xyz</li> <li>Use % for percentage in string format of colors, #1960 by @EdwardBetts</li> <li>Fixed issue causing <code>KeyError</code> to be raised when building schema from multiple <code>BaseModel</code> with the same names declared in separate classes, #1912 by @JSextonn</li> <li>Add <code>rediss</code> (Redis over SSL) protocol to <code>RedisDsn</code>   Allow URLs without <code>user</code> part (e.g., <code>rediss://:pass@localhost</code>), #1911 by @TrDex</li> <li>Add a new <code>frozen</code> boolean parameter to <code>Config</code> (default: <code>False</code>).   Setting <code>frozen=True</code> does everything that <code>allow_mutation=False</code> does, and also generates a <code>__hash__()</code> method for the model. This makes instances of the model potentially hashable if all the attributes are hashable, #1880 by @rhuille</li> <li>fix schema generation with multiple Enums having the same name, #1857 by @PrettyWood</li> <li>Added support for 13/19 digits VISA credit cards in <code>PaymentCardNumber</code> type, #1416 by @AlexanderSov</li> <li>fix: prevent <code>RecursionError</code> while using recursive <code>GenericModel</code>s, #1370 by @xppt</li> <li>use <code>enum</code> for <code>typing.Literal</code> in JSON schema, #1350 by @PrettyWood</li> <li>Fix: some recursive models did not require <code>update_forward_refs</code> and silently behaved incorrectly, #1201 by @PrettyWood</li> <li>Fix bug where generic models with fields where the typevar is nested in another type <code>a: List[T]</code> are considered to be concrete. This allows these models to be subclassed and composed as expected, #947 by @daviskirk</li> <li>Add <code>Config.copy_on_model_validation</code> flag. When set to <code>False</code>, pydantic will keep models used as fields   untouched on validation instead of reconstructing (copying) them, #265 by @PrettyWood</li> </ul>"},{"location":"changelog/#v174-2021-05-11","title":"v1.7.4 (2021-05-11)","text":"<ul> <li>Security fix: Fix <code>date</code> and <code>datetime</code> parsing so passing either <code>'infinity'</code> or <code>float('inf')</code>   (or their negative values) does not cause an infinite loop,   See security advisory CVE-2021-29510</li> </ul>"},{"location":"changelog/#v173-2020-11-30","title":"v1.7.3 (2020-11-30)","text":"<p>Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api, @mkeen, @meadsteve for their kind support.</p> <ul> <li>fix: set right default value for required (optional) fields, #2142 by @PrettyWood</li> <li>fix: support <code>underscore_attrs_are_private</code> with generic models, #2138 by @PrettyWood</li> <li>fix: update all modified field values in <code>root_validator</code> when <code>validate_assignment</code> is on, #2116 by @PrettyWood</li> <li>Allow pickling of <code>pydantic.dataclasses.dataclass</code> dynamically created from a built-in <code>dataclasses.dataclass</code>, #2111 by @aimestereo</li> <li>Fix a regression where Enum fields would not propagate keyword arguments to the schema, #2109 by @bm424</li> <li>Ignore <code>__doc__</code> as private attribute when <code>Config.underscore_attrs_are_private</code> is set, #2090 by @PrettyWood</li> </ul>"},{"location":"changelog/#v172-2020-11-01","title":"v1.7.2 (2020-11-01)","text":"<ul> <li>fix slow <code>GenericModel</code> concrete model creation, allow <code>GenericModel</code> concrete name reusing in module, #2078 by @Bobronium</li> <li>keep the order of the fields when <code>validate_assignment</code> is set, #2073 by @PrettyWood</li> <li>forward all the params of the stdlib <code>dataclass</code> when converted into pydantic <code>dataclass</code>, #2065 by @PrettyWood</li> </ul>"},{"location":"changelog/#v171-2020-10-28","title":"v1.7.1 (2020-10-28)","text":"<p>Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api, @mkeen for their kind support.</p> <ul> <li>fix annotation of <code>validate_arguments</code> when passing configuration as argument, #2055 by @layday</li> <li>Fix mypy assignment error when using <code>PrivateAttr</code>, #2048 by @aphedges</li> <li>fix <code>underscore_attrs_are_private</code> causing <code>TypeError</code> when overriding <code>__init__</code>, #2047 by @samuelcolvin</li> <li>Fixed regression introduced in v1.7 involving exception handling in field validators when <code>validate_assignment=True</code>, #2044 by @johnsabath</li> <li>fix: pydantic <code>dataclass</code> can inherit from stdlib <code>dataclass</code>   and <code>Config.arbitrary_types_allowed</code> is supported, #2042 by @PrettyWood</li> </ul>"},{"location":"changelog/#v17-2020-10-26","title":"v1.7 (2020-10-26)","text":"<p>Thank you to pydantic's sponsors: @timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api for their kind support.</p>"},{"location":"changelog/#highlights_2","title":"Highlights","text":"<ul> <li>Python 3.9 support, thanks @PrettyWood</li> <li>Private model attributes, thanks @Bobronium</li> <li>\"secrets files\" support in <code>BaseSettings</code>, thanks @mdgilene</li> <li>convert stdlib dataclasses to pydantic dataclasses and use stdlib dataclasses in models, thanks @PrettyWood</li> </ul>"},{"location":"changelog/#changes_9","title":"Changes","text":"<ul> <li>Breaking Change: remove <code>__field_defaults__</code>, add <code>default_factory</code> support with <code>BaseModel.construct</code>.   Use <code>.get_default()</code> method on fields in <code>__fields__</code> attribute instead, #1732 by @PrettyWood</li> <li>Rearrange CI to run linting as a separate job, split install recipes for different tasks, #2020 by @samuelcolvin</li> <li>Allows subclasses of generic models to make some, or all, of the superclass's type parameters concrete, while   also defining new type parameters in the subclass, #2005 by @choogeboom</li> <li>Call validator with the correct <code>values</code> parameter type in <code>BaseModel.__setattr__</code>,   when <code>validate_assignment = True</code> in model config, #1999 by @me-ransh</li> <li>Force <code>fields.Undefined</code> to be a singleton object, fixing inherited generic model schemas, #1981 by @daviskirk</li> <li>Include tests in source distributions, #1976 by @sbraz</li> <li>Add ability to use <code>min_length/max_length</code> constraints with secret types, #1974 by @uriyyo</li> <li>Also check <code>root_validators</code> when <code>validate_assignment</code> is on, #1971 by @PrettyWood</li> <li>Fix const validators not running when custom validators are present, #1957 by @hmvp</li> <li>add <code>deque</code> to field types, #1935 by @wozniakty</li> <li>add basic support for Python 3.9, #1832 by @PrettyWood</li> <li>Fix typo in the anchor of exporting_models.md#modelcopy and incorrect description, #1821 by @KimMachineGun</li> <li>Added ability for <code>BaseSettings</code> to read \"secret files\", #1820 by @mdgilene</li> <li>add <code>parse_raw_as</code> utility function, #1812 by @PrettyWood</li> <li>Support home directory relative paths for <code>dotenv</code> files (e.g. <code>~/.env</code>), #1803 by @PrettyWood</li> <li>Clarify documentation for <code>parse_file</code> to show that the argument   should be a file path not a file-like object, #1794 by @mdavis-xyz</li> <li>Fix false positive from mypy plugin when a class nested within a <code>BaseModel</code> is named <code>Model</code>, #1770 by @selimb</li> <li>add basic support of Pattern type in schema generation, #1767 by @PrettyWood</li> <li>Support custom title, description and default in schema of enums, #1748 by @PrettyWood</li> <li>Properly represent <code>Literal</code> Enums when <code>use_enum_values</code> is True, #1747 by @noelevans</li> <li>Allows timezone information to be added to strings to be formatted as time objects. Permitted formats are <code>Z</code> for UTC   or an offset for absolute positive or negative time shifts. Or the timezone data can be omitted, #1744 by @noelevans</li> <li>Add stub <code>__init__</code> with Python 3.6 signature for <code>ForwardRef</code>, #1738 by @sirtelemak</li> <li>Fix behaviour with forward refs and optional fields in nested models, #1736 by @PrettyWood</li> <li>add <code>Enum</code> and <code>IntEnum</code> as valid types for fields, #1735 by @PrettyWood</li> <li>Change default value of <code>__module__</code> argument of <code>create_model</code> from <code>None</code> to <code>'pydantic.main'</code>.   Set reference of created concrete model to it's module to allow pickling (not applied to models created in   functions), #1686 by @Bobronium</li> <li>Add private attributes support, #1679 by @Bobronium</li> <li>add <code>config</code> to <code>@validate_arguments</code>, #1663 by @samuelcolvin</li> <li>Allow descendant Settings models to override env variable names for the fields defined in parent Settings models with   <code>env</code> in their <code>Config</code>. Previously only <code>env_prefix</code> configuration option was applicable, #1561 by @ojomio</li> <li>Support <code>ref_template</code> when creating schema <code>$ref</code>s, #1479 by @kilo59</li> <li>Add a <code>__call__</code> stub to <code>PyObject</code> so that mypy will know that it is callable, #1352 by @brianmaissy</li> <li><code>pydantic.dataclasses.dataclass</code> decorator now supports built-in <code>dataclasses.dataclass</code>.   It is hence possible to convert an existing <code>dataclass</code> easily to add Pydantic validation.   Moreover nested dataclasses are also supported, #744 by @PrettyWood</li> </ul>"},{"location":"changelog/#v162-2021-05-11","title":"v1.6.2 (2021-05-11)","text":"<ul> <li>Security fix: Fix <code>date</code> and <code>datetime</code> parsing so passing either <code>'infinity'</code> or <code>float('inf')</code>   (or their negative values) does not cause an infinite loop,   See security advisory CVE-2021-29510</li> </ul>"},{"location":"changelog/#v161-2020-07-15","title":"v1.6.1 (2020-07-15)","text":"<ul> <li>fix validation and parsing of nested models with <code>default_factory</code>, #1710 by @PrettyWood</li> </ul>"},{"location":"changelog/#v16-2020-07-11","title":"v1.6 (2020-07-11)","text":"<p>Thank you to pydantic's sponsors: @matin, @tiangolo, @chdsbd, @jorgecarleitao, and 1 anonymous sponsor for their kind support.</p> <ul> <li>Modify validators for <code>conlist</code> and <code>conset</code> to not have <code>always=True</code>, #1682 by @samuelcolvin</li> <li>add port check to <code>AnyUrl</code> (can't exceed 65536) ports are 16 insigned bits: <code>0 &lt;= port &lt;= 2**16-1</code> src: rfc793 header format, #1654 by @flapili</li> <li>Document default <code>regex</code> anchoring semantics, #1648 by @yurikhan</li> <li>Use <code>chain.from_iterable</code> in class_validators.py. This is a faster and more idiomatic way of using <code>itertools.chain</code>.   Instead of computing all the items in the iterable and storing them in memory, they are computed one-by-one and never   stored as a huge list. This can save on both runtime and memory space, #1642 by @cool-RR</li> <li>Add <code>conset()</code>, analogous to <code>conlist()</code>, #1623 by @patrickkwang</li> <li>make Pydantic errors (un)pickable, #1616 by @PrettyWood</li> <li>Allow custom encoding for <code>dotenv</code> files, #1615 by @PrettyWood</li> <li>Ensure <code>SchemaExtraCallable</code> is always defined to get type hints on BaseConfig, #1614 by @PrettyWood</li> <li>Update datetime parser to support negative timestamps, #1600 by @mlbiche</li> <li>Update mypy, remove <code>AnyType</code> alias for <code>Type[Any]</code>, #1598 by @samuelcolvin</li> <li>Adjust handling of root validators so that errors are aggregated from all failing root validators, instead of reporting on only the first root validator to fail, #1586 by @beezee</li> <li>Make <code>__modify_schema__</code> on Enums apply to the enum schema rather than fields that use the enum, #1581 by @therefromhere</li> <li>Fix behavior of <code>__all__</code> key when used in conjunction with index keys in advanced include/exclude of fields that are sequences, #1579 by @xspirus</li> <li>Subclass validators do not run when referencing a <code>List</code> field defined in a parent class when <code>each_item=True</code>. Added an example to the docs illustrating this, #1566 by @samueldeklund</li> <li>change <code>schema.field_class_to_schema</code> to support <code>frozenset</code> in schema, #1557 by @wangpeibao</li> <li>Call <code>__modify_schema__</code> only for the field schema, #1552 by @PrettyWood</li> <li>Move the assignment of <code>field.validate_always</code> in <code>fields.py</code> so the <code>always</code> parameter of validators work on inheritance, #1545 by @dcHHH</li> <li>Added support for UUID instantiation through 16 byte strings such as <code>b'\\x12\\x34\\x56\\x78' * 4</code>. This was done to support <code>BINARY(16)</code> columns in sqlalchemy, #1541 by @shawnwall</li> <li>Add a test assertion that <code>default_factory</code> can return a singleton, #1523 by @therefromhere</li> <li>Add <code>NameEmail.__eq__</code> so duplicate <code>NameEmail</code> instances are evaluated as equal, #1514 by @stephen-bunn</li> <li>Add datamodel-code-generator link in pydantic document site, #1500 by @koxudaxi</li> <li>Added a \"Discussion of Pydantic\" section to the documentation, with a link to \"Pydantic Introduction\" video by Alexander Hultn\u00e9r, #1499 by @hultner</li> <li>Avoid some side effects of <code>default_factory</code> by calling it only once   if possible and by not setting a default value in the schema, #1491 by @PrettyWood</li> <li>Added docs about dumping dataclasses to JSON, #1487 by @mikegrima</li> <li>Make <code>BaseModel.__signature__</code> class-only, so getting <code>__signature__</code> from model instance will raise <code>AttributeError</code>, #1466 by @Bobronium</li> <li>include <code>'format': 'password'</code> in the schema for secret types, #1424 by @atheuz</li> <li>Modify schema constraints on <code>ConstrainedFloat</code> so that <code>exclusiveMinimum</code> and   minimum are not included in the schema if they are equal to <code>-math.inf</code> and   <code>exclusiveMaximum</code> and <code>maximum</code> are not included if they are equal to <code>math.inf</code>, #1417 by @vdwees</li> <li>Squash internal <code>__root__</code> dicts in <code>.dict()</code> (and, by extension, in <code>.json()</code>), #1414 by @patrickkwang</li> <li>Move <code>const</code> validator to post-validators so it validates the parsed value, #1410 by @selimb</li> <li>Fix model validation to handle nested literals, e.g. <code>Literal['foo', Literal['bar']]</code>, #1364 by @DBCerigo</li> <li>Remove <code>user_required = True</code> from <code>RedisDsn</code>, neither user nor password are required, #1275 by @samuelcolvin</li> <li>Remove extra <code>allOf</code> from schema for fields with <code>Union</code> and custom <code>Field</code>, #1209 by @mostaphaRoudsari</li> <li>Updates OpenAPI schema generation to output all enums as separate models.   Instead of inlining the enum values in the model schema, models now use a <code>$ref</code>   property to point to the enum definition, #1173 by @calvinwyoung</li> </ul>"},{"location":"changelog/#v151-2020-04-23","title":"v1.5.1 (2020-04-23)","text":"<ul> <li>Signature generation with <code>extra: allow</code> never uses a field name, #1418 by @prettywood</li> <li>Avoid mutating <code>Field</code> default value, #1412 by @prettywood</li> </ul>"},{"location":"changelog/#v15-2020-04-18","title":"v1.5 (2020-04-18)","text":"<ul> <li>Make includes/excludes arguments for <code>.dict()</code>, <code>._iter()</code>, ..., immutable, #1404 by @AlexECX</li> <li>Always use a field's real name with includes/excludes in <code>model._iter()</code>, regardless of <code>by_alias</code>, #1397 by @AlexECX</li> <li>Update constr regex example to include start and end lines, #1396 by @lmcnearney</li> <li>Confirm that shallow <code>model.copy()</code> does make a shallow copy of attributes, #1383 by @samuelcolvin</li> <li>Renaming <code>model_name</code> argument of <code>main.create_model()</code> to <code>__model_name</code> to allow using <code>model_name</code> as a field name, #1367 by @kittipatv</li> <li>Replace raising of exception to silent passing  for non-Var attributes in mypy plugin, #1345 by @b0g3r</li> <li>Remove <code>typing_extensions</code> dependency for Python 3.8, #1342 by @prettywood</li> <li>Make <code>SecretStr</code> and <code>SecretBytes</code> initialization idempotent, #1330 by @atheuz</li> <li>document making secret types dumpable using the json method, #1328 by @atheuz</li> <li>Move all testing and build to github actions, add windows and macos binaries,   thank you @StephenBrown2 for much help, #1326 by @samuelcolvin</li> <li>fix card number length check in <code>PaymentCardNumber</code>, <code>PaymentCardBrand</code> now inherits from <code>str</code>, #1317 by @samuelcolvin</li> <li>Have <code>BaseModel</code> inherit from <code>Representation</code> to make mypy happy when overriding <code>__str__</code>, #1310 by @FuegoFro</li> <li>Allow <code>None</code> as input to all optional list fields, #1307 by @prettywood</li> <li>Add <code>datetime</code> field to <code>default_factory</code> example, #1301 by @StephenBrown2</li> <li>Allow subclasses of known types to be encoded with superclass encoder, #1291 by @StephenBrown2</li> <li>Exclude exported fields from all elements of a list/tuple of submodels/dicts with <code>'__all__'</code>, #1286 by @masalim2</li> <li>Add pydantic.color.Color objects as available input for Color fields, #1258 by @leosussan</li> <li>In examples, type nullable fields as <code>Optional</code>, so that these are valid mypy annotations, #1248 by @kokes</li> <li>Make <code>pattern_validator()</code> accept pre-compiled <code>Pattern</code> objects. Fix <code>str_validator()</code> return type to <code>str</code>, #1237 by @adamgreg</li> <li>Document how to manage Generics and inheritance, #1229 by @esadruhn</li> <li><code>update_forward_refs()</code> method of BaseModel now copies <code>__dict__</code> of class module instead of modyfying it, #1228 by @paul-ilyin</li> <li>Support instance methods and class methods with <code>@validate_arguments</code>, #1222 by @samuelcolvin</li> <li>Add <code>default_factory</code> argument to <code>Field</code> to create a dynamic default value by passing a zero-argument callable, #1210 by @prettywood</li> <li>add support for <code>NewType</code> of <code>List</code>, <code>Optional</code>, etc, #1207 by @Kazy</li> <li>fix mypy signature for <code>root_validator</code>, #1192 by @samuelcolvin</li> <li>Fixed parsing of nested 'custom root type' models, #1190 by @Shados</li> <li>Add <code>validate_arguments</code> function decorator which checks the arguments to a function matches type annotations, #1179 by @samuelcolvin</li> <li>Add <code>__signature__</code> to models, #1034 by @Bobronium</li> <li>Refactor <code>._iter()</code> method, 10x speed boost for <code>dict(model)</code>, #1017 by @Bobronium</li> </ul>"},{"location":"changelog/#v14-2020-01-24","title":"v1.4 (2020-01-24)","text":"<ul> <li>Breaking Change: alias precedence logic changed so aliases on a field always take priority over   an alias from <code>alias_generator</code> to avoid buggy/unexpected behaviour,   see here for details, #1178 by @samuelcolvin</li> <li>Add support for unicode and punycode in TLDs, #1182 by @jamescurtin</li> <li>Fix <code>cls</code> argument in validators during assignment, #1172 by @samuelcolvin</li> <li>completing Luhn algorithm for <code>PaymentCardNumber</code>, #1166 by @cuencandres</li> <li>add support for generics that implement <code>__get_validators__</code> like a custom data type, #1159 by @tiangolo</li> <li>add support for infinite generators with <code>Iterable</code>, #1152 by @tiangolo</li> <li>fix <code>url_regex</code> to accept schemas with <code>+</code>, <code>-</code> and <code>.</code> after the first character, #1142 by @samuelcolvin</li> <li>move <code>version_info()</code> to <code>version.py</code>, suggest its use in issues, #1138 by @samuelcolvin</li> <li>Improve pydantic import time by roughly 50% by deferring some module loading and regex compilation, #1127 by @samuelcolvin</li> <li>Fix <code>EmailStr</code> and <code>NameEmail</code> to accept instances of themselves in cython, #1126 by @koxudaxi</li> <li>Pass model class to the <code>Config.schema_extra</code> callable, #1125 by @therefromhere</li> <li>Fix regex for username and password in URLs, #1115 by @samuelcolvin</li> <li>Add support for nested generic models, #1104 by @dmontagu</li> <li>add <code>__all__</code> to <code>__init__.py</code> to prevent \"implicit reexport\" errors from mypy, #1072 by @samuelcolvin</li> <li>Add support for using \"dotenv\" files with <code>BaseSettings</code>, #1011 by @acnebs</li> </ul>"},{"location":"changelog/#v13-2019-12-21","title":"v1.3 (2019-12-21)","text":"<ul> <li>Change <code>schema</code> and <code>schema_model</code> to handle dataclasses by using their <code>__pydantic_model__</code> feature, #792 by @aviramha</li> <li>Added option for <code>root_validator</code> to be skipped if values validation fails using keyword <code>skip_on_failure=True</code>, #1049 by @aviramha</li> <li>Allow <code>Config.schema_extra</code> to be a callable so that the generated schema can be post-processed, #1054 by @selimb</li> <li>Update mypy to version 0.750, #1057 by @dmontagu</li> <li>Trick Cython into allowing str subclassing, #1061 by @skewty</li> <li>Prevent type attributes being added to schema unless the attribute <code>__schema_attributes__</code> is <code>True</code>, #1064 by @samuelcolvin</li> <li>Change <code>BaseModel.parse_file</code> to use <code>Config.json_loads</code>, #1067 by @kierandarcy</li> <li>Fix for optional <code>Json</code> fields, #1073 by @volker48</li> <li>Change the default number of threads used when compiling with cython to one,   allow override via the <code>CYTHON_NTHREADS</code> environment variable, #1074 by @samuelcolvin</li> <li>Run FastAPI tests during Pydantic's CI tests, #1075 by @tiangolo</li> <li>My mypy strictness constraints, and associated tweaks to type annotations, #1077 by @samuelcolvin</li> <li>Add <code>__eq__</code> to SecretStr and SecretBytes to allow \"value equals\", #1079 by @sbv-trueenergy</li> <li>Fix schema generation for nested None case, #1088 by @lutostag</li> <li>Consistent checks for sequence like objects, #1090 by @samuelcolvin</li> <li>Fix <code>Config</code> inheritance on <code>BaseSettings</code> when used with <code>env_prefix</code>, #1091 by @samuelcolvin</li> <li>Fix for <code>__modify_schema__</code> when it conflicted with <code>field_class_to_schema*</code>, #1102 by @samuelcolvin</li> <li>docs: Fix explanation of case sensitive environment variable names when populating <code>BaseSettings</code> subclass attributes, #1105 by @tribals</li> <li>Rename django-rest-framework benchmark in documentation, #1119 by @frankie567</li> </ul>"},{"location":"changelog/#v12-2019-11-28","title":"v1.2 (2019-11-28)","text":"<ul> <li>Possible Breaking Change: Add support for required <code>Optional</code> with <code>name: Optional[AnyType] = Field(...)</code>   and refactor <code>ModelField</code> creation to preserve <code>required</code> parameter value, #1031 by @tiangolo;   see here for details</li> <li>Add benchmarks for <code>cattrs</code>, #513 by @sebastianmika</li> <li>Add <code>exclude_none</code> option to <code>dict()</code> and friends, #587 by @niknetniko</li> <li>Add benchmarks for <code>valideer</code>, #670 by @gsakkis</li> <li>Add <code>parse_obj_as</code> and <code>parse_file_as</code> functions for ad-hoc parsing of data into arbitrary pydantic-compatible types, #934 by @dmontagu</li> <li>Add <code>allow_reuse</code> argument to validators, thus allowing validator reuse, #940 by @dmontagu</li> <li>Add support for mapping types for custom root models, #958 by @dmontagu</li> <li>Mypy plugin support for dataclasses, #966 by @koxudaxi</li> <li>Add support for dataclasses default factory, #968 by @ahirner</li> <li>Add a <code>ByteSize</code> type for converting byte string (<code>1GB</code>) to plain bytes, #977 by @dgasmith</li> <li>Fix mypy complaint about <code>@root_validator(pre=True)</code>, #984 by @samuelcolvin</li> <li>Add manylinux binaries for Python 3.8 to pypi, also support manylinux2010, #994 by @samuelcolvin</li> <li>Adds ByteSize conversion to another unit, #995 by @dgasmith</li> <li>Fix <code>__str__</code> and <code>__repr__</code> inheritance for models, #1022 by @samuelcolvin</li> <li>add testimonials section to docs, #1025 by @sullivancolin</li> <li>Add support for <code>typing.Literal</code> for Python 3.8, #1026 by @dmontagu</li> </ul>"},{"location":"changelog/#v111-2019-11-20","title":"v1.1.1 (2019-11-20)","text":"<ul> <li>Fix bug where use of complex fields on sub-models could cause fields to be incorrectly configured, #1015 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v11-2019-11-07","title":"v1.1 (2019-11-07)","text":"<ul> <li>Add a mypy plugin for type checking <code>BaseModel.__init__</code> and more, #722 by @dmontagu</li> <li>Change return type typehint for <code>GenericModel.__class_getitem__</code> to prevent PyCharm warnings, #936 by @dmontagu</li> <li>Fix usage of <code>Any</code> to allow <code>None</code>, also support <code>TypeVar</code> thus allowing use of un-parameterised collection types   e.g. <code>Dict</code> and <code>List</code>, #962 by @samuelcolvin</li> <li>Set <code>FieldInfo</code> on subfields to fix schema generation for complex nested types, #965 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v10-2019-10-23","title":"v1.0 (2019-10-23)","text":"<ul> <li>Breaking Change: deprecate the <code>Model.fields</code> property, use <code>Model.__fields__</code> instead, #883 by @samuelcolvin</li> <li>Breaking Change: Change the precedence of aliases so child model aliases override parent aliases,   including using <code>alias_generator</code>, #904 by @samuelcolvin</li> <li>Breaking change: Rename <code>skip_defaults</code> to <code>exclude_unset</code>, and add ability to exclude actual defaults, #915 by @dmontagu</li> <li>Add <code>**kwargs</code> to <code>pydantic.main.ModelMetaclass.__new__</code> so <code>__init_subclass__</code> can take custom parameters on extended   <code>BaseModel</code> classes, #867 by @retnikt</li> <li>Fix field of a type that has a default value, #880 by @koxudaxi</li> <li>Use <code>FutureWarning</code> instead of <code>DeprecationWarning</code> when <code>alias</code> instead of <code>env</code> is used for settings models, #881 by @samuelcolvin</li> <li>Fix issue with <code>BaseSettings</code> inheritance and <code>alias</code> getting set to <code>None</code>, #882 by @samuelcolvin</li> <li>Modify <code>__repr__</code> and <code>__str__</code> methods to be consistent across all public classes, add <code>__pretty__</code> to support   python-devtools, #884 by @samuelcolvin</li> <li>deprecation warning for <code>case_insensitive</code> on <code>BaseSettings</code> config, #885 by @samuelcolvin</li> <li>For <code>BaseSettings</code> merge environment variables and in-code values recursively, as long as they create a valid object   when merged together, to allow splitting init arguments, #888 by @idmitrievsky</li> <li>change secret types example, #890 by @ashears</li> <li>Change the signature of <code>Model.construct()</code> to be more user-friendly, document <code>construct()</code> usage, #898 by @samuelcolvin</li> <li>Add example for the <code>construct()</code> method, #907 by @ashears</li> <li>Improve use of <code>Field</code> constraints on complex types, raise an error if constraints are not enforceable,   also support tuples with an ellipsis <code>Tuple[X, ...]</code>, <code>Sequence</code> and <code>FrozenSet</code> in schema, #909 by @samuelcolvin</li> <li>update docs for bool missing valid value, #911 by @trim21</li> <li>Better <code>str</code>/<code>repr</code> logic for <code>ModelField</code>, #912 by @samuelcolvin</li> <li>Fix <code>ConstrainedList</code>, update schema generation to reflect <code>min_items</code> and <code>max_items</code> <code>Field()</code> arguments, #917 by @samuelcolvin</li> <li>Allow abstracts sets (eg. dict keys) in the <code>include</code> and <code>exclude</code> arguments of <code>dict()</code>, #921 by @samuelcolvin</li> <li>Fix JSON serialization errors on <code>ValidationError.json()</code> by using <code>pydantic_encoder</code>, #922 by @samuelcolvin</li> <li>Clarify usage of <code>remove_untouched</code>, improve error message for types with no validators, #926 by @retnikt</li> </ul>"},{"location":"changelog/#v10b2-2019-10-07","title":"v1.0b2 (2019-10-07)","text":"<ul> <li>Mark <code>StrictBool</code> typecheck as <code>bool</code> to allow for default values without mypy errors, #690 by @dmontagu</li> <li>Transfer the documentation build from sphinx to mkdocs, re-write much of the documentation, #856 by @samuelcolvin</li> <li>Add support for custom naming schemes for <code>GenericModel</code> subclasses, #859 by @dmontagu</li> <li>Add <code>if TYPE_CHECKING:</code> to the excluded lines for test coverage, #874 by @dmontagu</li> <li>Rename <code>allow_population_by_alias</code> to <code>allow_population_by_field_name</code>, remove unnecessary warning about it, #875 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v10b1-2019-10-01","title":"v1.0b1 (2019-10-01)","text":"<ul> <li>Breaking Change: rename <code>Schema</code> to <code>Field</code>, make it a function to placate mypy, #577 by @samuelcolvin</li> <li>Breaking Change: modify parsing behavior for <code>bool</code>, #617 by @dmontagu</li> <li>Breaking Change: <code>get_validators</code> is no longer recognised, use <code>__get_validators__</code>.   <code>Config.ignore_extra</code> and <code>Config.allow_extra</code> are no longer recognised, use <code>Config.extra</code>, #720 by @samuelcolvin</li> <li>Breaking Change: modify default config settings for <code>BaseSettings</code>; <code>case_insensitive</code> renamed to <code>case_sensitive</code>,   default changed to <code>case_sensitive = False</code>, <code>env_prefix</code> default changed to <code>''</code> - e.g. no prefix, #721 by @dmontagu</li> <li>Breaking change: Implement <code>root_validator</code> and rename root errors from <code>__obj__</code> to <code>__root__</code>, #729 by @samuelcolvin</li> <li>Breaking Change: alter the behaviour of <code>dict(model)</code> so that sub-models are nolonger   converted to dictionaries, #733 by @samuelcolvin</li> <li>Breaking change: Added <code>initvars</code> support to <code>post_init_post_parse</code>, #748 by @Raphael-C-Almeida</li> <li>Breaking Change: Make <code>BaseModel.json()</code> only serialize the <code>__root__</code> key for models with custom root, #752 by @dmontagu</li> <li>Breaking Change: complete rewrite of <code>URL</code> parsing logic, #755 by @samuelcolvin</li> <li>Breaking Change: preserve superclass annotations for field-determination when not provided in subclass, #757 by @dmontagu</li> <li>Breaking Change: <code>BaseSettings</code> now uses the special <code>env</code> settings to define which environment variables to   read, not aliases, #847 by @samuelcolvin</li> <li>add support for <code>assert</code> statements inside validators, #653 by @abdusco</li> <li>Update documentation to specify the use of <code>pydantic.dataclasses.dataclass</code> and subclassing <code>pydantic.BaseModel</code>, #710 by @maddosaurus</li> <li>Allow custom JSON decoding and encoding via <code>json_loads</code> and <code>json_dumps</code> <code>Config</code> properties, #714 by @samuelcolvin</li> <li>make all annotated fields occur in the order declared, #715 by @dmontagu</li> <li>use pytest to test <code>mypy</code> integration, #735 by @dmontagu</li> <li>add <code>__repr__</code> method to <code>ErrorWrapper</code>, #738 by @samuelcolvin</li> <li>Added support for <code>FrozenSet</code> members in dataclasses, and a better error when attempting to use types from the <code>typing</code> module that are not supported by Pydantic, #745 by @djpetti</li> <li>add documentation for Pycharm Plugin, #750 by @koxudaxi</li> <li>fix broken examples in the docs, #753 by @dmontagu</li> <li>moving typing related objects into <code>pydantic.typing</code>, #761 by @samuelcolvin</li> <li>Minor performance improvements to <code>ErrorWrapper</code>, <code>ValidationError</code> and datetime parsing, #763 by @samuelcolvin</li> <li>Improvements to <code>datetime</code>/<code>date</code>/<code>time</code>/<code>timedelta</code> types: more descriptive errors,   change errors to <code>value_error</code> not <code>type_error</code>, support bytes, #766 by @samuelcolvin</li> <li>fix error messages for <code>Literal</code> types with multiple allowed values, #770 by @dmontagu</li> <li>Improved auto-generated <code>title</code> field in JSON schema by converting underscore to space, #772 by @skewty</li> <li>support <code>mypy --no-implicit-reexport</code> for dataclasses, also respect <code>--no-implicit-reexport</code> in pydantic itself, #783 by @samuelcolvin</li> <li>add the <code>PaymentCardNumber</code> type, #790 by @matin</li> <li>Fix const validations for lists, #794 by @hmvp</li> <li>Set <code>additionalProperties</code> to false in schema for models with extra fields disallowed, #796 by @Code0x58</li> <li><code>EmailStr</code> validation method now returns local part case-sensitive per RFC 5321, #798 by @henriklindgren</li> <li>Added ability to validate strictness to <code>ConstrainedFloat</code>, <code>ConstrainedInt</code> and <code>ConstrainedStr</code> and added   <code>StrictFloat</code> and <code>StrictInt</code> classes, #799 by @DerRidda</li> <li>Improve handling of <code>None</code> and <code>Optional</code>, replace <code>whole</code> with <code>each_item</code> (inverse meaning, default <code>False</code>)   on validators, #803 by @samuelcolvin</li> <li>add support for <code>Type[T]</code> type hints, #807 by @timonbimon</li> <li>Performance improvements from removing <code>change_exceptions</code>, change how pydantic error are constructed, #819 by @samuelcolvin</li> <li>Fix the error message arising when a <code>BaseModel</code>-type model field causes a <code>ValidationError</code> during parsing, #820 by @dmontagu</li> <li>allow <code>getter_dict</code> on <code>Config</code>, modify <code>GetterDict</code> to be more like a <code>Mapping</code> object and thus easier to work with, #821 by @samuelcolvin</li> <li>Only check <code>TypeVar</code> param on base <code>GenericModel</code> class, #842 by @zpencerq</li> <li>rename <code>Model._schema_cache</code> -&gt; <code>Model.__schema_cache__</code>, <code>Model._json_encoder</code> -&gt; <code>Model.__json_encoder__</code>,   <code>Model._custom_root_type</code> -&gt; <code>Model.__custom_root_type__</code>, #851 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0322-2019-08-17","title":"v0.32.2 (2019-08-17)","text":"<p>(Docs are available here)</p> <ul> <li>fix <code>__post_init__</code> usage with dataclass inheritance, fix #739 by @samuelcolvin</li> <li>fix required fields validation on GenericModels classes, #742 by @amitbl</li> <li>fix defining custom <code>Schema</code> on <code>GenericModel</code> fields, #754 by @amitbl</li> </ul>"},{"location":"changelog/#v0321-2019-08-08","title":"v0.32.1 (2019-08-08)","text":"<ul> <li>do not validate extra fields when <code>validate_assignment</code> is on, #724 by @YaraslauZhylko</li> </ul>"},{"location":"changelog/#v032-2019-08-06","title":"v0.32 (2019-08-06)","text":"<ul> <li>add model name to <code>ValidationError</code> error message, #676 by @dmontagu</li> <li>breaking change: remove <code>__getattr__</code> and rename <code>__values__</code> to <code>__dict__</code> on <code>BaseModel</code>,   deprecation warning on use <code>__values__</code> attr, attributes access speed increased up to 14 times, #712 by @Bobronium</li> <li>support <code>ForwardRef</code> (without self-referencing annotations) in Python 3.6, #706 by @koxudaxi</li> <li>implement <code>schema_extra</code> in <code>Config</code> sub-class, #663 by @tiangolo</li> </ul>"},{"location":"changelog/#v0311-2019-07-31","title":"v0.31.1 (2019-07-31)","text":"<ul> <li>fix json generation for <code>EnumError</code>, #697 by @dmontagu</li> <li>update numerous dependencies</li> </ul>"},{"location":"changelog/#v031-2019-07-24","title":"v0.31 (2019-07-24)","text":"<ul> <li>better support for floating point <code>multiple_of</code> values, #652 by @justindujardin</li> <li>fix schema generation for <code>NewType</code> and <code>Literal</code>, #649 by @dmontagu</li> <li>fix <code>alias_generator</code> and field config conflict, #645 by @gmetzker and #658 by @Bobronium</li> <li>more detailed message for <code>EnumError</code>, #673 by @dmontagu</li> <li>add advanced exclude support for <code>dict</code>, <code>json</code> and <code>copy</code>, #648 by @Bobronium</li> <li>fix bug in <code>GenericModel</code> for models with concrete parameterized fields, #672 by @dmontagu</li> <li>add documentation for <code>Literal</code> type, #651 by @dmontagu</li> <li>add <code>Config.keep_untouched</code> for custom descriptors support, #679 by @Bobronium</li> <li>use <code>inspect.cleandoc</code> internally to get model description, #657 by @tiangolo</li> <li>add <code>Color</code> to schema generation, by @euri10</li> <li>add documentation for Literal type, #651 by @dmontagu</li> </ul>"},{"location":"changelog/#v0301-2019-07-15","title":"v0.30.1 (2019-07-15)","text":"<ul> <li>fix so nested classes which inherit and change <code>__init__</code> are correctly processed while still allowing <code>self</code> as a   parameter, #644 by @lnaden and @dgasmith</li> </ul>"},{"location":"changelog/#v030-2019-07-07","title":"v0.30 (2019-07-07)","text":"<ul> <li>enforce single quotes in code, #612 by @samuelcolvin</li> <li>fix infinite recursion with dataclass inheritance and <code>__post_init__</code>, #606 by @Hanaasagi</li> <li>fix default values for <code>GenericModel</code>, #610 by @dmontagu</li> <li>clarify that self-referencing models require Python 3.7+, #616 by @vlcinsky</li> <li>fix truncate for types, #611 by @dmontagu</li> <li>add <code>alias_generator</code> support, #622 by @Bobronium</li> <li>fix unparameterized generic type schema generation, #625 by @dmontagu</li> <li>fix schema generation with multiple/circular references to the same model, #621 by @tiangolo and @wongpat</li> <li>support custom root types, #628 by @koxudaxi</li> <li>support <code>self</code> as a field name in <code>parse_obj</code>, #632 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v029-2019-06-19","title":"v0.29 (2019-06-19)","text":"<ul> <li>support dataclasses.InitVar, #592 by @pfrederiks</li> <li>Updated documentation to elucidate the usage of <code>Union</code> when defining multiple types under an attribute's   annotation and showcase how the type-order can affect marshalling of provided values, #594 by @somada141</li> <li>add <code>conlist</code> type, #583 by @hmvp</li> <li>add support for generics, #595 by @dmontagu</li> </ul>"},{"location":"changelog/#v028-2019-06-06","title":"v0.28 (2019-06-06)","text":"<ul> <li>fix support for JSON Schema generation when using models with circular references in Python 3.7, #572 by @tiangolo</li> <li>support <code>__post_init_post_parse__</code> on dataclasses, #567 by @sevaho</li> <li>allow dumping dataclasses to JSON, #575 by @samuelcolvin and @DanielOberg</li> <li>ORM mode, #562 by @samuelcolvin</li> <li>fix <code>pydantic.compiled</code> on ipython, #573 by @dmontagu and @samuelcolvin</li> <li>add <code>StrictBool</code> type, #579 by @cazgp</li> </ul>"},{"location":"changelog/#v027-2019-05-30","title":"v0.27 (2019-05-30)","text":"<ul> <li>breaking change <code>_pydantic_post_init</code> to execute dataclass' original <code>__post_init__</code> before   validation, #560 by @HeavenVolkoff</li> <li>fix handling of generic types without specified parameters, #550 by @dmontagu</li> <li>breaking change (maybe): this is the first release compiled with cython, see the docs and please   submit an issue if you run into problems</li> </ul>"},{"location":"changelog/#v0270a1-2019-05-26","title":"v0.27.0a1 (2019-05-26)","text":"<ul> <li>fix JSON Schema for <code>list</code>, <code>tuple</code>, and <code>set</code>, #540 by @tiangolo</li> <li>compiling with cython, <code>manylinux</code> binaries, some other performance improvements, #548 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v026-2019-05-22","title":"v0.26 (2019-05-22)","text":"<ul> <li>fix to schema generation for <code>IPvAnyAddress</code>, <code>IPvAnyInterface</code>, <code>IPvAnyNetwork</code> #498 by @pilosus</li> <li>fix variable length tuples support, #495 by @pilosus</li> <li>fix return type hint for <code>create_model</code>, #526 by @dmontagu</li> <li>Breaking Change: fix <code>.dict(skip_keys=True)</code> skipping values set via alias (this involves changing   <code>validate_model()</code> to always returns <code>Tuple[Dict[str, Any], Set[str], Optional[ValidationError]]</code>), #517 by @sommd</li> <li>fix to schema generation for <code>IPv4Address</code>, <code>IPv6Address</code>, <code>IPv4Interface</code>,   <code>IPv6Interface</code>, <code>IPv4Network</code>, <code>IPv6Network</code> #532 by @euri10</li> <li>add <code>Color</code> type, #504 by @pilosus and @samuelcolvin</li> </ul>"},{"location":"changelog/#v025-2019-05-05","title":"v0.25 (2019-05-05)","text":"<ul> <li>Improve documentation on self-referencing models and annotations, #487 by @theenglishway</li> <li>fix <code>.dict()</code> with extra keys, #490 by @JaewonKim</li> <li>support <code>const</code> keyword in <code>Schema</code>, #434 by @Sean1708</li> </ul>"},{"location":"changelog/#v024-2019-04-23","title":"v0.24 (2019-04-23)","text":"<ul> <li>fix handling <code>ForwardRef</code> in sub-types, like <code>Union</code>, #464 by @tiangolo</li> <li>fix secret serialization, #465 by @atheuz</li> <li>Support custom validators for dataclasses, #454 by @primal100</li> <li>fix <code>parse_obj</code> to cope with dict-like objects, #472 by @samuelcolvin</li> <li>fix to schema generation in nested dataclass-based models, #474 by @NoAnyLove</li> <li>fix <code>json</code> for <code>Path</code>, <code>FilePath</code>, and <code>DirectoryPath</code> objects, #473 by @mikegoodspeed</li> </ul>"},{"location":"changelog/#v023-2019-04-04","title":"v0.23 (2019-04-04)","text":"<ul> <li>improve documentation for contributing section, #441 by @pilosus</li> <li>improve README.rst to include essential information about the package, #446 by @pilosus</li> <li><code>IntEnum</code> support, #444 by @potykion</li> <li>fix PyObject callable value, #409 by @pilosus</li> <li>fix <code>black</code> deprecation warnings after update, #451 by @pilosus</li> <li>fix <code>ForwardRef</code> collection bug, #450 by @tigerwings</li> <li>Support specialized <code>ClassVars</code>, #455 by @tyrylu</li> <li>fix JSON serialization for <code>ipaddress</code> types, #333 by @pilosus</li> <li>add <code>SecretStr</code> and <code>SecretBytes</code> types, #452 by @atheuz</li> </ul>"},{"location":"changelog/#v022-2019-03-29","title":"v0.22 (2019-03-29)","text":"<ul> <li>add <code>IPv{4,6,Any}Network</code> and <code>IPv{4,6,Any}Interface</code> types from <code>ipaddress</code> stdlib, #333 by @pilosus</li> <li>add docs for <code>datetime</code> types, #386 by @pilosus</li> <li>fix to schema generation in dataclass-based models, #408 by @pilosus</li> <li>fix path in nested models, #437 by @kataev</li> <li>add <code>Sequence</code> support, #304 by @pilosus</li> </ul>"},{"location":"changelog/#v0210-2019-03-15","title":"v0.21.0 (2019-03-15)","text":"<ul> <li>fix typo in <code>NoneIsNotAllowedError</code> message, #414 by @YaraslauZhylko</li> <li>add <code>IPvAnyAddress</code>, <code>IPv4Address</code> and <code>IPv6Address</code> types, #333 by @pilosus</li> </ul>"},{"location":"changelog/#v0201-2019-02-26","title":"v0.20.1 (2019-02-26)","text":"<ul> <li>fix type hints of <code>parse_obj</code> and similar methods, #405 by @erosennin</li> <li>fix submodel validation, #403 by @samuelcolvin</li> <li>correct type hints for <code>ValidationError.json</code>, #406 by @layday</li> </ul>"},{"location":"changelog/#v0200-2019-02-18","title":"v0.20.0 (2019-02-18)","text":"<ul> <li>fix tests for Python 3.8, #396 by @samuelcolvin</li> <li>Adds fields to the <code>dir</code> method for autocompletion in interactive sessions, #398 by @dgasmith</li> <li>support <code>ForwardRef</code> (and therefore <code>from __future__ import annotations</code>) with dataclasses, #397 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0200a1-2019-02-13","title":"v0.20.0a1 (2019-02-13)","text":"<ul> <li>breaking change (maybe): more sophisticated argument parsing for validators, any subset of   <code>values</code>, <code>config</code> and <code>field</code> is now permitted, eg. <code>(cls, value, field)</code>,   however the variadic key word argument (\"<code>**kwargs</code>\") must be called <code>kwargs</code>, #388 by @samuelcolvin</li> <li>breaking change: Adds <code>skip_defaults</code> argument to <code>BaseModel.dict()</code> to allow skipping of fields that   were not explicitly set, signature of <code>Model.construct()</code> changed, #389 by @dgasmith</li> <li>add <code>py.typed</code> marker file for PEP-561 support, #391 by @je-l</li> <li>Fix <code>extra</code> behaviour for multiple inheritance/mix-ins, #394 by @YaraslauZhylko</li> </ul>"},{"location":"changelog/#v0190-2019-02-04","title":"v0.19.0 (2019-02-04)","text":"<ul> <li>Support <code>Callable</code> type hint, fix #279 by @proofit404</li> <li>Fix schema for fields with <code>validator</code> decorator, fix #375 by @tiangolo</li> <li>Add <code>multiple_of</code> constraint to <code>ConstrainedDecimal</code>, <code>ConstrainedFloat</code>, <code>ConstrainedInt</code>   and their related types <code>condecimal</code>, <code>confloat</code>, and <code>conint</code> #371, thanks @StephenBrown2</li> <li>Deprecated <code>ignore_extra</code> and <code>allow_extra</code> Config fields in favor of <code>extra</code>, #352 by @liiight</li> <li>Add type annotations to all functions, test fully with mypy, #373 by @samuelcolvin</li> <li>fix for 'missing' error with <code>validate_all</code> or <code>validate_always</code>, #381 by @samuelcolvin</li> <li>Change the second/millisecond watershed for date/datetime parsing to <code>2e10</code>, #385 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0182-2019-01-22","title":"v0.18.2 (2019-01-22)","text":"<ul> <li>Fix to schema generation with <code>Optional</code> fields, fix #361 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0181-2019-01-17","title":"v0.18.1 (2019-01-17)","text":"<ul> <li>add <code>ConstrainedBytes</code> and <code>conbytes</code> types, #315 @Gr1N</li> <li>adding <code>MANIFEST.in</code> to include license in package <code>.tar.gz</code>, #358 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0180-2019-01-13","title":"v0.18.0 (2019-01-13)","text":"<ul> <li>breaking change: don't call validators on keys of dictionaries, #254 by @samuelcolvin</li> <li>Fix validators with <code>always=True</code> when the default is <code>None</code> or the type is optional, also prevent   <code>whole</code> validators being called for sub-fields, fix #132 by @samuelcolvin</li> <li>improve documentation for settings priority and allow it to be easily changed, #343 by @samuelcolvin</li> <li>fix <code>ignore_extra=False</code> and <code>allow_population_by_alias=True</code>, fix #257 by @samuelcolvin</li> <li>breaking change: Set <code>BaseConfig</code> attributes <code>min_anystr_length</code> and <code>max_anystr_length</code> to   <code>None</code> by default, fix #349 in #350 by @tiangolo</li> <li>add support for postponed annotations, #348 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0170-2018-12-27","title":"v0.17.0 (2018-12-27)","text":"<ul> <li>fix schema for <code>timedelta</code> as number, #325 by @tiangolo</li> <li>prevent validators being called repeatedly after inheritance, #327 by @samuelcolvin</li> <li>prevent duplicate validator check in ipython, fix #312 by @samuelcolvin</li> <li>add \"Using Pydantic\" section to docs, #323 by @tiangolo &amp; #326 by @samuelcolvin</li> <li>fix schema generation for fields annotated as <code>: dict</code>, <code>: list</code>,   <code>: tuple</code> and <code>: set</code>, #330 &amp; #335 by @nkonin</li> <li>add support for constrained strings as dict keys in schema, #332 by @tiangolo</li> <li>support for passing Config class in dataclasses decorator, #276 by @jarekkar   (breaking change: this supersedes the <code>validate_assignment</code> argument with <code>config</code>)</li> <li>support for nested dataclasses, #334 by @samuelcolvin</li> <li>better errors when getting an <code>ImportError</code> with <code>PyObject</code>, #309 by @samuelcolvin</li> <li>rename <code>get_validators</code> to <code>__get_validators__</code>, deprecation warning on use of old name, #338 by @samuelcolvin</li> <li>support <code>ClassVar</code> by excluding such attributes from fields, #184 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0161-2018-12-10","title":"v0.16.1 (2018-12-10)","text":"<ul> <li>fix <code>create_model</code> to correctly use the passed <code>__config__</code>, #320 by @hugoduncan</li> </ul>"},{"location":"changelog/#v0160-2018-12-03","title":"v0.16.0 (2018-12-03)","text":"<ul> <li>breaking change: refactor schema generation to be compatible with JSON Schema and OpenAPI specs, #308 by @tiangolo</li> <li>add <code>schema</code> to <code>schema</code> module to generate top-level schemas from base models, #308 by @tiangolo</li> <li>add additional fields to <code>Schema</code> class to declare validation for <code>str</code> and numeric values, #311 by @tiangolo</li> <li>rename <code>_schema</code> to <code>schema</code> on fields, #318 by @samuelcolvin</li> <li>add <code>case_insensitive</code> option to <code>BaseSettings</code> <code>Config</code>, #277 by @jasonkuhrt</li> </ul>"},{"location":"changelog/#v0150-2018-11-18","title":"v0.15.0 (2018-11-18)","text":"<ul> <li>move codebase to use black, #287 by @samuelcolvin</li> <li>fix alias use in settings, #286 by @jasonkuhrt and @samuelcolvin</li> <li>fix datetime parsing in <code>parse_date</code>, #298 by @samuelcolvin</li> <li>allow dataclass inheritance, fix #293 by @samuelcolvin</li> <li>fix <code>PyObject = None</code>, fix #305 by @samuelcolvin</li> <li>allow <code>Pattern</code> type, fix #303 by @samuelcolvin</li> </ul>"},{"location":"changelog/#v0140-2018-10-02","title":"v0.14.0 (2018-10-02)","text":"<ul> <li>dataclasses decorator, #269 by @Gaunt and @samuelcolvin</li> </ul>"},{"location":"changelog/#v0131-2018-09-21","title":"v0.13.1 (2018-09-21)","text":"<ul> <li>fix issue where int_validator doesn't cast a <code>bool</code> to an <code>int</code> #264 by @nphyatt</li> <li>add deep copy support for <code>BaseModel.copy()</code> #249, @gangefors</li> </ul>"},{"location":"changelog/#v0130-2018-08-25","title":"v0.13.0 (2018-08-25)","text":"<ul> <li>raise an exception if a field's name shadows an existing <code>BaseModel</code> attribute #242</li> <li>add <code>UrlStr</code> and <code>urlstr</code> types #236</li> <li>timedelta json encoding ISO8601 and total seconds, custom json encoders #247, by @cfkanesan and @samuelcolvin</li> <li>allow <code>timedelta</code> objects as values for properties of type <code>timedelta</code> (matches <code>datetime</code> etc. behavior) #247</li> </ul>"},{"location":"changelog/#v0121-2018-07-31","title":"v0.12.1 (2018-07-31)","text":"<ul> <li>fix schema generation for fields defined using <code>typing.Any</code> #237</li> </ul>"},{"location":"changelog/#v0120-2018-07-31","title":"v0.12.0 (2018-07-31)","text":"<ul> <li>add <code>by_alias</code> argument in <code>.dict()</code> and <code>.json()</code> model methods #205</li> <li>add Json type support #214</li> <li>support tuples #227</li> <li>major improvements and changes to schema #213</li> </ul>"},{"location":"changelog/#v0112-2018-07-05","title":"v0.11.2 (2018-07-05)","text":"<ul> <li>add <code>NewType</code> support #115</li> <li>fix <code>list</code>, <code>set</code> &amp; <code>tuple</code> validation #225</li> <li>separate out <code>validate_model</code> method, allow errors to be returned along with valid values #221</li> </ul>"},{"location":"changelog/#v0111-2018-07-02","title":"v0.11.1 (2018-07-02)","text":"<ul> <li>support Python 3.7 #216, thanks @layday</li> <li>Allow arbitrary types in model #209, thanks @oldPadavan</li> </ul>"},{"location":"changelog/#v0110-2018-06-28","title":"v0.11.0 (2018-06-28)","text":"<ul> <li>make <code>list</code>, <code>tuple</code> and <code>set</code> types stricter #86</li> <li>breaking change: remove msgpack parsing #201</li> <li>add <code>FilePath</code> and <code>DirectoryPath</code> types #10</li> <li>model schema generation #190</li> <li>JSON serialization of models and schemas #133</li> </ul>"},{"location":"changelog/#v0100-2018-06-11","title":"v0.10.0 (2018-06-11)","text":"<ul> <li>add <code>Config.allow_population_by_alias</code> #160, thanks @bendemaree</li> <li>breaking change: new errors format #179, thanks @Gr1N</li> <li>breaking change: removed <code>Config.min_number_size</code> and <code>Config.max_number_size</code> #183, thanks @Gr1N</li> <li>breaking change: correct behaviour of <code>lt</code> and <code>gt</code> arguments to <code>conint</code> etc. #188   for the old behaviour use <code>le</code> and <code>ge</code> #194, thanks @jaheba</li> <li>added error context and ability to redefine error message templates using <code>Config.error_msg_templates</code> #183,   thanks @Gr1N</li> <li>fix typo in validator exception #150</li> <li>copy defaults to model values, so different models don't share objects #154</li> </ul>"},{"location":"changelog/#v091-2018-05-10","title":"v0.9.1 (2018-05-10)","text":"<ul> <li>allow custom <code>get_field_config</code> on config classes #159</li> <li>add <code>UUID1</code>, <code>UUID3</code>, <code>UUID4</code> and <code>UUID5</code> types #167, thanks @Gr1N</li> <li>modify some inconsistent docstrings and annotations #173, thanks @YannLuo</li> <li>fix type annotations for exotic types #171, thanks @Gr1N</li> <li>re-use type validators in exotic types #171</li> <li>scheduled monthly requirements updates #168</li> <li>add <code>Decimal</code>, <code>ConstrainedDecimal</code> and <code>condecimal</code> types #170, thanks @Gr1N</li> </ul>"},{"location":"changelog/#v090-2018-04-28","title":"v0.9.0 (2018-04-28)","text":"<ul> <li>tweak email-validator import error message #145</li> <li>fix parse error of <code>parse_date()</code> and <code>parse_datetime()</code> when input is 0 #144, thanks @YannLuo</li> <li>add <code>Config.anystr_strip_whitespace</code> and <code>strip_whitespace</code> kwarg to <code>constr</code>,   by default values is <code>False</code> #163, thanks @Gr1N</li> <li>add <code>ConstrainedFloat</code>, <code>confloat</code>, <code>PositiveFloat</code> and <code>NegativeFloat</code> types #166, thanks @Gr1N</li> </ul>"},{"location":"changelog/#v080-2018-03-25","title":"v0.8.0 (2018-03-25)","text":"<ul> <li>fix type annotation for <code>inherit_config</code> #139</li> <li>breaking change: check for invalid field names in validators #140</li> <li>validate attributes of parent models #141</li> <li>breaking change: email validation now uses   email-validator #142</li> </ul>"},{"location":"changelog/#v071-2018-02-07","title":"v0.7.1 (2018-02-07)","text":"<ul> <li>fix bug with <code>create_model</code> modifying the base class</li> </ul>"},{"location":"changelog/#v070-2018-02-06","title":"v0.7.0 (2018-02-06)","text":"<ul> <li>added compatibility with abstract base classes (ABCs) #123</li> <li>add <code>create_model</code> method #113 #125</li> <li>breaking change: rename <code>.config</code> to <code>.__config__</code> on a model</li> <li>breaking change: remove deprecated <code>.values()</code> on a model, use <code>.dict()</code> instead</li> <li>remove use of <code>OrderedDict</code> and use simple dict #126</li> <li>add <code>Config.use_enum_values</code> #127</li> <li>add wildcard validators of the form <code>@validate('*')</code> #128</li> </ul>"},{"location":"changelog/#v064-2018-02-01","title":"v0.6.4 (2018-02-01)","text":"<ul> <li>allow Python date and times objects #122</li> </ul>"},{"location":"changelog/#v063-2017-11-26","title":"v0.6.3 (2017-11-26)","text":"<ul> <li>fix direct install without <code>README.rst</code> present</li> </ul>"},{"location":"changelog/#v062-2017-11-13","title":"v0.6.2 (2017-11-13)","text":"<ul> <li>errors for invalid validator use</li> <li>safer check for complex models in <code>Settings</code></li> </ul>"},{"location":"changelog/#v061-2017-11-08","title":"v0.6.1 (2017-11-08)","text":"<ul> <li>prevent duplicate validators, #101</li> <li>add <code>always</code> kwarg to validators, #102</li> </ul>"},{"location":"changelog/#v060-2017-11-07","title":"v0.6.0 (2017-11-07)","text":"<ul> <li>assignment validation #94, thanks petroswork!</li> <li>JSON in environment variables for complex types, #96</li> <li>add <code>validator</code> decorators for complex validation, #97</li> <li>depreciate <code>values(...)</code> and replace with <code>.dict(...)</code>, #99</li> </ul>"},{"location":"changelog/#v050-2017-10-23","title":"v0.5.0 (2017-10-23)","text":"<ul> <li>add <code>UUID</code> validation #89</li> <li>remove <code>index</code> and <code>track</code> from error object (json) if they're null #90</li> <li>improve the error text when a list is provided rather than a dict #90</li> <li>add benchmarks table to docs #91</li> </ul>"},{"location":"changelog/#v040-2017-07-08","title":"v0.4.0 (2017-07-08)","text":"<ul> <li>show length in string validation error</li> <li>fix aliases in config during inheritance #55</li> <li>simplify error display</li> <li>use unicode ellipsis in <code>truncate</code></li> <li>add <code>parse_obj</code>, <code>parse_raw</code> and <code>parse_file</code> helper functions #58</li> <li>switch annotation only fields to come first in fields list not last</li> </ul>"},{"location":"changelog/#v030-2017-06-21","title":"v0.3.0 (2017-06-21)","text":"<ul> <li>immutable models via <code>config.allow_mutation = False</code>, associated cleanup and performance improvement #44</li> <li>immutable helper methods <code>construct()</code> and <code>copy()</code> #53</li> <li>allow pickling of models #53</li> <li><code>setattr</code> is removed as <code>__setattr__</code> is now intelligent #44</li> <li><code>raise_exception</code> removed, Models now always raise exceptions #44</li> <li>instance method validators removed</li> <li>django-restful-framework benchmarks added #47</li> <li>fix inheritance bug #49</li> <li>make str type stricter so list, dict etc are not coerced to strings. #52</li> <li>add <code>StrictStr</code> which only always strings as input #52</li> </ul>"},{"location":"changelog/#v021-2017-06-07","title":"v0.2.1 (2017-06-07)","text":"<ul> <li>pypi and travis together messed up the deploy of <code>v0.2</code> this should fix it</li> </ul>"},{"location":"changelog/#v020-2017-06-07","title":"v0.2.0 (2017-06-07)","text":"<ul> <li>breaking change: <code>values()</code> on a model is now a method not a property,   takes <code>include</code> and <code>exclude</code> arguments</li> <li>allow annotation only fields to support mypy</li> <li>add pretty <code>to_string(pretty=True)</code> method for models</li> </ul>"},{"location":"changelog/#v010-2017-06-03","title":"v0.1.0 (2017-06-03)","text":"<ul> <li>add docs</li> <li>add history</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>We'd love you to contribute to Pydantic!</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Questions, feature requests and bug reports are all welcome as discussions or issues. However, to report a security vulnerability, please see our security policy.</p> <p>To make it as simple as possible for us to help you, please include the output of the following call in your issue:</p> <p><pre><code>python -c \"import pydantic.version; print(pydantic.version.version_info())\"\n</code></pre> If you're using Pydantic prior to v2.0 please use: <pre><code>python -c \"import pydantic.utils; print(pydantic.utils.version_info())\"\n</code></pre></p> <p>Please try to always include the above unless you're unable to install Pydantic or know it's not relevant to your question or feature request.</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>It should be extremely simple to get started and create a Pull Request. Pydantic is released regularly so you should see your improvements release in a matter of days or weeks \ud83d\ude80.</p> <p>Unless your change is trivial (typo, docs tweak etc.), please create an issue to discuss the change before creating a pull request.</p> <p>Pydantic V1 is in maintenance mode</p> <p>Pydantic v1 is in maintenance mode, meaning that only bug fixes and security fixes will be accepted. New features should be targeted at Pydantic v2.</p> <p>To submit a fix to Pydantic v1, use the <code>1.10.X-fixes</code> as a target branch.</p> <p>If you're looking for something to get your teeth into, check out the \"help wanted\" label on github.</p> <p>To make contributing as easy and fast as possible, you'll want to run tests and linting locally. Luckily, Pydantic has few dependencies, doesn't require compiling and tests don't need access to databases, etc. Because of this, setting up and running the tests should be very simple.</p> <p>Tip</p> <p>tl;dr: use <code>make format</code> to fix formatting, <code>make</code> to run tests and linting and <code>make docs</code> to build the docs.</p>"},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<p>You'll need the following prerequisites:</p> <ul> <li>Any Python version between Python 3.9 and 3.12</li> <li>virtualenv or other virtual environment tool</li> <li>git</li> <li>make</li> <li>PDM</li> </ul>"},{"location":"contributing/#installation-and-setup","title":"Installation and setup","text":"<p>Fork the repository on GitHub and clone your fork locally.</p> <pre><code># Clone your fork and cd into the repo directory\ngit clone git@github.com:&lt;your username&gt;/pydantic.git\ncd pydantic\n\n# Install PDM and pre-commit\n# We use pipx here, for other options see:\n# https://pdm.fming.dev/latest/#installation\n# https://pre-commit.com/#install\n# To get pipx itself:\n# https://pypa.github.io/pipx/\npipx install pdm\npipx install pre-commit\n\n# Install pydantic, dependencies, test dependencies and doc dependencies\nmake install\n</code></pre>"},{"location":"contributing/#check-out-a-new-branch-and-make-your-changes","title":"Check out a new branch and make your changes","text":"<p>Create a new branch for your changes.</p> <pre><code># Checkout a new branch and make your changes\ngit checkout -b my-new-feature-branch\n# Make your changes...\n</code></pre>"},{"location":"contributing/#run-tests-and-linting","title":"Run tests and linting","text":"<p>Run tests and linting locally to make sure everything is working as expected.</p> <pre><code># Run automated code formatting and linting\nmake format\n# Pydantic uses ruff, an awesome Python linter written in rust\n# https://github.com/astral-sh/ruff\n\n# Run tests and linting\nmake\n# There are a few sub-commands in Makefile like `test`, `testcov` and `lint`\n# which you might want to use, but generally just `make` should be all you need.\n# You can run `make help` to see more options.\n</code></pre>"},{"location":"contributing/#build-documentation","title":"Build documentation","text":"<p>If you've made any changes to the documentation (including changes to function signatures, class definitions, or docstrings that will appear in the API documentation), make sure it builds successfully.</p> <pre><code># Build documentation\nmake docs\n# If you have changed the documentation, make sure it builds successfully.\n# You can also use `pdm run mkdocs serve` to serve the documentation at localhost:8000\n</code></pre>"},{"location":"contributing/#commit-and-push-your-changes","title":"Commit and push your changes","text":"<p>Commit your changes, push your branch to GitHub, and create a pull request.</p> <p>Please follow the pull request template and fill in as much information as possible. Link to any relevant issues and include a description of your changes.</p> <p>When your pull request is ready for review, add a comment with the message \"please review\" and we'll take a look as soon as we can.</p>"},{"location":"contributing/#documentation-style","title":"Documentation style","text":"<p>Documentation is written in Markdown and built using Material for MkDocs. API documentation is build from docstrings using mkdocstrings.</p>"},{"location":"contributing/#code-documentation","title":"Code documentation","text":"<p>When contributing to Pydantic, please make sure that all code is well documented. The following should be documented using properly formatted docstrings:</p> <ul> <li>Modules</li> <li>Class definitions</li> <li>Function definitions</li> <li>Module-level variables</li> </ul> <p>Pydantic uses Google-style docstrings formatted according to PEP 257 guidelines. (See Example Google Style Python Docstrings for further examples.)</p> <p>pydocstyle is used for linting docstrings. You can run <code>make format</code> to check your docstrings.</p> <p>Where this is a conflict between Google-style docstrings and pydocstyle linting, follow the pydocstyle linting hints.</p> <p>Class attributes and function arguments should be documented in the format \"name: description.\" When applicable, a return type should be documented with just a description. Types are inferred from the signature.</p> <pre><code>class Foo:\n    \"\"\"A class docstring.\n\n    Attributes:\n        bar: A description of bar. Defaults to \"bar\".\n    \"\"\"\n\n    bar: str = 'bar'\n</code></pre> <pre><code>def bar(self, baz: int) -&gt; str:\n    \"\"\"A function docstring.\n\n    Args:\n        baz: A description of `baz`.\n\n    Returns:\n        A description of the return value.\n    \"\"\"\n\n    return 'bar'\n</code></pre> <p>You may include example code in docstrings. This code should be complete, self-contained, and runnable. Docstring examples are tested, so make sure they are correct and complete. See <code>FieldInfo.from_annotated_attribute</code> for an example.</p> <p>Class and instance attributes</p> <p>Class attributes should be documented in the class docstring.</p> <p>Instance attributes should be documented as \"Args\" in the <code>__init__</code> docstring.</p>"},{"location":"contributing/#documentation-style_1","title":"Documentation Style","text":"<p>In general, documentation should be written in a friendly, approachable style. It should be easy to read and understand, and should be as concise as possible while still being complete.</p> <p>Code examples are encouraged, but should be kept short and simple. However, every code example should be complete, self-contained, and runnable. (If you're not sure how to do this, ask for help!) We prefer print output to naked asserts, but if you're testing something that doesn't have a useful print output, asserts are fine.</p> <p>Pydantic's unit test will test all code examples in the documentation, so it's important that they are correct and complete. When adding a new code example, use the following to test examples and update their formatting and output:</p> <pre><code># Run tests and update code examples\npytest tests/test_docs.py --update-examples\n</code></pre>"},{"location":"contributing/#debugging-python-and-rust","title":"Debugging Python and Rust","text":"<p>If you're working with <code>pydantic</code> and <code>pydantic-core</code>, you might find it helpful to debug Python and Rust code together. Here's a quick guide on how to do that. This tutorial is done in VSCode, but you can use similar steps in other IDEs.</p>"},{"location":"contributing/#badges","title":"Badges","text":"<p>Pydantic has a badge that you can use to show that your project uses Pydantic. You can use this badge in your <code>README.md</code>:</p>"},{"location":"contributing/#with-markdown","title":"With Markdown","text":"<pre><code>[![Pydantic v1](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json)](https://pydantic.dev)\n\n[![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)](https://pydantic.dev)\n</code></pre>"},{"location":"contributing/#with-restructuredtext","title":"With reStructuredText","text":"<pre><code>.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json\n    :target: https://pydantic.dev\n    :alt: Pydantic\n\n.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json\n    :target: https://pydantic.dev\n    :alt: Pydantic\n</code></pre>"},{"location":"contributing/#with-html","title":"With HTML","text":"<pre><code>&lt;a href=\"https://pydantic.dev\"&gt;&lt;img src=\"https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json\" alt=\"Pydantic Version 1\" style=\"max-width:100%;\"&gt;&lt;/a&gt;\n\n&lt;a href=\"https://pydantic.dev\"&gt;&lt;img src=\"https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json\" alt=\"Pydantic Version 2\" style=\"max-width:100%;\"&gt;&lt;/a&gt;\n</code></pre>"},{"location":"help_with_pydantic/","title":"Getting help with Pydantic","text":"<p>If you need help getting started with Pydantic or with advanced usage, the following sources may be useful.</p>"},{"location":"help_with_pydantic/#usage-documentation","title":"Usage Documentation","text":"<p>The usage documentation is the most complete guide on how to use Pydantic.</p>"},{"location":"help_with_pydantic/#api-documentation","title":"API Documentation","text":"<p>The API documentation give reference docs for all public Pydantic APIs.</p>"},{"location":"help_with_pydantic/#github-discussions","title":"GitHub Discussions","text":"<p>GitHub discussions are useful for asking questions, your question and the answer will help everyone.</p>"},{"location":"help_with_pydantic/#stack-overflow","title":"Stack Overflow","text":"<p>Use the <code>pydantic</code> tag on Stack Overflow to ask questions, note this is not always monitored by the core Pydantic team.</p>"},{"location":"help_with_pydantic/#youtube","title":"YouTube","text":"<p>Youtube as lots of useful videos on Pydantic.</p> <p>In particular Marcelo Trylesinski's video \"Pydantic V1 to V2 - The Migration\" has helped people a lot when migrating from Pydantic V1 to V2.</p>"},{"location":"install/","title":"Installation","text":"<p>Installation is as simple as:</p> <pre><code>pip install pydantic\n</code></pre> <p>Pydantic has a few dependencies:</p> <ul> <li><code>pydantic-core</code>: Core validation logic for pydantic written in rust.</li> <li><code>typing-extensions</code>: Backport of the standard library typing module.</li> <li><code>annotated-types</code>: Reusable constraint types to use with <code>typing.Annotated</code>.</li> </ul> <p>If you've got Python 3.8+ and <code>pip</code> installed, you're good to go.</p> <p>Pydantic is also available on conda under the conda-forge channel:</p> <pre><code>conda install pydantic -c conda-forge\n</code></pre>"},{"location":"install/#optional-dependencies","title":"Optional dependencies","text":"<p>Pydantic has the following optional dependencies:</p> <ul> <li>Email validation provided by the email-validator package.</li> </ul> <p>To install optional dependencies along with Pydantic:</p> <pre><code>pip install pydantic[email]\n</code></pre> <p>Of course, you can also install requirements manually with <code>pip install email-validator</code>.</p>"},{"location":"install/#install-from-repository","title":"Install from repository","text":"<p>And if you prefer to install Pydantic directly from the repository:</p> <pre><code>pip install git+https://github.com/pydantic/pydantic@main#egg=pydantic\n# or with the `email` extra:\npip install git+https://github.com/pydantic/pydantic@main#egg=pydantic[email]\n</code></pre>"},{"location":"migration/","title":"Migration Guide","text":"<p>Pydantic V2 introduces a number of changes to the API, including some breaking changes.</p> <p>This page provides a guide highlighting the most important changes to help you migrate your code from Pydantic V1 to Pydantic V2.</p>"},{"location":"migration/#install-pydantic-v2","title":"Install Pydantic V2","text":"<p>Pydantic V2 is now the current production release of Pydantic. You can install Pydantic V2 from PyPI:</p> <pre><code>pip install -U pydantic\n</code></pre> <p>If you encounter any issues, please create an issue in GitHub using the <code>bug V2</code> label. This will help us to actively monitor and track errors, and to continue to improve the library's performance.</p> <p>If you need to use latest Pydantic V1 for any reason, see the Continue using Pydantic V1 features section below for details on installation and imports from <code>pydantic.v1</code>.</p>"},{"location":"migration/#code-transformation-tool","title":"Code transformation tool","text":"<p>We have created a tool to help you migrate your code. This tool is still in beta, but we hope it will help you to migrate your code more quickly.</p> <p>You can install the tool from PyPI:</p> <pre><code>pip install bump-pydantic\n</code></pre> <p>The usage is simple. If your project structure is:</p> <pre><code>* repo_folder\n    * my_package\n        * &lt;python source files&gt; ...\n</code></pre> <p>Then you'll want to do:</p> <pre><code>cd /path/to/repo_folder\nbump-pydantic my_package\n</code></pre> <p>See more about it on the Bump Pydantic repository.</p>"},{"location":"migration/#continue-using-pydantic-v1-features","title":"Continue using Pydantic V1 features","text":"<p>Pydantic V1 is still available when you need it, though we recommend migrating to Pydantic V2 for its improvements and new features.</p> <p>If you need to use latest Pydantic V1, you can install it with:</p> <pre><code>pip install \"pydantic==1.*\"\n</code></pre> <p>The Pydantic V2 package also continues to provide access to the Pydantic V1 API by importing through <code>pydantic.v1</code>.</p> <p>For example, you can use the <code>BaseModel</code> class from Pydantic V1 instead of the Pydantic V2 <code>pydantic.BaseModel</code> class:</p> <pre><code>from pydantic.v1 import BaseModel\n</code></pre> <p>You can also import functions that have been removed from Pydantic V2, such as <code>lenient_isinstance</code>:</p> <pre><code>from pydantic.v1.utils import lenient_isinstance\n</code></pre> <p>Pydantic V1 documentation is available at https://docs.pydantic.dev/1.10/.</p>"},{"location":"migration/#using-pydantic-v1-features-in-a-v1v2-environment","title":"Using Pydantic v1 features in a v1/v2 environment","text":"<p>As of <code>pydantic&gt;=1.10.17</code>, the <code>pydantic.v1</code> namespace can be used within V1. This makes it easier to migrate to V2, which also supports the <code>pydantic.v1</code> namespace. In order to unpin a <code>pydantic&lt;2</code> dependency and continue using V1 features, take the following steps:</p> <ol> <li>Replace <code>pydantic&lt;2</code> with <code>pydantic&gt;=1.10.17</code></li> <li>Find and replace all occurrences of:</li> </ol> <pre><code>from pydantic.&lt;module&gt; import &lt;object&gt;\n</code></pre> <p>with:</p> <pre><code>from pydantic.v1.&lt;module&gt; import &lt;object&gt;\n</code></pre> <p>Here's how you can import <code>pydantic</code>'s v1 features based on your version of <code>pydantic</code>:</p> <code>pydantic&gt;=1.10.17,&lt;3</code><code>pydantic&lt;3</code> <p>As of <code>v1.10.17</code> the <code>.v1</code> namespace is available in V1, allowing imports as below:</p> <pre><code>from pydantic.v1.fields import ModelField\n</code></pre> <p>All versions of Pydantic V1 and V2 support the following import pattern, in case you don't know which version of Pydantic you are using:</p> <pre><code>try:\n    from pydantic.v1.fields import ModelField\nexcept ImportError:\n    from pydantic.fields import ModelField\n</code></pre> <p>Note</p> <p>When importing modules using <code>pydantic&gt;=1.10.17,&lt;2</code> with the <code>.v1</code> namespace these modules will not be the same module as the same import without the <code>.v1</code> namespace, but the symbols imported will be. For example <code>pydantic.v1.fields is not pydantic.fields</code> but <code>pydantic.v1.fields.ModelField is pydantic.fields.ModelField</code>. Luckily, this is not likely to be relevant in the vast majority of cases. It's just an unfortunate consequence of providing a smoother migration experience.</p>"},{"location":"migration/#migration-guide","title":"Migration guide","text":"<p>The following sections provide details on the most important changes in Pydantic V2.</p>"},{"location":"migration/#changes-to-pydanticbasemodel","title":"Changes to <code>pydantic.BaseModel</code>","text":"<p>Various method names have been changed; all non-deprecated <code>BaseModel</code> methods now have names matching either the format <code>model_.*</code> or <code>__.*pydantic.*__</code>. Where possible, we have retained the deprecated methods with their old names to help ease migration, but calling them will emit <code>DeprecationWarning</code>s.</p> Pydantic V1 Pydantic V2 <code>__fields__</code> <code>model_fields</code> <code>__private_attributes__</code> <code>__pydantic_private__</code> <code>__validators__</code> <code>__pydantic_validator__</code> <code>construct()</code> <code>model_construct()</code> <code>copy()</code> <code>model_copy()</code> <code>dict()</code> <code>model_dump()</code> <code>json_schema()</code> <code>model_json_schema()</code> <code>json()</code> <code>model_dump_json()</code> <code>parse_obj()</code> <code>model_validate()</code> <code>update_forward_refs()</code> <code>model_rebuild()</code> <ul> <li>Some of the built-in data-loading functionality has been slated for removal. In particular,     <code>parse_raw</code> and <code>parse_file</code> are now deprecated. In Pydantic V2, <code>model_validate_json</code> works like <code>parse_raw</code>. Otherwise, you should load the data and then pass it to <code>model_validate</code>.</li> <li>The <code>from_orm</code> method has been deprecated; you can now just use <code>model_validate</code> (equivalent to <code>parse_obj</code> from   Pydantic V1) to achieve something similar, as long as you've set <code>from_attributes=True</code> in the model config.</li> <li>The <code>__eq__</code> method has changed for models.<ul> <li>Models can only be equal to other <code>BaseModel</code> instances.</li> <li>For two model instances to be equal, they must have the same:<ul> <li>Type (or, in the case of generic models, non-parametrized generic origin type)</li> <li>Field values</li> <li>Extra values (only relevant when <code>model_config['extra'] == 'allow'</code>)</li> <li>Private attribute values; models with different values of private attributes are no longer equal.</li> <li>Models are no longer equal to the dicts containing their data.</li> <li>Non-generic models of different types are never equal.</li> <li>Generic models with different origin types are never equal. We don't require exact type equality so that,     for example, instances of <code>MyGenericModel[Any]</code> could be equal to instances of <code>MyGenericModel[int]</code>.</li> </ul> </li> </ul> </li> <li>We have replaced the use of the <code>__root__</code> field to specify a \"custom root model\" with a new type called     <code>RootModel</code> which is intended to replace the functionality of     using a field called <code>__root__</code> in Pydantic V1. Note, <code>RootModel</code> types no longer support the <code>arbitrary_types_allowed</code>     config setting. See this issue comment for an explanation.</li> <li>We have significantly expanded Pydantic's capabilities related to customizing serialization. In particular, we have     added the <code>@field_serializer</code>,     <code>@model_serializer</code>, and     <code>@computed_field</code> decorators, which each address various     shortcomings from Pydantic V1.<ul> <li>See Custom serializers for the usage docs of these new decorators.</li> <li>Due to performance overhead and implementation complexity, we have now deprecated support for specifying     <code>json_encoders</code> in the model config. This functionality was originally added for the purpose of achieving custom     serialization logic, and we think the new serialization decorators are a better choice in most common scenarios.</li> </ul> </li> <li>We have changed the behavior related to serializing subclasses of models when they occur as nested fields in a parent   model. In V1, we would always include all fields from the subclass instance. In V2, when we dump a model, we only   include the fields that are defined on the annotated type of the field. This helps prevent some accidental security   bugs. You can read more about this (including how to opt out of this behavior) in the   Subclass instances for fields of BaseModel, dataclasses, TypedDict   section of the model exporting docs.</li> <li><code>GetterDict</code> has been removed as it was just an implementation detail of <code>orm_mode</code>, which has been removed.</li> <li>In many cases, arguments passed to the constructor will be copied in order to perform validation and, where necessary, coercion.   This is notable in the case of passing mutable objects as arguments to a constructor.   You can see an example + more detail here.</li> <li>The <code>.json()</code> method is deprecated, and attempting to use this deprecated method with arguments such as <code>indent</code> or <code>ensure_ascii</code> may lead to confusing errors. For best results, switch to V2's equivalent, <code>model_dump_json()</code>. If you'd still like to use said arguments, you can use this workaround.</li> <li>JSON serialization of non-string key values is generally done with <code>str(key)</code>, leading to some changes in behavior such as the following:</li> </ul> <pre><code>from typing import Dict, Optional\n\nfrom pydantic import BaseModel as V2BaseModel\nfrom pydantic.v1 import BaseModel as V1BaseModel\n\n\nclass V1Model(V1BaseModel):\n    a: Dict[Optional[str], int]\n\n\nclass V2Model(V2BaseModel):\n    a: Dict[Optional[str], int]\n\n\nv1_model = V1Model(a={None: 123})\nv2_model = V2Model(a={None: 123})\n\n# V1\nprint(v1_model.json())\n#&gt; {\"a\": {\"null\": 123}}\n\n# V2\nprint(v2_model.model_dump_json())\n#&gt; {\"a\":{\"None\":123}}\n</code></pre> <ul> <li><code>model_dump_json()</code> results are compacted in order to save space, and don't always exactly match that of <code>json.dumps()</code> output. That being said, you can easily modify the separators used in <code>json.dumps()</code> results in order to align the two outputs:</li> </ul> <pre><code>import json\nfrom typing import List\n\nfrom pydantic import BaseModel as V2BaseModel\nfrom pydantic.v1 import BaseModel as V1BaseModel\n\n\nclass V1Model(V1BaseModel):\n    a: List[str]\n\n\nclass V2Model(V2BaseModel):\n    a: List[str]\n\n\nv1_model = V1Model(a=['fancy', 'sushi'])\nv2_model = V2Model(a=['fancy', 'sushi'])\n\n# V1\nprint(v1_model.json())\n#&gt; {\"a\": [\"fancy\", \"sushi\"]}\n\n# V2\nprint(v2_model.model_dump_json())\n#&gt; {\"a\":[\"fancy\",\"sushi\"]}\n\n# Plain json.dumps\nprint(json.dumps(v2_model.model_dump()))\n#&gt; {\"a\": [\"fancy\", \"sushi\"]}\n\n# Modified json.dumps\nprint(json.dumps(v2_model.model_dump(), separators=(',', ':')))\n#&gt; {\"a\":[\"fancy\",\"sushi\"]}\n</code></pre>"},{"location":"migration/#changes-to-pydanticgenericsgenericmodel","title":"Changes to <code>pydantic.generics.GenericModel</code>","text":"<p>The <code>pydantic.generics.GenericModel</code> class is no longer necessary, and has been removed. Instead, you can now create generic <code>BaseModel</code> subclasses by just adding <code>Generic</code> as a parent class on a <code>BaseModel</code> subclass directly. This looks like <code>class MyGenericModel(BaseModel, Generic[T]): ...</code>.</p> <p>Mixing of V1 and V2 models is not supported which means that type parameters of such generic <code>BaseModel</code> (V2) cannot be V1 models.</p> <p>While it may not raise an error, we strongly advise against using parametrized generics in <code>isinstance</code> checks.</p> <ul> <li>For example, you should not do <code>isinstance(my_model, MyGenericModel[int])</code>.     However, it is fine to do <code>isinstance(my_model, MyGenericModel)</code>. (Note that for standard generics, it would raise     an error to do a subclass check with a parameterized generic.)</li> <li>If you need to perform <code>isinstance</code> checks against parametrized generics, you can do this by subclassing the     parametrized generic class. This looks like <code>class MyIntModel(MyGenericModel[int]): ...</code> and     <code>isinstance(my_model, MyIntModel)</code>.</li> </ul> <p>Find more information in the Generic models documentation.</p>"},{"location":"migration/#changes-to-pydanticfield","title":"Changes to <code>pydantic.Field</code>","text":"<p><code>Field</code> no longer supports arbitrary keyword arguments to be added to the JSON schema. Instead, any extra data you want to add to the JSON schema should be passed as a dictionary to the <code>json_schema_extra</code> keyword argument.</p> <p>In Pydantic V1, the <code>alias</code> property returns the field's name when no alias is set. In Pydantic V2, this behavior has changed to return <code>None</code> when no alias is set.</p> <p>The following properties have been removed from or changed in <code>Field</code>:</p> <ul> <li><code>const</code></li> <li><code>min_items</code> (use <code>min_length</code> instead)</li> <li><code>max_items</code> (use <code>max_length</code> instead)</li> <li><code>unique_items</code></li> <li><code>allow_mutation</code> (use <code>frozen</code> instead)</li> <li><code>regex</code> (use <code>pattern</code> instead)</li> <li><code>final</code> (use the typing.Final type hint instead)</li> </ul> <p>Field constraints are no longer automatically pushed down to the parameters of generics.  For example, you can no longer validate every element of a list matches a regex by providing <code>my_list: list[str] = Field(pattern=\".*\")</code>.  Instead, use <code>typing.Annotated</code> to provide an annotation on the <code>str</code> itself: <code>my_list: list[Annotated[str, Field(pattern=\".*\")]]</code></p> <ul> <li>[TODO: Need to document any other backwards-incompatible changes to <code>pydantic.Field</code>]</li> </ul>"},{"location":"migration/#changes-to-dataclasses","title":"Changes to dataclasses","text":"<p>Pydantic dataclasses continue to be useful for enabling the data validation on standard dataclasses without having to subclass <code>BaseModel</code>. Pydantic V2 introduces the following changes to this dataclass behavior:</p> <ul> <li>When used as fields, dataclasses (Pydantic or vanilla) no longer accept tuples as validation inputs; dicts should be   used instead.</li> <li>The <code>__post_init__</code> in Pydantic dataclasses will now be called after validation, rather than before.<ul> <li>As a result, the <code>__post_init_post_parse__</code> method would have become redundant, so has been removed.</li> </ul> </li> <li>Pydantic no longer supports <code>extra='allow'</code> for Pydantic dataclasses, where extra fields passed to the initializer would be     stored as extra attributes on the dataclass. <code>extra='ignore'</code> is still supported for the purpose of ignoring     unexpected fields while parsing data, they just won't be stored on the instance.</li> <li>Pydantic dataclasses no longer have an attribute <code>__pydantic_model__</code>, and no longer use an underlying <code>BaseModel</code>     to perform validation or provide other functionality.<ul> <li>To perform validation, generate a JSON schema, or make use of     any other functionality that may have required <code>__pydantic_model__</code> in V1, you should now wrap the dataclass     with a <code>TypeAdapter</code> (discussed more below) and     make use of its methods.</li> </ul> </li> <li>In Pydantic V1, if you used a vanilla (i.e., non-Pydantic) dataclass as a field, the config of the parent type would     be used as though it was the config for the dataclass itself as well. In Pydantic V2, this is no longer the case.<ul> <li>In Pydantic V2, to override the config (like you would with <code>model_config</code> on a <code>BaseModel</code>),     you can use the <code>config</code> parameter on the <code>@dataclass</code> decorator.     See Dataclass Config for examples.</li> </ul> </li> </ul>"},{"location":"migration/#changes-to-config","title":"Changes to config","text":"<ul> <li> <p>In Pydantic V2, to specify config on a model, you should set a class attribute called <code>model_config</code> to be a dict   with the key/value pairs you want to be used as the config. The Pydantic V1 behavior to create a class called <code>Config</code>   in the namespace of the parent <code>BaseModel</code> subclass is now deprecated.</p> </li> <li> <p>When subclassing a model, the <code>model_config</code> attribute is inherited. This is helpful in the case where you'd like to use a base class with a given configuration for many models. Note, if you inherit from multiple <code>BaseModel</code> subclasses, like <code>class MyModel(Model1, Model2)</code>, the non-default settings in the <code>model_config</code> attribute from the two models will be merged, and for any settings defined in both, those from <code>Model2</code> will override those from <code>Model1</code>.</p> </li> <li> <p>The following config settings have been removed:</p> <ul> <li><code>allow_mutation</code> \u2014 this has been removed. You should be able to use frozen equivalently (inverse of current use).</li> <li><code>error_msg_templates</code></li> <li><code>fields</code> \u2014 this was the source of various bugs, so has been removed.   You should be able to use <code>Annotated</code> on fields to modify them as desired.</li> <li><code>getter_dict</code> \u2014 <code>orm_mode</code> has been removed, and this implementation detail is no longer necessary.</li> <li><code>smart_union</code>.</li> <li><code>underscore_attrs_are_private</code> \u2014 the Pydantic V2 behavior is now the same as if this was always set   to <code>True</code> in Pydantic V1.</li> <li><code>json_loads</code></li> <li><code>json_dumps</code></li> <li><code>copy_on_model_validation</code></li> <li><code>post_init_call</code></li> </ul> </li> <li> <p>The following config settings have been renamed:</p> <ul> <li><code>allow_population_by_field_name</code> \u2192 <code>populate_by_name</code></li> <li><code>anystr_lower</code> \u2192 <code>str_to_lower</code></li> <li><code>anystr_strip_whitespace</code> \u2192 <code>str_strip_whitespace</code></li> <li><code>anystr_upper</code> \u2192 <code>str_to_upper</code></li> <li><code>keep_untouched</code> \u2192 <code>ignored_types</code></li> <li><code>max_anystr_length</code> \u2192 <code>str_max_length</code></li> <li><code>min_anystr_length</code> \u2192 <code>str_min_length</code></li> <li><code>orm_mode</code> \u2192 <code>from_attributes</code></li> <li><code>schema_extra</code> \u2192 <code>json_schema_extra</code></li> <li><code>validate_all</code> \u2192 <code>validate_default</code></li> </ul> </li> </ul> <p>See the <code>ConfigDict</code> API reference for more details.</p>"},{"location":"migration/#changes-to-validators","title":"Changes to validators","text":""},{"location":"migration/#validator-and-root_validator-are-deprecated","title":"<code>@validator</code> and <code>@root_validator</code> are deprecated","text":"<ul> <li><code>@validator</code> has been deprecated, and should be replaced with <code>@field_validator</code>, which provides various new features     and improvements.<ul> <li>The new <code>@field_validator</code> decorator does not have the <code>each_item</code> keyword argument; validators you want to     apply to items within a generic container should be added by annotating the type argument. See     validators in Annotated metadata for details.     This looks like <code>List[Annotated[int, Field(ge=0)]]</code></li> <li>Even if you keep using the deprecated <code>@validator</code> decorator, you can no longer add the <code>field</code> or     <code>config</code> arguments to the signature of validator functions. If you need access to these, you'll need     to migrate to <code>@field_validator</code> \u2014 see the next section     for more details.</li> <li>If you use the <code>always=True</code> keyword argument to a validator function, note that standard validators     for the annotated type will also be applied even to defaults, not just the custom validators. For     example, despite the fact that the validator below will never error, the following code raises a <code>ValidationError</code>:</li> </ul> </li> </ul> <p>Note</p> <p>To avoid this, you can use the <code>validate_default</code> argument in the <code>Field</code> function. When set to <code>True</code>, it mimics the behavior of <code>always=True</code> in Pydantic v1. However, the new way of using <code>validate_default</code> is encouraged as it provides more flexibility and control.</p> <pre><code>from pydantic import BaseModel, validator\n\n\nclass Model(BaseModel):\n    x: str = 1\n\n    @validator('x', always=True)\n    @classmethod\n    def validate_x(cls, v):\n        return v\n\n\nModel()\n</code></pre> <ul> <li><code>@root_validator</code> has been deprecated, and should be replaced with     <code>@model_validator</code>, which also provides new features and improvements.<ul> <li>Under some circumstances (such as assignment when <code>model_config['validate_assignment'] is True</code>),     the <code>@model_validator</code> decorator will receive an instance of the model, not a dict of values. You may     need to be careful to handle this case.</li> <li>Even if you keep using the deprecated <code>@root_validator</code> decorator, due to refactors in validation logic,     you can no longer run with <code>skip_on_failure=False</code> (which is the default value of this keyword argument,     so must be set explicitly to <code>True</code>).</li> </ul> </li> </ul>"},{"location":"migration/#changes-to-validators-allowed-signatures","title":"Changes to <code>@validator</code>'s allowed signatures","text":"<p>In Pydantic V1, functions wrapped by <code>@validator</code> could receive keyword arguments with metadata about what was being validated. Some of these arguments have been removed from <code>@field_validator</code> in Pydantic V2:</p> <ul> <li><code>config</code>: Pydantic V2's config is now a dictionary instead of a class, which means this argument is no longer     backwards compatible. If you need to access the configuration you should migrate to <code>@field_validator</code> and use     <code>info.config</code>.</li> <li><code>field</code>: this argument used to be a <code>ModelField</code> object, which was a quasi-internal class that no longer exists     in Pydantic V2. Most of this information can still be accessed by using the field name from <code>info.field_name</code>     to index into <code>cls.model_fields</code></li> </ul> <pre><code>from pydantic import BaseModel, ValidationInfo, field_validator\n\n\nclass Model(BaseModel):\n    x: int\n\n    @field_validator('x')\n    def val_x(cls, v: int, info: ValidationInfo) -&gt; int:\n        assert info.config is not None\n        print(info.config.get('title'))\n        #&gt; Model\n        print(cls.model_fields[info.field_name].is_required())\n        #&gt; True\n        return v\n\n\nModel(x=1)\n</code></pre>"},{"location":"migration/#typeerror-is-no-longer-converted-to-validationerror-in-validators","title":"<code>TypeError</code> is no longer converted to <code>ValidationError</code> in validators","text":"<p>Previously, when raising a <code>TypeError</code> within a validator function, that error would be wrapped into a <code>ValidationError</code> and, in some cases (such as with FastAPI), these errors might be displayed to end users. This led to a variety of undesirable behavior \u2014 for example, calling a function with the wrong signature might produce a user-facing <code>ValidationError</code>.</p> <p>However, in Pydantic V2, when a <code>TypeError</code> is raised in a validator, it is no longer converted into a <code>ValidationError</code>:</p> <pre><code>import pytest\n\nfrom pydantic import BaseModel, field_validator  # or validator\n\n\nclass Model(BaseModel):\n    x: int\n\n    @field_validator('x')\n    def val_x(cls, v: int) -&gt; int:\n        return str.lower(v)  # raises a TypeError\n\n\nwith pytest.raises(TypeError):\n    Model(x=1)\n</code></pre> <p>This applies to all validation decorators.</p>"},{"location":"migration/#validator-behavior-changes","title":"Validator behavior changes","text":"<p>Pydantic V2 includes some changes to type coercion. For example:</p> <ul> <li>coercing <code>int</code>, <code>float</code>, and <code>Decimal</code> values to strings is now optional and disabled by default, see   Coerce Numbers to Strings.</li> <li>iterable of pairs is no longer coerced to a dict.</li> </ul> <p>See the Conversion table for details on Pydantic V2 type coercion defaults.</p>"},{"location":"migration/#the-allow_reuse-keyword-argument-is-no-longer-necessary","title":"The <code>allow_reuse</code> keyword argument is no longer necessary","text":"<p>Previously, Pydantic tracked \"reused\" functions in decorators as this was a common source of mistakes. We did this by comparing the function's fully qualified name (module name + function name), which could result in false positives. The <code>allow_reuse</code> keyword argument could be used to disable this when it was intentional.</p> <p>Our approach to detecting repeatedly defined functions has been overhauled to only error for redefinition within a single class, reducing false positives and bringing the behavior more in line with the errors that type checkers and linters would give for defining a method with the same name multiple times in a single class definition.</p> <p>In nearly all cases, if you were using <code>allow_reuse=True</code>, you should be able to simply delete that keyword argument and have things keep working as expected.</p>"},{"location":"migration/#validate_arguments-has-been-renamed-to-validate_call","title":"<code>@validate_arguments</code> has been renamed to <code>@validate_call</code>","text":"<p>In Pydantic V2, the <code>@validate_arguments</code> decorator has been renamed to <code>@validate_call</code>.</p> <p>In Pydantic V1, the decorated function had various attributes added, such as <code>raw_function</code>, and <code>validate</code> (which could be used to validate arguments without actually calling the decorated function). Due to limited use of these attributes, and performance-oriented changes in implementation, we have not preserved this functionality in <code>@validate_call</code>.</p>"},{"location":"migration/#input-types-are-not-preserved","title":"Input types are not preserved","text":"<p>In Pydantic V1 we made great efforts to preserve the types of all field inputs for generic collections when they were proper subtypes of the field annotations. For example, given the annotation <code>Mapping[str, int]</code> if you passed in a <code>collection.Counter()</code> you'd get a <code>collection.Counter()</code> as the value.</p> <p>Supporting this behavior in V2 would have negative performance implications for the general case (we'd have to check types every time) and would add a lot of complexity to validation. Further, even in V1 this behavior was inconsistent and partially broken: it did not work for many types (<code>str</code>, <code>UUID</code>, etc.), and for generic collections it's impossible to re-build the original input correctly without a lot of special casing (consider <code>ChainMap</code>; rebuilding the input is necessary because we need to replace values after validation, e.g. if coercing strings to ints).</p> <p>In Pydantic V2 we no longer attempt to preserve the input type in all cases; instead, we only promise that the output type will match the type annotations.</p> <p>Going back to the <code>Mapping</code> example, we promise the output will be a valid <code>Mapping</code>, and in practice it will be a plain <code>dict</code>:</p> <pre><code>from typing import Mapping\n\nfrom pydantic import TypeAdapter\n\n\nclass MyDict(dict):\n    pass\n\n\nta = TypeAdapter(Mapping[str, int])\nv = ta.validate_python(MyDict())\nprint(type(v))\n#&gt; &lt;class 'dict'&gt;\n</code></pre> <p>If you want the output type to be a specific type, consider annotating it as such or implementing a custom validator:</p> <pre><code>from typing import Any, Mapping, TypeVar\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import (\n    TypeAdapter,\n    ValidationInfo,\n    ValidatorFunctionWrapHandler,\n    WrapValidator,\n)\n\n\ndef restore_input_type(\n    value: Any, handler: ValidatorFunctionWrapHandler, _info: ValidationInfo\n) -&gt; Any:\n    return type(value)(handler(value))\n\n\nT = TypeVar('T')\nPreserveType = Annotated[T, WrapValidator(restore_input_type)]\n\n\nta = TypeAdapter(PreserveType[Mapping[str, int]])\n\n\nclass MyDict(dict):\n    pass\n\n\nv = ta.validate_python(MyDict())\nassert type(v) is MyDict\n</code></pre> <p>While we don't promise to preserve input types everywhere, we do preserve them for subclasses of <code>BaseModel</code>, and for dataclasses:</p> <pre><code>import pydantic.dataclasses\nfrom pydantic import BaseModel\n\n\nclass InnerModel(BaseModel):\n    x: int\n\n\nclass OuterModel(BaseModel):\n    inner: InnerModel\n\n\nclass SubInnerModel(InnerModel):\n    y: int\n\n\nm = OuterModel(inner=SubInnerModel(x=1, y=2))\nprint(m)\n#&gt; inner=SubInnerModel(x=1, y=2)\n\n\n@pydantic.dataclasses.dataclass\nclass InnerDataclass:\n    x: int\n\n\n@pydantic.dataclasses.dataclass\nclass SubInnerDataclass(InnerDataclass):\n    y: int\n\n\n@pydantic.dataclasses.dataclass\nclass OuterDataclass:\n    inner: InnerDataclass\n\n\nd = OuterDataclass(inner=SubInnerDataclass(x=1, y=2))\nprint(d)\n#&gt; OuterDataclass(inner=SubInnerDataclass(x=1, y=2))\n</code></pre>"},{"location":"migration/#changes-to-handling-of-standard-types","title":"Changes to Handling of Standard Types","text":""},{"location":"migration/#dicts","title":"Dicts","text":"<p>Iterables of pairs (which include empty iterables) no longer pass validation for fields of type <code>dict</code>.</p>"},{"location":"migration/#unions","title":"Unions","text":"<p>While union types will still attempt validation of each choice from left to right, they now preserve the type of the input whenever possible, even if the correct type is not the first choice for which the input would pass validation. As a demonstration, consider the following example:</p> <pre><code>from typing import Union\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    x: Union[int, str]\n\n\nprint(Model(x='1'))\n#&gt; x='1'\n</code></pre> <p>In Pydantic V1, the printed result would have been <code>x=1</code>, since the value would pass validation as an <code>int</code>. In Pydantic V2, we recognize that the value is an instance of one of the cases and short-circuit the standard union validation.</p> <p>To revert to the non-short-circuiting left-to-right behavior of V1, annotate the union with <code>Field(union_mode='left_to_right')</code>. See Union Mode for more details.</p>"},{"location":"migration/#required-optional-and-nullable-fields","title":"Required, optional, and nullable fields","text":"<p>Pydantic V2 changes some of the logic for specifying whether a field annotated as <code>Optional</code> is required (i.e., has no default value) or not (i.e., has a default value of <code>None</code> or any other value of the corresponding type), and now more closely matches the behavior of <code>dataclasses</code>. Similarly, fields annotated as <code>Any</code> no longer have a default value of <code>None</code>.</p> <p>The following table describes the behavior of field annotations in V2:</p> State Field Definition Required, cannot be <code>None</code> <code>f1: str</code> Not required, cannot be <code>None</code>, is <code>'abc'</code> by default <code>f2: str = 'abc'</code> Required, can be <code>None</code> <code>f3: Optional[str]</code> Not required, can be <code>None</code>, is <code>None</code> by default <code>f4: Optional[str] = None</code> Not required, can be <code>None</code>, is <code>'abc'</code> by default <code>f5: Optional[str] = 'abc'</code> Required, can be any type (including <code>None</code>) <code>f6: Any</code> Not required, can be any type (including <code>None</code>) <code>f7: Any = None</code> <p>Note</p> <p>A field annotated as <code>typing.Optional[T]</code> will be required, and will allow for a value of <code>None</code>. It does not mean that the field has a default value of <code>None</code>. (This is a breaking change from V1.)</p> <p>Note</p> <p>Any default value if provided makes a field not required.</p> <p>Here is a code example demonstrating the above: <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Foo(BaseModel):\n    f1: str  # required, cannot be None\n    f2: Optional[str]  # required, can be None - same as str | None\n    f3: Optional[str] = None  # not required, can be None\n    f4: str = 'Foobar'  # not required, but cannot be None\n\n\ntry:\n    Foo(f1=None, f2=None, f4='b')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Foo\n    f1\n      Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    \"\"\"\n</code></pre></p>"},{"location":"migration/#patterns-regex-on-strings","title":"Patterns / regex on strings","text":"<p>Pydantic V1 used Python's regex library. Pydantic V2 uses the Rust regex crate. This crate is not just a \"Rust version of regular expressions\", it's a completely different approach to regular expressions. In particular, it promises linear time searching of strings in exchange for dropping a couple of features (namely look arounds and backreferences). We believe this is a tradeoff worth making, in particular because Pydantic is used to validate untrusted input where ensuring things don't accidentally run in exponential time depending on the untrusted input is important. On the flipside, for anyone not using these features complex regex validation should be orders of magnitude faster because it's done in Rust and in linear time.</p> <p>If you still want to use Python's regex library, you can use the <code>regex_engine</code> config setting.</p>"},{"location":"migration/#introduction-of-typeadapter","title":"Introduction of <code>TypeAdapter</code>","text":"<p>Pydantic V1 had weak support for validating or serializing non-<code>BaseModel</code> types.</p> <p>To work with them, you had to either create a \"root\" model or use the utility functions in <code>pydantic.tools</code> (namely, <code>parse_obj_as</code> and <code>schema_of</code>).</p> <p>In Pydantic V2 this is a lot easier: the <code>TypeAdapter</code> class lets you create an object with methods for validating, serializing, and producing JSON schemas for arbitrary types. This serves as a complete replacement for <code>parse_obj_as</code> and <code>schema_of</code> (which are now deprecated), and also covers some of the use cases of \"root\" models. (<code>RootModel</code>, discussed above, covers the others.)</p> <pre><code>from typing import List\n\nfrom pydantic import TypeAdapter\n\nadapter = TypeAdapter(List[int])\nassert adapter.validate_python(['1', '2', '3']) == [1, 2, 3]\nprint(adapter.json_schema())\n#&gt; {'items': {'type': 'integer'}, 'type': 'array'}\n</code></pre> <p>Due to limitations of inferring generic types with common type checkers, to get proper typing in some scenarios, you may need to explicitly specify the generic parameter:</p> <pre><code>from pydantic import TypeAdapter\n\nadapter = TypeAdapter[str | int](str | int)\n...\n</code></pre> <p>See Type Adapter for more information.</p>"},{"location":"migration/#defining-custom-types","title":"Defining custom types","text":"<p>We have completely overhauled the way custom types are defined in pydantic.</p> <p>We have exposed hooks for generating both <code>pydantic-core</code> and JSON schemas, allowing you to get all the performance benefits of Pydantic V2 even when using your own custom types.</p> <p>We have also introduced ways to use <code>typing.Annotated</code> to add custom validation to your own types.</p> <p>The main changes are:</p> <ul> <li><code>__get_validators__</code> should be replaced with <code>__get_pydantic_core_schema__</code>.   See Custom Data Types for more information.</li> <li><code>__modify_schema__</code> becomes <code>__get_pydantic_json_schema__</code>.   See JSON Schema Customization for more information.</li> </ul> <p>Additionally, you can use <code>typing.Annotated</code> to modify or provide the <code>__get_pydantic_core_schema__</code> and <code>__get_pydantic_json_schema__</code> functions of a type by annotating it, rather than modifying the type itself. This provides a powerful and flexible mechanism for integrating third-party types with Pydantic, and in some cases may help you remove hacks from Pydantic V1 introduced to work around the limitations for custom types.</p> <p>See Custom Data Types for more information.</p>"},{"location":"migration/#changes-to-json-schema-generation","title":"Changes to JSON schema generation","text":"<p>We received many requests over the years to make changes to the JSON schemas that pydantic generates.</p> <p>In Pydantic V2, we have tried to address many of the common requests:</p> <ul> <li>The JSON schema for <code>Optional</code> fields now indicates that the value <code>null</code> is allowed.</li> <li>The <code>Decimal</code> type is now exposed in JSON schema (and serialized) as a string.</li> <li>The JSON schema no longer preserves namedtuples as namedtuples.</li> <li>The JSON schema we generate by default now targets draft 2020-12 (with some OpenAPI extensions).</li> <li>When they differ, you can now specify if you want the JSON schema representing the inputs to validation,     or the outputs from serialization.</li> </ul> <p>However, there have been many reasonable requests over the years for changes which we have not chosen to implement.</p> <p>In Pydantic V1, even if you were willing to implement changes yourself, it was very difficult because the JSON schema generation process involved various recursive function calls; to override one, you'd have to copy and modify the whole implementation.</p> <p>In Pydantic V2, one of our design goals was to make it easier to customize JSON schema generation. To this end, we have introduced the class <code>GenerateJsonSchema</code>, which implements the translation of a type's pydantic-core schema into a JSON schema. By design, this class breaks the JSON schema generation process into smaller methods that can be easily overridden in subclasses to modify the \"global\" approach to generating JSON schema.</p> <p>The various methods that can be used to produce JSON schema (such as <code>BaseModel.model_json_schema</code> or <code>TypeAdapter.json_schema</code>) accept a keyword argument <code>schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema</code>, and you can pass your custom subclass to these methods in order to use your own approach to generating JSON schema.</p> <p>Hopefully this means that if you disagree with any of the choices we've made, or if you are reliant on behaviors in Pydantic V1 that have changed in Pydantic V2, you can use a custom <code>schema_generator</code>, modifying the <code>GenerateJsonSchema</code> class as necessary for your application.</p>"},{"location":"migration/#basesettings-has-moved-to-pydantic-settings","title":"<code>BaseSettings</code> has moved to <code>pydantic-settings</code>","text":"<p><code>BaseSettings</code>, the base object for Pydantic settings management, has been moved to a separate package, <code>pydantic-settings</code>.</p> <p>Also, the <code>parse_env_var</code> classmethod has been removed. So, you need to customise settings sources to have your own parsing function.</p>"},{"location":"migration/#color-and-payment-card-numbers-moved-to-pydantic-extra-types","title":"Color and Payment Card Numbers moved to <code>pydantic-extra-types</code>","text":"<p>The following special-use types have been moved to the Pydantic Extra Types package, which may be installed separately if needed.</p> <ul> <li>Color Types</li> <li>Payment Card Numbers</li> </ul>"},{"location":"migration/#url-and-dsn-types-in-pydanticnetworks-no-longer-inherit-from-str","title":"Url and Dsn types in <code>pydantic.networks</code> no longer inherit from <code>str</code>","text":"<p>In Pydantic V1 the <code>AnyUrl</code> type inherited from <code>str</code>, and all the other <code>Url</code> and <code>Dsn</code> types inherited from these. In Pydantic V2 these types are built on two new <code>Url</code> and <code>MultiHostUrl</code> classes using <code>Annotated</code>.</p> <p>Inheriting from <code>str</code> had upsides and downsides, and for V2 we decided it would be better to remove this. To use these types in APIs which expect <code>str</code> you'll now need to convert them (with <code>str(url)</code>).</p> <p>Pydantic V2 uses Rust's Url crate for URL validation. Some of the URL validation differs slightly from the previous behavior in V1. One notable difference is that the new <code>Url</code> types append slashes to the validated version if no path is included, even if a slash is not specified in the argument to a <code>Url</code> type constructor. See the example below for this behavior:</p> <pre><code>from pydantic import AnyUrl\n\nassert str(AnyUrl(url='https://google.com')) == 'https://google.com/'\nassert str(AnyUrl(url='https://google.com/')) == 'https://google.com/'\nassert str(AnyUrl(url='https://google.com/api')) == 'https://google.com/api'\nassert str(AnyUrl(url='https://google.com/api/')) == 'https://google.com/api/'\n</code></pre> <p>If you still want to use the old behavior without the appended slash, take a look at this solution.</p>"},{"location":"migration/#constrained-types","title":"Constrained types","text":"<p>The <code>Constrained*</code> classes were removed, and you should replace them by <code>Annotated[&lt;type&gt;, Field(...)]</code>, for example:</p> <pre><code>from pydantic import BaseModel, ConstrainedInt\n\n\nclass MyInt(ConstrainedInt):\n    ge = 0\n\n\nclass Model(BaseModel):\n    x: MyInt\n</code></pre> <p>...becomes:</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\nMyInt = Annotated[int, Field(ge=0)]\n\n\nclass Model(BaseModel):\n    x: MyInt\n</code></pre> <p>Read more about it in the Composing types via <code>Annotated</code> docs.</p> <p>For <code>ConstrainedStr</code> you can use <code>StringConstraints</code> instead.</p>"},{"location":"migration/#mypy-plugins","title":"Mypy Plugins","text":"<p>Pydantic V2 contains a mypy plugin in <code>pydantic.mypy</code>.</p> <p>When using V1 features the <code>pydantic.v1.mypy</code> plugin might need to also be enabled.</p> <p>To configure the <code>mypy</code> plugins:</p> <p>=== <code>mypy.ini</code></p> <pre><code>```ini\n[mypy]\nplugins = pydantic.mypy, pydantic.v1.mypy # include `.v1.mypy` if required.\n```\n</code></pre> <p>=== <code>pyproject.toml</code></p> <pre><code>```toml\n[tool.mypy]\nplugins = [\n    \"pydantic.mypy\",\n    \"pydantic.v1.mypy\",\n]\n```\n</code></pre>"},{"location":"migration/#other-changes","title":"Other changes","text":"<ul> <li>Dropped support for <code>email-validator&lt;2.0.0</code>. Make sure to update   using <code>pip install -U email-validator</code>.</li> </ul>"},{"location":"migration/#moved-in-pydantic-v2","title":"Moved in Pydantic V2","text":"Pydantic V1 Pydantic V2 <code>pydantic.BaseSettings</code> <code>pydantic_settings.BaseSettings</code> <code>pydantic.color</code> <code>pydantic_extra_types.color</code> <code>pydantic.types.PaymentCardBrand</code> <code>pydantic_extra_types.PaymentCardBrand</code> <code>pydantic.types.PaymentCardNumber</code> <code>pydantic_extra_types.PaymentCardNumber</code> <code>pydantic.utils.version_info</code> <code>pydantic.version.version_info</code> <code>pydantic.error_wrappers.ValidationError</code> <code>pydantic.ValidationError</code> <code>pydantic.utils.to_camel</code> <code>pydantic.alias_generators.to_pascal</code> <code>pydantic.utils.to_lower_camel</code> <code>pydantic.alias_generators.to_camel</code> <code>pydantic.PyObject</code> <code>pydantic.ImportString</code>"},{"location":"migration/#deprecated-and-moved-in-pydantic-v2","title":"Deprecated and moved in Pydantic V2","text":"Pydantic V1 Pydantic V2 <code>pydantic.tools.schema_of</code> <code>pydantic.deprecated.tools.schema_of</code> <code>pydantic.tools.parse_obj_as</code> <code>pydantic.deprecated.tools.parse_obj_as</code> <code>pydantic.tools.schema_json_of</code> <code>pydantic.deprecated.tools.schema_json_of</code> <code>pydantic.json.pydantic_encoder</code> <code>pydantic.deprecated.json.pydantic_encoder</code> <code>pydantic.validate_arguments</code> <code>pydantic.deprecated.decorator.validate_arguments</code> <code>pydantic.json.custom_pydantic_encoder</code> <code>pydantic.deprecated.json.custom_pydantic_encoder</code> <code>pydantic.json.ENCODERS_BY_TYPE</code> <code>pydantic.deprecated.json.ENCODERS_BY_TYPE</code> <code>pydantic.json.timedelta_isoformat</code> <code>pydantic.deprecated.json.timedelta_isoformat</code> <code>pydantic.decorator.validate_arguments</code> <code>pydantic.deprecated.decorator.validate_arguments</code> <code>pydantic.class_validators.validator</code> <code>pydantic.deprecated.class_validators.validator</code> <code>pydantic.class_validators.root_validator</code> <code>pydantic.deprecated.class_validators.root_validator</code> <code>pydantic.utils.deep_update</code> <code>pydantic.v1.utils.deep_update</code> <code>pydantic.utils.GetterDict</code> <code>pydantic.v1.utils.GetterDict</code> <code>pydantic.utils.lenient_issubclass</code> <code>pydantic.v1.utils.lenient_issubclass</code> <code>pydantic.utils.lenient_isinstance</code> <code>pydantic.v1.utils.lenient_isinstance</code> <code>pydantic.utils.is_valid_field</code> <code>pydantic.v1.utils.is_valid_field</code> <code>pydantic.utils.update_not_none</code> <code>pydantic.v1.utils.update_not_none</code> <code>pydantic.utils.import_string</code> <code>pydantic.v1.utils.import_string</code> <code>pydantic.utils.Representation</code> <code>pydantic.v1.utils.Representation</code> <code>pydantic.utils.ROOT_KEY</code> <code>pydantic.v1.utils.ROOT_KEY</code> <code>pydantic.utils.smart_deepcopy</code> <code>pydantic.v1.utils.smart_deepcopy</code> <code>pydantic.utils.sequence_like</code> <code>pydantic.v1.utils.sequence_like</code>"},{"location":"migration/#removed-in-pydantic-v2","title":"Removed in Pydantic V2","text":"<ul> <li><code>pydantic.ConstrainedBytes</code></li> <li><code>pydantic.ConstrainedDate</code></li> <li><code>pydantic.ConstrainedDecimal</code></li> <li><code>pydantic.ConstrainedFloat</code></li> <li><code>pydantic.ConstrainedFrozenSet</code></li> <li><code>pydantic.ConstrainedInt</code></li> <li><code>pydantic.ConstrainedList</code></li> <li><code>pydantic.ConstrainedSet</code></li> <li><code>pydantic.ConstrainedStr</code></li> <li><code>pydantic.JsonWrapper</code></li> <li><code>pydantic.NoneBytes</code><ul> <li>This was an alias to <code>None | bytes</code>.</li> </ul> </li> <li><code>pydantic.NoneStr</code><ul> <li>This was an alias to <code>None | str</code>.</li> </ul> </li> <li><code>pydantic.NoneStrBytes</code><ul> <li>This was an alias to <code>None | str | bytes</code>.</li> </ul> </li> <li><code>pydantic.Protocol</code></li> <li><code>pydantic.Required</code></li> <li><code>pydantic.StrBytes</code><ul> <li>This was an alias to <code>str | bytes</code>.</li> </ul> </li> <li><code>pydantic.compiled</code></li> <li><code>pydantic.config.get_config</code></li> <li><code>pydantic.config.inherit_config</code></li> <li><code>pydantic.config.prepare_config</code></li> <li><code>pydantic.create_model_from_namedtuple</code></li> <li><code>pydantic.create_model_from_typeddict</code></li> <li><code>pydantic.dataclasses.create_pydantic_model_from_dataclass</code></li> <li><code>pydantic.dataclasses.make_dataclass_validator</code></li> <li><code>pydantic.dataclasses.set_validation</code></li> <li><code>pydantic.datetime_parse.parse_date</code></li> <li><code>pydantic.datetime_parse.parse_time</code></li> <li><code>pydantic.datetime_parse.parse_datetime</code></li> <li><code>pydantic.datetime_parse.parse_duration</code></li> <li><code>pydantic.error_wrappers.ErrorWrapper</code></li> <li><code>pydantic.errors.AnyStrMaxLengthError</code></li> <li><code>pydantic.errors.AnyStrMinLengthError</code></li> <li><code>pydantic.errors.ArbitraryTypeError</code></li> <li><code>pydantic.errors.BoolError</code></li> <li><code>pydantic.errors.BytesError</code></li> <li><code>pydantic.errors.CallableError</code></li> <li><code>pydantic.errors.ClassError</code></li> <li><code>pydantic.errors.ColorError</code></li> <li><code>pydantic.errors.ConfigError</code></li> <li><code>pydantic.errors.DataclassTypeError</code></li> <li><code>pydantic.errors.DateError</code></li> <li><code>pydantic.errors.DateNotInTheFutureError</code></li> <li><code>pydantic.errors.DateNotInThePastError</code></li> <li><code>pydantic.errors.DateTimeError</code></li> <li><code>pydantic.errors.DecimalError</code></li> <li><code>pydantic.errors.DecimalIsNotFiniteError</code></li> <li><code>pydantic.errors.DecimalMaxDigitsError</code></li> <li><code>pydantic.errors.DecimalMaxPlacesError</code></li> <li><code>pydantic.errors.DecimalWholeDigitsError</code></li> <li><code>pydantic.errors.DictError</code></li> <li><code>pydantic.errors.DurationError</code></li> <li><code>pydantic.errors.EmailError</code></li> <li><code>pydantic.errors.EnumError</code></li> <li><code>pydantic.errors.EnumMemberError</code></li> <li><code>pydantic.errors.ExtraError</code></li> <li><code>pydantic.errors.FloatError</code></li> <li><code>pydantic.errors.FrozenSetError</code></li> <li><code>pydantic.errors.FrozenSetMaxLengthError</code></li> <li><code>pydantic.errors.FrozenSetMinLengthError</code></li> <li><code>pydantic.errors.HashableError</code></li> <li><code>pydantic.errors.IPv4AddressError</code></li> <li><code>pydantic.errors.IPv4InterfaceError</code></li> <li><code>pydantic.errors.IPv4NetworkError</code></li> <li><code>pydantic.errors.IPv6AddressError</code></li> <li><code>pydantic.errors.IPv6InterfaceError</code></li> <li><code>pydantic.errors.IPv6NetworkError</code></li> <li><code>pydantic.errors.IPvAnyAddressError</code></li> <li><code>pydantic.errors.IPvAnyInterfaceError</code></li> <li><code>pydantic.errors.IPvAnyNetworkError</code></li> <li><code>pydantic.errors.IntEnumError</code></li> <li><code>pydantic.errors.IntegerError</code></li> <li><code>pydantic.errors.InvalidByteSize</code></li> <li><code>pydantic.errors.InvalidByteSizeUnit</code></li> <li><code>pydantic.errors.InvalidDiscriminator</code></li> <li><code>pydantic.errors.InvalidLengthForBrand</code></li> <li><code>pydantic.errors.JsonError</code></li> <li><code>pydantic.errors.JsonTypeError</code></li> <li><code>pydantic.errors.ListError</code></li> <li><code>pydantic.errors.ListMaxLengthError</code></li> <li><code>pydantic.errors.ListMinLengthError</code></li> <li><code>pydantic.errors.ListUniqueItemsError</code></li> <li><code>pydantic.errors.LuhnValidationError</code></li> <li><code>pydantic.errors.MissingDiscriminator</code></li> <li><code>pydantic.errors.MissingError</code></li> <li><code>pydantic.errors.NoneIsAllowedError</code></li> <li><code>pydantic.errors.NoneIsNotAllowedError</code></li> <li><code>pydantic.errors.NotDigitError</code></li> <li><code>pydantic.errors.NotNoneError</code></li> <li><code>pydantic.errors.NumberNotGeError</code></li> <li><code>pydantic.errors.NumberNotGtError</code></li> <li><code>pydantic.errors.NumberNotLeError</code></li> <li><code>pydantic.errors.NumberNotLtError</code></li> <li><code>pydantic.errors.NumberNotMultipleError</code></li> <li><code>pydantic.errors.PathError</code></li> <li><code>pydantic.errors.PathNotADirectoryError</code></li> <li><code>pydantic.errors.PathNotAFileError</code></li> <li><code>pydantic.errors.PathNotExistsError</code></li> <li><code>pydantic.errors.PatternError</code></li> <li><code>pydantic.errors.PyObjectError</code></li> <li><code>pydantic.errors.PydanticTypeError</code></li> <li><code>pydantic.errors.PydanticValueError</code></li> <li><code>pydantic.errors.SequenceError</code></li> <li><code>pydantic.errors.SetError</code></li> <li><code>pydantic.errors.SetMaxLengthError</code></li> <li><code>pydantic.errors.SetMinLengthError</code></li> <li><code>pydantic.errors.StrError</code></li> <li><code>pydantic.errors.StrRegexError</code></li> <li><code>pydantic.errors.StrictBoolError</code></li> <li><code>pydantic.errors.SubclassError</code></li> <li><code>pydantic.errors.TimeError</code></li> <li><code>pydantic.errors.TupleError</code></li> <li><code>pydantic.errors.TupleLengthError</code></li> <li><code>pydantic.errors.UUIDError</code></li> <li><code>pydantic.errors.UUIDVersionError</code></li> <li><code>pydantic.errors.UrlError</code></li> <li><code>pydantic.errors.UrlExtraError</code></li> <li><code>pydantic.errors.UrlHostError</code></li> <li><code>pydantic.errors.UrlHostTldError</code></li> <li><code>pydantic.errors.UrlPortError</code></li> <li><code>pydantic.errors.UrlSchemeError</code></li> <li><code>pydantic.errors.UrlSchemePermittedError</code></li> <li><code>pydantic.errors.UrlUserInfoError</code></li> <li><code>pydantic.errors.WrongConstantError</code></li> <li><code>pydantic.main.validate_model</code></li> <li><code>pydantic.networks.stricturl</code></li> <li><code>pydantic.parse_file_as</code></li> <li><code>pydantic.parse_raw_as</code></li> <li><code>pydantic.stricturl</code></li> <li><code>pydantic.tools.parse_file_as</code></li> <li><code>pydantic.tools.parse_raw_as</code></li> <li><code>pydantic.types.JsonWrapper</code></li> <li><code>pydantic.types.NoneBytes</code></li> <li><code>pydantic.types.NoneStr</code></li> <li><code>pydantic.types.NoneStrBytes</code></li> <li><code>pydantic.types.PyObject</code></li> <li><code>pydantic.types.StrBytes</code></li> <li><code>pydantic.typing.evaluate_forwardref</code></li> <li><code>pydantic.typing.AbstractSetIntStr</code></li> <li><code>pydantic.typing.AnyCallable</code></li> <li><code>pydantic.typing.AnyClassMethod</code></li> <li><code>pydantic.typing.CallableGenerator</code></li> <li><code>pydantic.typing.DictAny</code></li> <li><code>pydantic.typing.DictIntStrAny</code></li> <li><code>pydantic.typing.DictStrAny</code></li> <li><code>pydantic.typing.IntStr</code></li> <li><code>pydantic.typing.ListStr</code></li> <li><code>pydantic.typing.MappingIntStrAny</code></li> <li><code>pydantic.typing.NoArgAnyCallable</code></li> <li><code>pydantic.typing.NoneType</code></li> <li><code>pydantic.typing.ReprArgs</code></li> <li><code>pydantic.typing.SetStr</code></li> <li><code>pydantic.typing.StrPath</code></li> <li><code>pydantic.typing.TupleGenerator</code></li> <li><code>pydantic.typing.WithArgsTypes</code></li> <li><code>pydantic.typing.all_literal_values</code></li> <li><code>pydantic.typing.display_as_type</code></li> <li><code>pydantic.typing.get_all_type_hints</code></li> <li><code>pydantic.typing.get_args</code></li> <li><code>pydantic.typing.get_origin</code></li> <li><code>pydantic.typing.get_sub_types</code></li> <li><code>pydantic.typing.is_callable_type</code></li> <li><code>pydantic.typing.is_classvar</code></li> <li><code>pydantic.typing.is_finalvar</code></li> <li><code>pydantic.typing.is_literal_type</code></li> <li><code>pydantic.typing.is_namedtuple</code></li> <li><code>pydantic.typing.is_new_type</code></li> <li><code>pydantic.typing.is_none_type</code></li> <li><code>pydantic.typing.is_typeddict</code></li> <li><code>pydantic.typing.is_typeddict_special</code></li> <li><code>pydantic.typing.is_union</code></li> <li><code>pydantic.typing.new_type_supertype</code></li> <li><code>pydantic.typing.resolve_annotations</code></li> <li><code>pydantic.typing.typing_base</code></li> <li><code>pydantic.typing.update_field_forward_refs</code></li> <li><code>pydantic.typing.update_model_forward_refs</code></li> <li><code>pydantic.utils.ClassAttribute</code></li> <li><code>pydantic.utils.DUNDER_ATTRIBUTES</code></li> <li><code>pydantic.utils.PyObjectStr</code></li> <li><code>pydantic.utils.ValueItems</code></li> <li><code>pydantic.utils.almost_equal_floats</code></li> <li><code>pydantic.utils.get_discriminator_alias_and_values</code></li> <li><code>pydantic.utils.get_model</code></li> <li><code>pydantic.utils.get_unique_discriminator_alias</code></li> <li><code>pydantic.utils.in_ipython</code></li> <li><code>pydantic.utils.is_valid_identifier</code></li> <li><code>pydantic.utils.path_type</code></li> <li><code>pydantic.utils.validate_field_name</code></li> <li><code>pydantic.validate_model</code></li> </ul>"},{"location":"pydantic_people/","title":"Pydantic People","text":"<p>Pydantic has an amazing community of contributors, reviewers, and experts that help propel the project forward. Here, we celebrate those people and their contributions.</p>"},{"location":"pydantic_people/#maintainers","title":"Maintainers","text":"<p>These are the current maintainers of the Pydantic repository. Feel free to tag us if you have questions, review requests, or feature requests for which you'd like feedback!</p> @samuelcolvin @adriangb @sydney-runkle @dmontagu @davidhewitt @hramezani @alexmojaki @Kludex"},{"location":"pydantic_people/#experts","title":"Experts","text":"<p>These are the users that have helped others the most with questions in GitHub through all time.</p> @PrettyWood Questions replied: 143 @uriyyo Questions replied: 93 @Viicos Questions replied: 87 @lesnik512 Questions replied: 21 @harunyasar Questions replied: 17 @nymous Questions replied: 13 @ybressler Questions replied: None"},{"location":"pydantic_people/#most-active-users-last-month","title":"Most active users last month","text":"<p>These are the users that have helped others the most with questions in GitHub during the last month.</p> @Viicos Questions replied: 15"},{"location":"pydantic_people/#top-contributors","title":"Top contributors","text":"<p>These are the users that have created the most pull requests that have been merged.</p> @PrettyWood Contributions: 122 @Viicos Contributions: 77 @dependabot-preview Contributions: 75 @tpdorsey Contributions: 71 @lig Contributions: 49 @pyup-bot Contributions: 46 @tiangolo Contributions: 22 @Bobronium Contributions: 19 @Gr1N Contributions: 17 @uriyyo Contributions: 15 @pilosus Contributions: 12 @misrasaurabh1 Contributions: 12 @yezz123 Contributions: 11 @StephenBrown2 Contributions: 10 @koxudaxi Contributions: 9 @cdce8p Contributions: 9 @aminalaee Contributions: 8 @NeevCohen Contributions: 8 @layday Contributions: 7 @daviskirk Contributions: 7 @dgasmith Contributions: 6 @Atheuz Contributions: 6 @tlambert03 Contributions: 6 @nuno-andre Contributions: 5 @ofek Contributions: 5 @kc0506 Contributions: 5 @hmvp Contributions: 4 @retnikt Contributions: 4 @therefromhere Contributions: 4 @JeanArhancet Contributions: 4 @commonism Contributions: 4 @JensHeinrich Contributions: 4 @mgorny Contributions: 4 @ornariece Contributions: 4 @exs-dwoodward Contributions: 4 @dAIsySHEng1 Contributions: 4"},{"location":"pydantic_people/#top-reviewers","title":"Top Reviewers","text":"<p>These are the users that have reviewed the most Pull Requests from others, assisting with code quality, documentation, bug fixes, feature requests, etc.</p> @PrettyWood Reviews: 211 @lig Reviews: 103 @tpdorsey Reviews: 77 @Viicos Reviews: 77 @tiangolo Reviews: 44 @Bobronium Reviews: 27 @Gr1N Reviews: 17 @StephenBrown2 Reviews: 17 @ybressler Reviews: 15 @uriyyo Reviews: 11 @koxudaxi Reviews: 10 @daviskirk Reviews: 10 @yezz123 Reviews: 10 @Zac-HD Reviews: 8 @layday Reviews: 7 @pilosus Reviews: 6 @Kilo59 Reviews: 6 @JeanArhancet Reviews: 6 @MarkusSintonen Reviews: 6 @tlambert03 Reviews: 5 @christianbundy Reviews: 5 @hyperlint-ai Reviews: 5 @graingert Reviews: 4 @hmvp Reviews: 4 @wozniakty Reviews: 4 @nuno-andre Reviews: 4 @antdking Reviews: 4 @dimaqq Reviews: 4 @JensHeinrich Reviews: 4 @nix010 Reviews: 4"},{"location":"pydantic_people/#about-the-data","title":"About the data","text":"<p>The data displayed above is calculated monthly via the Github GraphQL API.</p> <p>The source code for this script is located here. Many thanks to Sebasti\u00e1n Ram\u00edrez for the script from which we based this logic.</p> <p>Depending on changing conditions, the thresholds for the different categories of contributors may change in the future.</p>"},{"location":"version-policy/","title":"Version Policy","text":"<p>First of all, we recognize that the transitions from Pydantic V1 to V2 has been and will be painful for some users. We're sorry about this pain , it was an unfortunate but necessary step to correct design mistakes of V1.</p> <p>There will not be another breaking change of this magnitude!</p>"},{"location":"version-policy/#pydantic-v1","title":"Pydantic V1","text":"<p>Active development of V1 has already stopped, however critical bug fixes and security vulnerabilities will be fixed in V1 until the release of Pydantic V3.</p>"},{"location":"version-policy/#pydantic-v2","title":"Pydantic V2","text":"<p>We will not intentionally make breaking changes in minor releases of V2.</p> <p>Functionality marked as deprecated will not be removed until the next major V3 release.</p> <p>Of course, some apparently safe changes and bug fixes will inevitably break some users' code \u2014 obligatory link to xkcd.</p> <p>The following changes will NOT be considered breaking changes, and may occur in minor releases:</p> <ul> <li>Changing the format of JSON Schema references.</li> <li>Changing the <code>msg</code>, <code>ctx</code>, and <code>loc</code> fields of <code>ValidationError</code> exceptions. <code>type</code> will not change \u2014 if you're programmatically parsing error messages, you should use <code>type</code>.</li> <li>Adding new keys to <code>ValidationError</code> exceptions \u2014 e.g. we intend to add <code>line_number</code> and <code>column_number</code> to errors when validating JSON once we migrate to a new JSON parser.</li> <li>Adding new <code>ValidationError</code> errors.</li> <li>Changing how <code>__repr__</code> behaves, even of public classes.</li> </ul> <p>In all cases we will aim to minimize churn and do so only when justified by the increase of quality of Pydantic for users.</p>"},{"location":"version-policy/#pydantic-v3-and-beyond","title":"Pydantic V3 and beyond","text":"<p>We expect to make new major releases roughly once a year going forward, although as mentioned above, any associated breaking changes should be trivial to fix compared to the V1-to-V2 transition.</p>"},{"location":"version-policy/#experimental-features","title":"Experimental Features","text":"<p>At Pydantic, we like to move quickly and innovate! To that end, we may introduce experimental features in minor releases.</p> <p>Usage Documentation</p> <p>To learn more about our current experimental features, see the experimental features documentation.</p> <p>Please keep in mind, experimental features are active works in progress. If these features are successful, they'll eventually become part of Pydantic. If unsuccessful, said features will be removed with little notice. While in its experimental phase, a feature's API and behaviors may not be stable, and it's very possible that changes made to the feature will not be backward-compatible.</p>"},{"location":"version-policy/#naming-conventions","title":"Naming Conventions","text":"<p>We use one of the following naming conventions to indicate that a feature is experimental:</p> <ol> <li> <p>The feature is located in the <code>experimental</code> module. In this case, you can access the feature like this:</p> <pre><code>from pydantic.experimental import feature_name\n</code></pre> </li> <li> <p>The feature is located in the main module, but prefixed with <code>experimental_</code>. This case occurs when we add a new field, argument, or method to an existing data structure already within the main <code>pydantic</code> module.</p> </li> </ol> <p>New features with these naming conventions are subject to change or removal, and we are looking for feedback and suggestions before making them a permanent part of Pydantic. See the feedback section for more information.</p>"},{"location":"version-policy/#importing-experimental-features","title":"Importing Experimental Features","text":"<p>When you import an experimental feature from the <code>experimental</code> module, you'll see a warning message that the feature is experimental. You can disable this warning with the following:</p> <pre><code>import warnings\n\nfrom pydantic import PydanticExperimentalWarning\n\nwarnings.filterwarnings('ignore', category=PydanticExperimentalWarning)\n</code></pre>"},{"location":"version-policy/#lifecycle-of-experimental-features","title":"Lifecycle of Experimental Features","text":"<ol> <li>A new feature is added, either in the <code>experimental</code> module or with the <code>experimental_</code> prefix.</li> <li>The behavior is often modified during patch/minor releases, with potential API/behavior changes.</li> <li>If the feature is successful, we promote it to Pydantic with the following steps:     a. If it was in the <code>experimental</code> module, the feature is cloned to Pydantic's main module. The original experimental feature still remains in the <code>experimental</code> module, but it will show a warning when used. If the feature was already in the main Pydantic module, we create a copy of the feature without the <code>experimental_</code> prefix, so the feature exists with both the official and experimental names. A deprecation warning is attached to the experimental version.     b. At some point, the code of the experimental feature is removed, but there will still be a stub of the feature that provides an error message with appropriate instructions.     c. As a last step, the experimental version of the feature is entirely removed from the codebase.</li> </ol> <p>If the feature is unsuccessful or unpopular, it's removed with little notice. A stub will remain in the location of the deprecated feature with an error message.</p> <p>Thanks to streamlit for the inspiration for the lifecycle and naming conventions of our new experimental feature patterns.</p>"},{"location":"version-policy/#support-for-python-versions","title":"Support for Python versions","text":"<p>Pydantic will drop support for a Python version when the following conditions are met:</p> <ul> <li>The Python version has reached its expected end of life.</li> <li>less than 5% of downloads of the most recent minor release are using that version.</li> </ul>"},{"location":"why/","title":"Why use Pydantic?","text":"<p>Today, Pydantic is downloaded many times a month and used by some of the largest and most recognisable organisations in the world.</p> <p>It's hard to know why so many people have adopted Pydantic since its inception six years ago, but here are a few guesses.</p>"},{"location":"why/#type-hints","title":"Type hints powering schema validation","text":"<p>The schema that Pydantic validates against is generally defined by Python type hints.</p> <p>Type hints are great for this since, if you're writing modern Python, you already know how to use them. Using type hints also means that Pydantic integrates well with static typing tools (like mypy and Pyright) and IDEs (like PyCharm and VSCode).</p> Example - just type hints <p>(This example requires Python 3.9+) <pre><code>from typing import Annotated, Literal\n\nfrom annotated_types import Gt\n\nfrom pydantic import BaseModel\n\n\nclass Fruit(BaseModel):\n    name: str  # (1)!\n    color: Literal['red', 'green']  # (2)!\n    weight: Annotated[float, Gt(0)]  # (3)!\n    bazam: dict[str, list[tuple[int, bool, float]]]  # (4)!\n\n\nprint(\n    Fruit(\n        name='Apple',\n        color='red',\n        weight=4.2,\n        bazam={'foobar': [(1, True, 0.1)]},\n    )\n)\n#&gt; name='Apple' color='red' weight=4.2 bazam={'foobar': [(1, True, 0.1)]}\n</code></pre></p> <ol> <li>The <code>name</code> field is simply annotated with <code>str</code> \u2014 any string is allowed.</li> <li>The <code>Literal</code> type is used to enforce that <code>color</code> is either <code>'red'</code> or <code>'green'</code>.</li> <li>Even when we want to apply constraints not encapsulated in Python types, we can use <code>Annotated</code>    and <code>annotated-types</code> to enforce constraints while still keeping typing support.</li> <li>I'm not claiming \"bazam\" is really an attribute of fruit, but rather to show that arbitrarily complex types can easily be validated.</li> </ol> <p>Learn more</p> <p>See the documentation on supported types.</p>"},{"location":"why/#performance","title":"Performance","text":"<p>Pydantic's core validation logic is implemented in a separate package (<code>pydantic-core</code>), where validation for most types is implemented in Rust.</p> <p>As a result, Pydantic is among the fastest data validation libraries for Python.</p> Performance Example - Pydantic vs. dedicated code <p>In general, dedicated code should be much faster than a general-purpose validator, but in this example Pydantic is &gt;300% faster than dedicated code when parsing JSON and validating URLs.</p> Performance Example<pre><code>import json\nimport timeit\nfrom urllib.parse import urlparse\n\nimport requests\n\nfrom pydantic import HttpUrl, TypeAdapter\n\nreps = 7\nnumber = 100\nr = requests.get('https://api.github.com/emojis')\nr.raise_for_status()\nemojis_json = r.content\n\n\ndef emojis_pure_python(raw_data):\n    data = json.loads(raw_data)\n    output = {}\n    for key, value in data.items():\n        assert isinstance(key, str)\n        url = urlparse(value)\n        assert url.scheme in ('https', 'http')\n        output[key] = url\n\n\nemojis_pure_python_times = timeit.repeat(\n    'emojis_pure_python(emojis_json)',\n    globals={\n        'emojis_pure_python': emojis_pure_python,\n        'emojis_json': emojis_json,\n    },\n    repeat=reps,\n    number=number,\n)\nprint(f'pure python: {min(emojis_pure_python_times) / number * 1000:0.2f}ms')\n#&gt; pure python: 5.32ms\n\ntype_adapter = TypeAdapter(dict[str, HttpUrl])\nemojis_pydantic_times = timeit.repeat(\n    'type_adapter.validate_json(emojis_json)',\n    globals={\n        'type_adapter': type_adapter,\n        'HttpUrl': HttpUrl,\n        'emojis_json': emojis_json,\n    },\n    repeat=reps,\n    number=number,\n)\nprint(f'pydantic: {min(emojis_pydantic_times) / number * 1000:0.2f}ms')\n#&gt; pydantic: 1.54ms\n\nprint(\n    f'Pydantic {min(emojis_pure_python_times) / min(emojis_pydantic_times):0.2f}x faster'\n)\n#&gt; Pydantic 3.45x faster\n</code></pre> <p>Unlike other performance-centric libraries written in compiled languages, Pydantic also has excellent support for customizing validation via functional validators.</p> <p>Learn more</p> <p>Samuel Colvin's talk at PyCon 2023 explains how <code>pydantic-core</code> works and how it integrates with Pydantic.</p>"},{"location":"why/#serialization","title":"Serialization","text":"<p>Pydantic provides functionality to serialize model in three ways:</p> <ol> <li>To a Python <code>dict</code> made up of the associated Python objects.</li> <li>To a Python <code>dict</code> made up only of \"jsonable\" types.</li> <li>To a JSON string.</li> </ol> <p>In all three modes, the output can be customized by excluding specific fields, excluding unset fields, excluding default values, and excluding <code>None</code> values.</p> Example - Serialization 3 ways <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel\n\n\nclass Meeting(BaseModel):\n    when: datetime\n    where: bytes\n    why: str = 'No idea'\n\n\nm = Meeting(when='2020-01-01T12:00', where='home')\nprint(m.model_dump(exclude_unset=True))\n#&gt; {'when': datetime.datetime(2020, 1, 1, 12, 0), 'where': b'home'}\nprint(m.model_dump(exclude={'where'}, mode='json'))\n#&gt; {'when': '2020-01-01T12:00:00', 'why': 'No idea'}\nprint(m.model_dump_json(exclude_defaults=True))\n#&gt; {\"when\":\"2020-01-01T12:00:00\",\"where\":\"home\"}\n</code></pre> <p>Learn more</p> <p>See the documentation on serialization.</p>"},{"location":"why/#json-schema","title":"JSON Schema","text":"<p>A JSON Schema can be generated for any Pydantic schema \u2014 allowing self-documenting APIs and integration with a wide variety of tools which support the JSON Schema format.</p> Example - JSON Schema <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel\n\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    zipcode: str\n\n\nclass Meeting(BaseModel):\n    when: datetime\n    where: Address\n    why: str = 'No idea'\n\n\nprint(Meeting.model_json_schema())\n\"\"\"\n{\n    '$defs': {\n        'Address': {\n            'properties': {\n                'street': {'title': 'Street', 'type': 'string'},\n                'city': {'title': 'City', 'type': 'string'},\n                'zipcode': {'title': 'Zipcode', 'type': 'string'},\n            },\n            'required': ['street', 'city', 'zipcode'],\n            'title': 'Address',\n            'type': 'object',\n        }\n    },\n    'properties': {\n        'when': {'format': 'date-time', 'title': 'When', 'type': 'string'},\n        'where': {'$ref': '#/$defs/Address'},\n        'why': {'default': 'No idea', 'title': 'Why', 'type': 'string'},\n    },\n    'required': ['when', 'where'],\n    'title': 'Meeting',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <p>Pydantic is compliant with the latest version of JSON Schema specification (2020-12), which is compatible with OpenAPI 3.1.</p> <p>Learn more</p> <p>See the documentation on JSON Schema.</p>"},{"location":"why/#strict-lax","title":"Strict mode and data coercion","text":"<p>By default, Pydantic is tolerant to common incorrect types and coerces data to the right type \u2014 e.g. a numeric string passed to an <code>int</code> field will be parsed as an <code>int</code>.</p> <p>Pydantic also has as strict mode, where types are not coerced and a validation error is raised unless the input data exactly matches the expected schema.</p> <p>But strict mode would be pretty useless when validating JSON data since JSON doesn't have types matching many common Python types like <code>datetime</code>, <code>UUID</code> or <code>bytes</code>.</p> <p>To solve this, Pydantic can parse and validate JSON in one step. This allows sensible data conversion (e.g. when parsing strings into <code>datetime</code> objects). Since the JSON parsing is implemented in Rust, it's also very performant.</p> Example - Strict mode that's actually useful <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Meeting(BaseModel):\n    when: datetime\n    where: bytes\n\n\nm = Meeting.model_validate({'when': '2020-01-01T12:00', 'where': 'home'})\nprint(m)\n#&gt; when=datetime.datetime(2020, 1, 1, 12, 0) where=b'home'\ntry:\n    m = Meeting.model_validate(\n        {'when': '2020-01-01T12:00', 'where': 'home'}, strict=True\n    )\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for Meeting\n    when\n      Input should be a valid datetime [type=datetime_type, input_value='2020-01-01T12:00', input_type=str]\n    where\n      Input should be a valid bytes [type=bytes_type, input_value='home', input_type=str]\n    \"\"\"\n\nm_json = Meeting.model_validate_json(\n    '{\"when\": \"2020-01-01T12:00\", \"where\": \"home\"}'\n)\nprint(m_json)\n#&gt; when=datetime.datetime(2020, 1, 1, 12, 0) where=b'home'\n</code></pre> <p>Learn more</p> <p>See the documentation on strict mode.</p>"},{"location":"why/#dataclasses-typeddict-more","title":"Dataclasses, TypedDicts, and more","text":"<p>Pydantic provides four ways to create schemas and perform validation and serialization:</p> <ol> <li><code>BaseModel</code> \u2014 Pydantic's own super class with many common utilities available via instance methods.</li> <li>Pydantic dataclasses \u2014 a wrapper around standard dataclasses with additional validation performed.</li> <li><code>TypeAdapter</code> \u2014 a general way to adapt any type for validation and serialization.    This allows types like <code>TypedDict</code> and <code>NamedTuple</code>    to be validated as well as simple types (like <code>int</code> or <code>timedelta</code>) \u2014 all types supported    can be used with <code>TypeAdapter</code>.</li> <li><code>validate_call</code> \u2014 a decorator to perform validation when calling a function.</li> </ol> Example - schema based on a <code>TypedDict</code> <pre><code>from datetime import datetime\n\nfrom typing_extensions import NotRequired, TypedDict\n\nfrom pydantic import TypeAdapter\n\n\nclass Meeting(TypedDict):\n    when: datetime\n    where: bytes\n    why: NotRequired[str]\n\n\nmeeting_adapter = TypeAdapter(Meeting)\nm = meeting_adapter.validate_python(  # (1)!\n    {'when': '2020-01-01T12:00', 'where': 'home'}\n)\nprint(m)\n#&gt; {'when': datetime.datetime(2020, 1, 1, 12, 0), 'where': b'home'}\nmeeting_adapter.dump_python(m, exclude={'where'})  # (2)!\n\nprint(meeting_adapter.json_schema())  # (3)!\n\"\"\"\n{\n    'properties': {\n        'when': {'format': 'date-time', 'title': 'When', 'type': 'string'},\n        'where': {'format': 'binary', 'title': 'Where', 'type': 'string'},\n        'why': {'title': 'Why', 'type': 'string'},\n    },\n    'required': ['when', 'where'],\n    'title': 'Meeting',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <ol> <li><code>TypeAdapter</code> for a <code>TypedDict</code> performing validation,    it can also validate JSON data directly with <code>validate_json</code>.</li> <li><code>dump_python</code> to serialise a <code>TypedDict</code>    to a python object, it can also serialise to JSON with <code>dump_json</code>.</li> <li><code>TypeAdapter</code> can also generate a JSON Schema.</li> </ol>"},{"location":"why/#customisation","title":"Customisation","text":"<p>Functional validators and serializers, as well as a powerful protocol for custom types, means the way Pydantic operates can be customized on a per-field or per-type basis.</p> Customisation Example - wrap validators <p>\"wrap validators\" are new in Pydantic V2 and are one of the most powerful ways to customize validation.</p> <pre><code>from datetime import datetime, timezone\nfrom typing import Any\n\nfrom pydantic_core.core_schema import ValidatorFunctionWrapHandler\n\nfrom pydantic import BaseModel, field_validator\n\n\nclass Meeting(BaseModel):\n    when: datetime\n\n    @field_validator('when', mode='wrap')\n    def when_now(\n        cls, input_value: Any, handler: ValidatorFunctionWrapHandler\n    ) -&gt; datetime:\n        if input_value == 'now':\n            return datetime.now()\n        when = handler(input_value)\n        # in this specific application we know tz naive datetimes are in UTC\n        if when.tzinfo is None:\n            when = when.replace(tzinfo=timezone.utc)\n        return when\n\n\nprint(Meeting(when='2020-01-01T12:00+01:00'))\n#&gt; when=datetime.datetime(2020, 1, 1, 12, 0, tzinfo=TzInfo(+01:00))\nprint(Meeting(when='now'))\n#&gt; when=datetime.datetime(2032, 1, 2, 3, 4, 5, 6)\nprint(Meeting(when='2020-01-01T12:00'))\n#&gt; when=datetime.datetime(2020, 1, 1, 12, 0, tzinfo=datetime.timezone.utc)\n</code></pre> <p>Learn more</p> <p>See the documentation on validators, custom serializers, and custom types.</p>"},{"location":"why/#ecosystem","title":"Ecosystem","text":"<p>At the time of writing there are 466,400 repositories on GitHub and 8,119 packages on PyPI that depend on Pydantic.</p> <p>Some notable libraries that depend on Pydantic:</p> <ul> <li><code>huggingface/transformers</code> 107,475 stars</li> <li><code>tiangolo/fastapi</code> 60,355 stars</li> <li><code>hwchase17/langchain</code> 54,514 stars</li> <li><code>apache/airflow</code> 30,955 stars</li> <li><code>microsoft/DeepSpeed</code> 26,908 stars</li> <li><code>ray-project/ray</code> 26,600 stars</li> <li><code>lm-sys/FastChat</code> 24,924 stars</li> <li><code>Lightning-AI/lightning</code> 24,034 stars</li> <li><code>OpenBB-finance/OpenBBTerminal</code> 22,785 stars</li> <li><code>gradio-app/gradio</code> 19,726 stars</li> <li><code>pola-rs/polars</code> 18,587 stars</li> <li><code>mindsdb/mindsdb</code> 17,242 stars</li> <li><code>RasaHQ/rasa</code> 16,695 stars</li> <li><code>mlflow/mlflow</code> 14,780 stars</li> <li><code>heartexlabs/label-studio</code> 13,634 stars</li> <li><code>spotDL/spotify-downloader</code> 12,124 stars</li> <li><code>Sanster/lama-cleaner</code> 12,075 stars</li> <li><code>airbytehq/airbyte</code> 11,174 stars</li> <li><code>openai/evals</code> 11,110 stars</li> <li><code>matrix-org/synapse</code> 11,071 stars</li> <li><code>ydataai/ydata-profiling</code> 10,884 stars</li> <li><code>pyodide/pyodide</code> 10,245 stars</li> <li><code>tiangolo/sqlmodel</code> 10,160 stars</li> <li><code>lucidrains/DALLE2-pytorch</code> 9,916 stars</li> <li><code>pynecone-io/reflex</code> 9,679 stars</li> <li><code>PaddlePaddle/PaddleNLP</code> 9,663 stars</li> <li><code>aws/serverless-application-model</code> 9,061 stars</li> <li><code>modin-project/modin</code> 8,808 stars</li> <li><code>great-expectations/great_expectations</code> 8,613 stars</li> <li><code>dagster-io/dagster</code> 7,908 stars</li> <li><code>NVlabs/SPADE</code> 7,407 stars</li> <li><code>brycedrennan/imaginAIry</code> 7,217 stars</li> <li><code>chroma-core/chroma</code> 7,127 stars</li> <li><code>lucidrains/imagen-pytorch</code> 7,089 stars</li> <li><code>sqlfluff/sqlfluff</code> 6,278 stars</li> <li><code>deeppavlov/DeepPavlov</code> 6,278 stars</li> <li><code>autogluon/autogluon</code> 5,966 stars</li> <li><code>bridgecrewio/checkov</code> 5,747 stars</li> <li><code>bentoml/BentoML</code> 5,275 stars</li> <li><code>replicate/cog</code> 5,089 stars</li> <li><code>vitalik/django-ninja</code> 4,623 stars</li> <li><code>apache/iceberg</code> 4,479 stars</li> <li><code>jina-ai/discoart</code> 3,820 stars</li> <li><code>embedchain/embedchain</code> 3,493 stars</li> <li><code>skypilot-org/skypilot</code> 3,052 stars</li> <li><code>PrefectHQ/marvin</code> 2,985 stars</li> <li><code>microsoft/FLAML</code> 2,569 stars</li> <li><code>docarray/docarray</code> 2,353 stars</li> <li><code>aws-powertools/powertools-lambda-python</code> 2,198 stars</li> <li><code>NVIDIA/NeMo-Guardrails</code> 1,830 stars</li> <li><code>roman-right/beanie</code> 1,299 stars</li> <li><code>art049/odmantic</code> 807 stars</li> </ul> <p>More libraries using Pydantic can be found at <code>Kludex/awesome-pydantic</code>.</p>"},{"location":"why/#using-pydantic","title":"Organisations using Pydantic","text":"<p>Some notable companies and organisations using Pydantic together with comments on why/how we know they're using Pydantic.</p> <p>The organisations below are included because they match one or more of the following criteria:</p> <ul> <li>Using Pydantic as a dependency in a public repository.</li> <li>Referring traffic to the Pydantic documentation site from an organization-internal domain \u2014 specific referrers are not included since they're generally not in the public domain.</li> <li>Direct communication between the Pydantic team and engineers employed by the organization about usage of Pydantic within the organization.</li> </ul> <p>We've included some extra detail where appropriate and already in the public domain.</p>"},{"location":"why/#org-adobe","title":"Adobe","text":"<p><code>adobe/dy-sql</code> uses Pydantic.</p>"},{"location":"why/#org-amazon","title":"Amazon and AWS","text":"<ul> <li>powertools-lambda-python</li> <li>awslabs/gluonts</li> <li>AWS sponsored Samuel Colvin $5,000 to work on Pydantic in 2022</li> </ul>"},{"location":"why/#org-anthropic","title":"Anthropic","text":"<p><code>anthropics/anthropic-sdk-python</code> uses Pydantic.</p>"},{"location":"why/#org-apple","title":"Apple","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-asml","title":"ASML","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-astrazeneca","title":"AstraZeneca","text":"<p>Multiple repos in the <code>AstraZeneca</code> GitHub org depend on Pydantic.</p>"},{"location":"why/#org-cisco","title":"Cisco Systems","text":"<ul> <li>Pydantic is listed in their report of Open Source Used In RADKit.</li> <li><code>cisco/webex-assistant-sdk</code></li> </ul>"},{"location":"why/#org-comcast","title":"Comcast","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-datadog","title":"Datadog","text":"<ul> <li>Extensive use of Pydantic in <code>DataDog/integrations-core</code> and other repos</li> <li>Communication with engineers from Datadog about how they use Pydantic.</li> </ul>"},{"location":"why/#org-facebook","title":"Facebook","text":"<p>Multiple repos in the <code>facebookresearch</code> GitHub org depend on Pydantic.</p>"},{"location":"why/#org-github","title":"GitHub","text":"<p>GitHub sponsored Pydantic $750 in 2022</p>"},{"location":"why/#org-google","title":"Google","text":"<p>Extensive use of Pydantic in <code>google/turbinia</code> and other repos.</p>"},{"location":"why/#org-hsbc","title":"HSBC","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-ibm","title":"IBM","text":"<p>Multiple repos in the <code>IBM</code> GitHub org depend on Pydantic.</p>"},{"location":"why/#org-intel","title":"Intel","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-intuit","title":"Intuit","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-ipcc","title":"Intergovernmental Panel on Climate Change","text":"<p>Tweet explaining how the IPCC use Pydantic.</p>"},{"location":"why/#org-jpmorgan","title":"JPMorgan","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-jupyter","title":"Jupyter","text":"<ul> <li>The developers of the Jupyter notebook are using Pydantic for subprojects</li> <li>Through the FastAPI-based Jupyter server Jupyverse</li> <li>FPS's configuration management.</li> </ul>"},{"location":"why/#org-microsoft","title":"Microsoft","text":"<ul> <li>DeepSpeed deep learning optimisation library uses Pydantic extensively</li> <li>Multiple repos in the <code>microsoft</code> GitHub org depend on Pydantic, in particular their</li> <li>Pydantic is also used in the <code>Azure</code> GitHub org</li> <li>Comments on GitHub show Microsoft engineers using Pydantic as part of Windows and Office</li> </ul>"},{"location":"why/#org-molssi","title":"Molecular Science Software Institute","text":"<p>Multiple repos in the <code>MolSSI</code> GitHub org depend on Pydantic.</p>"},{"location":"why/#org-nasa","title":"NASA","text":"<p>Multiple repos in the <code>NASA</code> GitHub org depend on Pydantic.</p> <p>NASA are also using Pydantic via FastAPI in their JWST project to process images from the James Webb Space Telescope, see this tweet.</p>"},{"location":"why/#org-netflix","title":"Netflix","text":"<p>Multiple repos in the <code>Netflix</code> GitHub org depend on Pydantic.</p>"},{"location":"why/#org-nsa","title":"NSA","text":"<p>The <code>nsacyber/WALKOFF</code> repo depends on Pydantic.</p>"},{"location":"why/#org-nvidia","title":"NVIDIA","text":"<p>Multiple repositories in the <code>NVIDIA</code> GitHub org depend on Pydantic.</p> <p>Their \"Omniverse Services\" depends on Pydantic according to their documentation.</p>"},{"location":"why/#org-openai","title":"OpenAI","text":"<p>OpenAI use Pydantic for their ChatCompletions API, as per this discussion on GitHub.</p> <p>Anecdotally, OpenAI use Pydantic extensively for their internal services.</p>"},{"location":"why/#org-oracle","title":"Oracle","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-palantir","title":"Palantir","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-qualcomm","title":"Qualcomm","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-redhat","title":"Red Hat","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-revolut","title":"Revolut","text":"<p>Anecdotally, all internal services at Revolut are built with FastAPI and therefore Pydantic.</p>"},{"location":"why/#org-robusta","title":"Robusta","text":"<p>The <code>robusta-dev/robusta</code> repo depends on Pydantic.</p>"},{"location":"why/#org-salesforce","title":"Salesforce","text":"<p>Salesforce sponsored Samuel Colvin $10,000 to work on Pydantic in 2022.</p>"},{"location":"why/#org-starbucks","title":"Starbucks","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-ti","title":"Texas Instruments","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-twilio","title":"Twilio","text":"<p>(Based on the criteria described above)</p>"},{"location":"why/#org-twitter","title":"Twitter","text":"<p>Twitter's <code>the-algorithm</code> repo where they open sourced their recommendation engine uses Pydantic.</p>"},{"location":"why/#org-ukhomeoffice","title":"UK Home Office","text":"<p>(Based on the criteria described above)</p>"},{"location":"api/aliases/","title":"Aliases","text":"<p>Support for alias configurations.</p>"},{"location":"api/aliases/#pydantic.aliases.AliasPath","title":"AliasPath  <code>dataclass</code>","text":"<pre><code>AliasPath(first_arg: str, *args: str | int)\n</code></pre> <p>Usage Documentation</p> <p><code>AliasPath</code> and <code>AliasChoices</code></p> <p>A data class used by <code>validation_alias</code> as a convenience to create aliases.</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>list[int | str]</code> <p>A list of string or integer aliases.</p> Source code in <code>pydantic/aliases.py</code> <pre><code>def __init__(self, first_arg: str, *args: str | int) -&gt; None:\n    self.path = [first_arg] + list(args)\n</code></pre>"},{"location":"api/aliases/#pydantic.aliases.AliasPath.convert_to_aliases","title":"convert_to_aliases","text":"<pre><code>convert_to_aliases() -&gt; list[str | int]\n</code></pre> <p>Converts arguments to a list of string or integer aliases.</p> <p>Returns:</p> Type Description <code>list[str | int]</code> <p>The list of aliases.</p> Source code in <code>pydantic/aliases.py</code> <pre><code>def convert_to_aliases(self) -&gt; list[str | int]:\n    \"\"\"Converts arguments to a list of string or integer aliases.\n\n    Returns:\n        The list of aliases.\n    \"\"\"\n    return self.path\n</code></pre>"},{"location":"api/aliases/#pydantic.aliases.AliasPath.search_dict_for_path","title":"search_dict_for_path","text":"<pre><code>search_dict_for_path(d: dict) -&gt; Any\n</code></pre> <p>Searches a dictionary for the path specified by the alias.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The value at the specified path, or <code>PydanticUndefined</code> if the path is not found.</p> Source code in <code>pydantic/aliases.py</code> <pre><code>def search_dict_for_path(self, d: dict) -&gt; Any:\n    \"\"\"Searches a dictionary for the path specified by the alias.\n\n    Returns:\n        The value at the specified path, or `PydanticUndefined` if the path is not found.\n    \"\"\"\n    v = d\n    for k in self.path:\n        if isinstance(v, str):\n            # disallow indexing into a str, like for AliasPath('x', 0) and x='abc'\n            return PydanticUndefined\n        try:\n            v = v[k]\n        except (KeyError, IndexError, TypeError):\n            return PydanticUndefined\n    return v\n</code></pre>"},{"location":"api/aliases/#pydantic.aliases.AliasChoices","title":"AliasChoices  <code>dataclass</code>","text":"<pre><code>AliasChoices(\n    first_choice: str | AliasPath, *choices: str | AliasPath\n)\n</code></pre> <p>Usage Documentation</p> <p><code>AliasPath</code> and <code>AliasChoices</code></p> <p>A data class used by <code>validation_alias</code> as a convenience to create aliases.</p> <p>Attributes:</p> Name Type Description <code>choices</code> <code>list[str | AliasPath]</code> <p>A list containing a string or <code>AliasPath</code>.</p> Source code in <code>pydantic/aliases.py</code> <pre><code>def __init__(self, first_choice: str | AliasPath, *choices: str | AliasPath) -&gt; None:\n    self.choices = [first_choice] + list(choices)\n</code></pre>"},{"location":"api/aliases/#pydantic.aliases.AliasChoices.convert_to_aliases","title":"convert_to_aliases","text":"<pre><code>convert_to_aliases() -&gt; list[list[str | int]]\n</code></pre> <p>Converts arguments to a list of lists containing string or integer aliases.</p> <p>Returns:</p> Type Description <code>list[list[str | int]]</code> <p>The list of aliases.</p> Source code in <code>pydantic/aliases.py</code> <pre><code>def convert_to_aliases(self) -&gt; list[list[str | int]]:\n    \"\"\"Converts arguments to a list of lists containing string or integer aliases.\n\n    Returns:\n        The list of aliases.\n    \"\"\"\n    aliases: list[list[str | int]] = []\n    for c in self.choices:\n        if isinstance(c, AliasPath):\n            aliases.append(c.convert_to_aliases())\n        else:\n            aliases.append([c])\n    return aliases\n</code></pre>"},{"location":"api/aliases/#pydantic.aliases.AliasGenerator","title":"AliasGenerator  <code>dataclass</code>","text":"<pre><code>AliasGenerator(\n    alias: Callable[[str], str] | None = None,\n    validation_alias: (\n        Callable[[str], str | AliasPath | AliasChoices]\n        | None\n    ) = None,\n    serialization_alias: Callable[[str], str] | None = None,\n)\n</code></pre> <p>Usage Documentation</p> <p>Using an <code>AliasGenerator</code></p> <p>A data class used by <code>alias_generator</code> as a convenience to create various aliases.</p> <p>Attributes:</p> Name Type Description <code>alias</code> <code>Callable[[str], str] | None</code> <p>A callable that takes a field name and returns an alias for it.</p> <code>validation_alias</code> <code>Callable[[str], str | AliasPath | AliasChoices] | None</code> <p>A callable that takes a field name and returns a validation alias for it.</p> <code>serialization_alias</code> <code>Callable[[str], str] | None</code> <p>A callable that takes a field name and returns a serialization alias for it.</p>"},{"location":"api/aliases/#pydantic.aliases.AliasGenerator.generate_aliases","title":"generate_aliases","text":"<pre><code>generate_aliases(\n    field_name: str,\n) -&gt; tuple[\n    str | None,\n    str | AliasPath | AliasChoices | None,\n    str | None,\n]\n</code></pre> <p>Generate <code>alias</code>, <code>validation_alias</code>, and <code>serialization_alias</code> for a field.</p> <p>Returns:</p> Type Description <code>tuple[str | None, str | AliasPath | AliasChoices | None, str | None]</code> <p>A tuple of three aliases - validation, alias, and serialization.</p> Source code in <code>pydantic/aliases.py</code> <pre><code>def generate_aliases(self, field_name: str) -&gt; tuple[str | None, str | AliasPath | AliasChoices | None, str | None]:\n    \"\"\"Generate `alias`, `validation_alias`, and `serialization_alias` for a field.\n\n    Returns:\n        A tuple of three aliases - validation, alias, and serialization.\n    \"\"\"\n    alias = self._generate_alias('alias', (str,), field_name)\n    validation_alias = self._generate_alias('validation_alias', (str, AliasChoices, AliasPath), field_name)\n    serialization_alias = self._generate_alias('serialization_alias', (str,), field_name)\n\n    return alias, validation_alias, serialization_alias  # type: ignore\n</code></pre>"},{"location":"api/annotated_handlers/","title":"Annotated Handlers","text":"<p>Type annotations to use with <code>__get_pydantic_core_schema__</code> and <code>__get_pydantic_json_schema__</code>.</p>"},{"location":"api/annotated_handlers/#pydantic.annotated_handlers.GetJsonSchemaHandler","title":"GetJsonSchemaHandler","text":"<p>Handler to call into the next JSON schema generation function.</p> <p>Attributes:</p> Name Type Description <code>mode</code> <code>JsonSchemaMode</code> <p>Json schema mode, can be <code>validation</code> or <code>serialization</code>.</p>"},{"location":"api/annotated_handlers/#pydantic.annotated_handlers.GetJsonSchemaHandler.resolve_ref_schema","title":"resolve_ref_schema","text":"<pre><code>resolve_ref_schema(\n    maybe_ref_json_schema: JsonSchemaValue,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Get the real schema for a <code>{\"$ref\": ...}</code> schema. If the schema given is not a <code>$ref</code> schema, it will be returned as is. This means you don't have to check before calling this function.</p> <p>Parameters:</p> Name Type Description Default <code>maybe_ref_json_schema</code> <code>JsonSchemaValue</code> <p>A JsonSchemaValue which may be a <code>$ref</code> schema.</p> required <p>Raises:</p> Type Description <code>LookupError</code> <p>If the ref is not found.</p> <p>Returns:</p> Name Type Description <code>JsonSchemaValue</code> <code>JsonSchemaValue</code> <p>A JsonSchemaValue that has no <code>$ref</code>.</p> Source code in <code>pydantic/annotated_handlers.py</code> <pre><code>def resolve_ref_schema(self, maybe_ref_json_schema: JsonSchemaValue, /) -&gt; JsonSchemaValue:\n    \"\"\"Get the real schema for a `{\"$ref\": ...}` schema.\n    If the schema given is not a `$ref` schema, it will be returned as is.\n    This means you don't have to check before calling this function.\n\n    Args:\n        maybe_ref_json_schema: A JsonSchemaValue which may be a `$ref` schema.\n\n    Raises:\n        LookupError: If the ref is not found.\n\n    Returns:\n        JsonSchemaValue: A JsonSchemaValue that has no `$ref`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/annotated_handlers/#pydantic.annotated_handlers.GetCoreSchemaHandler","title":"GetCoreSchemaHandler","text":"<p>Handler to call into the next CoreSchema schema generation function.</p>"},{"location":"api/annotated_handlers/#pydantic.annotated_handlers.GetCoreSchemaHandler.field_name","title":"field_name  <code>property</code>","text":"<pre><code>field_name: str | None\n</code></pre> <p>Get the name of the closest field to this validator.</p>"},{"location":"api/annotated_handlers/#pydantic.annotated_handlers.GetCoreSchemaHandler.generate_schema","title":"generate_schema","text":"<pre><code>generate_schema(source_type: Any) -&gt; CoreSchema\n</code></pre> <p>Generate a schema unrelated to the current context. Use this function if e.g. you are handling schema generation for a sequence and want to generate a schema for its items. Otherwise, you may end up doing something like applying a <code>min_length</code> constraint that was intended for the sequence itself to its items!</p> <p>Parameters:</p> Name Type Description Default <code>source_type</code> <code>Any</code> <p>The input type.</p> required <p>Returns:</p> Name Type Description <code>CoreSchema</code> <code>CoreSchema</code> <p>The <code>pydantic-core</code> CoreSchema generated.</p> Source code in <code>pydantic/annotated_handlers.py</code> <pre><code>def generate_schema(self, source_type: Any, /) -&gt; core_schema.CoreSchema:\n    \"\"\"Generate a schema unrelated to the current context.\n    Use this function if e.g. you are handling schema generation for a sequence\n    and want to generate a schema for its items.\n    Otherwise, you may end up doing something like applying a `min_length` constraint\n    that was intended for the sequence itself to its items!\n\n    Args:\n        source_type: The input type.\n\n    Returns:\n        CoreSchema: The `pydantic-core` CoreSchema generated.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/annotated_handlers/#pydantic.annotated_handlers.GetCoreSchemaHandler.resolve_ref_schema","title":"resolve_ref_schema","text":"<pre><code>resolve_ref_schema(\n    maybe_ref_schema: CoreSchema,\n) -&gt; CoreSchema\n</code></pre> <p>Get the real schema for a <code>definition-ref</code> schema. If the schema given is not a <code>definition-ref</code> schema, it will be returned as is. This means you don't have to check before calling this function.</p> <p>Parameters:</p> Name Type Description Default <code>maybe_ref_schema</code> <code>CoreSchema</code> <p>A <code>CoreSchema</code>, <code>ref</code>-based or not.</p> required <p>Raises:</p> Type Description <code>LookupError</code> <p>If the <code>ref</code> is not found.</p> <p>Returns:</p> Type Description <code>CoreSchema</code> <p>A concrete <code>CoreSchema</code>.</p> Source code in <code>pydantic/annotated_handlers.py</code> <pre><code>def resolve_ref_schema(self, maybe_ref_schema: core_schema.CoreSchema, /) -&gt; core_schema.CoreSchema:\n    \"\"\"Get the real schema for a `definition-ref` schema.\n    If the schema given is not a `definition-ref` schema, it will be returned as is.\n    This means you don't have to check before calling this function.\n\n    Args:\n        maybe_ref_schema: A `CoreSchema`, `ref`-based or not.\n\n    Raises:\n        LookupError: If the `ref` is not found.\n\n    Returns:\n        A concrete `CoreSchema`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/base_model/","title":"BaseModel","text":"<p>Pydantic models are simply classes which inherit from <code>BaseModel</code> and define fields as annotated attributes.</p>"},{"location":"api/base_model/#pydantic.BaseModel","title":"pydantic.BaseModel","text":"<p>Usage Documentation</p> <p>Models</p> <p>A base class for creating Pydantic models.</p> <p>Attributes:</p> Name Type Description <code>__class_vars__</code> <code>set[str]</code> <p>The names of the class variables defined on the model.</p> <code>__private_attributes__</code> <code>Dict[str, ModelPrivateAttr]</code> <p>Metadata about the private attributes of the model.</p> <code>__signature__</code> <code>Signature</code> <p>The synthesized <code>__init__</code> <code>Signature</code> of the model.</p> <code>__pydantic_complete__</code> <code>bool</code> <p>Whether model building is completed, or if there are still undefined fields.</p> <code>__pydantic_core_schema__</code> <code>CoreSchema</code> <p>The core schema of the model.</p> <code>__pydantic_custom_init__</code> <code>bool</code> <p>Whether the model has a custom <code>__init__</code> function.</p> <code>__pydantic_decorators__</code> <code>DecoratorInfos</code> <p>Metadata containing the decorators defined on the model. This replaces <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</p> <code>__pydantic_generic_metadata__</code> <code>PydanticGenericMetadata</code> <p>Metadata for generic models; contains data used for a similar purpose to args, origin, parameters in typing-module generics. May eventually be replaced by these.</p> <code>__pydantic_parent_namespace__</code> <code>Dict[str, Any] | None</code> <p>Parent namespace of the model, used for automatic rebuilding of models.</p> <code>__pydantic_post_init__</code> <code>None | Literal['model_post_init']</code> <p>The name of the post-init method for the model, if defined.</p> <code>__pydantic_root_model__</code> <code>bool</code> <p>Whether the model is a <code>RootModel</code>.</p> <code>__pydantic_serializer__</code> <code>SchemaSerializer</code> <p>The <code>pydantic-core</code> <code>SchemaSerializer</code> used to dump instances of the model.</p> <code>__pydantic_validator__</code> <code>SchemaValidator | PluggableSchemaValidator</code> <p>The <code>pydantic-core</code> <code>SchemaValidator</code> used to validate instances of the model.</p> <code>__pydantic_extra__</code> <code>dict[str, Any] | None</code> <p>A dictionary containing extra values, if <code>extra</code> is set to <code>'allow'</code>.</p> <code>__pydantic_fields_set__</code> <code>set[str]</code> <p>The names of fields explicitly set during instantiation.</p> <code>__pydantic_private__</code> <code>dict[str, Any] | None</code> <p>Values of private attributes set on the model instance.</p> Source code in <code>pydantic/main.py</code> <pre><code>class BaseModel(metaclass=_model_construction.ModelMetaclass):\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/models/\n\n    A base class for creating Pydantic models.\n\n    Attributes:\n        __class_vars__: The names of the class variables defined on the model.\n        __private_attributes__: Metadata about the private attributes of the model.\n        __signature__: The synthesized `__init__` [`Signature`][inspect.Signature] of the model.\n\n        __pydantic_complete__: Whether model building is completed, or if there are still undefined fields.\n        __pydantic_core_schema__: The core schema of the model.\n        __pydantic_custom_init__: Whether the model has a custom `__init__` function.\n        __pydantic_decorators__: Metadata containing the decorators defined on the model.\n            This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\n        __pydantic_generic_metadata__: Metadata for generic models; contains data used for a similar purpose to\n            __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\n        __pydantic_parent_namespace__: Parent namespace of the model, used for automatic rebuilding of models.\n        __pydantic_post_init__: The name of the post-init method for the model, if defined.\n        __pydantic_root_model__: Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\n        __pydantic_serializer__: The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\n        __pydantic_validator__: The `pydantic-core` `SchemaValidator` used to validate instances of the model.\n\n        __pydantic_extra__: A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra]\n            is set to `'allow'`.\n        __pydantic_fields_set__: The names of fields explicitly set during instantiation.\n        __pydantic_private__: Values of private attributes set on the model instance.\n    \"\"\"\n\n    # Class attributes:\n    # `model_fields` and `__pydantic_decorators__` must be set for\n    # `GenerateSchema.model_schema` to work for a plain `BaseModel` annotation.\n\n    model_config: ClassVar[ConfigDict] = ConfigDict()\n    \"\"\"\n    Configuration for the model, should be a dictionary conforming to [`ConfigDict`][pydantic.config.ConfigDict].\n    \"\"\"\n\n    # Because `dict` is in the local namespace of the `BaseModel` class, we use `Dict` for annotations.\n    # TODO v3 fallback to `dict` when the deprecated `dict` method gets removed.\n    model_fields: ClassVar[Dict[str, FieldInfo]] = {}  # noqa: UP006\n    \"\"\"\n    Metadata about the fields defined on the model,\n    mapping of field names to [`FieldInfo`][pydantic.fields.FieldInfo] objects.\n\n    This replaces `Model.__fields__` from Pydantic V1.\n    \"\"\"\n\n    model_computed_fields: ClassVar[Dict[str, ComputedFieldInfo]] = {}  # noqa: UP006\n    \"\"\"A dictionary of computed field names and their corresponding `ComputedFieldInfo` objects.\"\"\"\n\n    __class_vars__: ClassVar[set[str]]\n    \"\"\"The names of the class variables defined on the model.\"\"\"\n\n    __private_attributes__: ClassVar[Dict[str, ModelPrivateAttr]]  # noqa: UP006\n    \"\"\"Metadata about the private attributes of the model.\"\"\"\n\n    __signature__: ClassVar[Signature]\n    \"\"\"The synthesized `__init__` [`Signature`][inspect.Signature] of the model.\"\"\"\n\n    __pydantic_complete__: ClassVar[bool] = False\n    \"\"\"Whether model building is completed, or if there are still undefined fields.\"\"\"\n\n    __pydantic_core_schema__: ClassVar[CoreSchema]\n    \"\"\"The core schema of the model.\"\"\"\n\n    __pydantic_custom_init__: ClassVar[bool]\n    \"\"\"Whether the model has a custom `__init__` method.\"\"\"\n\n    __pydantic_decorators__: ClassVar[_decorators.DecoratorInfos] = _decorators.DecoratorInfos()\n    \"\"\"Metadata containing the decorators defined on the model.\n    This replaces `Model.__validators__` and `Model.__root_validators__` from Pydantic V1.\"\"\"\n\n    __pydantic_generic_metadata__: ClassVar[_generics.PydanticGenericMetadata]\n    \"\"\"Metadata for generic models; contains data used for a similar purpose to\n    __args__, __origin__, __parameters__ in typing-module generics. May eventually be replaced by these.\"\"\"\n\n    __pydantic_parent_namespace__: ClassVar[Dict[str, Any] | None] = None  # noqa: UP006\n    \"\"\"Parent namespace of the model, used for automatic rebuilding of models.\"\"\"\n\n    __pydantic_post_init__: ClassVar[None | Literal['model_post_init']]\n    \"\"\"The name of the post-init method for the model, if defined.\"\"\"\n\n    __pydantic_root_model__: ClassVar[bool] = False\n    \"\"\"Whether the model is a [`RootModel`][pydantic.root_model.RootModel].\"\"\"\n\n    __pydantic_serializer__: ClassVar[SchemaSerializer]\n    \"\"\"The `pydantic-core` `SchemaSerializer` used to dump instances of the model.\"\"\"\n\n    __pydantic_validator__: ClassVar[SchemaValidator | PluggableSchemaValidator]\n    \"\"\"The `pydantic-core` `SchemaValidator` used to validate instances of the model.\"\"\"\n\n    __pydantic_extra__: dict[str, Any] | None = _model_construction.NoInitField(init=False)\n    \"\"\"A dictionary containing extra values, if [`extra`][pydantic.config.ConfigDict.extra] is set to `'allow'`.\"\"\"\n\n    __pydantic_fields_set__: set[str] = _model_construction.NoInitField(init=False)\n    \"\"\"The names of fields explicitly set during instantiation.\"\"\"\n\n    __pydantic_private__: dict[str, Any] | None = _model_construction.NoInitField(init=False)\n    \"\"\"Values of private attributes set on the model instance.\"\"\"\n\n    if not TYPE_CHECKING:\n        # Prevent `BaseModel` from being instantiated directly\n        # (defined in an `if not TYPE_CHECKING` block for clarity and to avoid type checking errors):\n        __pydantic_core_schema__ = _mock_val_ser.MockCoreSchema(\n            'Pydantic models should inherit from BaseModel, BaseModel cannot be instantiated directly',\n            code='base-model-instantiated',\n        )\n        __pydantic_validator__ = _mock_val_ser.MockValSer(\n            'Pydantic models should inherit from BaseModel, BaseModel cannot be instantiated directly',\n            val_or_ser='validator',\n            code='base-model-instantiated',\n        )\n        __pydantic_serializer__ = _mock_val_ser.MockValSer(\n            'Pydantic models should inherit from BaseModel, BaseModel cannot be instantiated directly',\n            val_or_ser='serializer',\n            code='base-model-instantiated',\n        )\n\n    __slots__ = '__dict__', '__pydantic_fields_set__', '__pydantic_extra__', '__pydantic_private__'\n\n    def __init__(self, /, **data: Any) -&gt; None:\n        \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n        Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n        validated to form a valid model.\n\n        `self` is explicitly positional-only to allow `self` as a field name.\n        \"\"\"\n        # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n        __tracebackhide__ = True\n        validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n        if self is not validated_self:\n            warnings.warn(\n                'A custom validator is returning a value other than `self`.\\n'\n                \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n                'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n                category=None,\n            )\n\n    # The following line sets a flag that we use to determine when `__init__` gets overridden by the user\n    __init__.__pydantic_base_init__ = True  # pyright: ignore[reportFunctionMemberAccess]\n\n    @property\n    def model_extra(self) -&gt; dict[str, Any] | None:\n        \"\"\"Get extra fields set during validation.\n\n        Returns:\n            A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n        \"\"\"\n        return self.__pydantic_extra__\n\n    @property\n    def model_fields_set(self) -&gt; set[str]:\n        \"\"\"Returns the set of fields that have been explicitly set on this model instance.\n\n        Returns:\n            A set of strings representing the fields that have been set,\n                i.e. that were not filled from defaults.\n        \"\"\"\n        return self.__pydantic_fields_set__\n\n    @classmethod\n    def model_construct(cls, _fields_set: set[str] | None = None, **values: Any) -&gt; Self:  # noqa: C901\n        \"\"\"Creates a new instance of the `Model` class with validated data.\n\n        Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n        Default values are respected, but no other validation is performed.\n\n        !!! note\n            `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n            That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n            and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n            Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n            an error if extra values are passed, but they will be ignored.\n\n        Args:\n            _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n                this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n                Otherwise, the field names from the `values` argument will be used.\n            values: Trusted or pre-validated data dictionary.\n\n        Returns:\n            A new instance of the `Model` class with validated data.\n        \"\"\"\n        m = cls.__new__(cls)\n        fields_values: dict[str, Any] = {}\n        fields_set = set()\n\n        for name, field in cls.model_fields.items():\n            if field.alias is not None and field.alias in values:\n                fields_values[name] = values.pop(field.alias)\n                fields_set.add(name)\n\n            if (name not in fields_set) and (field.validation_alias is not None):\n                validation_aliases: list[str | AliasPath] = (\n                    field.validation_alias.choices\n                    if isinstance(field.validation_alias, AliasChoices)\n                    else [field.validation_alias]\n                )\n\n                for alias in validation_aliases:\n                    if isinstance(alias, str) and alias in values:\n                        fields_values[name] = values.pop(alias)\n                        fields_set.add(name)\n                        break\n                    elif isinstance(alias, AliasPath):\n                        value = alias.search_dict_for_path(values)\n                        if value is not PydanticUndefined:\n                            fields_values[name] = value\n                            fields_set.add(name)\n                            break\n\n            if name not in fields_set:\n                if name in values:\n                    fields_values[name] = values.pop(name)\n                    fields_set.add(name)\n                elif not field.is_required():\n                    fields_values[name] = field.get_default(call_default_factory=True)\n        if _fields_set is None:\n            _fields_set = fields_set\n\n        _extra: dict[str, Any] | None = values if cls.model_config.get('extra') == 'allow' else None\n        _object_setattr(m, '__dict__', fields_values)\n        _object_setattr(m, '__pydantic_fields_set__', _fields_set)\n        if not cls.__pydantic_root_model__:\n            _object_setattr(m, '__pydantic_extra__', _extra)\n\n        if cls.__pydantic_post_init__:\n            m.model_post_init(None)\n            # update private attributes with values set\n            if hasattr(m, '__pydantic_private__') and m.__pydantic_private__ is not None:\n                for k, v in values.items():\n                    if k in m.__private_attributes__:\n                        m.__pydantic_private__[k] = v\n\n        elif not cls.__pydantic_root_model__:\n            # Note: if there are any private attributes, cls.__pydantic_post_init__ would exist\n            # Since it doesn't, that means that `__pydantic_private__` should be set to None\n            _object_setattr(m, '__pydantic_private__', None)\n\n        return m\n\n    def model_copy(self, *, update: dict[str, Any] | None = None, deep: bool = False) -&gt; Self:\n        \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#model_copy\n\n        Returns a copy of the model.\n\n        Args:\n            update: Values to change/add in the new model. Note: the data is not validated\n                before creating the new model. You should trust this data.\n            deep: Set to `True` to make a deep copy of the model.\n\n        Returns:\n            New model instance.\n        \"\"\"\n        copied = self.__deepcopy__() if deep else self.__copy__()\n        if update:\n            if self.model_config.get('extra') == 'allow':\n                for k, v in update.items():\n                    if k in self.model_fields:\n                        copied.__dict__[k] = v\n                    else:\n                        if copied.__pydantic_extra__ is None:\n                            copied.__pydantic_extra__ = {}\n                        copied.__pydantic_extra__[k] = v\n            else:\n                copied.__dict__.update(update)\n            copied.__pydantic_fields_set__.update(update.keys())\n        return copied\n\n    def model_dump(\n        self,\n        *,\n        mode: Literal['json', 'python'] | str = 'python',\n        include: IncEx = None,\n        exclude: IncEx = None,\n        context: Any | None = None,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        round_trip: bool = False,\n        warnings: bool | Literal['none', 'warn', 'error'] = True,\n        serialize_as_any: bool = False,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#modelmodel_dump\n\n        Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n        Args:\n            mode: The mode in which `to_python` should run.\n                If mode is 'json', the output will only contain JSON serializable types.\n                If mode is 'python', the output may contain non-JSON-serializable Python objects.\n            include: A set of fields to include in the output.\n            exclude: A set of fields to exclude from the output.\n            context: Additional context to pass to the serializer.\n            by_alias: Whether to use the field's alias in the dictionary key if defined.\n            exclude_unset: Whether to exclude fields that have not been explicitly set.\n            exclude_defaults: Whether to exclude fields that are set to their default value.\n            exclude_none: Whether to exclude fields that have a value of `None`.\n            round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n            warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n                \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n            serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n\n        Returns:\n            A dictionary representation of the model.\n        \"\"\"\n        return self.__pydantic_serializer__.to_python(\n            self,\n            mode=mode,\n            by_alias=by_alias,\n            include=include,\n            exclude=exclude,\n            context=context,\n            exclude_unset=exclude_unset,\n            exclude_defaults=exclude_defaults,\n            exclude_none=exclude_none,\n            round_trip=round_trip,\n            warnings=warnings,\n            serialize_as_any=serialize_as_any,\n        )\n\n    def model_dump_json(\n        self,\n        *,\n        indent: int | None = None,\n        include: IncEx = None,\n        exclude: IncEx = None,\n        context: Any | None = None,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        round_trip: bool = False,\n        warnings: bool | Literal['none', 'warn', 'error'] = True,\n        serialize_as_any: bool = False,\n    ) -&gt; str:\n        \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#modelmodel_dump_json\n\n        Generates a JSON representation of the model using Pydantic's `to_json` method.\n\n        Args:\n            indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n            include: Field(s) to include in the JSON output.\n            exclude: Field(s) to exclude from the JSON output.\n            context: Additional context to pass to the serializer.\n            by_alias: Whether to serialize using field aliases.\n            exclude_unset: Whether to exclude fields that have not been explicitly set.\n            exclude_defaults: Whether to exclude fields that are set to their default value.\n            exclude_none: Whether to exclude fields that have a value of `None`.\n            round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n            warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n                \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n            serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n\n        Returns:\n            A JSON string representation of the model.\n        \"\"\"\n        return self.__pydantic_serializer__.to_json(\n            self,\n            indent=indent,\n            include=include,\n            exclude=exclude,\n            context=context,\n            by_alias=by_alias,\n            exclude_unset=exclude_unset,\n            exclude_defaults=exclude_defaults,\n            exclude_none=exclude_none,\n            round_trip=round_trip,\n            warnings=warnings,\n            serialize_as_any=serialize_as_any,\n        ).decode()\n\n    @classmethod\n    def model_json_schema(\n        cls,\n        by_alias: bool = True,\n        ref_template: str = DEFAULT_REF_TEMPLATE,\n        schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n        mode: JsonSchemaMode = 'validation',\n    ) -&gt; dict[str, Any]:\n        \"\"\"Generates a JSON schema for a model class.\n\n        Args:\n            by_alias: Whether to use attribute aliases or not.\n            ref_template: The reference template.\n            schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n                `GenerateJsonSchema` with your desired modifications\n            mode: The mode in which to generate the schema.\n\n        Returns:\n            The JSON schema for the given model class.\n        \"\"\"\n        return model_json_schema(\n            cls, by_alias=by_alias, ref_template=ref_template, schema_generator=schema_generator, mode=mode\n        )\n\n    @classmethod\n    def model_parametrized_name(cls, params: tuple[type[Any], ...]) -&gt; str:\n        \"\"\"Compute the class name for parametrizations of generic classes.\n\n        This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n\n        Args:\n            params: Tuple of types of the class. Given a generic class\n                `Model` with 2 type variables and a concrete model `Model[str, int]`,\n                the value `(str, int)` would be passed to `params`.\n\n        Returns:\n            String representing the new class where `params` are passed to `cls` as type variables.\n\n        Raises:\n            TypeError: Raised when trying to generate concrete names for non-generic models.\n        \"\"\"\n        if not issubclass(cls, typing.Generic):\n            raise TypeError('Concrete names should only be generated for generic models.')\n\n        # Any strings received should represent forward references, so we handle them specially below.\n        # If we eventually move toward wrapping them in a ForwardRef in __class_getitem__ in the future,\n        # we may be able to remove this special case.\n        param_names = [param if isinstance(param, str) else _repr.display_as_type(param) for param in params]\n        params_component = ', '.join(param_names)\n        return f'{cls.__name__}[{params_component}]'\n\n    def model_post_init(self, __context: Any) -&gt; None:\n        \"\"\"Override this method to perform additional initialization after `__init__` and `model_construct`.\n        This is useful if you want to do some validation that requires the entire model to be initialized.\n        \"\"\"\n        pass\n\n    @classmethod\n    def model_rebuild(\n        cls,\n        *,\n        force: bool = False,\n        raise_errors: bool = True,\n        _parent_namespace_depth: int = 2,\n        _types_namespace: dict[str, Any] | None = None,\n    ) -&gt; bool | None:\n        \"\"\"Try to rebuild the pydantic-core schema for the model.\n\n        This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n        the initial attempt to build the schema, and automatic rebuilding fails.\n\n        Args:\n            force: Whether to force the rebuilding of the model schema, defaults to `False`.\n            raise_errors: Whether to raise errors, defaults to `True`.\n            _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n            _types_namespace: The types namespace, defaults to `None`.\n\n        Returns:\n            Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n            If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n        \"\"\"\n        if not force and cls.__pydantic_complete__:\n            return None\n        else:\n            if '__pydantic_core_schema__' in cls.__dict__:\n                delattr(cls, '__pydantic_core_schema__')  # delete cached value to ensure full rebuild happens\n            if _types_namespace is not None:\n                types_namespace: dict[str, Any] | None = _types_namespace.copy()\n            else:\n                if _parent_namespace_depth &gt; 0:\n                    frame_parent_ns = (\n                        _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth, force=True) or {}\n                    )\n                    cls_parent_ns = (\n                        _model_construction.unpack_lenient_weakvaluedict(cls.__pydantic_parent_namespace__) or {}\n                    )\n                    types_namespace = {**cls_parent_ns, **frame_parent_ns}\n                    cls.__pydantic_parent_namespace__ = _model_construction.build_lenient_weakvaluedict(types_namespace)\n                else:\n                    types_namespace = _model_construction.unpack_lenient_weakvaluedict(\n                        cls.__pydantic_parent_namespace__\n                    )\n\n                types_namespace = _typing_extra.merge_cls_and_parent_ns(cls, types_namespace)\n\n            # manually override defer_build so complete_model_class doesn't skip building the model again\n            config = {**cls.model_config, 'defer_build': False}\n            return _model_construction.complete_model_class(\n                cls,\n                cls.__name__,\n                _config.ConfigWrapper(config, check=False),\n                raise_errors=raise_errors,\n                types_namespace=types_namespace,\n            )\n\n    @classmethod\n    def model_validate(\n        cls,\n        obj: Any,\n        *,\n        strict: bool | None = None,\n        from_attributes: bool | None = None,\n        context: Any | None = None,\n    ) -&gt; Self:\n        \"\"\"Validate a pydantic model instance.\n\n        Args:\n            obj: The object to validate.\n            strict: Whether to enforce types strictly.\n            from_attributes: Whether to extract data from object attributes.\n            context: Additional context to pass to the validator.\n\n        Raises:\n            ValidationError: If the object could not be validated.\n\n        Returns:\n            The validated model instance.\n        \"\"\"\n        # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n        __tracebackhide__ = True\n        return cls.__pydantic_validator__.validate_python(\n            obj, strict=strict, from_attributes=from_attributes, context=context\n        )\n\n    @classmethod\n    def model_validate_json(\n        cls,\n        json_data: str | bytes | bytearray,\n        *,\n        strict: bool | None = None,\n        context: Any | None = None,\n    ) -&gt; Self:\n        \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/json/#json-parsing\n\n        Validate the given JSON data against the Pydantic model.\n\n        Args:\n            json_data: The JSON data to validate.\n            strict: Whether to enforce types strictly.\n            context: Extra variables to pass to the validator.\n\n        Returns:\n            The validated Pydantic model.\n\n        Raises:\n            ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n        \"\"\"\n        # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n        __tracebackhide__ = True\n        return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)\n\n    @classmethod\n    def model_validate_strings(\n        cls,\n        obj: Any,\n        *,\n        strict: bool | None = None,\n        context: Any | None = None,\n    ) -&gt; Self:\n        \"\"\"Validate the given object with string data against the Pydantic model.\n\n        Args:\n            obj: The object containing string data to validate.\n            strict: Whether to enforce types strictly.\n            context: Extra variables to pass to the validator.\n\n        Returns:\n            The validated Pydantic model.\n        \"\"\"\n        # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n        __tracebackhide__ = True\n        return cls.__pydantic_validator__.validate_strings(obj, strict=strict, context=context)\n\n    @classmethod\n    def __get_pydantic_core_schema__(cls, source: type[BaseModel], handler: GetCoreSchemaHandler, /) -&gt; CoreSchema:\n        \"\"\"Hook into generating the model's CoreSchema.\n\n        Args:\n            source: The class we are generating a schema for.\n                This will generally be the same as the `cls` argument if this is a classmethod.\n            handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n\n        Returns:\n            A `pydantic-core` `CoreSchema`.\n        \"\"\"\n        # Only use the cached value from this _exact_ class; we don't want one from a parent class\n        # This is why we check `cls.__dict__` and don't use `cls.__pydantic_core_schema__` or similar.\n        schema = cls.__dict__.get('__pydantic_core_schema__')\n        if schema is not None and not isinstance(schema, _mock_val_ser.MockCoreSchema):\n            # Due to the way generic classes are built, it's possible that an invalid schema may be temporarily\n            # set on generic classes. I think we could resolve this to ensure that we get proper schema caching\n            # for generics, but for simplicity for now, we just always rebuild if the class has a generic origin.\n            if not cls.__pydantic_generic_metadata__['origin']:\n                return cls.__pydantic_core_schema__\n\n        return handler(source)\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls,\n        core_schema: CoreSchema,\n        handler: GetJsonSchemaHandler,\n        /,\n    ) -&gt; JsonSchemaValue:\n        \"\"\"Hook into generating the model's JSON schema.\n\n        Args:\n            core_schema: A `pydantic-core` CoreSchema.\n                You can ignore this argument and call the handler with a new CoreSchema,\n                wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n                or just call the handler with the original schema.\n            handler: Call into Pydantic's internal JSON schema generation.\n                This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n                generation fails.\n                Since this gets called by `BaseModel.model_json_schema` you can override the\n                `schema_generator` argument to that function to change JSON schema generation globally\n                for a type.\n\n        Returns:\n            A JSON schema, as a Python object.\n        \"\"\"\n        return handler(core_schema)\n\n    @classmethod\n    def __pydantic_init_subclass__(cls, **kwargs: Any) -&gt; None:\n        \"\"\"This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n        only after the class is actually fully initialized. In particular, attributes like `model_fields` will\n        be present when this is called.\n\n        This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n        and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n        `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n\n        This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n        any kwargs passed to the class definition that aren't used internally by pydantic.\n\n        Args:\n            **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n                by pydantic.\n        \"\"\"\n        pass\n\n    def __class_getitem__(\n        cls, typevar_values: type[Any] | tuple[type[Any], ...]\n    ) -&gt; type[BaseModel] | _forward_ref.PydanticRecursiveRef:\n        cached = _generics.get_cached_generic_type_early(cls, typevar_values)\n        if cached is not None:\n            return cached\n\n        if cls is BaseModel:\n            raise TypeError('Type parameters should be placed on typing.Generic, not BaseModel')\n        if not hasattr(cls, '__parameters__'):\n            raise TypeError(f'{cls} cannot be parametrized because it does not inherit from typing.Generic')\n        if not cls.__pydantic_generic_metadata__['parameters'] and typing.Generic not in cls.__bases__:\n            raise TypeError(f'{cls} is not a generic class')\n\n        if not isinstance(typevar_values, tuple):\n            typevar_values = (typevar_values,)\n        _generics.check_parameters_count(cls, typevar_values)\n\n        # Build map from generic typevars to passed params\n        typevars_map: dict[_typing_extra.TypeVarType, type[Any]] = dict(\n            zip(cls.__pydantic_generic_metadata__['parameters'], typevar_values)\n        )\n\n        if _utils.all_identical(typevars_map.keys(), typevars_map.values()) and typevars_map:\n            submodel = cls  # if arguments are equal to parameters it's the same object\n            _generics.set_cached_generic_type(cls, typevar_values, submodel)\n        else:\n            parent_args = cls.__pydantic_generic_metadata__['args']\n            if not parent_args:\n                args = typevar_values\n            else:\n                args = tuple(_generics.replace_types(arg, typevars_map) for arg in parent_args)\n\n            origin = cls.__pydantic_generic_metadata__['origin'] or cls\n            model_name = origin.model_parametrized_name(args)\n            params = tuple(\n                {param: None for param in _generics.iter_contained_typevars(typevars_map.values())}\n            )  # use dict as ordered set\n\n            with _generics.generic_recursion_self_type(origin, args) as maybe_self_type:\n                if maybe_self_type is not None:\n                    return maybe_self_type\n\n                cached = _generics.get_cached_generic_type_late(cls, typevar_values, origin, args)\n                if cached is not None:\n                    return cached\n\n                # Attempt to rebuild the origin in case new types have been defined\n                try:\n                    # depth 3 gets you above this __class_getitem__ call\n                    origin.model_rebuild(_parent_namespace_depth=3)\n                except PydanticUndefinedAnnotation:\n                    # It's okay if it fails, it just means there are still undefined types\n                    # that could be evaluated later.\n                    # TODO: Make sure validation fails if there are still undefined types, perhaps using MockValidator\n                    pass\n\n                submodel = _generics.create_generic_submodel(model_name, origin, args, params)\n\n                # Update cache\n                _generics.set_cached_generic_type(cls, typevar_values, submodel, origin, args)\n\n        return submodel\n\n    def __copy__(self) -&gt; Self:\n        \"\"\"Returns a shallow copy of the model.\"\"\"\n        cls = type(self)\n        m = cls.__new__(cls)\n        _object_setattr(m, '__dict__', copy(self.__dict__))\n        _object_setattr(m, '__pydantic_extra__', copy(self.__pydantic_extra__))\n        _object_setattr(m, '__pydantic_fields_set__', copy(self.__pydantic_fields_set__))\n\n        if not hasattr(self, '__pydantic_private__') or self.__pydantic_private__ is None:\n            _object_setattr(m, '__pydantic_private__', None)\n        else:\n            _object_setattr(\n                m,\n                '__pydantic_private__',\n                {k: v for k, v in self.__pydantic_private__.items() if v is not PydanticUndefined},\n            )\n\n        return m\n\n    def __deepcopy__(self, memo: dict[int, Any] | None = None) -&gt; Self:\n        \"\"\"Returns a deep copy of the model.\"\"\"\n        cls = type(self)\n        m = cls.__new__(cls)\n        _object_setattr(m, '__dict__', deepcopy(self.__dict__, memo=memo))\n        _object_setattr(m, '__pydantic_extra__', deepcopy(self.__pydantic_extra__, memo=memo))\n        # This next line doesn't need a deepcopy because __pydantic_fields_set__ is a set[str],\n        # and attempting a deepcopy would be marginally slower.\n        _object_setattr(m, '__pydantic_fields_set__', copy(self.__pydantic_fields_set__))\n\n        if not hasattr(self, '__pydantic_private__') or self.__pydantic_private__ is None:\n            _object_setattr(m, '__pydantic_private__', None)\n        else:\n            _object_setattr(\n                m,\n                '__pydantic_private__',\n                deepcopy({k: v for k, v in self.__pydantic_private__.items() if v is not PydanticUndefined}, memo=memo),\n            )\n\n        return m\n\n    if not TYPE_CHECKING:\n        # We put `__getattr__` in a non-TYPE_CHECKING block because otherwise, mypy allows arbitrary attribute access\n        # The same goes for __setattr__ and __delattr__, see: https://github.com/pydantic/pydantic/issues/8643\n\n        def __getattr__(self, item: str) -&gt; Any:\n            private_attributes = object.__getattribute__(self, '__private_attributes__')\n            if item in private_attributes:\n                attribute = private_attributes[item]\n                if hasattr(attribute, '__get__'):\n                    return attribute.__get__(self, type(self))  # type: ignore\n\n                try:\n                    # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items\n                    return self.__pydantic_private__[item]  # type: ignore\n                except KeyError as exc:\n                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n            else:\n                # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.\n                # See `BaseModel.__repr_args__` for more details\n                try:\n                    pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')\n                except AttributeError:\n                    pydantic_extra = None\n\n                if pydantic_extra:\n                    try:\n                        return pydantic_extra[item]\n                    except KeyError as exc:\n                        raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n                else:\n                    if hasattr(self.__class__, item):\n                        return super().__getattribute__(item)  # Raises AttributeError if appropriate\n                    else:\n                        # this is the current error\n                        raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\n\n        def __setattr__(self, name: str, value: Any) -&gt; None:\n            if name in self.__class_vars__:\n                raise AttributeError(\n                    f'{name!r} is a ClassVar of `{self.__class__.__name__}` and cannot be set on an instance. '\n                    f'If you want to set a value on the class, use `{self.__class__.__name__}.{name} = value`.'\n                )\n            elif not _fields.is_valid_field_name(name):\n                if self.__pydantic_private__ is None or name not in self.__private_attributes__:\n                    _object_setattr(self, name, value)\n                else:\n                    attribute = self.__private_attributes__[name]\n                    if hasattr(attribute, '__set__'):\n                        attribute.__set__(self, value)  # type: ignore\n                    else:\n                        self.__pydantic_private__[name] = value\n                return\n\n            self._check_frozen(name, value)\n\n            attr = getattr(self.__class__, name, None)\n            if isinstance(attr, property):\n                attr.__set__(self, value)\n            elif self.model_config.get('validate_assignment', None):\n                self.__pydantic_validator__.validate_assignment(self, name, value)\n            elif self.model_config.get('extra') != 'allow' and name not in self.model_fields:\n                # TODO - matching error\n                raise ValueError(f'\"{self.__class__.__name__}\" object has no field \"{name}\"')\n            elif self.model_config.get('extra') == 'allow' and name not in self.model_fields:\n                if self.model_extra and name in self.model_extra:\n                    self.__pydantic_extra__[name] = value  # type: ignore\n                else:\n                    try:\n                        getattr(self, name)\n                    except AttributeError:\n                        # attribute does not already exist on instance, so put it in extra\n                        self.__pydantic_extra__[name] = value  # type: ignore\n                    else:\n                        # attribute _does_ already exist on instance, and was not in extra, so update it\n                        _object_setattr(self, name, value)\n            else:\n                self.__dict__[name] = value\n                self.__pydantic_fields_set__.add(name)\n\n        def __delattr__(self, item: str) -&gt; Any:\n            if item in self.__private_attributes__:\n                attribute = self.__private_attributes__[item]\n                if hasattr(attribute, '__delete__'):\n                    attribute.__delete__(self)  # type: ignore\n                    return\n\n                try:\n                    # Note: self.__pydantic_private__ cannot be None if self.__private_attributes__ has items\n                    del self.__pydantic_private__[item]  # type: ignore\n                    return\n                except KeyError as exc:\n                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}') from exc\n\n            self._check_frozen(item, None)\n\n            if item in self.model_fields:\n                object.__delattr__(self, item)\n            elif self.__pydantic_extra__ is not None and item in self.__pydantic_extra__:\n                del self.__pydantic_extra__[item]\n            else:\n                try:\n                    object.__delattr__(self, item)\n                except AttributeError:\n                    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')\n\n    def _check_frozen(self, name: str, value: Any) -&gt; None:\n        if self.model_config.get('frozen', None):\n            typ = 'frozen_instance'\n        elif getattr(self.model_fields.get(name), 'frozen', False):\n            typ = 'frozen_field'\n        else:\n            return\n        error: pydantic_core.InitErrorDetails = {\n            'type': typ,\n            'loc': (name,),\n            'input': value,\n        }\n        raise pydantic_core.ValidationError.from_exception_data(self.__class__.__name__, [error])\n\n    def __getstate__(self) -&gt; dict[Any, Any]:\n        private = self.__pydantic_private__\n        if private:\n            private = {k: v for k, v in private.items() if v is not PydanticUndefined}\n        return {\n            '__dict__': self.__dict__,\n            '__pydantic_extra__': self.__pydantic_extra__,\n            '__pydantic_fields_set__': self.__pydantic_fields_set__,\n            '__pydantic_private__': private,\n        }\n\n    def __setstate__(self, state: dict[Any, Any]) -&gt; None:\n        _object_setattr(self, '__pydantic_fields_set__', state.get('__pydantic_fields_set__', {}))\n        _object_setattr(self, '__pydantic_extra__', state.get('__pydantic_extra__', {}))\n        _object_setattr(self, '__pydantic_private__', state.get('__pydantic_private__', {}))\n        _object_setattr(self, '__dict__', state.get('__dict__', {}))\n\n    if not TYPE_CHECKING:\n\n        def __eq__(self, other: Any) -&gt; bool:\n            if isinstance(other, BaseModel):\n                # When comparing instances of generic types for equality, as long as all field values are equal,\n                # only require their generic origin types to be equal, rather than exact type equality.\n                # This prevents headaches like MyGeneric(x=1) != MyGeneric[Any](x=1).\n                self_type = self.__pydantic_generic_metadata__['origin'] or self.__class__\n                other_type = other.__pydantic_generic_metadata__['origin'] or other.__class__\n\n                # Perform common checks first\n                if not (\n                    self_type == other_type\n                    and getattr(self, '__pydantic_private__', None) == getattr(other, '__pydantic_private__', None)\n                    and self.__pydantic_extra__ == other.__pydantic_extra__\n                ):\n                    return False\n\n                # We only want to compare pydantic fields but ignoring fields is costly.\n                # We'll perform a fast check first, and fallback only when needed\n                # See GH-7444 and GH-7825 for rationale and a performance benchmark\n\n                # First, do the fast (and sometimes faulty) __dict__ comparison\n                if self.__dict__ == other.__dict__:\n                    # If the check above passes, then pydantic fields are equal, we can return early\n                    return True\n\n                # We don't want to trigger unnecessary costly filtering of __dict__ on all unequal objects, so we return\n                # early if there are no keys to ignore (we would just return False later on anyway)\n                model_fields = type(self).model_fields.keys()\n                if self.__dict__.keys() &lt;= model_fields and other.__dict__.keys() &lt;= model_fields:\n                    return False\n\n                # If we reach here, there are non-pydantic-fields keys, mapped to unequal values, that we need to ignore\n                # Resort to costly filtering of the __dict__ objects\n                # We use operator.itemgetter because it is much faster than dict comprehensions\n                # NOTE: Contrary to standard python class and instances, when the Model class has a default value for an\n                # attribute and the model instance doesn't have a corresponding attribute, accessing the missing attribute\n                # raises an error in BaseModel.__getattr__ instead of returning the class attribute\n                # So we can use operator.itemgetter() instead of operator.attrgetter()\n                getter = operator.itemgetter(*model_fields) if model_fields else lambda _: _utils._SENTINEL\n                try:\n                    return getter(self.__dict__) == getter(other.__dict__)\n                except KeyError:\n                    # In rare cases (such as when using the deprecated BaseModel.copy() method),\n                    # the __dict__ may not contain all model fields, which is how we can get here.\n                    # getter(self.__dict__) is much faster than any 'safe' method that accounts\n                    # for missing keys, and wrapping it in a `try` doesn't slow things down much\n                    # in the common case.\n                    self_fields_proxy = _utils.SafeGetItemProxy(self.__dict__)\n                    other_fields_proxy = _utils.SafeGetItemProxy(other.__dict__)\n                    return getter(self_fields_proxy) == getter(other_fields_proxy)\n\n            # other instance is not a BaseModel\n            else:\n                return NotImplemented  # delegate to the other item in the comparison\n\n    if TYPE_CHECKING:\n        # We put `__init_subclass__` in a TYPE_CHECKING block because, even though we want the type-checking benefits\n        # described in the signature of `__init_subclass__` below, we don't want to modify the default behavior of\n        # subclass initialization.\n\n        def __init_subclass__(cls, **kwargs: Unpack[ConfigDict]):\n            \"\"\"This signature is included purely to help type-checkers check arguments to class declaration, which\n            provides a way to conveniently set model_config key/value pairs.\n\n            ```py\n            from pydantic import BaseModel\n\n            class MyModel(BaseModel, extra='allow'): ...\n            ```\n\n            However, this may be deceiving, since the _actual_ calls to `__init_subclass__` will not receive any\n            of the config arguments, and will only receive any keyword arguments passed during class initialization\n            that are _not_ expected keys in ConfigDict. (This is due to the way `ModelMetaclass.__new__` works.)\n\n            Args:\n                **kwargs: Keyword arguments passed to the class definition, which set model_config\n\n            Note:\n                You may want to override `__pydantic_init_subclass__` instead, which behaves similarly but is called\n                *after* the class is fully initialized.\n            \"\"\"\n\n    def __iter__(self) -&gt; TupleGenerator:\n        \"\"\"So `dict(model)` works.\"\"\"\n        yield from [(k, v) for (k, v) in self.__dict__.items() if not k.startswith('_')]\n        extra = self.__pydantic_extra__\n        if extra:\n            yield from extra.items()\n\n    def __repr__(self) -&gt; str:\n        return f'{self.__repr_name__()}({self.__repr_str__(\", \")})'\n\n    def __repr_args__(self) -&gt; _repr.ReprArgs:\n        for k, v in self.__dict__.items():\n            field = self.model_fields.get(k)\n            if field and field.repr:\n                yield k, v\n\n        # `__pydantic_extra__` can fail to be set if the model is not yet fully initialized.\n        # This can happen if a `ValidationError` is raised during initialization and the instance's\n        # repr is generated as part of the exception handling. Therefore, we use `getattr` here\n        # with a fallback, even though the type hints indicate the attribute will always be present.\n        try:\n            pydantic_extra = object.__getattribute__(self, '__pydantic_extra__')\n        except AttributeError:\n            pydantic_extra = None\n\n        if pydantic_extra is not None:\n            yield from ((k, v) for k, v in pydantic_extra.items())\n        yield from ((k, getattr(self, k)) for k, v in self.model_computed_fields.items() if v.repr)\n\n    # take logic from `_repr.Representation` without the side effects of inheritance, see #5740\n    __repr_name__ = _repr.Representation.__repr_name__\n    __repr_str__ = _repr.Representation.__repr_str__\n    __pretty__ = _repr.Representation.__pretty__\n    __rich_repr__ = _repr.Representation.__rich_repr__\n\n    def __str__(self) -&gt; str:\n        return self.__repr_str__(' ')\n\n    # ##### Deprecated methods from v1 #####\n    @property\n    @typing_extensions.deprecated(\n        'The `__fields__` attribute is deprecated, use `model_fields` instead.', category=None\n    )\n    def __fields__(self) -&gt; dict[str, FieldInfo]:\n        warnings.warn(\n            'The `__fields__` attribute is deprecated, use `model_fields` instead.', category=PydanticDeprecatedSince20\n        )\n        return self.model_fields\n\n    @property\n    @typing_extensions.deprecated(\n        'The `__fields_set__` attribute is deprecated, use `model_fields_set` instead.',\n        category=None,\n    )\n    def __fields_set__(self) -&gt; set[str]:\n        warnings.warn(\n            'The `__fields_set__` attribute is deprecated, use `model_fields_set` instead.',\n            category=PydanticDeprecatedSince20,\n        )\n        return self.__pydantic_fields_set__\n\n    @typing_extensions.deprecated('The `dict` method is deprecated; use `model_dump` instead.', category=None)\n    def dict(  # noqa: D102\n        self,\n        *,\n        include: IncEx = None,\n        exclude: IncEx = None,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n    ) -&gt; Dict[str, Any]:  # noqa UP006\n        warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n        return self.model_dump(\n            include=include,\n            exclude=exclude,\n            by_alias=by_alias,\n            exclude_unset=exclude_unset,\n            exclude_defaults=exclude_defaults,\n            exclude_none=exclude_none,\n        )\n\n    @typing_extensions.deprecated('The `json` method is deprecated; use `model_dump_json` instead.', category=None)\n    def json(  # noqa: D102\n        self,\n        *,\n        include: IncEx = None,\n        exclude: IncEx = None,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        encoder: Callable[[Any], Any] | None = PydanticUndefined,  # type: ignore[assignment]\n        models_as_dict: bool = PydanticUndefined,  # type: ignore[assignment]\n        **dumps_kwargs: Any,\n    ) -&gt; str:\n        warnings.warn(\n            'The `json` method is deprecated; use `model_dump_json` instead.', category=PydanticDeprecatedSince20\n        )\n        if encoder is not PydanticUndefined:\n            raise TypeError('The `encoder` argument is no longer supported; use field serializers instead.')\n        if models_as_dict is not PydanticUndefined:\n            raise TypeError('The `models_as_dict` argument is no longer supported; use a model serializer instead.')\n        if dumps_kwargs:\n            raise TypeError('`dumps_kwargs` keyword arguments are no longer supported.')\n        return self.model_dump_json(\n            include=include,\n            exclude=exclude,\n            by_alias=by_alias,\n            exclude_unset=exclude_unset,\n            exclude_defaults=exclude_defaults,\n            exclude_none=exclude_none,\n        )\n\n    @classmethod\n    @typing_extensions.deprecated('The `parse_obj` method is deprecated; use `model_validate` instead.', category=None)\n    def parse_obj(cls, obj: Any) -&gt; Self:  # noqa: D102\n        warnings.warn(\n            'The `parse_obj` method is deprecated; use `model_validate` instead.', category=PydanticDeprecatedSince20\n        )\n        return cls.model_validate(obj)\n\n    @classmethod\n    @typing_extensions.deprecated(\n        'The `parse_raw` method is deprecated; if your data is JSON use `model_validate_json`, '\n        'otherwise load the data then use `model_validate` instead.',\n        category=None,\n    )\n    def parse_raw(  # noqa: D102\n        cls,\n        b: str | bytes,\n        *,\n        content_type: str | None = None,\n        encoding: str = 'utf8',\n        proto: DeprecatedParseProtocol | None = None,\n        allow_pickle: bool = False,\n    ) -&gt; Self:  # pragma: no cover\n        warnings.warn(\n            'The `parse_raw` method is deprecated; if your data is JSON use `model_validate_json`, '\n            'otherwise load the data then use `model_validate` instead.',\n            category=PydanticDeprecatedSince20,\n        )\n        from .deprecated import parse\n\n        try:\n            obj = parse.load_str_bytes(\n                b,\n                proto=proto,\n                content_type=content_type,\n                encoding=encoding,\n                allow_pickle=allow_pickle,\n            )\n        except (ValueError, TypeError) as exc:\n            import json\n\n            # try to match V1\n            if isinstance(exc, UnicodeDecodeError):\n                type_str = 'value_error.unicodedecode'\n            elif isinstance(exc, json.JSONDecodeError):\n                type_str = 'value_error.jsondecode'\n            elif isinstance(exc, ValueError):\n                type_str = 'value_error'\n            else:\n                type_str = 'type_error'\n\n            # ctx is missing here, but since we've added `input` to the error, we're not pretending it's the same\n            error: pydantic_core.InitErrorDetails = {\n                # The type: ignore on the next line is to ignore the requirement of LiteralString\n                'type': pydantic_core.PydanticCustomError(type_str, str(exc)),  # type: ignore\n                'loc': ('__root__',),\n                'input': b,\n            }\n            raise pydantic_core.ValidationError.from_exception_data(cls.__name__, [error])\n        return cls.model_validate(obj)\n\n    @classmethod\n    @typing_extensions.deprecated(\n        'The `parse_file` method is deprecated; load the data from file, then if your data is JSON '\n        'use `model_validate_json`, otherwise `model_validate` instead.',\n        category=None,\n    )\n    def parse_file(  # noqa: D102\n        cls,\n        path: str | Path,\n        *,\n        content_type: str | None = None,\n        encoding: str = 'utf8',\n        proto: DeprecatedParseProtocol | None = None,\n        allow_pickle: bool = False,\n    ) -&gt; Self:\n        warnings.warn(\n            'The `parse_file` method is deprecated; load the data from file, then if your data is JSON '\n            'use `model_validate_json`, otherwise `model_validate` instead.',\n            category=PydanticDeprecatedSince20,\n        )\n        from .deprecated import parse\n\n        obj = parse.load_file(\n            path,\n            proto=proto,\n            content_type=content_type,\n            encoding=encoding,\n            allow_pickle=allow_pickle,\n        )\n        return cls.parse_obj(obj)\n\n    @classmethod\n    @typing_extensions.deprecated(\n        'The `from_orm` method is deprecated; set '\n        \"`model_config['from_attributes']=True` and use `model_validate` instead.\",\n        category=None,\n    )\n    def from_orm(cls, obj: Any) -&gt; Self:  # noqa: D102\n        warnings.warn(\n            'The `from_orm` method is deprecated; set '\n            \"`model_config['from_attributes']=True` and use `model_validate` instead.\",\n            category=PydanticDeprecatedSince20,\n        )\n        if not cls.model_config.get('from_attributes', None):\n            raise PydanticUserError(\n                'You must set the config attribute `from_attributes=True` to use from_orm', code=None\n            )\n        return cls.model_validate(obj)\n\n    @classmethod\n    @typing_extensions.deprecated('The `construct` method is deprecated; use `model_construct` instead.', category=None)\n    def construct(cls, _fields_set: set[str] | None = None, **values: Any) -&gt; Self:  # noqa: D102\n        warnings.warn(\n            'The `construct` method is deprecated; use `model_construct` instead.', category=PydanticDeprecatedSince20\n        )\n        return cls.model_construct(_fields_set=_fields_set, **values)\n\n    @typing_extensions.deprecated(\n        'The `copy` method is deprecated; use `model_copy` instead. '\n        'See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`.',\n        category=None,\n    )\n    def copy(\n        self,\n        *,\n        include: AbstractSetIntStr | MappingIntStrAny | None = None,\n        exclude: AbstractSetIntStr | MappingIntStrAny | None = None,\n        update: Dict[str, Any] | None = None,  # noqa UP006\n        deep: bool = False,\n    ) -&gt; Self:  # pragma: no cover\n        \"\"\"Returns a copy of the model.\n\n        !!! warning \"Deprecated\"\n            This method is now deprecated; use `model_copy` instead.\n\n        If you need `include` or `exclude`, use:\n\n        ```py\n        data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n        data = {**data, **(update or {})}\n        copied = self.model_validate(data)\n        ```\n\n        Args:\n            include: Optional set or mapping specifying which fields to include in the copied model.\n            exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n            update: Optional dictionary of field-value pairs to override field values in the copied model.\n            deep: If True, the values of fields that are Pydantic models will be deep-copied.\n\n        Returns:\n            A copy of the model with included, excluded and updated fields as specified.\n        \"\"\"\n        warnings.warn(\n            'The `copy` method is deprecated; use `model_copy` instead. '\n            'See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`.',\n            category=PydanticDeprecatedSince20,\n        )\n        from .deprecated import copy_internals\n\n        values = dict(\n            copy_internals._iter(\n                self, to_dict=False, by_alias=False, include=include, exclude=exclude, exclude_unset=False\n            ),\n            **(update or {}),\n        )\n        if self.__pydantic_private__ is None:\n            private = None\n        else:\n            private = {k: v for k, v in self.__pydantic_private__.items() if v is not PydanticUndefined}\n\n        if self.__pydantic_extra__ is None:\n            extra: dict[str, Any] | None = None\n        else:\n            extra = self.__pydantic_extra__.copy()\n            for k in list(self.__pydantic_extra__):\n                if k not in values:  # k was in the exclude\n                    extra.pop(k)\n            for k in list(values):\n                if k in self.__pydantic_extra__:  # k must have come from extra\n                    extra[k] = values.pop(k)\n\n        # new `__pydantic_fields_set__` can have unset optional fields with a set value in `update` kwarg\n        if update:\n            fields_set = self.__pydantic_fields_set__ | update.keys()\n        else:\n            fields_set = set(self.__pydantic_fields_set__)\n\n        # removing excluded fields from `__pydantic_fields_set__`\n        if exclude:\n            fields_set -= set(exclude)\n\n        return copy_internals._copy_and_set_values(self, values, fields_set, extra, private, deep=deep)\n\n    @classmethod\n    @typing_extensions.deprecated('The `schema` method is deprecated; use `model_json_schema` instead.', category=None)\n    def schema(  # noqa: D102\n        cls, by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE\n    ) -&gt; Dict[str, Any]:  # noqa UP006\n        warnings.warn(\n            'The `schema` method is deprecated; use `model_json_schema` instead.', category=PydanticDeprecatedSince20\n        )\n        return cls.model_json_schema(by_alias=by_alias, ref_template=ref_template)\n\n    @classmethod\n    @typing_extensions.deprecated(\n        'The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead.',\n        category=None,\n    )\n    def schema_json(  # noqa: D102\n        cls, *, by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE, **dumps_kwargs: Any\n    ) -&gt; str:  # pragma: no cover\n        warnings.warn(\n            'The `schema_json` method is deprecated; use `model_json_schema` and json.dumps instead.',\n            category=PydanticDeprecatedSince20,\n        )\n        import json\n\n        from .deprecated.json import pydantic_encoder\n\n        return json.dumps(\n            cls.model_json_schema(by_alias=by_alias, ref_template=ref_template),\n            default=pydantic_encoder,\n            **dumps_kwargs,\n        )\n\n    @classmethod\n    @typing_extensions.deprecated('The `validate` method is deprecated; use `model_validate` instead.', category=None)\n    def validate(cls, value: Any) -&gt; Self:  # noqa: D102\n        warnings.warn(\n            'The `validate` method is deprecated; use `model_validate` instead.', category=PydanticDeprecatedSince20\n        )\n        return cls.model_validate(value)\n\n    @classmethod\n    @typing_extensions.deprecated(\n        'The `update_forward_refs` method is deprecated; use `model_rebuild` instead.',\n        category=None,\n    )\n    def update_forward_refs(cls, **localns: Any) -&gt; None:  # noqa: D102\n        warnings.warn(\n            'The `update_forward_refs` method is deprecated; use `model_rebuild` instead.',\n            category=PydanticDeprecatedSince20,\n        )\n        if localns:  # pragma: no cover\n            raise TypeError('`localns` arguments are not longer accepted.')\n        cls.model_rebuild(force=True)\n\n    @typing_extensions.deprecated(\n        'The private method `_iter` will be removed and should no longer be used.', category=None\n    )\n    def _iter(self, *args: Any, **kwargs: Any) -&gt; Any:\n        warnings.warn(\n            'The private method `_iter` will be removed and should no longer be used.',\n            category=PydanticDeprecatedSince20,\n        )\n        from .deprecated import copy_internals\n\n        return copy_internals._iter(self, *args, **kwargs)\n\n    @typing_extensions.deprecated(\n        'The private method `_copy_and_set_values` will be removed and should no longer be used.',\n        category=None,\n    )\n    def _copy_and_set_values(self, *args: Any, **kwargs: Any) -&gt; Any:\n        warnings.warn(\n            'The private method `_copy_and_set_values` will be removed and should no longer be used.',\n            category=PydanticDeprecatedSince20,\n        )\n        from .deprecated import copy_internals\n\n        return copy_internals._copy_and_set_values(self, *args, **kwargs)\n\n    @classmethod\n    @typing_extensions.deprecated(\n        'The private method `_get_value` will be removed and should no longer be used.',\n        category=None,\n    )\n    def _get_value(cls, *args: Any, **kwargs: Any) -&gt; Any:\n        warnings.warn(\n            'The private method `_get_value` will be removed and should no longer be used.',\n            category=PydanticDeprecatedSince20,\n        )\n        from .deprecated import copy_internals\n\n        return copy_internals._get_value(cls, *args, **kwargs)\n\n    @typing_extensions.deprecated(\n        'The private method `_calculate_keys` will be removed and should no longer be used.',\n        category=None,\n    )\n    def _calculate_keys(self, *args: Any, **kwargs: Any) -&gt; Any:\n        warnings.warn(\n            'The private method `_calculate_keys` will be removed and should no longer be used.',\n            category=PydanticDeprecatedSince20,\n        )\n        from .deprecated import copy_internals\n\n        return copy_internals._calculate_keys(self, *args, **kwargs)\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.__init__","title":"__init__","text":"<pre><code>__init__(**data: Any) -&gt; None\n</code></pre> <p>Raises <code>ValidationError</code> if the input data cannot be validated to form a valid model.</p> <p><code>self</code> is explicitly positional-only to allow <code>self</code> as a field name.</p> Source code in <code>pydantic/main.py</code> <pre><code>def __init__(self, /, **data: Any) -&gt; None:\n    \"\"\"Create a new model by parsing and validating input data from keyword arguments.\n\n    Raises [`ValidationError`][pydantic_core.ValidationError] if the input data cannot be\n    validated to form a valid model.\n\n    `self` is explicitly positional-only to allow `self` as a field name.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n    if self is not validated_self:\n        warnings.warn(\n            'A custom validator is returning a value other than `self`.\\n'\n            \"Returning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\\n\"\n            'See the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.',\n            category=None,\n        )\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_config","title":"model_config  <code>class-attribute</code>","text":"<pre><code>model_config: ConfigDict = ConfigDict()\n</code></pre> <p>Configuration for the model, should be a dictionary conforming to <code>ConfigDict</code>.</p>"},{"location":"api/base_model/#pydantic.BaseModel.model_computed_fields","title":"model_computed_fields  <code>class-attribute</code>","text":"<pre><code>model_computed_fields: Dict[str, ComputedFieldInfo] = {}\n</code></pre> <p>A dictionary of computed field names and their corresponding <code>ComputedFieldInfo</code> objects.</p>"},{"location":"api/base_model/#pydantic.BaseModel.model_extra","title":"model_extra  <code>property</code>","text":"<pre><code>model_extra: dict[str, Any] | None\n</code></pre> <p>Get extra fields set during validation.</p> <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>A dictionary of extra fields, or <code>None</code> if <code>config.extra</code> is not set to <code>\"allow\"</code>.</p>"},{"location":"api/base_model/#pydantic.BaseModel.model_fields","title":"model_fields  <code>class-attribute</code>","text":"<pre><code>model_fields: Dict[str, FieldInfo] = {}\n</code></pre> <p>Metadata about the fields defined on the model, mapping of field names to <code>FieldInfo</code> objects.</p> <p>This replaces <code>Model.__fields__</code> from Pydantic V1.</p>"},{"location":"api/base_model/#pydantic.BaseModel.model_fields_set","title":"model_fields_set  <code>property</code>","text":"<pre><code>model_fields_set: set[str]\n</code></pre> <p>Returns the set of fields that have been explicitly set on this model instance.</p> <p>Returns:</p> Type Description <code>set[str]</code> <p>A set of strings representing the fields that have been set, i.e. that were not filled from defaults.</p>"},{"location":"api/base_model/#pydantic.BaseModel.__pydantic_core_schema__","title":"__pydantic_core_schema__  <code>class-attribute</code>","text":"<pre><code>__pydantic_core_schema__: CoreSchema\n</code></pre> <p>The core schema of the model.</p>"},{"location":"api/base_model/#pydantic.BaseModel.model_construct","title":"model_construct  <code>classmethod</code>","text":"<pre><code>model_construct(\n    _fields_set: set[str] | None = None, **values: Any\n) -&gt; Self\n</code></pre> <p>Creates a new instance of the <code>Model</code> class with validated data.</p> <p>Creates a new model setting <code>__dict__</code> and <code>__pydantic_fields_set__</code> from trusted or pre-validated data. Default values are respected, but no other validation is performed.</p> <p>Note</p> <p><code>model_construct()</code> generally respects the <code>model_config.extra</code> setting on the provided model. That is, if <code>model_config.extra == 'allow'</code>, then all extra passed values are added to the model instance's <code>__dict__</code> and <code>__pydantic_extra__</code> fields. If <code>model_config.extra == 'ignore'</code> (the default), then all extra passed values are ignored. Because no validation is performed with a call to <code>model_construct()</code>, having <code>model_config.extra == 'forbid'</code> does not result in an error if extra values are passed, but they will be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>_fields_set</code> <code>set[str] | None</code> <p>A set of field names that were originally explicitly set during instantiation. If provided, this is directly used for the <code>model_fields_set</code> attribute. Otherwise, the field names from the <code>values</code> argument will be used.</p> <code>None</code> <code>values</code> <code>Any</code> <p>Trusted or pre-validated data dictionary.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new instance of the <code>Model</code> class with validated data.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_construct(cls, _fields_set: set[str] | None = None, **values: Any) -&gt; Self:  # noqa: C901\n    \"\"\"Creates a new instance of the `Model` class with validated data.\n\n    Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n    Default values are respected, but no other validation is performed.\n\n    !!! note\n        `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n        That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n        and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n        Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n        an error if extra values are passed, but they will be ignored.\n\n    Args:\n        _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n            this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n            Otherwise, the field names from the `values` argument will be used.\n        values: Trusted or pre-validated data dictionary.\n\n    Returns:\n        A new instance of the `Model` class with validated data.\n    \"\"\"\n    m = cls.__new__(cls)\n    fields_values: dict[str, Any] = {}\n    fields_set = set()\n\n    for name, field in cls.model_fields.items():\n        if field.alias is not None and field.alias in values:\n            fields_values[name] = values.pop(field.alias)\n            fields_set.add(name)\n\n        if (name not in fields_set) and (field.validation_alias is not None):\n            validation_aliases: list[str | AliasPath] = (\n                field.validation_alias.choices\n                if isinstance(field.validation_alias, AliasChoices)\n                else [field.validation_alias]\n            )\n\n            for alias in validation_aliases:\n                if isinstance(alias, str) and alias in values:\n                    fields_values[name] = values.pop(alias)\n                    fields_set.add(name)\n                    break\n                elif isinstance(alias, AliasPath):\n                    value = alias.search_dict_for_path(values)\n                    if value is not PydanticUndefined:\n                        fields_values[name] = value\n                        fields_set.add(name)\n                        break\n\n        if name not in fields_set:\n            if name in values:\n                fields_values[name] = values.pop(name)\n                fields_set.add(name)\n            elif not field.is_required():\n                fields_values[name] = field.get_default(call_default_factory=True)\n    if _fields_set is None:\n        _fields_set = fields_set\n\n    _extra: dict[str, Any] | None = values if cls.model_config.get('extra') == 'allow' else None\n    _object_setattr(m, '__dict__', fields_values)\n    _object_setattr(m, '__pydantic_fields_set__', _fields_set)\n    if not cls.__pydantic_root_model__:\n        _object_setattr(m, '__pydantic_extra__', _extra)\n\n    if cls.__pydantic_post_init__:\n        m.model_post_init(None)\n        # update private attributes with values set\n        if hasattr(m, '__pydantic_private__') and m.__pydantic_private__ is not None:\n            for k, v in values.items():\n                if k in m.__private_attributes__:\n                    m.__pydantic_private__[k] = v\n\n    elif not cls.__pydantic_root_model__:\n        # Note: if there are any private attributes, cls.__pydantic_post_init__ would exist\n        # Since it doesn't, that means that `__pydantic_private__` should be set to None\n        _object_setattr(m, '__pydantic_private__', None)\n\n    return m\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_copy","title":"model_copy","text":"<pre><code>model_copy(\n    *,\n    update: dict[str, Any] | None = None,\n    deep: bool = False\n) -&gt; Self\n</code></pre> <p>Usage Documentation</p> <p><code>model_copy(...)</code> <p>Returns a copy of the model.</p> <p>Parameters:</p> Name Type Description Default <code>update</code> <code>dict[str, Any] | None</code> <p>Values to change/add in the new model. Note: the data is not validated before creating the new model. You should trust this data.</p> <code>None</code> <code>deep</code> <code>bool</code> <p>Set to <code>True</code> to make a deep copy of the model.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>New model instance.</p> Source code in <code>pydantic/main.py</code> <pre><code>def model_copy(self, *, update: dict[str, Any] | None = None, deep: bool = False) -&gt; Self:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#model_copy\n\n    Returns a copy of the model.\n\n    Args:\n        update: Values to change/add in the new model. Note: the data is not validated\n            before creating the new model. You should trust this data.\n        deep: Set to `True` to make a deep copy of the model.\n\n    Returns:\n        New model instance.\n    \"\"\"\n    copied = self.__deepcopy__() if deep else self.__copy__()\n    if update:\n        if self.model_config.get('extra') == 'allow':\n            for k, v in update.items():\n                if k in self.model_fields:\n                    copied.__dict__[k] = v\n                else:\n                    if copied.__pydantic_extra__ is None:\n                        copied.__pydantic_extra__ = {}\n                    copied.__pydantic_extra__[k] = v\n        else:\n            copied.__dict__.update(update)\n        copied.__pydantic_fields_set__.update(update.keys())\n    return copied\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_dump","title":"model_dump","text":"<pre><code>model_dump(\n    *,\n    mode: Literal[\"json\", \"python\"] | str = \"python\",\n    include: IncEx = None,\n    exclude: IncEx = None,\n    context: Any | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: (\n        bool | Literal[\"none\", \"warn\", \"error\"]\n    ) = True,\n    serialize_as_any: bool = False\n) -&gt; dict[str, Any]\n</code></pre> <p>Usage Documentation</p> <p><code>model.model_dump(...)</code> </p> <p>Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>Literal['json', 'python'] | str</code> <p>The mode in which <code>to_python</code> should run. If mode is 'json', the output will only contain JSON serializable types. If mode is 'python', the output may contain non-JSON-serializable Python objects.</p> <code>'python'</code> <code>include</code> <code>IncEx</code> <p>A set of fields to include in the output.</p> <code>None</code> <code>exclude</code> <code>IncEx</code> <p>A set of fields to exclude from the output.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>Additional context to pass to the serializer.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use the field's alias in the dictionary key if defined.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that have not been explicitly set.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that are set to their default value.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>If True, dumped values should be valid as input for non-idempotent types such as Json[T].</p> <code>False</code> <code>warnings</code> <code>bool | Literal['none', 'warn', 'error']</code> <p>How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors, \"error\" raises a <code>PydanticSerializationError</code>.</p> <code>True</code> <code>serialize_as_any</code> <code>bool</code> <p>Whether to serialize fields with duck-typing serialization behavior.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dictionary representation of the model.</p> Source code in <code>pydantic/main.py</code> <pre><code>def model_dump(\n    self,\n    *,\n    mode: Literal['json', 'python'] | str = 'python',\n    include: IncEx = None,\n    exclude: IncEx = None,\n    context: Any | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool | Literal['none', 'warn', 'error'] = True,\n    serialize_as_any: bool = False,\n) -&gt; dict[str, Any]:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#modelmodel_dump\n\n    Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n    Args:\n        mode: The mode in which `to_python` should run.\n            If mode is 'json', the output will only contain JSON serializable types.\n            If mode is 'python', the output may contain non-JSON-serializable Python objects.\n        include: A set of fields to include in the output.\n        exclude: A set of fields to exclude from the output.\n        context: Additional context to pass to the serializer.\n        by_alias: Whether to use the field's alias in the dictionary key if defined.\n        exclude_unset: Whether to exclude fields that have not been explicitly set.\n        exclude_defaults: Whether to exclude fields that are set to their default value.\n        exclude_none: Whether to exclude fields that have a value of `None`.\n        round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n        warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n            \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n        serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n\n    Returns:\n        A dictionary representation of the model.\n    \"\"\"\n    return self.__pydantic_serializer__.to_python(\n        self,\n        mode=mode,\n        by_alias=by_alias,\n        include=include,\n        exclude=exclude,\n        context=context,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        round_trip=round_trip,\n        warnings=warnings,\n        serialize_as_any=serialize_as_any,\n    )\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_dump_json","title":"model_dump_json","text":"<pre><code>model_dump_json(\n    *,\n    indent: int | None = None,\n    include: IncEx = None,\n    exclude: IncEx = None,\n    context: Any | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: (\n        bool | Literal[\"none\", \"warn\", \"error\"]\n    ) = True,\n    serialize_as_any: bool = False\n) -&gt; str\n</code></pre> <p>Usage Documentation</p> <p><code>model.model_dump_json(...)</code> </p> <p>Generates a JSON representation of the model using Pydantic's <code>to_json</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>indent</code> <code>int | None</code> <p>Indentation to use in the JSON output. If None is passed, the output will be compact.</p> <code>None</code> <code>include</code> <code>IncEx</code> <p>Field(s) to include in the JSON output.</p> <code>None</code> <code>exclude</code> <code>IncEx</code> <p>Field(s) to exclude from the JSON output.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>Additional context to pass to the serializer.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to serialize using field aliases.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that have not been explicitly set.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that are set to their default value.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>If True, dumped values should be valid as input for non-idempotent types such as Json[T].</p> <code>False</code> <code>warnings</code> <code>bool | Literal['none', 'warn', 'error']</code> <p>How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors, \"error\" raises a <code>PydanticSerializationError</code>.</p> <code>True</code> <code>serialize_as_any</code> <code>bool</code> <p>Whether to serialize fields with duck-typing serialization behavior.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>A JSON string representation of the model.</p> Source code in <code>pydantic/main.py</code> <pre><code>def model_dump_json(\n    self,\n    *,\n    indent: int | None = None,\n    include: IncEx = None,\n    exclude: IncEx = None,\n    context: Any | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool | Literal['none', 'warn', 'error'] = True,\n    serialize_as_any: bool = False,\n) -&gt; str:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/serialization/#modelmodel_dump_json\n\n    Generates a JSON representation of the model using Pydantic's `to_json` method.\n\n    Args:\n        indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n        include: Field(s) to include in the JSON output.\n        exclude: Field(s) to exclude from the JSON output.\n        context: Additional context to pass to the serializer.\n        by_alias: Whether to serialize using field aliases.\n        exclude_unset: Whether to exclude fields that have not been explicitly set.\n        exclude_defaults: Whether to exclude fields that are set to their default value.\n        exclude_none: Whether to exclude fields that have a value of `None`.\n        round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n        warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n            \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n        serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n\n    Returns:\n        A JSON string representation of the model.\n    \"\"\"\n    return self.__pydantic_serializer__.to_json(\n        self,\n        indent=indent,\n        include=include,\n        exclude=exclude,\n        context=context,\n        by_alias=by_alias,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        round_trip=round_trip,\n        warnings=warnings,\n        serialize_as_any=serialize_as_any,\n    ).decode()\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_json_schema","title":"model_json_schema  <code>classmethod</code>","text":"<pre><code>model_json_schema(\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[\n        GenerateJsonSchema\n    ] = GenerateJsonSchema,\n    mode: JsonSchemaMode = \"validation\",\n) -&gt; dict[str, Any]\n</code></pre> <p>Generates a JSON schema for a model class.</p> <p>Parameters:</p> Name Type Description Default <code>by_alias</code> <code>bool</code> <p>Whether to use attribute aliases or not.</p> <code>True</code> <code>ref_template</code> <code>str</code> <p>The reference template.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>To override the logic used to generate the JSON schema, as a subclass of <code>GenerateJsonSchema</code> with your desired modifications</p> <code>GenerateJsonSchema</code> <code>mode</code> <code>JsonSchemaMode</code> <p>The mode in which to generate the schema.</p> <code>'validation'</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The JSON schema for the given model class.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_json_schema(\n    cls,\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n    mode: JsonSchemaMode = 'validation',\n) -&gt; dict[str, Any]:\n    \"\"\"Generates a JSON schema for a model class.\n\n    Args:\n        by_alias: Whether to use attribute aliases or not.\n        ref_template: The reference template.\n        schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n            `GenerateJsonSchema` with your desired modifications\n        mode: The mode in which to generate the schema.\n\n    Returns:\n        The JSON schema for the given model class.\n    \"\"\"\n    return model_json_schema(\n        cls, by_alias=by_alias, ref_template=ref_template, schema_generator=schema_generator, mode=mode\n    )\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_parametrized_name","title":"model_parametrized_name  <code>classmethod</code>","text":"<pre><code>model_parametrized_name(\n    params: tuple[type[Any], ...]\n) -&gt; str\n</code></pre> <p>Compute the class name for parametrizations of generic classes.</p> <p>This method can be overridden to achieve a custom naming scheme for generic BaseModels.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>tuple[type[Any], ...]</code> <p>Tuple of types of the class. Given a generic class <code>Model</code> with 2 type variables and a concrete model <code>Model[str, int]</code>, the value <code>(str, int)</code> would be passed to <code>params</code>.</p> required <p>Returns:</p> Type Description <code>str</code> <p>String representing the new class where <code>params</code> are passed to <code>cls</code> as type variables.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>Raised when trying to generate concrete names for non-generic models.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_parametrized_name(cls, params: tuple[type[Any], ...]) -&gt; str:\n    \"\"\"Compute the class name for parametrizations of generic classes.\n\n    This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n\n    Args:\n        params: Tuple of types of the class. Given a generic class\n            `Model` with 2 type variables and a concrete model `Model[str, int]`,\n            the value `(str, int)` would be passed to `params`.\n\n    Returns:\n        String representing the new class where `params` are passed to `cls` as type variables.\n\n    Raises:\n        TypeError: Raised when trying to generate concrete names for non-generic models.\n    \"\"\"\n    if not issubclass(cls, typing.Generic):\n        raise TypeError('Concrete names should only be generated for generic models.')\n\n    # Any strings received should represent forward references, so we handle them specially below.\n    # If we eventually move toward wrapping them in a ForwardRef in __class_getitem__ in the future,\n    # we may be able to remove this special case.\n    param_names = [param if isinstance(param, str) else _repr.display_as_type(param) for param in params]\n    params_component = ', '.join(param_names)\n    return f'{cls.__name__}[{params_component}]'\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_post_init","title":"model_post_init","text":"<pre><code>model_post_init(__context: Any) -&gt; None\n</code></pre> <p>Override this method to perform additional initialization after <code>__init__</code> and <code>model_construct</code>. This is useful if you want to do some validation that requires the entire model to be initialized.</p> Source code in <code>pydantic/main.py</code> <pre><code>def model_post_init(self, __context: Any) -&gt; None:\n    \"\"\"Override this method to perform additional initialization after `__init__` and `model_construct`.\n    This is useful if you want to do some validation that requires the entire model to be initialized.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_rebuild","title":"model_rebuild  <code>classmethod</code>","text":"<pre><code>model_rebuild(\n    *,\n    force: bool = False,\n    raise_errors: bool = True,\n    _parent_namespace_depth: int = 2,\n    _types_namespace: dict[str, Any] | None = None\n) -&gt; bool | None\n</code></pre> <p>Try to rebuild the pydantic-core schema for the model.</p> <p>This may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails.</p> <p>Parameters:</p> Name Type Description Default <code>force</code> <code>bool</code> <p>Whether to force the rebuilding of the model schema, defaults to <code>False</code>.</p> <code>False</code> <code>raise_errors</code> <code>bool</code> <p>Whether to raise errors, defaults to <code>True</code>.</p> <code>True</code> <code>_parent_namespace_depth</code> <code>int</code> <p>The depth level of the parent namespace, defaults to 2.</p> <code>2</code> <code>_types_namespace</code> <code>dict[str, Any] | None</code> <p>The types namespace, defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool | None</code> <p>Returns <code>None</code> if the schema is already \"complete\" and rebuilding was not required.</p> <code>bool | None</code> <p>If rebuilding was required, returns <code>True</code> if rebuilding was successful, otherwise <code>False</code>.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_rebuild(\n    cls,\n    *,\n    force: bool = False,\n    raise_errors: bool = True,\n    _parent_namespace_depth: int = 2,\n    _types_namespace: dict[str, Any] | None = None,\n) -&gt; bool | None:\n    \"\"\"Try to rebuild the pydantic-core schema for the model.\n\n    This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n    the initial attempt to build the schema, and automatic rebuilding fails.\n\n    Args:\n        force: Whether to force the rebuilding of the model schema, defaults to `False`.\n        raise_errors: Whether to raise errors, defaults to `True`.\n        _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n        _types_namespace: The types namespace, defaults to `None`.\n\n    Returns:\n        Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n        If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n    \"\"\"\n    if not force and cls.__pydantic_complete__:\n        return None\n    else:\n        if '__pydantic_core_schema__' in cls.__dict__:\n            delattr(cls, '__pydantic_core_schema__')  # delete cached value to ensure full rebuild happens\n        if _types_namespace is not None:\n            types_namespace: dict[str, Any] | None = _types_namespace.copy()\n        else:\n            if _parent_namespace_depth &gt; 0:\n                frame_parent_ns = (\n                    _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth, force=True) or {}\n                )\n                cls_parent_ns = (\n                    _model_construction.unpack_lenient_weakvaluedict(cls.__pydantic_parent_namespace__) or {}\n                )\n                types_namespace = {**cls_parent_ns, **frame_parent_ns}\n                cls.__pydantic_parent_namespace__ = _model_construction.build_lenient_weakvaluedict(types_namespace)\n            else:\n                types_namespace = _model_construction.unpack_lenient_weakvaluedict(\n                    cls.__pydantic_parent_namespace__\n                )\n\n            types_namespace = _typing_extra.merge_cls_and_parent_ns(cls, types_namespace)\n\n        # manually override defer_build so complete_model_class doesn't skip building the model again\n        config = {**cls.model_config, 'defer_build': False}\n        return _model_construction.complete_model_class(\n            cls,\n            cls.__name__,\n            _config.ConfigWrapper(config, check=False),\n            raise_errors=raise_errors,\n            types_namespace=types_namespace,\n        )\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_validate","title":"model_validate  <code>classmethod</code>","text":"<pre><code>model_validate(\n    obj: Any,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: Any | None = None\n) -&gt; Self\n</code></pre> <p>Validate a pydantic model instance.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The object to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to enforce types strictly.</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to extract data from object attributes.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>Additional context to pass to the validator.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If the object could not be validated.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The validated model instance.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_validate(\n    cls,\n    obj: Any,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: Any | None = None,\n) -&gt; Self:\n    \"\"\"Validate a pydantic model instance.\n\n    Args:\n        obj: The object to validate.\n        strict: Whether to enforce types strictly.\n        from_attributes: Whether to extract data from object attributes.\n        context: Additional context to pass to the validator.\n\n    Raises:\n        ValidationError: If the object could not be validated.\n\n    Returns:\n        The validated model instance.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    return cls.__pydantic_validator__.validate_python(\n        obj, strict=strict, from_attributes=from_attributes, context=context\n    )\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_validate_json","title":"model_validate_json  <code>classmethod</code>","text":"<pre><code>model_validate_json(\n    json_data: str | bytes | bytearray,\n    *,\n    strict: bool | None = None,\n    context: Any | None = None\n) -&gt; Self\n</code></pre> <p>Usage Documentation</p> <p>Json Parsing</p> <p>Validate the given JSON data against the Pydantic model.</p> <p>Parameters:</p> Name Type Description Default <code>json_data</code> <code>str | bytes | bytearray</code> <p>The JSON data to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to enforce types strictly.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>Extra variables to pass to the validator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The validated Pydantic model.</p> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If <code>json_data</code> is not a JSON string or the object could not be validated.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_validate_json(\n    cls,\n    json_data: str | bytes | bytearray,\n    *,\n    strict: bool | None = None,\n    context: Any | None = None,\n) -&gt; Self:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/json/#json-parsing\n\n    Validate the given JSON data against the Pydantic model.\n\n    Args:\n        json_data: The JSON data to validate.\n        strict: Whether to enforce types strictly.\n        context: Extra variables to pass to the validator.\n\n    Returns:\n        The validated Pydantic model.\n\n    Raises:\n        ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    return cls.__pydantic_validator__.validate_json(json_data, strict=strict, context=context)\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.model_validate_strings","title":"model_validate_strings  <code>classmethod</code>","text":"<pre><code>model_validate_strings(\n    obj: Any,\n    *,\n    strict: bool | None = None,\n    context: Any | None = None\n) -&gt; Self\n</code></pre> <p>Validate the given object with string data against the Pydantic model.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The object containing string data to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to enforce types strictly.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>Extra variables to pass to the validator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The validated Pydantic model.</p> Source code in <code>pydantic/main.py</code> <pre><code>@classmethod\ndef model_validate_strings(\n    cls,\n    obj: Any,\n    *,\n    strict: bool | None = None,\n    context: Any | None = None,\n) -&gt; Self:\n    \"\"\"Validate the given object with string data against the Pydantic model.\n\n    Args:\n        obj: The object containing string data to validate.\n        strict: Whether to enforce types strictly.\n        context: Extra variables to pass to the validator.\n\n    Returns:\n        The validated Pydantic model.\n    \"\"\"\n    # `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\n    __tracebackhide__ = True\n    return cls.__pydantic_validator__.validate_strings(obj, strict=strict, context=context)\n</code></pre>"},{"location":"api/base_model/#pydantic.BaseModel.copy","title":"copy","text":"<pre><code>copy(\n    *,\n    include: (\n        AbstractSetIntStr | MappingIntStrAny | None\n    ) = None,\n    exclude: (\n        AbstractSetIntStr | MappingIntStrAny | None\n    ) = None,\n    update: Dict[str, Any] | None = None,\n    deep: bool = False\n) -&gt; Self\n</code></pre> <p>Returns a copy of the model.</p> <p>Deprecated</p> <p>This method is now deprecated; use <code>model_copy</code> instead.</p> <p>If you need <code>include</code> or <code>exclude</code>, use:</p> <pre><code>data = self.model_dump(include=include, exclude=exclude, round_trip=True)\ndata = {**data, **(update or {})}\ncopied = self.model_validate(data)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>include</code> <code>AbstractSetIntStr | MappingIntStrAny | None</code> <p>Optional set or mapping specifying which fields to include in the copied model.</p> <code>None</code> <code>exclude</code> <code>AbstractSetIntStr | MappingIntStrAny | None</code> <p>Optional set or mapping specifying which fields to exclude in the copied model.</p> <code>None</code> <code>update</code> <code>Dict[str, Any] | None</code> <p>Optional dictionary of field-value pairs to override field values in the copied model.</p> <code>None</code> <code>deep</code> <code>bool</code> <p>If True, the values of fields that are Pydantic models will be deep-copied.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A copy of the model with included, excluded and updated fields as specified.</p> Source code in <code>pydantic/main.py</code> <pre><code>@typing_extensions.deprecated(\n    'The `copy` method is deprecated; use `model_copy` instead. '\n    'See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`.',\n    category=None,\n)\ndef copy(\n    self,\n    *,\n    include: AbstractSetIntStr | MappingIntStrAny | None = None,\n    exclude: AbstractSetIntStr | MappingIntStrAny | None = None,\n    update: Dict[str, Any] | None = None,  # noqa UP006\n    deep: bool = False,\n) -&gt; Self:  # pragma: no cover\n    \"\"\"Returns a copy of the model.\n\n    !!! warning \"Deprecated\"\n        This method is now deprecated; use `model_copy` instead.\n\n    If you need `include` or `exclude`, use:\n\n    ```py\n    data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n    data = {**data, **(update or {})}\n    copied = self.model_validate(data)\n    ```\n\n    Args:\n        include: Optional set or mapping specifying which fields to include in the copied model.\n        exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n        update: Optional dictionary of field-value pairs to override field values in the copied model.\n        deep: If True, the values of fields that are Pydantic models will be deep-copied.\n\n    Returns:\n        A copy of the model with included, excluded and updated fields as specified.\n    \"\"\"\n    warnings.warn(\n        'The `copy` method is deprecated; use `model_copy` instead. '\n        'See the docstring of `BaseModel.copy` for details about how to handle `include` and `exclude`.',\n        category=PydanticDeprecatedSince20,\n    )\n    from .deprecated import copy_internals\n\n    values = dict(\n        copy_internals._iter(\n            self, to_dict=False, by_alias=False, include=include, exclude=exclude, exclude_unset=False\n        ),\n        **(update or {}),\n    )\n    if self.__pydantic_private__ is None:\n        private = None\n    else:\n        private = {k: v for k, v in self.__pydantic_private__.items() if v is not PydanticUndefined}\n\n    if self.__pydantic_extra__ is None:\n        extra: dict[str, Any] | None = None\n    else:\n        extra = self.__pydantic_extra__.copy()\n        for k in list(self.__pydantic_extra__):\n            if k not in values:  # k was in the exclude\n                extra.pop(k)\n        for k in list(values):\n            if k in self.__pydantic_extra__:  # k must have come from extra\n                extra[k] = values.pop(k)\n\n    # new `__pydantic_fields_set__` can have unset optional fields with a set value in `update` kwarg\n    if update:\n        fields_set = self.__pydantic_fields_set__ | update.keys()\n    else:\n        fields_set = set(self.__pydantic_fields_set__)\n\n    # removing excluded fields from `__pydantic_fields_set__`\n    if exclude:\n        fields_set -= set(exclude)\n\n    return copy_internals._copy_and_set_values(self, values, fields_set, extra, private, deep=deep)\n</code></pre>"},{"location":"api/base_model/#pydantic.create_model","title":"pydantic.create_model","text":"<pre><code>create_model(\n    model_name: str,\n    /,\n    *,\n    __config__: ConfigDict | None = None,\n    __doc__: str | None = None,\n    __base__: (\n        type[ModelT] | tuple[type[ModelT], ...] | None\n    ) = None,\n    __module__: str | None = None,\n    __validators__: (\n        dict[str, Callable[..., Any]] | None\n    ) = None,\n    __cls_kwargs__: dict[str, Any] | None = None,\n    __slots__: tuple[str, ...] | None = None,\n    **field_definitions: Any,\n) -&gt; type[ModelT]\n</code></pre> <p>Usage Documentation</p> <p>Dynamic model creation</p> <p>Dynamically creates and returns a new Pydantic model, in other words, <code>create_model</code> dynamically creates a subclass of <code>BaseModel</code>.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name of the newly created model.</p> required <code>__config__</code> <code>ConfigDict | None</code> <p>The configuration of the new model.</p> <code>None</code> <code>__doc__</code> <code>str | None</code> <p>The docstring of the new model.</p> <code>None</code> <code>__base__</code> <code>type[ModelT] | tuple[type[ModelT], ...] | None</code> <p>The base class or classes for the new model.</p> <code>None</code> <code>__module__</code> <code>str | None</code> <p>The name of the module that the model belongs to; if <code>None</code>, the value is taken from <code>sys._getframe(1)</code></p> <code>None</code> <code>__validators__</code> <code>dict[str, Callable[..., Any]] | None</code> <p>A dictionary of methods that validate fields. The keys are the names of the validation methods to be added to the model, and the values are the validation methods themselves. You can read more about functional validators here.</p> <code>None</code> <code>__cls_kwargs__</code> <code>dict[str, Any] | None</code> <p>A dictionary of keyword arguments for class creation, such as <code>metaclass</code>.</p> <code>None</code> <code>__slots__</code> <code>tuple[str, ...] | None</code> <p>Deprecated. Should not be passed to <code>create_model</code>.</p> <code>None</code> <code>**field_definitions</code> <code>Any</code> <p>Attributes of the new model. They should be passed in the format: <code>&lt;name&gt;=(&lt;type&gt;, &lt;default value&gt;)</code>, <code>&lt;name&gt;=(&lt;type&gt;, &lt;FieldInfo&gt;)</code>, or <code>typing.Annotated[&lt;type&gt;, &lt;FieldInfo&gt;]</code>. Any additional metadata in <code>typing.Annotated[&lt;type&gt;, &lt;FieldInfo&gt;, ...]</code> will be ignored.</p> <code>{}</code> <p>Returns:</p> Type Description <code>type[ModelT]</code> <p>The new model.</p> <p>Raises:</p> Type Description <code>PydanticUserError</code> <p>If <code>__base__</code> and <code>__config__</code> are both passed.</p> Source code in <code>pydantic/main.py</code> <pre><code>def create_model(  # noqa: C901\n    model_name: str,\n    /,\n    *,\n    __config__: ConfigDict | None = None,\n    __doc__: str | None = None,\n    __base__: type[ModelT] | tuple[type[ModelT], ...] | None = None,\n    __module__: str | None = None,\n    __validators__: dict[str, Callable[..., Any]] | None = None,\n    __cls_kwargs__: dict[str, Any] | None = None,\n    __slots__: tuple[str, ...] | None = None,\n    **field_definitions: Any,\n) -&gt; type[ModelT]:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/models/#dynamic-model-creation\n\n    Dynamically creates and returns a new Pydantic model, in other words, `create_model` dynamically creates a\n    subclass of [`BaseModel`][pydantic.BaseModel].\n\n    Args:\n        model_name: The name of the newly created model.\n        __config__: The configuration of the new model.\n        __doc__: The docstring of the new model.\n        __base__: The base class or classes for the new model.\n        __module__: The name of the module that the model belongs to;\n            if `None`, the value is taken from `sys._getframe(1)`\n        __validators__: A dictionary of methods that validate fields. The keys are the names of the validation methods to\n            be added to the model, and the values are the validation methods themselves. You can read more about functional\n            validators [here](https://docs.pydantic.dev/2.9/concepts/validators/#field-validators).\n        __cls_kwargs__: A dictionary of keyword arguments for class creation, such as `metaclass`.\n        __slots__: Deprecated. Should not be passed to `create_model`.\n        **field_definitions: Attributes of the new model. They should be passed in the format:\n            `&lt;name&gt;=(&lt;type&gt;, &lt;default value&gt;)`, `&lt;name&gt;=(&lt;type&gt;, &lt;FieldInfo&gt;)`, or `typing.Annotated[&lt;type&gt;, &lt;FieldInfo&gt;]`.\n            Any additional metadata in `typing.Annotated[&lt;type&gt;, &lt;FieldInfo&gt;, ...]` will be ignored.\n\n    Returns:\n        The new [model][pydantic.BaseModel].\n\n    Raises:\n        PydanticUserError: If `__base__` and `__config__` are both passed.\n    \"\"\"\n    if __slots__ is not None:\n        # __slots__ will be ignored from here on\n        warnings.warn('__slots__ should not be passed to create_model', RuntimeWarning)\n\n    if __base__ is not None:\n        if __config__ is not None:\n            raise PydanticUserError(\n                'to avoid confusion `__config__` and `__base__` cannot be used together',\n                code='create-model-config-base',\n            )\n        if not isinstance(__base__, tuple):\n            __base__ = (__base__,)\n    else:\n        __base__ = (cast('type[ModelT]', BaseModel),)\n\n    __cls_kwargs__ = __cls_kwargs__ or {}\n\n    fields = {}\n    annotations = {}\n\n    for f_name, f_def in field_definitions.items():\n        if not _fields.is_valid_field_name(f_name):\n            warnings.warn(f'fields may not start with an underscore, ignoring \"{f_name}\"', RuntimeWarning)\n        if isinstance(f_def, tuple):\n            f_def = cast('tuple[str, Any]', f_def)\n            try:\n                f_annotation, f_value = f_def\n            except ValueError as e:\n                raise PydanticUserError(\n                    'Field definitions should be a `(&lt;type&gt;, &lt;default&gt;)`.',\n                    code='create-model-field-definitions',\n                ) from e\n\n        elif _typing_extra.is_annotated(f_def):\n            (f_annotation, f_value, *_) = typing_extensions.get_args(\n                f_def\n            )  # first two input are expected from Annotated, refer to https://docs.python.org/3/library/typing.html#typing.Annotated\n            FieldInfo = _import_utils.import_cached_field_info()\n\n            if not isinstance(f_value, FieldInfo):\n                raise PydanticUserError(\n                    'Field definitions should be a Annotated[&lt;type&gt;, &lt;FieldInfo&gt;]',\n                    code='create-model-field-definitions',\n                )\n\n        else:\n            f_annotation, f_value = None, f_def\n\n        if f_annotation:\n            annotations[f_name] = f_annotation\n        fields[f_name] = f_value\n\n    if __module__ is None:\n        f = sys._getframe(1)\n        __module__ = f.f_globals['__name__']\n\n    namespace: dict[str, Any] = {'__annotations__': annotations, '__module__': __module__}\n    if __doc__:\n        namespace.update({'__doc__': __doc__})\n    if __validators__:\n        namespace.update(__validators__)\n    namespace.update(fields)\n    if __config__:\n        namespace['model_config'] = _config.ConfigWrapper(__config__).config_dict\n    resolved_bases = types.resolve_bases(__base__)\n    meta, ns, kwds = types.prepare_class(model_name, resolved_bases, kwds=__cls_kwargs__)\n    if resolved_bases is not __base__:\n        ns['__orig_bases__'] = __base__\n    namespace.update(ns)\n\n    return meta(\n        model_name,\n        resolved_bases,\n        namespace,\n        __pydantic_reset_parent_namespace__=False,\n        _create_model_module=__module__,\n        **kwds,\n    )\n</code></pre>"},{"location":"api/config/","title":"Configuration","text":"<p>Configuration for Pydantic models.</p>"},{"location":"api/config/#pydantic.config.ConfigDict","title":"ConfigDict","text":"<p>               Bases: <code>TypedDict</code></p> <p>A TypedDict for configuring Pydantic behaviour.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.title","title":"title  <code>instance-attribute</code>","text":"<pre><code>title: str | None\n</code></pre> <p>The title for the generated JSON schema, defaults to the model's name</p>"},{"location":"api/config/#pydantic.config.ConfigDict.model_title_generator","title":"model_title_generator  <code>instance-attribute</code>","text":"<pre><code>model_title_generator: Callable[[type], str] | None\n</code></pre> <p>A callable that takes a model class and returns the title for it. Defaults to <code>None</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.field_title_generator","title":"field_title_generator  <code>instance-attribute</code>","text":"<pre><code>field_title_generator: (\n    Callable[[str, FieldInfo | ComputedFieldInfo], str]\n    | None\n)\n</code></pre> <p>A callable that takes a field's name and info and returns title for it. Defaults to <code>None</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.str_to_lower","title":"str_to_lower  <code>instance-attribute</code>","text":"<pre><code>str_to_lower: bool\n</code></pre> <p>Whether to convert all characters to lowercase for str types. Defaults to <code>False</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.str_to_upper","title":"str_to_upper  <code>instance-attribute</code>","text":"<pre><code>str_to_upper: bool\n</code></pre> <p>Whether to convert all characters to uppercase for str types. Defaults to <code>False</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.str_strip_whitespace","title":"str_strip_whitespace  <code>instance-attribute</code>","text":"<pre><code>str_strip_whitespace: bool\n</code></pre> <p>Whether to strip leading and trailing whitespace for str types.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.str_min_length","title":"str_min_length  <code>instance-attribute</code>","text":"<pre><code>str_min_length: int\n</code></pre> <p>The minimum length for str types. Defaults to <code>None</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.str_max_length","title":"str_max_length  <code>instance-attribute</code>","text":"<pre><code>str_max_length: int | None\n</code></pre> <p>The maximum length for str types. Defaults to <code>None</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.extra","title":"extra  <code>instance-attribute</code>","text":"<pre><code>extra: ExtraValues | None\n</code></pre> <p>Whether to ignore, allow, or forbid extra attributes during model initialization. Defaults to <code>'ignore'</code>.</p> <p>You can configure how pydantic handles the attributes that are not defined in the model:</p> <ul> <li><code>allow</code> - Allow any extra attributes.</li> <li><code>forbid</code> - Forbid any extra attributes.</li> <li><code>ignore</code> - Ignore any extra attributes.</li> </ul> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(extra='ignore')  # (1)!\n\n    name: str\n\n\nuser = User(name='John Doe', age=20)  # (2)!\nprint(user)\n#&gt; name='John Doe'\n</code></pre> <ol> <li>This is the default behaviour.</li> <li>The <code>age</code> argument is ignored.</li> </ol> <p>Instead, with <code>extra='allow'</code>, the <code>age</code> argument is included:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(extra='allow')\n\n    name: str\n\n\nuser = User(name='John Doe', age=20)  # (1)!\nprint(user)\n#&gt; name='John Doe' age=20\n</code></pre> <ol> <li>The <code>age</code> argument is included.</li> </ol> <p>With <code>extra='forbid'</code>, an error is raised:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(extra='forbid')\n\n    name: str\n\n\ntry:\n    User(name='John Doe', age=20)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for User\n    age\n    Extra inputs are not permitted [type=extra_forbidden, input_value=20, input_type=int]\n    '''\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.frozen","title":"frozen  <code>instance-attribute</code>","text":"<pre><code>frozen: bool\n</code></pre> <p>Whether models are faux-immutable, i.e. whether <code>__setattr__</code> is allowed, and also generates a <code>__hash__()</code> method for the model. This makes instances of the model potentially hashable if all the attributes are hashable. Defaults to <code>False</code>.</p> Note <p>On V1, the inverse of this setting was called <code>allow_mutation</code>, and was <code>True</code> by default.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.populate_by_name","title":"populate_by_name  <code>instance-attribute</code>","text":"<pre><code>populate_by_name: bool\n</code></pre> <p>Whether an aliased field may be populated by its name as given by the model attribute, as well as the alias. Defaults to <code>False</code>.</p> Note <p>The name of this configuration setting was changed in v2.0 from <code>allow_population_by_field_name</code> to <code>populate_by_name</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(populate_by_name=True)\n\n    name: str = Field(alias='full_name')  # (1)!\n    age: int\n\n\nuser = User(full_name='John Doe', age=20)  # (2)!\nprint(user)\n#&gt; name='John Doe' age=20\nuser = User(name='John Doe', age=20)  # (3)!\nprint(user)\n#&gt; name='John Doe' age=20\n</code></pre> <ol> <li>The field <code>'name'</code> has an alias <code>'full_name'</code>.</li> <li>The model is populated by the alias <code>'full_name'</code>.</li> <li>The model is populated by the field name <code>'name'</code>.</li> </ol>"},{"location":"api/config/#pydantic.config.ConfigDict.use_enum_values","title":"use_enum_values  <code>instance-attribute</code>","text":"<pre><code>use_enum_values: bool\n</code></pre> <p>Whether to populate models with the <code>value</code> property of enums, rather than the raw enum. This may be useful if you want to serialize <code>model.model_dump()</code> later. Defaults to <code>False</code>.</p> <p>Note</p> <p>If you have an <code>Optional[Enum]</code> value that you set a default for, you need to use <code>validate_default=True</code> for said Field to ensure that the <code>use_enum_values</code> flag takes effect on the default, as extracting an enum's value occurs during validation, not serialization.</p> <pre><code>from enum import Enum\nfrom typing import Optional\n\nfrom pydantic import BaseModel, ConfigDict, Field\n\n\nclass SomeEnum(Enum):\n    FOO = 'foo'\n    BAR = 'bar'\n    BAZ = 'baz'\n\n\nclass SomeModel(BaseModel):\n    model_config = ConfigDict(use_enum_values=True)\n\n    some_enum: SomeEnum\n    another_enum: Optional[SomeEnum] = Field(default=SomeEnum.FOO, validate_default=True)\n\n\nmodel1 = SomeModel(some_enum=SomeEnum.BAR)\nprint(model1.model_dump())\n# {'some_enum': 'bar', 'another_enum': 'foo'}\n\nmodel2 = SomeModel(some_enum=SomeEnum.BAR, another_enum=SomeEnum.BAZ)\nprint(model2.model_dump())\n#&gt; {'some_enum': 'bar', 'another_enum': 'baz'}\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.validate_assignment","title":"validate_assignment  <code>instance-attribute</code>","text":"<pre><code>validate_assignment: bool\n</code></pre> <p>Whether to validate the data when the model is changed. Defaults to <code>False</code>.</p> <p>The default behavior of Pydantic is to validate the data when the model is created.</p> <p>In case the user changes the data after the model is created, the model is not revalidated.</p> <pre><code>from pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n\nuser = User(name='John Doe')  # (1)!\nprint(user)\n#&gt; name='John Doe'\nuser.name = 123  # (1)!\nprint(user)\n#&gt; name=123\n</code></pre> <ol> <li>The validation happens only when the model is created.</li> <li>The validation does not happen when the data is changed.</li> </ol> <p>In case you want to revalidate the model when the data is changed, you can use <code>validate_assignment=True</code>:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\nclass User(BaseModel, validate_assignment=True):  # (1)!\n    name: str\n\nuser = User(name='John Doe')  # (2)!\nprint(user)\n#&gt; name='John Doe'\ntry:\n    user.name = 123  # (3)!\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for User\n    name\n      Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    '''\n</code></pre> <ol> <li>You can either use class keyword arguments, or <code>model_config</code> to set <code>validate_assignment=True</code>.</li> <li>The validation happens when the model is created.</li> <li>The validation also happens when the data is changed.</li> </ol>"},{"location":"api/config/#pydantic.config.ConfigDict.arbitrary_types_allowed","title":"arbitrary_types_allowed  <code>instance-attribute</code>","text":"<pre><code>arbitrary_types_allowed: bool\n</code></pre> <p>Whether arbitrary types are allowed for field types. Defaults to <code>False</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n# This is not a pydantic model, it's an arbitrary class\nclass Pet:\n    def __init__(self, name: str):\n        self.name = name\n\nclass Model(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    pet: Pet\n    owner: str\n\npet = Pet(name='Hedwig')\n# A simple check of instance type is used to validate the data\nmodel = Model(owner='Harry', pet=pet)\nprint(model)\n#&gt; pet=&lt;__main__.Pet object at 0x0123456789ab&gt; owner='Harry'\nprint(model.pet)\n#&gt; &lt;__main__.Pet object at 0x0123456789ab&gt;\nprint(model.pet.name)\n#&gt; Hedwig\nprint(type(model.pet))\n#&gt; &lt;class '__main__.Pet'&gt;\ntry:\n    # If the value is not an instance of the type, it's invalid\n    Model(owner='Harry', pet='Hedwig')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    pet\n      Input should be an instance of Pet [type=is_instance_of, input_value='Hedwig', input_type=str]\n    '''\n\n# Nothing in the instance of the arbitrary type is checked\n# Here name probably should have been a str, but it's not validated\npet2 = Pet(name=42)\nmodel2 = Model(owner='Harry', pet=pet2)\nprint(model2)\n#&gt; pet=&lt;__main__.Pet object at 0x0123456789ab&gt; owner='Harry'\nprint(model2.pet)\n#&gt; &lt;__main__.Pet object at 0x0123456789ab&gt;\nprint(model2.pet.name)\n#&gt; 42\nprint(type(model2.pet))\n#&gt; &lt;class '__main__.Pet'&gt;\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.from_attributes","title":"from_attributes  <code>instance-attribute</code>","text":"<pre><code>from_attributes: bool\n</code></pre> <p>Whether to build models and look up discriminators of tagged unions using python object attributes.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.loc_by_alias","title":"loc_by_alias  <code>instance-attribute</code>","text":"<pre><code>loc_by_alias: bool\n</code></pre> <p>Whether to use the actual key provided in the data (e.g. alias) for error <code>loc</code>s rather than the field's name. Defaults to <code>True</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.alias_generator","title":"alias_generator  <code>instance-attribute</code>","text":"<pre><code>alias_generator: (\n    Callable[[str], str] | AliasGenerator | None\n)\n</code></pre> <p>A callable that takes a field name and returns an alias for it or an instance of <code>AliasGenerator</code>. Defaults to <code>None</code>.</p> <p>When using a callable, the alias generator is used for both validation and serialization. If you want to use different alias generators for validation and serialization, you can use <code>AliasGenerator</code> instead.</p> <p>If data source field names do not match your code style (e. g. CamelCase fields), you can automatically generate aliases using <code>alias_generator</code>. Here's an example with a basic callable:</p> <pre><code>from pydantic import BaseModel, ConfigDict\nfrom pydantic.alias_generators import to_pascal\n\nclass Voice(BaseModel):\n    model_config = ConfigDict(alias_generator=to_pascal)\n\n    name: str\n    language_code: str\n\nvoice = Voice(Name='Filiz', LanguageCode='tr-TR')\nprint(voice.language_code)\n#&gt; tr-TR\nprint(voice.model_dump(by_alias=True))\n#&gt; {'Name': 'Filiz', 'LanguageCode': 'tr-TR'}\n</code></pre> <p>If you want to use different alias generators for validation and serialization, you can use <code>AliasGenerator</code>.</p> <pre><code>from pydantic import AliasGenerator, BaseModel, ConfigDict\nfrom pydantic.alias_generators import to_camel, to_pascal\n\nclass Athlete(BaseModel):\n    first_name: str\n    last_name: str\n    sport: str\n\n    model_config = ConfigDict(\n        alias_generator=AliasGenerator(\n            validation_alias=to_camel,\n            serialization_alias=to_pascal,\n        )\n    )\n\nathlete = Athlete(firstName='John', lastName='Doe', sport='track')\nprint(athlete.model_dump(by_alias=True))\n#&gt; {'FirstName': 'John', 'LastName': 'Doe', 'Sport': 'track'}\n</code></pre> Note <p>Pydantic offers three built-in alias generators: <code>to_pascal</code>, <code>to_camel</code>, and <code>to_snake</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.ignored_types","title":"ignored_types  <code>instance-attribute</code>","text":"<pre><code>ignored_types: tuple[type, ...]\n</code></pre> <p>A tuple of types that may occur as values of class attributes without annotations. This is typically used for custom descriptors (classes that behave like <code>property</code>). If an attribute is set on a class without an annotation and has a type that is not in this tuple (or otherwise recognized by pydantic), an error will be raised. Defaults to <code>()</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.allow_inf_nan","title":"allow_inf_nan  <code>instance-attribute</code>","text":"<pre><code>allow_inf_nan: bool\n</code></pre> <p>Whether to allow infinity (<code>+inf</code> an <code>-inf</code>) and NaN values to float and decimal fields. Defaults to <code>True</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.json_schema_extra","title":"json_schema_extra  <code>instance-attribute</code>","text":"<pre><code>json_schema_extra: JsonDict | JsonSchemaExtraCallable | None\n</code></pre> <p>A dict or callable to provide extra JSON schema properties. Defaults to <code>None</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.json_encoders","title":"json_encoders  <code>instance-attribute</code>","text":"<pre><code>json_encoders: dict[type[object], JsonEncoder] | None\n</code></pre> <p>A <code>dict</code> of custom JSON encoders for specific types. Defaults to <code>None</code>.</p> <p>Deprecated</p> <p>This config option is a carryover from v1. We originally planned to remove it in v2 but didn't have a 1:1 replacement so we are keeping it for now. It is still deprecated and will likely be removed in the future.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.strict","title":"strict  <code>instance-attribute</code>","text":"<pre><code>strict: bool\n</code></pre> <p>(new in V2) If <code>True</code>, strict validation is applied to all fields on the model.</p> <p>By default, Pydantic attempts to coerce values to the correct type, when possible.</p> <p>There are situations in which you may want to disable this behavior, and instead raise an error if a value's type does not match the field's type annotation.</p> <p>To configure strict mode for all fields on a model, you can set <code>strict=True</code> on the model.</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\nclass Model(BaseModel):\n    model_config = ConfigDict(strict=True)\n\n    name: str\n    age: int\n</code></pre> <p>See Strict Mode for more details.</p> <p>See the Conversion Table for more details on how Pydantic converts data in both strict and lax modes.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.revalidate_instances","title":"revalidate_instances  <code>instance-attribute</code>","text":"<pre><code>revalidate_instances: Literal[\n    \"always\", \"never\", \"subclass-instances\"\n]\n</code></pre> <p>When and how to revalidate models and dataclasses during validation. Accepts the string values of <code>'never'</code>, <code>'always'</code> and <code>'subclass-instances'</code>. Defaults to <code>'never'</code>.</p> <ul> <li><code>'never'</code> will not revalidate models and dataclasses during validation</li> <li><code>'always'</code> will revalidate models and dataclasses during validation</li> <li><code>'subclass-instances'</code> will revalidate models and dataclasses during validation if the instance is a     subclass of the model or dataclass</li> </ul> <p>By default, model and dataclass instances are not revalidated during validation.</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel\n\nclass User(BaseModel, revalidate_instances='never'):  # (1)!\n    hobbies: List[str]\n\nclass SubUser(User):\n    sins: List[str]\n\nclass Transaction(BaseModel):\n    user: User\n\nmy_user = User(hobbies=['reading'])\nt = Transaction(user=my_user)\nprint(t)\n#&gt; user=User(hobbies=['reading'])\n\nmy_user.hobbies = [1]  # (2)!\nt = Transaction(user=my_user)  # (3)!\nprint(t)\n#&gt; user=User(hobbies=[1])\n\nmy_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\nt = Transaction(user=my_sub_user)\nprint(t)\n#&gt; user=SubUser(hobbies=['scuba diving'], sins=['lying'])\n</code></pre> <ol> <li><code>revalidate_instances</code> is set to <code>'never'</code> by **default.</li> <li>The assignment is not validated, unless you set <code>validate_assignment</code> to <code>True</code> in the model's config.</li> <li>Since <code>revalidate_instances</code> is set to <code>never</code>, this is not revalidated.</li> </ol> <p>If you want to revalidate instances during validation, you can set <code>revalidate_instances</code> to <code>'always'</code> in the model's config.</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\nclass User(BaseModel, revalidate_instances='always'):  # (1)!\n    hobbies: List[str]\n\nclass SubUser(User):\n    sins: List[str]\n\nclass Transaction(BaseModel):\n    user: User\n\nmy_user = User(hobbies=['reading'])\nt = Transaction(user=my_user)\nprint(t)\n#&gt; user=User(hobbies=['reading'])\n\nmy_user.hobbies = [1]\ntry:\n    t = Transaction(user=my_user)  # (2)!\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Transaction\n    user.hobbies.0\n      Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    '''\n\nmy_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\nt = Transaction(user=my_sub_user)\nprint(t)  # (3)!\n#&gt; user=User(hobbies=['scuba diving'])\n</code></pre> <ol> <li><code>revalidate_instances</code> is set to <code>'always'</code>.</li> <li>The model is revalidated, since <code>revalidate_instances</code> is set to <code>'always'</code>.</li> <li>Using <code>'never'</code> we would have gotten <code>user=SubUser(hobbies=['scuba diving'], sins=['lying'])</code>.</li> </ol> <p>It's also possible to set <code>revalidate_instances</code> to <code>'subclass-instances'</code> to only revalidate instances of subclasses of the model.</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel\n\nclass User(BaseModel, revalidate_instances='subclass-instances'):  # (1)!\n    hobbies: List[str]\n\nclass SubUser(User):\n    sins: List[str]\n\nclass Transaction(BaseModel):\n    user: User\n\nmy_user = User(hobbies=['reading'])\nt = Transaction(user=my_user)\nprint(t)\n#&gt; user=User(hobbies=['reading'])\n\nmy_user.hobbies = [1]\nt = Transaction(user=my_user)  # (2)!\nprint(t)\n#&gt; user=User(hobbies=[1])\n\nmy_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\nt = Transaction(user=my_sub_user)\nprint(t)  # (3)!\n#&gt; user=User(hobbies=['scuba diving'])\n</code></pre> <ol> <li><code>revalidate_instances</code> is set to <code>'subclass-instances'</code>.</li> <li>This is not revalidated, since <code>my_user</code> is not a subclass of <code>User</code>.</li> <li>Using <code>'never'</code> we would have gotten <code>user=SubUser(hobbies=['scuba diving'], sins=['lying'])</code>.</li> </ol>"},{"location":"api/config/#pydantic.config.ConfigDict.ser_json_timedelta","title":"ser_json_timedelta  <code>instance-attribute</code>","text":"<pre><code>ser_json_timedelta: Literal['iso8601', 'float']\n</code></pre> <p>The format of JSON serialized timedeltas. Accepts the string values of <code>'iso8601'</code> and <code>'float'</code>. Defaults to <code>'iso8601'</code>.</p> <ul> <li><code>'iso8601'</code> will serialize timedeltas to ISO 8601 durations.</li> <li><code>'float'</code> will serialize timedeltas to the total number of seconds.</li> </ul>"},{"location":"api/config/#pydantic.config.ConfigDict.ser_json_bytes","title":"ser_json_bytes  <code>instance-attribute</code>","text":"<pre><code>ser_json_bytes: Literal['utf8', 'base64', 'hex']\n</code></pre> <p>The encoding of JSON serialized bytes. Defaults to <code>'utf8'</code>. Set equal to <code>val_json_bytes</code> to get back an equal value after serialization round trip.</p> <ul> <li><code>'utf8'</code> will serialize bytes to UTF-8 strings.</li> <li><code>'base64'</code> will serialize bytes to URL safe base64 strings.</li> <li><code>'hex'</code> will serialize bytes to hexadecimal strings.</li> </ul>"},{"location":"api/config/#pydantic.config.ConfigDict.val_json_bytes","title":"val_json_bytes  <code>instance-attribute</code>","text":"<pre><code>val_json_bytes: Literal['utf8', 'base64', 'hex']\n</code></pre> <p>The encoding of JSON serialized bytes to decode. Defaults to <code>'utf8'</code>. Set equal to <code>ser_json_bytes</code> to get back an equal value after serialization round trip.</p> <ul> <li><code>'utf8'</code> will deserialize UTF-8 strings to bytes.</li> <li><code>'base64'</code> will deserialize URL safe base64 strings to bytes.</li> <li><code>'hex'</code> will deserialize hexadecimal strings to bytes.</li> </ul>"},{"location":"api/config/#pydantic.config.ConfigDict.ser_json_inf_nan","title":"ser_json_inf_nan  <code>instance-attribute</code>","text":"<pre><code>ser_json_inf_nan: Literal['null', 'constants', 'strings']\n</code></pre> <p>The encoding of JSON serialized infinity and NaN float values. Defaults to <code>'null'</code>.</p> <ul> <li><code>'null'</code> will serialize infinity and NaN values as <code>null</code>.</li> <li><code>'constants'</code> will serialize infinity and NaN values as <code>Infinity</code> and <code>NaN</code>.</li> <li><code>'strings'</code> will serialize infinity as string <code>\"Infinity\"</code> and NaN as string <code>\"NaN\"</code>.</li> </ul>"},{"location":"api/config/#pydantic.config.ConfigDict.validate_default","title":"validate_default  <code>instance-attribute</code>","text":"<pre><code>validate_default: bool\n</code></pre> <p>Whether to validate default values during validation. Defaults to <code>False</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.validate_return","title":"validate_return  <code>instance-attribute</code>","text":"<pre><code>validate_return: bool\n</code></pre> <p>whether to validate the return value from call validators. Defaults to <code>False</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.protected_namespaces","title":"protected_namespaces  <code>instance-attribute</code>","text":"<pre><code>protected_namespaces: tuple[str, ...]\n</code></pre> <p>A <code>tuple</code> of strings that prevent model to have field which conflict with them. Defaults to <code>('model_', )</code>).</p> <p>Pydantic prevents collisions between model attributes and <code>BaseModel</code>'s own methods by namespacing them with the prefix <code>model_</code>.</p> <pre><code>import warnings\n\nfrom pydantic import BaseModel\n\nwarnings.filterwarnings('error')  # Raise warnings as errors\n\ntry:\n\n    class Model(BaseModel):\n        model_prefixed_field: str\n\nexcept UserWarning as e:\n    print(e)\n    '''\n    Field \"model_prefixed_field\" in Model has conflict with protected namespace \"model_\".\n\n    You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n    '''\n</code></pre> <p>You can customize this behavior using the <code>protected_namespaces</code> setting:</p> <pre><code>import warnings\n\nfrom pydantic import BaseModel, ConfigDict\n\nwarnings.filterwarnings('error')  # Raise warnings as errors\n\ntry:\n\n    class Model(BaseModel):\n        model_prefixed_field: str\n        also_protect_field: str\n\n        model_config = ConfigDict(\n            protected_namespaces=('protect_me_', 'also_protect_')\n        )\n\nexcept UserWarning as e:\n    print(e)\n    '''\n    Field \"also_protect_field\" in Model has conflict with protected namespace \"also_protect_\".\n\n    You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('protect_me_',)`.\n    '''\n</code></pre> <p>While Pydantic will only emit a warning when an item is in a protected namespace but does not actually have a collision, an error is raised if there is an actual collision with an existing attribute:</p> <pre><code>from pydantic import BaseModel\n\ntry:\n\n    class Model(BaseModel):\n        model_validate: str\n\nexcept NameError as e:\n    print(e)\n    '''\n    Field \"model_validate\" conflicts with member &lt;bound method BaseModel.model_validate of &lt;class 'pydantic.main.BaseModel'&gt;&gt; of protected namespace \"model_\".\n    '''\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.hide_input_in_errors","title":"hide_input_in_errors  <code>instance-attribute</code>","text":"<pre><code>hide_input_in_errors: bool\n</code></pre> <p>Whether to hide inputs when printing errors. Defaults to <code>False</code>.</p> <p>Pydantic shows the input value and type when it raises <code>ValidationError</code> during the validation.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\nclass Model(BaseModel):\n    a: str\n\ntry:\n    Model(a=123)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    a\n      Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    '''\n</code></pre> <p>You can hide the input value and type by setting the <code>hide_input_in_errors</code> config to <code>True</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\nclass Model(BaseModel):\n    a: str\n    model_config = ConfigDict(hide_input_in_errors=True)\n\ntry:\n    Model(a=123)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    a\n      Input should be a valid string [type=string_type]\n    '''\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.defer_build","title":"defer_build  <code>instance-attribute</code>","text":"<pre><code>defer_build: bool\n</code></pre> <p>Whether to defer model validator and serializer construction until the first model validation. Defaults to False.</p> <p>This can be useful to avoid the overhead of building models which are only used nested within other models, or when you want to manually define type namespace via <code>Model.model_rebuild(_types_namespace=...)</code>.</p> <p>See also <code>experimental_defer_build_mode</code>.</p> <p>Note</p> <p><code>defer_build</code> does not work by default with FastAPI Pydantic models. By default, the validator and serializer for said models is constructed immediately for FastAPI routes. You also need to define <code>experimental_defer_build_mode=('model', 'type_adapter')</code> with FastAPI models in order for <code>defer_build=True</code> to take effect. This additional (experimental) parameter is required for the deferred building due to FastAPI relying on <code>TypeAdapter</code>s.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.experimental_defer_build_mode","title":"experimental_defer_build_mode  <code>instance-attribute</code>","text":"<pre><code>experimental_defer_build_mode: tuple[\n    Literal[\"model\", \"type_adapter\"], ...\n]\n</code></pre> <p>Controls when <code>defer_build</code> is applicable. Defaults to <code>('model',)</code>.</p> <p>Due to backwards compatibility reasons <code>TypeAdapter</code> does not by default respect <code>defer_build</code>. Meaning when <code>defer_build</code> is <code>True</code> and <code>experimental_defer_build_mode</code> is the default <code>('model',)</code> then <code>TypeAdapter</code> immediately constructs its validator and serializer instead of postponing said construction until the first model validation. Set this to <code>('model', 'type_adapter')</code> to make <code>TypeAdapter</code> respect the <code>defer_build</code> so it postpones validator and serializer construction until the first validation or serialization.</p> <p>Note</p> <p>The <code>experimental_defer_build_mode</code> parameter is named with an underscore to suggest this is an experimental feature. It may be removed or changed in the future in a minor release.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.plugin_settings","title":"plugin_settings  <code>instance-attribute</code>","text":"<pre><code>plugin_settings: dict[str, object] | None\n</code></pre> <p>A <code>dict</code> of settings for plugins. Defaults to <code>None</code>.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.schema_generator","title":"schema_generator  <code>instance-attribute</code>","text":"<pre><code>schema_generator: type[GenerateSchema] | None\n</code></pre> <p>A custom core schema generator class to use when generating JSON schemas. Useful if you want to change the way types are validated across an entire model/schema. Defaults to <code>None</code>.</p> <p>The <code>GenerateSchema</code> interface is subject to change, currently only the <code>string_schema</code> method is public.</p> <p>See #6737 for details.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.json_schema_serialization_defaults_required","title":"json_schema_serialization_defaults_required  <code>instance-attribute</code>","text":"<pre><code>json_schema_serialization_defaults_required: bool\n</code></pre> <p>Whether fields with default values should be marked as required in the serialization schema. Defaults to <code>False</code>.</p> <p>This ensures that the serialization schema will reflect the fact a field with a default will always be present when serializing the model, even though it is not required for validation.</p> <p>However, there are scenarios where this may be undesirable \u2014 in particular, if you want to share the schema between validation and serialization, and don't mind fields with defaults being marked as not required during serialization. See #7209 for more details.</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\nclass Model(BaseModel):\n    a: str = 'a'\n\n    model_config = ConfigDict(json_schema_serialization_defaults_required=True)\n\nprint(Model.model_json_schema(mode='validation'))\n'''\n{\n    'properties': {'a': {'default': 'a', 'title': 'A', 'type': 'string'}},\n    'title': 'Model',\n    'type': 'object',\n}\n'''\nprint(Model.model_json_schema(mode='serialization'))\n'''\n{\n    'properties': {'a': {'default': 'a', 'title': 'A', 'type': 'string'}},\n    'required': ['a'],\n    'title': 'Model',\n    'type': 'object',\n}\n'''\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.json_schema_mode_override","title":"json_schema_mode_override  <code>instance-attribute</code>","text":"<pre><code>json_schema_mode_override: Literal[\n    \"validation\", \"serialization\", None\n]\n</code></pre> <p>If not <code>None</code>, the specified mode will be used to generate the JSON schema regardless of what <code>mode</code> was passed to the function call. Defaults to <code>None</code>.</p> <p>This provides a way to force the JSON schema generation to reflect a specific mode, e.g., to always use the validation schema.</p> <p>It can be useful when using frameworks (such as FastAPI) that may generate different schemas for validation and serialization that must both be referenced from the same schema; when this happens, we automatically append <code>-Input</code> to the definition reference for the validation schema and <code>-Output</code> to the definition reference for the serialization schema. By specifying a <code>json_schema_mode_override</code> though, this prevents the conflict between the validation and serialization schemas (since both will use the specified schema), and so prevents the suffixes from being added to the definition references.</p> <pre><code>from pydantic import BaseModel, ConfigDict, Json\n\nclass Model(BaseModel):\n    a: Json[int]  # requires a string to validate, but will dump an int\n\nprint(Model.model_json_schema(mode='serialization'))\n'''\n{\n    'properties': {'a': {'title': 'A', 'type': 'integer'}},\n    'required': ['a'],\n    'title': 'Model',\n    'type': 'object',\n}\n'''\n\nclass ForceInputModel(Model):\n    # the following ensures that even with mode='serialization', we\n    # will get the schema that would be generated for validation.\n    model_config = ConfigDict(json_schema_mode_override='validation')\n\nprint(ForceInputModel.model_json_schema(mode='serialization'))\n'''\n{\n    'properties': {\n        'a': {\n            'contentMediaType': 'application/json',\n            'contentSchema': {'type': 'integer'},\n            'title': 'A',\n            'type': 'string',\n        }\n    },\n    'required': ['a'],\n    'title': 'ForceInputModel',\n    'type': 'object',\n}\n'''\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.coerce_numbers_to_str","title":"coerce_numbers_to_str  <code>instance-attribute</code>","text":"<pre><code>coerce_numbers_to_str: bool\n</code></pre> <p>If <code>True</code>, enables automatic coercion of any <code>Number</code> type to <code>str</code> in \"lax\" (non-strict) mode. Defaults to <code>False</code>.</p> <p>Pydantic doesn't allow number types (<code>int</code>, <code>float</code>, <code>Decimal</code>) to be coerced as type <code>str</code> by default.</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, ConfigDict, ValidationError\n\nclass Model(BaseModel):\n    value: str\n\ntry:\n    print(Model(value=42))\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    value\n      Input should be a valid string [type=string_type, input_value=42, input_type=int]\n    '''\n\nclass Model(BaseModel):\n    model_config = ConfigDict(coerce_numbers_to_str=True)\n\n    value: str\n\nrepr(Model(value=42).value)\n#&gt; \"42\"\nrepr(Model(value=42.13).value)\n#&gt; \"42.13\"\nrepr(Model(value=Decimal('42.13')).value)\n#&gt; \"42.13\"\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.regex_engine","title":"regex_engine  <code>instance-attribute</code>","text":"<pre><code>regex_engine: Literal['rust-regex', 'python-re']\n</code></pre> <p>The regex engine to be used for pattern validation. Defaults to <code>'rust-regex'</code>.</p> <ul> <li><code>rust-regex</code> uses the <code>regex</code> Rust crate,   which is non-backtracking and therefore more DDoS resistant, but does not support all regex features.</li> <li><code>python-re</code> use the <code>re</code> module,   which supports all regex features, but may be slower.</li> </ul> <p>Note</p> <p>If you use a compiled regex pattern, the python-re engine will be used regardless of this setting. This is so that flags such as <code>re.IGNORECASE</code> are respected.</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field, ValidationError\n\nclass Model(BaseModel):\n    model_config = ConfigDict(regex_engine='python-re')\n\n    value: str = Field(pattern=r'^abc(?=def)')\n\nprint(Model(value='abcdef').value)\n#&gt; abcdef\n\ntry:\n    print(Model(value='abxyzcdef'))\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    value\n      String should match pattern '^abc(?=def)' [type=string_pattern_mismatch, input_value='abxyzcdef', input_type=str]\n    '''\n</code></pre>"},{"location":"api/config/#pydantic.config.ConfigDict.validation_error_cause","title":"validation_error_cause  <code>instance-attribute</code>","text":"<pre><code>validation_error_cause: bool\n</code></pre> <p>If <code>True</code>, Python exceptions that were part of a validation failure will be shown as an exception group as a cause. Can be useful for debugging. Defaults to <code>False</code>.</p> Note <p>Python 3.10 and older don't support exception groups natively. &lt;=3.10, backport must be installed: <code>pip install exceptiongroup</code>.</p> Note <p>The structure of validation errors are likely to change in future Pydantic versions. Pydantic offers no guarantees about their structure. Should be used for visual traceback debugging only.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.use_attribute_docstrings","title":"use_attribute_docstrings  <code>instance-attribute</code>","text":"<pre><code>use_attribute_docstrings: bool\n</code></pre> <p>Whether docstrings of attributes (bare string literals immediately following the attribute declaration) should be used for field descriptions. Defaults to <code>False</code>.</p> <p>Available in Pydantic v2.7+.</p> <p><pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\nclass Model(BaseModel):\n    model_config = ConfigDict(use_attribute_docstrings=True)\n\n    x: str\n    \"\"\"\n    Example of an attribute docstring\n    \"\"\"\n\n    y: int = Field(description=\"Description in Field\")\n    \"\"\"\n    Description in Field overrides attribute docstring\n    \"\"\"\n\n\nprint(Model.model_fields[\"x\"].description)\n# &gt; Example of an attribute docstring\nprint(Model.model_fields[\"y\"].description)\n# &gt; Description in Field\n</code></pre> This requires the source code of the class to be available at runtime.</p> <p>Usage with <code>TypedDict</code></p> <p>Due to current limitations, attribute docstrings detection may not work as expected when using <code>TypedDict</code> (in particular when multiple <code>TypedDict</code> classes have the same name in the same source file). The behavior can be different depending on the Python version used.</p>"},{"location":"api/config/#pydantic.config.ConfigDict.cache_strings","title":"cache_strings  <code>instance-attribute</code>","text":"<pre><code>cache_strings: bool | Literal['all', 'keys', 'none']\n</code></pre> <p>Whether to cache strings to avoid constructing new Python objects. Defaults to True.</p> <p>Enabling this setting should significantly improve validation performance while increasing memory usage slightly.</p> <ul> <li><code>True</code> or <code>'all'</code> (the default): cache all strings</li> <li><code>'keys'</code>: cache only dictionary keys</li> <li><code>False</code> or <code>'none'</code>: no caching</li> </ul> <p>Note</p> <p><code>True</code> or <code>'all'</code> is required to cache strings during general validation because validators don't know if they're in a key or a value.</p> <p>Tip</p> <p>If repeated strings are rare, it's recommended to use <code>'keys'</code> or <code>'none'</code> to reduce memory usage, as the performance difference is minimal if repeated strings are rare.</p>"},{"location":"api/config/#pydantic.config.with_config","title":"with_config","text":"<pre><code>with_config(\n    config: ConfigDict,\n) -&gt; Callable[[_TypeT], _TypeT]\n</code></pre> <p>Usage Documentation</p> <p>Configuration with <code>dataclass</code> from the standard library or <code>TypedDict</code></p> <p>A convenience decorator to set a Pydantic configuration on a <code>TypedDict</code> or a <code>dataclass</code> from the standard library.</p> <p>Although the configuration can be set using the <code>__pydantic_config__</code> attribute, it does not play well with type checkers, especially with <code>TypedDict</code>.</p> <p>Usage</p> <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import ConfigDict, TypeAdapter, with_config\n\n@with_config(ConfigDict(str_to_lower=True))\nclass Model(TypedDict):\n    x: str\n\nta = TypeAdapter(Model)\n\nprint(ta.validate_python({'x': 'ABC'}))\n#&gt; {'x': 'abc'}\n</code></pre> Source code in <code>pydantic/config.py</code> <pre><code>def with_config(config: ConfigDict) -&gt; Callable[[_TypeT], _TypeT]:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/config/#configuration-with-dataclass-from-the-standard-library-or-typeddict\n\n    A convenience decorator to set a [Pydantic configuration](config.md) on a `TypedDict` or a `dataclass` from the standard library.\n\n    Although the configuration can be set using the `__pydantic_config__` attribute, it does not play well with type checkers,\n    especially with `TypedDict`.\n\n    !!! example \"Usage\"\n\n        ```py\n        from typing_extensions import TypedDict\n\n        from pydantic import ConfigDict, TypeAdapter, with_config\n\n        @with_config(ConfigDict(str_to_lower=True))\n        class Model(TypedDict):\n            x: str\n\n        ta = TypeAdapter(Model)\n\n        print(ta.validate_python({'x': 'ABC'}))\n        #&gt; {'x': 'abc'}\n        ```\n    \"\"\"\n\n    def inner(class_: _TypeT, /) -&gt; _TypeT:\n        # Ideally, we would check for `class_` to either be a `TypedDict` or a stdlib dataclass.\n        # However, the `@with_config` decorator can be applied *after* `@dataclass`. To avoid\n        # common mistakes, we at least check for `class_` to not be a Pydantic model.\n        from ._internal._utils import is_model_class\n\n        if is_model_class(class_):\n            raise PydanticUserError(\n                f'Cannot use `with_config` on {class_.__name__} as it is a Pydantic model',\n                code='with-config-on-model',\n            )\n        class_.__pydantic_config__ = config\n        return class_\n\n    return inner\n</code></pre>"},{"location":"api/config/#pydantic.config.ExtraValues","title":"ExtraValues  <code>module-attribute</code>","text":"<pre><code>ExtraValues = Literal['allow', 'ignore', 'forbid']\n</code></pre>"},{"location":"api/config/#pydantic.alias_generators","title":"pydantic.alias_generators","text":"<p>Alias generators for converting between different capitalization conventions.</p>"},{"location":"api/config/#pydantic.alias_generators.to_pascal","title":"to_pascal","text":"<pre><code>to_pascal(snake: str) -&gt; str\n</code></pre> <p>Convert a snake_case string to PascalCase.</p> <p>Parameters:</p> Name Type Description Default <code>snake</code> <code>str</code> <p>The string to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The PascalCase string.</p> Source code in <code>pydantic/alias_generators.py</code> <pre><code>def to_pascal(snake: str) -&gt; str:\n    \"\"\"Convert a snake_case string to PascalCase.\n\n    Args:\n        snake: The string to convert.\n\n    Returns:\n        The PascalCase string.\n    \"\"\"\n    camel = snake.title()\n    return re.sub('([0-9A-Za-z])_(?=[0-9A-Z])', lambda m: m.group(1), camel)\n</code></pre>"},{"location":"api/config/#pydantic.alias_generators.to_camel","title":"to_camel","text":"<pre><code>to_camel(snake: str) -&gt; str\n</code></pre> <p>Convert a snake_case string to camelCase.</p> <p>Parameters:</p> Name Type Description Default <code>snake</code> <code>str</code> <p>The string to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The converted camelCase string.</p> Source code in <code>pydantic/alias_generators.py</code> <pre><code>def to_camel(snake: str) -&gt; str:\n    \"\"\"Convert a snake_case string to camelCase.\n\n    Args:\n        snake: The string to convert.\n\n    Returns:\n        The converted camelCase string.\n    \"\"\"\n    # If the string is already in camelCase and does not contain a digit followed\n    # by a lowercase letter, return it as it is\n    if re.match('^[a-z]+[A-Za-z0-9]*$', snake) and not re.search(r'\\d[a-z]', snake):\n        return snake\n\n    camel = to_pascal(snake)\n    return re.sub('(^_*[A-Z])', lambda m: m.group(1).lower(), camel)\n</code></pre>"},{"location":"api/config/#pydantic.alias_generators.to_snake","title":"to_snake","text":"<pre><code>to_snake(camel: str) -&gt; str\n</code></pre> <p>Convert a PascalCase, camelCase, or kebab-case string to snake_case.</p> <p>Parameters:</p> Name Type Description Default <code>camel</code> <code>str</code> <p>The string to convert.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The converted string in snake_case.</p> Source code in <code>pydantic/alias_generators.py</code> <pre><code>def to_snake(camel: str) -&gt; str:\n    \"\"\"Convert a PascalCase, camelCase, or kebab-case string to snake_case.\n\n    Args:\n        camel: The string to convert.\n\n    Returns:\n        The converted string in snake_case.\n    \"\"\"\n    # Handle the sequence of uppercase letters followed by a lowercase letter\n    snake = re.sub(r'([A-Z]+)([A-Z][a-z])', lambda m: f'{m.group(1)}_{m.group(2)}', camel)\n    # Insert an underscore between a lowercase letter and an uppercase letter\n    snake = re.sub(r'([a-z])([A-Z])', lambda m: f'{m.group(1)}_{m.group(2)}', snake)\n    # Insert an underscore between a digit and an uppercase letter\n    snake = re.sub(r'([0-9])([A-Z])', lambda m: f'{m.group(1)}_{m.group(2)}', snake)\n    # Insert an underscore between a lowercase letter and a digit\n    snake = re.sub(r'([a-z])([0-9])', lambda m: f'{m.group(1)}_{m.group(2)}', snake)\n    # Replace hyphens with underscores to handle kebab-case\n    snake = snake.replace('-', '_')\n    return snake.lower()\n</code></pre>"},{"location":"api/dataclasses/","title":"Pydantic Dataclasses","text":"<p>Provide an enhanced dataclass that performs validation.</p>"},{"location":"api/dataclasses/#pydantic.dataclasses.dataclass","title":"dataclass","text":"<pre><code>dataclass(\n    _cls: type[_T] | None = None,\n    *,\n    init: Literal[False] = False,\n    repr: bool = True,\n    eq: bool = True,\n    order: bool = False,\n    unsafe_hash: bool = False,\n    frozen: bool | None = None,\n    config: ConfigDict | type[object] | None = None,\n    validate_on_init: bool | None = None,\n    kw_only: bool = False,\n    slots: bool = False\n) -&gt; (\n    Callable[[type[_T]], type[PydanticDataclass]]\n    | type[PydanticDataclass]\n)\n</code></pre> <p>Usage Documentation</p> <p>Dataclasses</p> <p>A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python <code>dataclass</code>, but with added validation.</p> <p>This function should be used similarly to <code>dataclasses.dataclass</code>.</p> <p>Parameters:</p> Name Type Description Default <code>_cls</code> <code>type[_T] | None</code> <p>The target <code>dataclass</code>.</p> <code>None</code> <code>init</code> <code>Literal[False]</code> <p>Included for signature compatibility with <code>dataclasses.dataclass</code>, and is passed through to <code>dataclasses.dataclass</code> when appropriate. If specified, must be set to <code>False</code>, as pydantic inserts its own  <code>__init__</code> function.</p> <code>False</code> <code>repr</code> <code>bool</code> <p>A boolean indicating whether to include the field in the <code>__repr__</code> output.</p> <code>True</code> <code>eq</code> <code>bool</code> <p>Determines if a <code>__eq__</code> method should be generated for the class.</p> <code>True</code> <code>order</code> <code>bool</code> <p>Determines if comparison magic methods should be generated, such as <code>__lt__</code>, but not <code>__eq__</code>.</p> <code>False</code> <code>unsafe_hash</code> <code>bool</code> <p>Determines if a <code>__hash__</code> method should be included in the class, as in <code>dataclasses.dataclass</code>.</p> <code>False</code> <code>frozen</code> <code>bool | None</code> <p>Determines if the generated class should be a 'frozen' <code>dataclass</code>, which does not allow its attributes to be modified after it has been initialized. If not set, the value from the provided <code>config</code> argument will be used (and will default to <code>False</code> otherwise).</p> <code>None</code> <code>config</code> <code>ConfigDict | type[object] | None</code> <p>The Pydantic config to use for the <code>dataclass</code>.</p> <code>None</code> <code>validate_on_init</code> <code>bool | None</code> <p>A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses are validated on init.</p> <code>None</code> <code>kw_only</code> <code>bool</code> <p>Determines if <code>__init__</code> method parameters must be specified by keyword only. Defaults to <code>False</code>.</p> <code>False</code> <code>slots</code> <code>bool</code> <p>Determines if the generated class should be a 'slots' <code>dataclass</code>, which does not allow the addition of new attributes after instantiation.</p> <code>False</code> <p>Returns:</p> Type Description <code>Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]</code> <p>A decorator that accepts a class as its argument and returns a Pydantic <code>dataclass</code>.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>Raised if <code>init</code> is not <code>False</code> or <code>validate_on_init</code> is <code>False</code>.</p> Source code in <code>pydantic/dataclasses.py</code> <pre><code>@dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))\ndef dataclass(\n    _cls: type[_T] | None = None,\n    *,\n    init: Literal[False] = False,\n    repr: bool = True,\n    eq: bool = True,\n    order: bool = False,\n    unsafe_hash: bool = False,\n    frozen: bool | None = None,\n    config: ConfigDict | type[object] | None = None,\n    validate_on_init: bool | None = None,\n    kw_only: bool = False,\n    slots: bool = False,\n) -&gt; Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/dataclasses/\n\n    A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`,\n    but with added validation.\n\n    This function should be used similarly to `dataclasses.dataclass`.\n\n    Args:\n        _cls: The target `dataclass`.\n        init: Included for signature compatibility with `dataclasses.dataclass`, and is passed through to\n            `dataclasses.dataclass` when appropriate. If specified, must be set to `False`, as pydantic inserts its\n            own  `__init__` function.\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\n        eq: Determines if a `__eq__` method should be generated for the class.\n        order: Determines if comparison magic methods should be generated, such as `__lt__`, but not `__eq__`.\n        unsafe_hash: Determines if a `__hash__` method should be included in the class, as in `dataclasses.dataclass`.\n        frozen: Determines if the generated class should be a 'frozen' `dataclass`, which does not allow its\n            attributes to be modified after it has been initialized. If not set, the value from the provided `config` argument will be used (and will default to `False` otherwise).\n        config: The Pydantic config to use for the `dataclass`.\n        validate_on_init: A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses\n            are validated on init.\n        kw_only: Determines if `__init__` method parameters must be specified by keyword only. Defaults to `False`.\n        slots: Determines if the generated class should be a 'slots' `dataclass`, which does not allow the addition of\n            new attributes after instantiation.\n\n    Returns:\n        A decorator that accepts a class as its argument and returns a Pydantic `dataclass`.\n\n    Raises:\n        AssertionError: Raised if `init` is not `False` or `validate_on_init` is `False`.\n    \"\"\"\n    assert init is False, 'pydantic.dataclasses.dataclass only supports init=False'\n    assert validate_on_init is not False, 'validate_on_init=False is no longer supported'\n\n    if sys.version_info &gt;= (3, 10):\n        kwargs = {'kw_only': kw_only, 'slots': slots}\n    else:\n        kwargs = {}\n\n    def make_pydantic_fields_compatible(cls: type[Any]) -&gt; None:\n        \"\"\"Make sure that stdlib `dataclasses` understands `Field` kwargs like `kw_only`\n        To do that, we simply change\n          `x: int = pydantic.Field(..., kw_only=True)`\n        into\n          `x: int = dataclasses.field(default=pydantic.Field(..., kw_only=True), kw_only=True)`\n        \"\"\"\n        for annotation_cls in cls.__mro__:\n            # In Python &lt; 3.9, `__annotations__` might not be present if there are no fields.\n            # we therefore need to use `getattr` to avoid an `AttributeError`.\n            annotations = getattr(annotation_cls, '__annotations__', [])\n            for field_name in annotations:\n                field_value = getattr(cls, field_name, None)\n                # Process only if this is an instance of `FieldInfo`.\n                if not isinstance(field_value, FieldInfo):\n                    continue\n\n                # Initialize arguments for the standard `dataclasses.field`.\n                field_args: dict = {'default': field_value}\n\n                # Handle `kw_only` for Python 3.10+\n                if sys.version_info &gt;= (3, 10) and field_value.kw_only:\n                    field_args['kw_only'] = True\n\n                # Set `repr` attribute if it's explicitly specified to be not `True`.\n                if field_value.repr is not True:\n                    field_args['repr'] = field_value.repr\n\n                setattr(cls, field_name, dataclasses.field(**field_args))\n                # In Python 3.8, dataclasses checks cls.__dict__['__annotations__'] for annotations,\n                # so we must make sure it's initialized before we add to it.\n                if cls.__dict__.get('__annotations__') is None:\n                    cls.__annotations__ = {}\n                cls.__annotations__[field_name] = annotations[field_name]\n\n    def create_dataclass(cls: type[Any]) -&gt; type[PydanticDataclass]:\n        \"\"\"Create a Pydantic dataclass from a regular dataclass.\n\n        Args:\n            cls: The class to create the Pydantic dataclass from.\n\n        Returns:\n            A Pydantic dataclass.\n        \"\"\"\n        from ._internal._utils import is_model_class\n\n        if is_model_class(cls):\n            raise PydanticUserError(\n                f'Cannot create a Pydantic dataclass from {cls.__name__} as it is already a Pydantic model',\n                code='dataclass-on-model',\n            )\n\n        original_cls = cls\n\n        # if config is not explicitly provided, try to read it from the type\n        config_dict = config if config is not None else getattr(cls, '__pydantic_config__', None)\n        config_wrapper = _config.ConfigWrapper(config_dict)\n        decorators = _decorators.DecoratorInfos.build(cls)\n\n        # Keep track of the original __doc__ so that we can restore it after applying the dataclasses decorator\n        # Otherwise, classes with no __doc__ will have their signature added into the JSON schema description,\n        # since dataclasses.dataclass will set this as the __doc__\n        original_doc = cls.__doc__\n\n        if _pydantic_dataclasses.is_builtin_dataclass(cls):\n            # Don't preserve the docstring for vanilla dataclasses, as it may include the signature\n            # This matches v1 behavior, and there was an explicit test for it\n            original_doc = None\n\n            # We don't want to add validation to the existing std lib dataclass, so we will subclass it\n            #   If the class is generic, we need to make sure the subclass also inherits from Generic\n            #   with all the same parameters.\n            bases = (cls,)\n            if issubclass(cls, Generic):\n                generic_base = Generic[cls.__parameters__]  # type: ignore\n                bases = bases + (generic_base,)\n            cls = types.new_class(cls.__name__, bases)\n\n        make_pydantic_fields_compatible(cls)\n\n        # Respect frozen setting from dataclass constructor and fallback to config setting if not provided\n        if frozen is not None:\n            frozen_ = frozen\n            if config_wrapper.frozen:\n                # It's not recommended to define both, as the setting from the dataclass decorator will take priority.\n                warn(\n                    f'`frozen` is set via both the `dataclass` decorator and `config` for dataclass {cls.__name__!r}.'\n                    'This is not recommended. The `frozen` specification on `dataclass` will take priority.',\n                    category=UserWarning,\n                    stacklevel=2,\n                )\n        else:\n            frozen_ = config_wrapper.frozen or False\n\n        cls = dataclasses.dataclass(  # type: ignore[call-overload]\n            cls,\n            # the value of init here doesn't affect anything except that it makes it easier to generate a signature\n            init=True,\n            repr=repr,\n            eq=eq,\n            order=order,\n            unsafe_hash=unsafe_hash,\n            frozen=frozen_,\n            **kwargs,\n        )\n\n        cls.__pydantic_decorators__ = decorators  # type: ignore\n        cls.__doc__ = original_doc\n        cls.__module__ = original_cls.__module__\n        cls.__qualname__ = original_cls.__qualname__\n        cls.__pydantic_complete__ = False  # `complete_dataclass` will set it to `True` if successful.\n        _pydantic_dataclasses.complete_dataclass(cls, config_wrapper, raise_errors=False, types_namespace=None)\n        return cls\n\n    return create_dataclass if _cls is None else create_dataclass(_cls)\n</code></pre>"},{"location":"api/dataclasses/#pydantic.dataclasses.rebuild_dataclass","title":"rebuild_dataclass","text":"<pre><code>rebuild_dataclass(\n    cls: type[PydanticDataclass],\n    *,\n    force: bool = False,\n    raise_errors: bool = True,\n    _parent_namespace_depth: int = 2,\n    _types_namespace: dict[str, Any] | None = None\n) -&gt; bool | None\n</code></pre> <p>Try to rebuild the pydantic-core schema for the dataclass.</p> <p>This may be necessary when one of the annotations is a ForwardRef which could not be resolved during the initial attempt to build the schema, and automatic rebuilding fails.</p> <p>This is analogous to <code>BaseModel.model_rebuild</code>.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type[PydanticDataclass]</code> <p>The class to rebuild the pydantic-core schema for.</p> required <code>force</code> <code>bool</code> <p>Whether to force the rebuilding of the schema, defaults to <code>False</code>.</p> <code>False</code> <code>raise_errors</code> <code>bool</code> <p>Whether to raise errors, defaults to <code>True</code>.</p> <code>True</code> <code>_parent_namespace_depth</code> <code>int</code> <p>The depth level of the parent namespace, defaults to 2.</p> <code>2</code> <code>_types_namespace</code> <code>dict[str, Any] | None</code> <p>The types namespace, defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>bool | None</code> <p>Returns <code>None</code> if the schema is already \"complete\" and rebuilding was not required.</p> <code>bool | None</code> <p>If rebuilding was required, returns <code>True</code> if rebuilding was successful, otherwise <code>False</code>.</p> Source code in <code>pydantic/dataclasses.py</code> <pre><code>def rebuild_dataclass(\n    cls: type[PydanticDataclass],\n    *,\n    force: bool = False,\n    raise_errors: bool = True,\n    _parent_namespace_depth: int = 2,\n    _types_namespace: dict[str, Any] | None = None,\n) -&gt; bool | None:\n    \"\"\"Try to rebuild the pydantic-core schema for the dataclass.\n\n    This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n    the initial attempt to build the schema, and automatic rebuilding fails.\n\n    This is analogous to `BaseModel.model_rebuild`.\n\n    Args:\n        cls: The class to rebuild the pydantic-core schema for.\n        force: Whether to force the rebuilding of the schema, defaults to `False`.\n        raise_errors: Whether to raise errors, defaults to `True`.\n        _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n        _types_namespace: The types namespace, defaults to `None`.\n\n    Returns:\n        Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n        If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n    \"\"\"\n    if not force and cls.__pydantic_complete__:\n        return None\n    else:\n        if _types_namespace is not None:\n            types_namespace: dict[str, Any] | None = _types_namespace.copy()\n        else:\n            if _parent_namespace_depth &gt; 0:\n                frame_parent_ns = _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth) or {}\n                # Note: we may need to add something similar to cls.__pydantic_parent_namespace__ from BaseModel\n                #   here when implementing handling of recursive generics. See BaseModel.model_rebuild for reference.\n                types_namespace = frame_parent_ns\n            else:\n                types_namespace = {}\n\n            types_namespace = _typing_extra.merge_cls_and_parent_ns(cls, types_namespace)\n        return _pydantic_dataclasses.complete_dataclass(\n            cls,\n            _config.ConfigWrapper(cls.__pydantic_config__, check=False),\n            raise_errors=raise_errors,\n            types_namespace=types_namespace,\n        )\n</code></pre>"},{"location":"api/dataclasses/#pydantic.dataclasses.is_pydantic_dataclass","title":"is_pydantic_dataclass","text":"<pre><code>is_pydantic_dataclass(\n    class_: type[Any],\n) -&gt; TypeGuard[type[PydanticDataclass]]\n</code></pre> <p>Whether a class is a pydantic dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>class_</code> <code>type[Any]</code> <p>The class.</p> required <p>Returns:</p> Type Description <code>TypeGuard[type[PydanticDataclass]]</code> <p><code>True</code> if the class is a pydantic dataclass, <code>False</code> otherwise.</p> Source code in <code>pydantic/dataclasses.py</code> <pre><code>def is_pydantic_dataclass(class_: type[Any], /) -&gt; TypeGuard[type[PydanticDataclass]]:\n    \"\"\"Whether a class is a pydantic dataclass.\n\n    Args:\n        class_: The class.\n\n    Returns:\n        `True` if the class is a pydantic dataclass, `False` otherwise.\n    \"\"\"\n    try:\n        return '__pydantic_validator__' in class_.__dict__ and dataclasses.is_dataclass(class_)\n    except AttributeError:\n        return False\n</code></pre>"},{"location":"api/errors/","title":"Errors","text":"<p>Pydantic-specific errors.</p>"},{"location":"api/errors/#pydantic.errors.PydanticErrorMixin","title":"PydanticErrorMixin","text":"<pre><code>PydanticErrorMixin(\n    message: str, *, code: PydanticErrorCodes | None\n)\n</code></pre> <p>A mixin class for common functionality shared by all Pydantic-specific errors.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>A message describing the error.</p> <code>code</code> <p>An optional error code from PydanticErrorCodes enum.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str, *, code: PydanticErrorCodes | None) -&gt; None:\n    self.message = message\n    self.code = code\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticUserError","title":"PydanticUserError","text":"<pre><code>PydanticUserError(\n    message: str, *, code: PydanticErrorCodes | None\n)\n</code></pre> <p>               Bases: <code>PydanticErrorMixin</code>, <code>TypeError</code></p> <p>An error raised due to incorrect use of Pydantic.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str, *, code: PydanticErrorCodes | None) -&gt; None:\n    self.message = message\n    self.code = code\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticUndefinedAnnotation","title":"PydanticUndefinedAnnotation","text":"<pre><code>PydanticUndefinedAnnotation(name: str, message: str)\n</code></pre> <p>               Bases: <code>PydanticErrorMixin</code>, <code>NameError</code></p> <p>A subclass of <code>NameError</code> raised when handling undefined annotations during <code>CoreSchema</code> generation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <p>Name of the error.</p> <code>message</code> <p>Description of the error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, name: str, message: str) -&gt; None:\n    self.name = name\n    super().__init__(message=message, code='undefined-annotation')\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticUndefinedAnnotation.from_name_error","title":"from_name_error  <code>classmethod</code>","text":"<pre><code>from_name_error(name_error: NameError) -&gt; Self\n</code></pre> <p>Convert a <code>NameError</code> to a <code>PydanticUndefinedAnnotation</code> error.</p> <p>Parameters:</p> Name Type Description Default <code>name_error</code> <code>NameError</code> <p><code>NameError</code> to be converted.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>Converted <code>PydanticUndefinedAnnotation</code> error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>@classmethod\ndef from_name_error(cls, name_error: NameError) -&gt; Self:\n    \"\"\"Convert a `NameError` to a `PydanticUndefinedAnnotation` error.\n\n    Args:\n        name_error: `NameError` to be converted.\n\n    Returns:\n        Converted `PydanticUndefinedAnnotation` error.\n    \"\"\"\n    try:\n        name = name_error.name  # type: ignore  # python &gt; 3.10\n    except AttributeError:\n        name = re.search(r\".*'(.+?)'\", str(name_error)).group(1)  # type: ignore[union-attr]\n    return cls(name=name, message=str(name_error))\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticImportError","title":"PydanticImportError","text":"<pre><code>PydanticImportError(message: str)\n</code></pre> <p>               Bases: <code>PydanticErrorMixin</code>, <code>ImportError</code></p> <p>An error raised when an import fails due to module changes between V1 and V2.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Description of the error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str) -&gt; None:\n    super().__init__(message, code='import-error')\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticSchemaGenerationError","title":"PydanticSchemaGenerationError","text":"<pre><code>PydanticSchemaGenerationError(message: str)\n</code></pre> <p>               Bases: <code>PydanticUserError</code></p> <p>An error raised during failures to generate a <code>CoreSchema</code> for some type.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Description of the error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str) -&gt; None:\n    super().__init__(message, code='schema-for-unknown-type')\n</code></pre>"},{"location":"api/errors/#pydantic.errors.PydanticInvalidForJsonSchema","title":"PydanticInvalidForJsonSchema","text":"<pre><code>PydanticInvalidForJsonSchema(message: str)\n</code></pre> <p>               Bases: <code>PydanticUserError</code></p> <p>An error raised during failures to generate a JSON schema for some <code>CoreSchema</code>.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Description of the error.</p> Source code in <code>pydantic/errors.py</code> <pre><code>def __init__(self, message: str) -&gt; None:\n    super().__init__(message, code='invalid-for-json-schema')\n</code></pre>"},{"location":"api/experimental/","title":"Experimental","text":"<p>Experimental pipeline API functionality. Be careful with this API, it's subject to change.</p>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline","title":"_Pipeline  <code>dataclass</code>","text":"<pre><code>_Pipeline(_steps: tuple[_Step, ...])\n</code></pre> <p>               Bases: <code>Generic[_InT, _OutT]</code></p> <p>Abstract representation of a chain of validation, transformation, and parsing steps.</p>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.transform","title":"transform","text":"<pre><code>transform(\n    func: Callable[[_OutT], _NewOutT]\n) -&gt; _Pipeline[_InT, _NewOutT]\n</code></pre> <p>Transform the output of the previous step.</p> <p>If used as the first step in a pipeline, the type of the field is used. That is, the transformation is applied to after the value is parsed to the field's type.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def transform(\n    self,\n    func: Callable[[_OutT], _NewOutT],\n) -&gt; _Pipeline[_InT, _NewOutT]:\n    \"\"\"Transform the output of the previous step.\n\n    If used as the first step in a pipeline, the type of the field is used.\n    That is, the transformation is applied to after the value is parsed to the field's type.\n    \"\"\"\n    return _Pipeline[_InT, _NewOutT](self._steps + (_Transform(func),))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.validate_as","title":"validate_as","text":"<pre><code>validate_as(\n    tp: type[_NewOutT] | EllipsisType,\n    *,\n    strict: bool = False\n) -&gt; _Pipeline[_InT, Any]\n</code></pre> <p>Validate / parse the input into a new type.</p> <p>If no type is provided, the type of the field is used.</p> <p>Types are parsed in Pydantic's <code>lax</code> mode by default, but you can enable <code>strict</code> mode by passing <code>strict=True</code>.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def validate_as(self, tp: type[_NewOutT] | EllipsisType, *, strict: bool = False) -&gt; _Pipeline[_InT, Any]:  # type: ignore\n    \"\"\"Validate / parse the input into a new type.\n\n    If no type is provided, the type of the field is used.\n\n    Types are parsed in Pydantic's `lax` mode by default,\n    but you can enable `strict` mode by passing `strict=True`.\n    \"\"\"\n    if isinstance(tp, EllipsisType):\n        return _Pipeline[_InT, Any](self._steps + (_ValidateAs(_FieldTypeMarker, strict=strict),))\n    return _Pipeline[_InT, _NewOutT](self._steps + (_ValidateAs(tp, strict=strict),))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.validate_as_deferred","title":"validate_as_deferred","text":"<pre><code>validate_as_deferred(\n    func: Callable[[], type[_NewOutT]]\n) -&gt; _Pipeline[_InT, _NewOutT]\n</code></pre> <p>Parse the input into a new type, deferring resolution of the type until the current class is fully defined.</p> <p>This is useful when you need to reference the class in it's own type annotations.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def validate_as_deferred(self, func: Callable[[], type[_NewOutT]]) -&gt; _Pipeline[_InT, _NewOutT]:\n    \"\"\"Parse the input into a new type, deferring resolution of the type until the current class\n    is fully defined.\n\n    This is useful when you need to reference the class in it's own type annotations.\n    \"\"\"\n    return _Pipeline[_InT, _NewOutT](self._steps + (_ValidateAsDefer(func),))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.constrain","title":"constrain","text":"<pre><code>constrain(constraint: _ConstraintAnnotation) -&gt; Any\n</code></pre> <p>Constrain a value to meet a certain condition.</p> <p>We support most conditions from <code>annotated_types</code>, as well as regular expressions.</p> <p>Most of the time you'll be calling a shortcut method like <code>gt</code>, <code>lt</code>, <code>len</code>, etc so you don't need to call this directly.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def constrain(self, constraint: _ConstraintAnnotation) -&gt; Any:\n    \"\"\"Constrain a value to meet a certain condition.\n\n    We support most conditions from `annotated_types`, as well as regular expressions.\n\n    Most of the time you'll be calling a shortcut method like `gt`, `lt`, `len`, etc\n    so you don't need to call this directly.\n    \"\"\"\n    return _Pipeline[_InT, _OutT](self._steps + (_Constraint(constraint),))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.predicate","title":"predicate","text":"<pre><code>predicate(\n    func: Callable[[_NewOutT], bool]\n) -&gt; _Pipeline[_InT, _NewOutT]\n</code></pre> <p>Constrain a value to meet a certain predicate.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def predicate(self: _Pipeline[_InT, _NewOutT], func: Callable[[_NewOutT], bool]) -&gt; _Pipeline[_InT, _NewOutT]:\n    \"\"\"Constrain a value to meet a certain predicate.\"\"\"\n    return self.constrain(annotated_types.Predicate(func))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.gt","title":"gt","text":"<pre><code>gt(gt: _NewOutGt) -&gt; _Pipeline[_InT, _NewOutGt]\n</code></pre> <p>Constrain a value to be greater than a certain value.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def gt(self: _Pipeline[_InT, _NewOutGt], gt: _NewOutGt) -&gt; _Pipeline[_InT, _NewOutGt]:\n    \"\"\"Constrain a value to be greater than a certain value.\"\"\"\n    return self.constrain(annotated_types.Gt(gt))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.lt","title":"lt","text":"<pre><code>lt(lt: _NewOutLt) -&gt; _Pipeline[_InT, _NewOutLt]\n</code></pre> <p>Constrain a value to be less than a certain value.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def lt(self: _Pipeline[_InT, _NewOutLt], lt: _NewOutLt) -&gt; _Pipeline[_InT, _NewOutLt]:\n    \"\"\"Constrain a value to be less than a certain value.\"\"\"\n    return self.constrain(annotated_types.Lt(lt))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.ge","title":"ge","text":"<pre><code>ge(ge: _NewOutGe) -&gt; _Pipeline[_InT, _NewOutGe]\n</code></pre> <p>Constrain a value to be greater than or equal to a certain value.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def ge(self: _Pipeline[_InT, _NewOutGe], ge: _NewOutGe) -&gt; _Pipeline[_InT, _NewOutGe]:\n    \"\"\"Constrain a value to be greater than or equal to a certain value.\"\"\"\n    return self.constrain(annotated_types.Ge(ge))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.le","title":"le","text":"<pre><code>le(le: _NewOutLe) -&gt; _Pipeline[_InT, _NewOutLe]\n</code></pre> <p>Constrain a value to be less than or equal to a certain value.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def le(self: _Pipeline[_InT, _NewOutLe], le: _NewOutLe) -&gt; _Pipeline[_InT, _NewOutLe]:\n    \"\"\"Constrain a value to be less than or equal to a certain value.\"\"\"\n    return self.constrain(annotated_types.Le(le))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.len","title":"len","text":"<pre><code>len(\n    min_len: int, max_len: int | None = None\n) -&gt; _Pipeline[_InT, _NewOutLen]\n</code></pre> <p>Constrain a value to have a certain length.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def len(self: _Pipeline[_InT, _NewOutLen], min_len: int, max_len: int | None = None) -&gt; _Pipeline[_InT, _NewOutLen]:\n    \"\"\"Constrain a value to have a certain length.\"\"\"\n    return self.constrain(annotated_types.Len(min_len, max_len))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.multiple_of","title":"multiple_of","text":"<pre><code>multiple_of(multiple_of: Any) -&gt; _Pipeline[_InT, Any]\n</code></pre> <p>Constrain a value to be a multiple of a certain number.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def multiple_of(self: _Pipeline[_InT, Any], multiple_of: Any) -&gt; _Pipeline[_InT, Any]:\n    \"\"\"Constrain a value to be a multiple of a certain number.\"\"\"\n    return self.constrain(annotated_types.MultipleOf(multiple_of))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.eq","title":"eq","text":"<pre><code>eq(value: _OutT) -&gt; _Pipeline[_InT, _OutT]\n</code></pre> <p>Constrain a value to be equal to a certain value.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def eq(self: _Pipeline[_InT, _OutT], value: _OutT) -&gt; _Pipeline[_InT, _OutT]:\n    \"\"\"Constrain a value to be equal to a certain value.\"\"\"\n    return self.constrain(_Eq(value))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.not_eq","title":"not_eq","text":"<pre><code>not_eq(value: _OutT) -&gt; _Pipeline[_InT, _OutT]\n</code></pre> <p>Constrain a value to not be equal to a certain value.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def not_eq(self: _Pipeline[_InT, _OutT], value: _OutT) -&gt; _Pipeline[_InT, _OutT]:\n    \"\"\"Constrain a value to not be equal to a certain value.\"\"\"\n    return self.constrain(_NotEq(value))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.in_","title":"in_","text":"<pre><code>in_(values: Container[_OutT]) -&gt; _Pipeline[_InT, _OutT]\n</code></pre> <p>Constrain a value to be in a certain set.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def in_(self: _Pipeline[_InT, _OutT], values: Container[_OutT]) -&gt; _Pipeline[_InT, _OutT]:\n    \"\"\"Constrain a value to be in a certain set.\"\"\"\n    return self.constrain(_In(values))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.not_in","title":"not_in","text":"<pre><code>not_in(values: Container[_OutT]) -&gt; _Pipeline[_InT, _OutT]\n</code></pre> <p>Constrain a value to not be in a certain set.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def not_in(self: _Pipeline[_InT, _OutT], values: Container[_OutT]) -&gt; _Pipeline[_InT, _OutT]:\n    \"\"\"Constrain a value to not be in a certain set.\"\"\"\n    return self.constrain(_NotIn(values))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.otherwise","title":"otherwise","text":"<pre><code>otherwise(\n    other: _Pipeline[_OtherIn, _OtherOut]\n) -&gt; _Pipeline[_InT | _OtherIn, _OutT | _OtherOut]\n</code></pre> <p>Combine two validation chains, returning the result of the first chain if it succeeds, and the second chain if it fails.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def otherwise(self, other: _Pipeline[_OtherIn, _OtherOut]) -&gt; _Pipeline[_InT | _OtherIn, _OutT | _OtherOut]:\n    \"\"\"Combine two validation chains, returning the result of the first chain if it succeeds, and the second chain if it fails.\"\"\"\n    return _Pipeline((_PipelineOr(self, other),))\n</code></pre>"},{"location":"api/experimental/#pydantic.experimental.pipeline._Pipeline.then","title":"then","text":"<pre><code>then(\n    other: _Pipeline[_OutT, _OtherOut]\n) -&gt; _Pipeline[_InT, _OtherOut]\n</code></pre> <p>Pipe the result of one validation chain into another.</p> Source code in <code>pydantic/experimental/pipeline.py</code> <pre><code>def then(self, other: _Pipeline[_OutT, _OtherOut]) -&gt; _Pipeline[_InT, _OtherOut]:\n    \"\"\"Pipe the result of one validation chain into another.\"\"\"\n    return _Pipeline((_PipelineAnd(self, other),))\n</code></pre>"},{"location":"api/fields/","title":"Fields","text":"<p>Defining fields on models.</p>"},{"location":"api/fields/#pydantic.fields.Field","title":"Field","text":"<pre><code>Field(\n    default: Any = PydanticUndefined,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    alias: str | None = _Unset,\n    alias_priority: int | None = _Unset,\n    validation_alias: (\n        str | AliasPath | AliasChoices | None\n    ) = _Unset,\n    serialization_alias: str | None = _Unset,\n    title: str | None = _Unset,\n    field_title_generator: (\n        Callable[[str, FieldInfo], str] | None\n    ) = _Unset,\n    description: str | None = _Unset,\n    examples: list[Any] | None = _Unset,\n    exclude: bool | None = _Unset,\n    discriminator: str | Discriminator | None = _Unset,\n    deprecated: Deprecated | str | bool | None = _Unset,\n    json_schema_extra: (\n        JsonDict | Callable[[JsonDict], None] | None\n    ) = _Unset,\n    frozen: bool | None = _Unset,\n    validate_default: bool | None = _Unset,\n    repr: bool = _Unset,\n    init: bool | None = _Unset,\n    init_var: bool | None = _Unset,\n    kw_only: bool | None = _Unset,\n    pattern: str | Pattern[str] | None = _Unset,\n    strict: bool | None = _Unset,\n    coerce_numbers_to_str: bool | None = _Unset,\n    gt: SupportsGt | None = _Unset,\n    ge: SupportsGe | None = _Unset,\n    lt: SupportsLt | None = _Unset,\n    le: SupportsLe | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    min_length: int | None = _Unset,\n    max_length: int | None = _Unset,\n    union_mode: Literal[\"smart\", \"left_to_right\"] = _Unset,\n    fail_fast: bool | None = _Unset,\n    **extra: Unpack[_EmptyKwargs]\n) -&gt; Any\n</code></pre> <p>Usage Documentation</p> <p>Fields</p> <p>Create a field for objects that can be configured.</p> <p>Used to provide extra information about a field, either for the model schema or complex validation. Some arguments apply only to number fields (<code>int</code>, <code>float</code>, <code>Decimal</code>) and some apply only to <code>str</code>.</p> Note <ul> <li>Any <code>_Unset</code> objects will be replaced by the corresponding value defined in the <code>_DefaultValues</code> dictionary. If a key for the <code>_Unset</code> object is not found in the <code>_DefaultValues</code> dictionary, it will default to <code>None</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>Default value if the field is not set.</p> <code>PydanticUndefined</code> <code>default_factory</code> <code>Callable[[], Any] | None</code> <p>A callable to generate the default value, such as :func:<code>~datetime.utcnow</code>.</p> <code>_Unset</code> <code>alias</code> <code>str | None</code> <p>The name to use for the attribute when validating or serializing by alias. This is often used for things like converting between snake and camel case.</p> <code>_Unset</code> <code>alias_priority</code> <code>int | None</code> <p>Priority of the alias. This affects whether an alias generator is used.</p> <code>_Unset</code> <code>validation_alias</code> <code>str | AliasPath | AliasChoices | None</code> <p>Like <code>alias</code>, but only affects validation, not serialization.</p> <code>_Unset</code> <code>serialization_alias</code> <code>str | None</code> <p>Like <code>alias</code>, but only affects serialization, not validation.</p> <code>_Unset</code> <code>title</code> <code>str | None</code> <p>Human-readable title.</p> <code>_Unset</code> <code>field_title_generator</code> <code>Callable[[str, FieldInfo], str] | None</code> <p>A callable that takes a field name and returns title for it.</p> <code>_Unset</code> <code>description</code> <code>str | None</code> <p>Human-readable description.</p> <code>_Unset</code> <code>examples</code> <code>list[Any] | None</code> <p>Example values for this field.</p> <code>_Unset</code> <code>exclude</code> <code>bool | None</code> <p>Whether to exclude the field from the model serialization.</p> <code>_Unset</code> <code>discriminator</code> <code>str | Discriminator | None</code> <p>Field name or Discriminator for discriminating the type in a tagged union.</p> <code>_Unset</code> <code>deprecated</code> <code>Deprecated | str | bool | None</code> <p>A deprecation message, an instance of <code>warnings.deprecated</code> or the <code>typing_extensions.deprecated</code> backport, or a boolean. If <code>True</code>, a default deprecation message will be emitted when accessing the field.</p> <code>_Unset</code> <code>json_schema_extra</code> <code>JsonDict | Callable[[JsonDict], None] | None</code> <p>A dict or callable to provide extra JSON schema properties.</p> <code>_Unset</code> <code>frozen</code> <code>bool | None</code> <p>Whether the field is frozen. If true, attempts to change the value on an instance will raise an error.</p> <code>_Unset</code> <code>validate_default</code> <code>bool | None</code> <p>If <code>True</code>, apply validation to the default value every time you create an instance. Otherwise, for performance reasons, the default value of the field is trusted and not validated.</p> <code>_Unset</code> <code>repr</code> <code>bool</code> <p>A boolean indicating whether to include the field in the <code>__repr__</code> output.</p> <code>_Unset</code> <code>init</code> <code>bool | None</code> <p>Whether the field should be included in the constructor of the dataclass. (Only applies to dataclasses.)</p> <code>_Unset</code> <code>init_var</code> <code>bool | None</code> <p>Whether the field should only be included in the constructor of the dataclass. (Only applies to dataclasses.)</p> <code>_Unset</code> <code>kw_only</code> <code>bool | None</code> <p>Whether the field should be a keyword-only argument in the constructor of the dataclass. (Only applies to dataclasses.)</p> <code>_Unset</code> <code>coerce_numbers_to_str</code> <code>bool | None</code> <p>Whether to enable coercion of any <code>Number</code> type to <code>str</code> (not applicable in <code>strict</code> mode).</p> <code>_Unset</code> <code>strict</code> <code>bool | None</code> <p>If <code>True</code>, strict validation is applied to the field. See Strict Mode for details.</p> <code>_Unset</code> <code>gt</code> <code>SupportsGt | None</code> <p>Greater than. If set, value must be greater than this. Only applicable to numbers.</p> <code>_Unset</code> <code>ge</code> <code>SupportsGe | None</code> <p>Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.</p> <code>_Unset</code> <code>lt</code> <code>SupportsLt | None</code> <p>Less than. If set, value must be less than this. Only applicable to numbers.</p> <code>_Unset</code> <code>le</code> <code>SupportsLe | None</code> <p>Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.</p> <code>_Unset</code> <code>multiple_of</code> <code>float | None</code> <p>Value must be a multiple of this. Only applicable to numbers.</p> <code>_Unset</code> <code>min_length</code> <code>int | None</code> <p>Minimum length for iterables.</p> <code>_Unset</code> <code>max_length</code> <code>int | None</code> <p>Maximum length for iterables.</p> <code>_Unset</code> <code>pattern</code> <code>str | Pattern[str] | None</code> <p>Pattern for strings (a regular expression).</p> <code>_Unset</code> <code>allow_inf_nan</code> <code>bool | None</code> <p>Allow <code>inf</code>, <code>-inf</code>, <code>nan</code>. Only applicable to numbers.</p> <code>_Unset</code> <code>max_digits</code> <code>int | None</code> <p>Maximum number of allow digits for strings.</p> <code>_Unset</code> <code>decimal_places</code> <code>int | None</code> <p>Maximum number of decimal places allowed for numbers.</p> <code>_Unset</code> <code>union_mode</code> <code>Literal['smart', 'left_to_right']</code> <p>The strategy to apply when validating a union. Can be <code>smart</code> (the default), or <code>left_to_right</code>. See Union Mode for details.</p> <code>_Unset</code> <code>fail_fast</code> <code>bool | None</code> <p>If <code>True</code>, validation will stop on the first error. If <code>False</code>, all validation errors will be collected. This option can be applied only to iterable types (list, tuple, set, and frozenset).</p> <code>_Unset</code> <code>extra</code> <code>Unpack[_EmptyKwargs]</code> <p>(Deprecated) Extra fields that will be included in the JSON schema.</p> <p>Warning</p> <p>The <code>extra</code> kwargs is deprecated. Use <code>json_schema_extra</code> instead.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>A new <code>FieldInfo</code>. The return annotation is <code>Any</code> so <code>Field</code> can be used on type-annotated fields without causing a type error.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def Field(  # noqa: C901\n    default: Any = PydanticUndefined,\n    *,\n    default_factory: typing.Callable[[], Any] | None = _Unset,\n    alias: str | None = _Unset,\n    alias_priority: int | None = _Unset,\n    validation_alias: str | AliasPath | AliasChoices | None = _Unset,\n    serialization_alias: str | None = _Unset,\n    title: str | None = _Unset,\n    field_title_generator: typing_extensions.Callable[[str, FieldInfo], str] | None = _Unset,\n    description: str | None = _Unset,\n    examples: list[Any] | None = _Unset,\n    exclude: bool | None = _Unset,\n    discriminator: str | types.Discriminator | None = _Unset,\n    deprecated: Deprecated | str | bool | None = _Unset,\n    json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None = _Unset,\n    frozen: bool | None = _Unset,\n    validate_default: bool | None = _Unset,\n    repr: bool = _Unset,\n    init: bool | None = _Unset,\n    init_var: bool | None = _Unset,\n    kw_only: bool | None = _Unset,\n    pattern: str | typing.Pattern[str] | None = _Unset,\n    strict: bool | None = _Unset,\n    coerce_numbers_to_str: bool | None = _Unset,\n    gt: annotated_types.SupportsGt | None = _Unset,\n    ge: annotated_types.SupportsGe | None = _Unset,\n    lt: annotated_types.SupportsLt | None = _Unset,\n    le: annotated_types.SupportsLe | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    min_length: int | None = _Unset,\n    max_length: int | None = _Unset,\n    union_mode: Literal['smart', 'left_to_right'] = _Unset,\n    fail_fast: bool | None = _Unset,\n    **extra: Unpack[_EmptyKwargs],\n) -&gt; Any:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/fields\n\n    Create a field for objects that can be configured.\n\n    Used to provide extra information about a field, either for the model schema or complex validation. Some arguments\n    apply only to number fields (`int`, `float`, `Decimal`) and some apply only to `str`.\n\n    Note:\n        - Any `_Unset` objects will be replaced by the corresponding value defined in the `_DefaultValues` dictionary. If a key for the `_Unset` object is not found in the `_DefaultValues` dictionary, it will default to `None`\n\n    Args:\n        default: Default value if the field is not set.\n        default_factory: A callable to generate the default value, such as :func:`~datetime.utcnow`.\n        alias: The name to use for the attribute when validating or serializing by alias.\n            This is often used for things like converting between snake and camel case.\n        alias_priority: Priority of the alias. This affects whether an alias generator is used.\n        validation_alias: Like `alias`, but only affects validation, not serialization.\n        serialization_alias: Like `alias`, but only affects serialization, not validation.\n        title: Human-readable title.\n        field_title_generator: A callable that takes a field name and returns title for it.\n        description: Human-readable description.\n        examples: Example values for this field.\n        exclude: Whether to exclude the field from the model serialization.\n        discriminator: Field name or Discriminator for discriminating the type in a tagged union.\n        deprecated: A deprecation message, an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport,\n            or a boolean. If `True`, a default deprecation message will be emitted when accessing the field.\n        json_schema_extra: A dict or callable to provide extra JSON schema properties.\n        frozen: Whether the field is frozen. If true, attempts to change the value on an instance will raise an error.\n        validate_default: If `True`, apply validation to the default value every time you create an instance.\n            Otherwise, for performance reasons, the default value of the field is trusted and not validated.\n        repr: A boolean indicating whether to include the field in the `__repr__` output.\n        init: Whether the field should be included in the constructor of the dataclass.\n            (Only applies to dataclasses.)\n        init_var: Whether the field should _only_ be included in the constructor of the dataclass.\n            (Only applies to dataclasses.)\n        kw_only: Whether the field should be a keyword-only argument in the constructor of the dataclass.\n            (Only applies to dataclasses.)\n        coerce_numbers_to_str: Whether to enable coercion of any `Number` type to `str` (not applicable in `strict` mode).\n        strict: If `True`, strict validation is applied to the field.\n            See [Strict Mode](../concepts/strict_mode.md) for details.\n        gt: Greater than. If set, value must be greater than this. Only applicable to numbers.\n        ge: Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers.\n        lt: Less than. If set, value must be less than this. Only applicable to numbers.\n        le: Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers.\n        multiple_of: Value must be a multiple of this. Only applicable to numbers.\n        min_length: Minimum length for iterables.\n        max_length: Maximum length for iterables.\n        pattern: Pattern for strings (a regular expression).\n        allow_inf_nan: Allow `inf`, `-inf`, `nan`. Only applicable to numbers.\n        max_digits: Maximum number of allow digits for strings.\n        decimal_places: Maximum number of decimal places allowed for numbers.\n        union_mode: The strategy to apply when validating a union. Can be `smart` (the default), or `left_to_right`.\n            See [Union Mode](../concepts/unions.md#union-modes) for details.\n        fail_fast: If `True`, validation will stop on the first error. If `False`, all validation errors will be collected.\n            This option can be applied only to iterable types (list, tuple, set, and frozenset).\n        extra: (Deprecated) Extra fields that will be included in the JSON schema.\n\n            !!! warning Deprecated\n                The `extra` kwargs is deprecated. Use `json_schema_extra` instead.\n\n    Returns:\n        A new [`FieldInfo`][pydantic.fields.FieldInfo]. The return annotation is `Any` so `Field` can be used on\n            type-annotated fields without causing a type error.\n    \"\"\"\n    # Check deprecated and removed params from V1. This logic should eventually be removed.\n    const = extra.pop('const', None)  # type: ignore\n    if const is not None:\n        raise PydanticUserError('`const` is removed, use `Literal` instead', code='removed-kwargs')\n\n    min_items = extra.pop('min_items', None)  # type: ignore\n    if min_items is not None:\n        warn('`min_items` is deprecated and will be removed, use `min_length` instead', DeprecationWarning)\n        if min_length in (None, _Unset):\n            min_length = min_items  # type: ignore\n\n    max_items = extra.pop('max_items', None)  # type: ignore\n    if max_items is not None:\n        warn('`max_items` is deprecated and will be removed, use `max_length` instead', DeprecationWarning)\n        if max_length in (None, _Unset):\n            max_length = max_items  # type: ignore\n\n    unique_items = extra.pop('unique_items', None)  # type: ignore\n    if unique_items is not None:\n        raise PydanticUserError(\n            (\n                '`unique_items` is removed, use `Set` instead'\n                '(this feature is discussed in https://github.com/pydantic/pydantic-core/issues/296)'\n            ),\n            code='removed-kwargs',\n        )\n\n    allow_mutation = extra.pop('allow_mutation', None)  # type: ignore\n    if allow_mutation is not None:\n        warn('`allow_mutation` is deprecated and will be removed. use `frozen` instead', DeprecationWarning)\n        if allow_mutation is False:\n            frozen = True\n\n    regex = extra.pop('regex', None)  # type: ignore\n    if regex is not None:\n        raise PydanticUserError('`regex` is removed. use `pattern` instead', code='removed-kwargs')\n\n    if extra:\n        warn(\n            'Using extra keyword arguments on `Field` is deprecated and will be removed.'\n            ' Use `json_schema_extra` instead.'\n            f' (Extra keys: {\", \".join(k.__repr__() for k in extra.keys())})',\n            DeprecationWarning,\n        )\n        if not json_schema_extra or json_schema_extra is _Unset:\n            json_schema_extra = extra  # type: ignore\n\n    if (\n        validation_alias\n        and validation_alias is not _Unset\n        and not isinstance(validation_alias, (str, AliasChoices, AliasPath))\n    ):\n        raise TypeError('Invalid `validation_alias` type. it should be `str`, `AliasChoices`, or `AliasPath`')\n\n    if serialization_alias in (_Unset, None) and isinstance(alias, str):\n        serialization_alias = alias\n\n    if validation_alias in (_Unset, None):\n        validation_alias = alias\n\n    include = extra.pop('include', None)  # type: ignore\n    if include is not None:\n        warn('`include` is deprecated and does nothing. It will be removed, use `exclude` instead', DeprecationWarning)\n\n    return FieldInfo.from_field(\n        default,\n        default_factory=default_factory,\n        alias=alias,\n        alias_priority=alias_priority,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        title=title,\n        field_title_generator=field_title_generator,\n        description=description,\n        examples=examples,\n        exclude=exclude,\n        discriminator=discriminator,\n        deprecated=deprecated,\n        json_schema_extra=json_schema_extra,\n        frozen=frozen,\n        pattern=pattern,\n        validate_default=validate_default,\n        repr=repr,\n        init=init,\n        init_var=init_var,\n        kw_only=kw_only,\n        coerce_numbers_to_str=coerce_numbers_to_str,\n        strict=strict,\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        multiple_of=multiple_of,\n        min_length=min_length,\n        max_length=max_length,\n        allow_inf_nan=allow_inf_nan,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n        union_mode=union_mode,\n        fail_fast=fail_fast,\n    )\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo","title":"FieldInfo","text":"<pre><code>FieldInfo(**kwargs: Unpack[_FieldInfoInputs])\n</code></pre> <p>               Bases: <code>Representation</code></p> <p>This class holds information about a field.</p> <p><code>FieldInfo</code> is used for any field definition regardless of whether the <code>Field()</code> function is explicitly used.</p> <p>Warning</p> <p>You generally shouldn't be creating <code>FieldInfo</code> directly, you'll only need to use it when accessing <code>BaseModel</code> <code>.model_fields</code> internals.</p> <p>Attributes:</p> Name Type Description <code>annotation</code> <code>type[Any] | None</code> <p>The type annotation of the field.</p> <code>default</code> <code>Any</code> <p>The default value of the field.</p> <code>default_factory</code> <code>Callable[[], Any] | None</code> <p>The factory function used to construct the default for the field.</p> <code>alias</code> <code>str | None</code> <p>The alias name of the field.</p> <code>alias_priority</code> <code>int | None</code> <p>The priority of the field's alias.</p> <code>validation_alias</code> <code>str | AliasPath | AliasChoices | None</code> <p>The validation alias of the field.</p> <code>serialization_alias</code> <code>str | None</code> <p>The serialization alias of the field.</p> <code>title</code> <code>str | None</code> <p>The title of the field.</p> <code>field_title_generator</code> <code>Callable[[str, FieldInfo], str] | None</code> <p>A callable that takes a field name and returns title for it.</p> <code>description</code> <code>str | None</code> <p>The description of the field.</p> <code>examples</code> <code>list[Any] | None</code> <p>List of examples of the field.</p> <code>exclude</code> <code>bool | None</code> <p>Whether to exclude the field from the model serialization.</p> <code>discriminator</code> <code>str | Discriminator | None</code> <p>Field name or Discriminator for discriminating the type in a tagged union.</p> <code>deprecated</code> <code>Deprecated | str | bool | None</code> <p>A deprecation message, an instance of <code>warnings.deprecated</code> or the <code>typing_extensions.deprecated</code> backport, or a boolean. If <code>True</code>, a default deprecation message will be emitted when accessing the field.</p> <code>json_schema_extra</code> <code>JsonDict | Callable[[JsonDict], None] | None</code> <p>A dict or callable to provide extra JSON schema properties.</p> <code>frozen</code> <code>bool | None</code> <p>Whether the field is frozen.</p> <code>validate_default</code> <code>bool | None</code> <p>Whether to validate the default value of the field.</p> <code>repr</code> <code>bool</code> <p>Whether to include the field in representation of the model.</p> <code>init</code> <code>bool | None</code> <p>Whether the field should be included in the constructor of the dataclass.</p> <code>init_var</code> <code>bool | None</code> <p>Whether the field should only be included in the constructor of the dataclass, and not stored.</p> <code>kw_only</code> <code>bool | None</code> <p>Whether the field should be a keyword-only argument in the constructor of the dataclass.</p> <code>metadata</code> <code>list[Any]</code> <p>List of metadata constraints.</p> <p>See the signature of <code>pydantic.fields.Field</code> for more details about the expected arguments.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def __init__(self, **kwargs: Unpack[_FieldInfoInputs]) -&gt; None:\n    \"\"\"This class should generally not be initialized directly; instead, use the `pydantic.fields.Field` function\n    or one of the constructor classmethods.\n\n    See the signature of `pydantic.fields.Field` for more details about the expected arguments.\n    \"\"\"\n    self._attributes_set = {k: v for k, v in kwargs.items() if v is not _Unset}\n    kwargs = {k: _DefaultValues.get(k) if v is _Unset else v for k, v in kwargs.items()}  # type: ignore\n    self.annotation, annotation_metadata = self._extract_metadata(kwargs.get('annotation'))\n\n    default = kwargs.pop('default', PydanticUndefined)\n    if default is Ellipsis:\n        self.default = PydanticUndefined\n    else:\n        self.default = default\n\n    self.default_factory = kwargs.pop('default_factory', None)\n\n    if self.default is not PydanticUndefined and self.default_factory is not None:\n        raise TypeError('cannot specify both default and default_factory')\n\n    self.alias = kwargs.pop('alias', None)\n    self.validation_alias = kwargs.pop('validation_alias', None)\n    self.serialization_alias = kwargs.pop('serialization_alias', None)\n    alias_is_set = any(alias is not None for alias in (self.alias, self.validation_alias, self.serialization_alias))\n    self.alias_priority = kwargs.pop('alias_priority', None) or 2 if alias_is_set else None\n    self.title = kwargs.pop('title', None)\n    self.field_title_generator = kwargs.pop('field_title_generator', None)\n    self.description = kwargs.pop('description', None)\n    self.examples = kwargs.pop('examples', None)\n    self.exclude = kwargs.pop('exclude', None)\n    self.discriminator = kwargs.pop('discriminator', None)\n    # For compatibility with FastAPI&lt;=0.110.0, we preserve the existing value if it is not overridden\n    self.deprecated = kwargs.pop('deprecated', getattr(self, 'deprecated', None))\n    self.repr = kwargs.pop('repr', True)\n    self.json_schema_extra = kwargs.pop('json_schema_extra', None)\n    self.validate_default = kwargs.pop('validate_default', None)\n    self.frozen = kwargs.pop('frozen', None)\n    # currently only used on dataclasses\n    self.init = kwargs.pop('init', None)\n    self.init_var = kwargs.pop('init_var', None)\n    self.kw_only = kwargs.pop('kw_only', None)\n\n    self.metadata = self._collect_metadata(kwargs) + annotation_metadata  # type: ignore\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.from_field","title":"from_field  <code>staticmethod</code>","text":"<pre><code>from_field(\n    default: Any = PydanticUndefined,\n    **kwargs: Unpack[_FromFieldInfoInputs]\n) -&gt; FieldInfo\n</code></pre> <p>Create a new <code>FieldInfo</code> object with the <code>Field</code> function.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>The default value for the field. Defaults to Undefined.</p> <code>PydanticUndefined</code> <code>**kwargs</code> <code>Unpack[_FromFieldInfoInputs]</code> <p>Additional arguments dictionary.</p> <code>{}</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If 'annotation' is passed as a keyword argument.</p> <p>Returns:</p> Type Description <code>FieldInfo</code> <p>A new FieldInfo object with the given parameters.</p> Example <p>This is how you can create a field with default value like this:</p> <pre><code>import pydantic\n\nclass MyModel(pydantic.BaseModel):\n    foo: int = pydantic.Field(4)\n</code></pre> Source code in <code>pydantic/fields.py</code> <pre><code>@staticmethod\ndef from_field(default: Any = PydanticUndefined, **kwargs: Unpack[_FromFieldInfoInputs]) -&gt; FieldInfo:\n    \"\"\"Create a new `FieldInfo` object with the `Field` function.\n\n    Args:\n        default: The default value for the field. Defaults to Undefined.\n        **kwargs: Additional arguments dictionary.\n\n    Raises:\n        TypeError: If 'annotation' is passed as a keyword argument.\n\n    Returns:\n        A new FieldInfo object with the given parameters.\n\n    Example:\n        This is how you can create a field with default value like this:\n\n        ```python\n        import pydantic\n\n        class MyModel(pydantic.BaseModel):\n            foo: int = pydantic.Field(4)\n        ```\n    \"\"\"\n    if 'annotation' in kwargs:\n        raise TypeError('\"annotation\" is not permitted as a Field keyword argument')\n    return FieldInfo(default=default, **kwargs)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.from_annotation","title":"from_annotation  <code>staticmethod</code>","text":"<pre><code>from_annotation(annotation: type[Any]) -&gt; FieldInfo\n</code></pre> <p>Creates a <code>FieldInfo</code> instance from a bare annotation.</p> <p>This function is used internally to create a <code>FieldInfo</code> from a bare annotation like this:</p> <pre><code>import pydantic\n\nclass MyModel(pydantic.BaseModel):\n    foo: int  # &lt;-- like this\n</code></pre> <p>We also account for the case where the annotation can be an instance of <code>Annotated</code> and where one of the (not first) arguments in <code>Annotated</code> is an instance of <code>FieldInfo</code>, e.g.:</p> <pre><code>import annotated_types\nfrom typing_extensions import Annotated\n\nimport pydantic\n\nclass MyModel(pydantic.BaseModel):\n    foo: Annotated[int, annotated_types.Gt(42)]\n    bar: Annotated[int, pydantic.Field(gt=42)]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>annotation</code> <code>type[Any]</code> <p>An annotation object.</p> required <p>Returns:</p> Type Description <code>FieldInfo</code> <p>An instance of the field metadata.</p> Source code in <code>pydantic/fields.py</code> <pre><code>@staticmethod\ndef from_annotation(annotation: type[Any]) -&gt; FieldInfo:\n    \"\"\"Creates a `FieldInfo` instance from a bare annotation.\n\n    This function is used internally to create a `FieldInfo` from a bare annotation like this:\n\n    ```python\n    import pydantic\n\n    class MyModel(pydantic.BaseModel):\n        foo: int  # &lt;-- like this\n    ```\n\n    We also account for the case where the annotation can be an instance of `Annotated` and where\n    one of the (not first) arguments in `Annotated` is an instance of `FieldInfo`, e.g.:\n\n    ```python\n    import annotated_types\n    from typing_extensions import Annotated\n\n    import pydantic\n\n    class MyModel(pydantic.BaseModel):\n        foo: Annotated[int, annotated_types.Gt(42)]\n        bar: Annotated[int, pydantic.Field(gt=42)]\n    ```\n\n    Args:\n        annotation: An annotation object.\n\n    Returns:\n        An instance of the field metadata.\n    \"\"\"\n    final = False\n    if _typing_extra.is_finalvar(annotation):\n        final = True\n        if annotation is not typing_extensions.Final:\n            annotation = typing_extensions.get_args(annotation)[0]\n\n    if _typing_extra.is_annotated(annotation):\n        first_arg, *extra_args = typing_extensions.get_args(annotation)\n        if _typing_extra.is_finalvar(first_arg):\n            final = True\n        field_info_annotations = [a for a in extra_args if isinstance(a, FieldInfo)]\n        field_info = FieldInfo.merge_field_infos(*field_info_annotations, annotation=first_arg)\n        if field_info:\n            new_field_info = copy(field_info)\n            new_field_info.annotation = first_arg\n            new_field_info.frozen = final or field_info.frozen\n            metadata: list[Any] = []\n            for a in extra_args:\n                if _typing_extra.is_deprecated_instance(a):\n                    new_field_info.deprecated = a.message\n                elif not isinstance(a, FieldInfo):\n                    metadata.append(a)\n                else:\n                    metadata.extend(a.metadata)\n            new_field_info.metadata = metadata\n            return new_field_info\n\n    return FieldInfo(annotation=annotation, frozen=final or None)  # pyright: ignore[reportArgumentType]\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.from_annotated_attribute","title":"from_annotated_attribute  <code>staticmethod</code>","text":"<pre><code>from_annotated_attribute(\n    annotation: type[Any], default: Any\n) -&gt; FieldInfo\n</code></pre> <p>Create <code>FieldInfo</code> from an annotation with a default value.</p> <p>This is used in cases like the following:</p> <pre><code>import annotated_types\nfrom typing_extensions import Annotated\n\nimport pydantic\n\nclass MyModel(pydantic.BaseModel):\n    foo: int = 4  # &lt;-- like this\n    bar: Annotated[int, annotated_types.Gt(4)] = 4  # &lt;-- or this\n    spam: Annotated[int, pydantic.Field(gt=4)] = 4  # &lt;-- or this\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>annotation</code> <code>type[Any]</code> <p>The type annotation of the field.</p> required <code>default</code> <code>Any</code> <p>The default value of the field.</p> required <p>Returns:</p> Type Description <code>FieldInfo</code> <p>A field object with the passed values.</p> Source code in <code>pydantic/fields.py</code> <pre><code>@staticmethod\ndef from_annotated_attribute(annotation: type[Any], default: Any) -&gt; FieldInfo:\n    \"\"\"Create `FieldInfo` from an annotation with a default value.\n\n    This is used in cases like the following:\n\n    ```python\n    import annotated_types\n    from typing_extensions import Annotated\n\n    import pydantic\n\n    class MyModel(pydantic.BaseModel):\n        foo: int = 4  # &lt;-- like this\n        bar: Annotated[int, annotated_types.Gt(4)] = 4  # &lt;-- or this\n        spam: Annotated[int, pydantic.Field(gt=4)] = 4  # &lt;-- or this\n    ```\n\n    Args:\n        annotation: The type annotation of the field.\n        default: The default value of the field.\n\n    Returns:\n        A field object with the passed values.\n    \"\"\"\n    if annotation is default:\n        raise PydanticUserError(\n            'Error when building FieldInfo from annotated attribute. '\n            \"Make sure you don't have any field name clashing with a type annotation \",\n            code='unevaluable-type-annotation',\n        )\n\n    final = _typing_extra.is_finalvar(annotation)\n    if final and annotation is not typing_extensions.Final:\n        annotation = typing_extensions.get_args(annotation)[0]\n\n    if isinstance(default, FieldInfo):\n        default.annotation, annotation_metadata = FieldInfo._extract_metadata(annotation)  # pyright: ignore[reportArgumentType]\n        default.metadata += annotation_metadata\n        default = default.merge_field_infos(\n            *[x for x in annotation_metadata if isinstance(x, FieldInfo)], default, annotation=default.annotation\n        )\n        default.frozen = final or default.frozen\n        return default\n\n    if isinstance(default, dataclasses.Field):\n        init_var = False\n        if annotation is dataclasses.InitVar:\n            init_var = True\n            annotation = typing.cast(Any, Any)\n        elif isinstance(annotation, dataclasses.InitVar):\n            init_var = True\n            annotation = annotation.type\n\n        pydantic_field = FieldInfo._from_dataclass_field(default)\n        pydantic_field.annotation, annotation_metadata = FieldInfo._extract_metadata(annotation)  # pyright: ignore[reportArgumentType]\n        pydantic_field.metadata += annotation_metadata\n        pydantic_field = pydantic_field.merge_field_infos(\n            *[x for x in annotation_metadata if isinstance(x, FieldInfo)],\n            pydantic_field,\n            annotation=pydantic_field.annotation,\n        )\n        pydantic_field.frozen = final or pydantic_field.frozen\n        pydantic_field.init_var = init_var\n        pydantic_field.init = getattr(default, 'init', None)\n        pydantic_field.kw_only = getattr(default, 'kw_only', None)\n        return pydantic_field\n\n    if _typing_extra.is_annotated(annotation):\n        first_arg, *extra_args = typing_extensions.get_args(annotation)\n        field_infos = [a for a in extra_args if isinstance(a, FieldInfo)]\n        field_info = FieldInfo.merge_field_infos(*field_infos, annotation=first_arg, default=default)\n        metadata: list[Any] = []\n        for a in extra_args:\n            if _typing_extra.is_deprecated_instance(a):\n                field_info.deprecated = a.message\n            elif not isinstance(a, FieldInfo):\n                metadata.append(a)\n            else:\n                metadata.extend(a.metadata)\n        field_info.metadata = metadata\n        return field_info\n\n    return FieldInfo(annotation=annotation, default=default, frozen=final or None)  # pyright: ignore[reportArgumentType]\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.merge_field_infos","title":"merge_field_infos  <code>staticmethod</code>","text":"<pre><code>merge_field_infos(\n    *field_infos: FieldInfo, **overrides: Any\n) -&gt; FieldInfo\n</code></pre> <p>Merge <code>FieldInfo</code> instances keeping only explicitly set attributes.</p> <p>Later <code>FieldInfo</code> instances override earlier ones.</p> <p>Returns:</p> Name Type Description <code>FieldInfo</code> <code>FieldInfo</code> <p>A merged FieldInfo instance.</p> Source code in <code>pydantic/fields.py</code> <pre><code>@staticmethod\ndef merge_field_infos(*field_infos: FieldInfo, **overrides: Any) -&gt; FieldInfo:\n    \"\"\"Merge `FieldInfo` instances keeping only explicitly set attributes.\n\n    Later `FieldInfo` instances override earlier ones.\n\n    Returns:\n        FieldInfo: A merged FieldInfo instance.\n    \"\"\"\n    if len(field_infos) == 1:\n        # No merging necessary, but we still need to make a copy and apply the overrides\n        field_info = copy(field_infos[0])\n        field_info._attributes_set.update(overrides)\n\n        default_override = overrides.pop('default', PydanticUndefined)\n        if default_override is Ellipsis:\n            default_override = PydanticUndefined\n        if default_override is not PydanticUndefined:\n            field_info.default = default_override\n\n        for k, v in overrides.items():\n            setattr(field_info, k, v)\n        return field_info  # type: ignore\n\n    merged_field_info_kwargs: dict[str, Any] = {}\n    metadata = {}\n    for field_info in field_infos:\n        attributes_set = field_info._attributes_set.copy()\n\n        try:\n            json_schema_extra = attributes_set.pop('json_schema_extra')\n            existing_json_schema_extra = merged_field_info_kwargs.get('json_schema_extra', {})\n\n            if isinstance(existing_json_schema_extra, dict) and isinstance(json_schema_extra, dict):\n                merged_field_info_kwargs['json_schema_extra'] = {**existing_json_schema_extra, **json_schema_extra}\n            else:\n                # if ever there's a case of a callable, we'll just keep the last json schema extra spec\n                merged_field_info_kwargs['json_schema_extra'] = json_schema_extra\n        except KeyError:\n            pass\n\n        # later FieldInfo instances override everything except json_schema_extra from earlier FieldInfo instances\n        merged_field_info_kwargs.update(attributes_set)\n\n        for x in field_info.metadata:\n            if not isinstance(x, FieldInfo):\n                metadata[type(x)] = x\n\n    merged_field_info_kwargs.update(overrides)\n    field_info = FieldInfo(**merged_field_info_kwargs)\n    field_info.metadata = list(metadata.values())\n    return field_info\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.deprecation_message","title":"deprecation_message  <code>property</code>","text":"<pre><code>deprecation_message: str | None\n</code></pre> <p>The deprecation message to be emitted, or <code>None</code> if not set.</p>"},{"location":"api/fields/#pydantic.fields.FieldInfo.get_default","title":"get_default","text":"<pre><code>get_default(*, call_default_factory: bool = False) -&gt; Any\n</code></pre> <p>Get the default value.</p> <p>We expose an option for whether to call the default_factory (if present), as calling it may result in side effects that we want to avoid. However, there are times when it really should be called (namely, when instantiating a model via <code>model_construct</code>).</p> <p>Parameters:</p> Name Type Description Default <code>call_default_factory</code> <code>bool</code> <p>Whether to call the default_factory or not. Defaults to <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Any</code> <p>The default value, calling the default factory if requested or <code>None</code> if not set.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def get_default(self, *, call_default_factory: bool = False) -&gt; Any:\n    \"\"\"Get the default value.\n\n    We expose an option for whether to call the default_factory (if present), as calling it may\n    result in side effects that we want to avoid. However, there are times when it really should\n    be called (namely, when instantiating a model via `model_construct`).\n\n    Args:\n        call_default_factory: Whether to call the default_factory or not. Defaults to `False`.\n\n    Returns:\n        The default value, calling the default factory if requested or `None` if not set.\n    \"\"\"\n    if self.default_factory is None:\n        return _utils.smart_deepcopy(self.default)\n    elif call_default_factory:\n        return self.default_factory()\n    else:\n        return None\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.is_required","title":"is_required","text":"<pre><code>is_required() -&gt; bool\n</code></pre> <p>Check if the field is required (i.e., does not have a default value or factory).</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the field is required, <code>False</code> otherwise.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def is_required(self) -&gt; bool:\n    \"\"\"Check if the field is required (i.e., does not have a default value or factory).\n\n    Returns:\n        `True` if the field is required, `False` otherwise.\n    \"\"\"\n    return self.default is PydanticUndefined and self.default_factory is None\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.rebuild_annotation","title":"rebuild_annotation","text":"<pre><code>rebuild_annotation() -&gt; Any\n</code></pre> <p>Attempts to rebuild the original annotation for use in function signatures.</p> <p>If metadata is present, it adds it to the original annotation using <code>Annotated</code>. Otherwise, it returns the original annotation as-is.</p> <p>Note that because the metadata has been flattened, the original annotation may not be reconstructed exactly as originally provided, e.g. if the original type had unrecognized annotations, or was annotated with a call to <code>pydantic.Field</code>.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The rebuilt annotation.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def rebuild_annotation(self) -&gt; Any:\n    \"\"\"Attempts to rebuild the original annotation for use in function signatures.\n\n    If metadata is present, it adds it to the original annotation using\n    `Annotated`. Otherwise, it returns the original annotation as-is.\n\n    Note that because the metadata has been flattened, the original annotation\n    may not be reconstructed exactly as originally provided, e.g. if the original\n    type had unrecognized annotations, or was annotated with a call to `pydantic.Field`.\n\n    Returns:\n        The rebuilt annotation.\n    \"\"\"\n    if not self.metadata:\n        return self.annotation\n    else:\n        # Annotated arguments must be a tuple\n        return typing_extensions.Annotated[(self.annotation, *self.metadata)]  # type: ignore\n</code></pre>"},{"location":"api/fields/#pydantic.fields.FieldInfo.apply_typevars_map","title":"apply_typevars_map","text":"<pre><code>apply_typevars_map(\n    typevars_map: dict[Any, Any] | None,\n    types_namespace: dict[str, Any] | None,\n) -&gt; None\n</code></pre> <p>Apply a <code>typevars_map</code> to the annotation.</p> <p>This method is used when analyzing parametrized generic types to replace typevars with their concrete types.</p> <p>This method applies the <code>typevars_map</code> to the annotation in place.</p> <p>Parameters:</p> Name Type Description Default <code>typevars_map</code> <code>dict[Any, Any] | None</code> <p>A dictionary mapping type variables to their concrete types.</p> required <code>types_namespace</code> <code>dict | None</code> <p>A dictionary containing related types to the annotated type.</p> required See Also <p>pydantic._internal._generics.replace_types is used for replacing the typevars with     their concrete types.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def apply_typevars_map(self, typevars_map: dict[Any, Any] | None, types_namespace: dict[str, Any] | None) -&gt; None:\n    \"\"\"Apply a `typevars_map` to the annotation.\n\n    This method is used when analyzing parametrized generic types to replace typevars with their concrete types.\n\n    This method applies the `typevars_map` to the annotation in place.\n\n    Args:\n        typevars_map: A dictionary mapping type variables to their concrete types.\n        types_namespace (dict | None): A dictionary containing related types to the annotated type.\n\n    See Also:\n        pydantic._internal._generics.replace_types is used for replacing the typevars with\n            their concrete types.\n    \"\"\"\n    annotation = _typing_extra.eval_type_lenient(self.annotation, types_namespace)\n    self.annotation = _generics.replace_types(annotation, typevars_map)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.PrivateAttr","title":"PrivateAttr","text":"<pre><code>PrivateAttr(\n    default: Any = PydanticUndefined,\n    *,\n    default_factory: Callable[[], Any] | None = None,\n    init: Literal[False] = False\n) -&gt; Any\n</code></pre> <p>Usage Documentation</p> <p>Private model attributes</p> <p>Indicates that an attribute is intended for private use and not handled during normal validation/serialization.</p> <p>Private attributes are not validated by Pydantic, so it's up to you to ensure they are used in a type-safe manner.</p> <p>Private attributes are stored in <code>__private_attributes__</code> on the model.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>Any</code> <p>The attribute's default value. Defaults to Undefined.</p> <code>PydanticUndefined</code> <code>default_factory</code> <code>Callable[[], Any] | None</code> <p>Callable that will be called when a default value is needed for this attribute. If both <code>default</code> and <code>default_factory</code> are set, an error will be raised.</p> <code>None</code> <code>init</code> <code>Literal[False]</code> <p>Whether the attribute should be included in the constructor of the dataclass. Always <code>False</code>.</p> <code>False</code> <p>Returns:</p> Type Description <code>Any</code> <p>An instance of <code>ModelPrivateAttr</code> class.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>default</code> and <code>default_factory</code> are set.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def PrivateAttr(\n    default: Any = PydanticUndefined,\n    *,\n    default_factory: typing.Callable[[], Any] | None = None,\n    init: Literal[False] = False,\n) -&gt; Any:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/models/#private-model-attributes\n\n    Indicates that an attribute is intended for private use and not handled during normal validation/serialization.\n\n    Private attributes are not validated by Pydantic, so it's up to you to ensure they are used in a type-safe manner.\n\n    Private attributes are stored in `__private_attributes__` on the model.\n\n    Args:\n        default: The attribute's default value. Defaults to Undefined.\n        default_factory: Callable that will be\n            called when a default value is needed for this attribute.\n            If both `default` and `default_factory` are set, an error will be raised.\n        init: Whether the attribute should be included in the constructor of the dataclass. Always `False`.\n\n    Returns:\n        An instance of [`ModelPrivateAttr`][pydantic.fields.ModelPrivateAttr] class.\n\n    Raises:\n        ValueError: If both `default` and `default_factory` are set.\n    \"\"\"\n    if default is not PydanticUndefined and default_factory is not None:\n        raise TypeError('cannot specify both default and default_factory')\n\n    return ModelPrivateAttr(\n        default,\n        default_factory=default_factory,\n    )\n</code></pre>"},{"location":"api/fields/#pydantic.fields.ModelPrivateAttr","title":"ModelPrivateAttr","text":"<pre><code>ModelPrivateAttr(\n    default: Any = PydanticUndefined,\n    *,\n    default_factory: Callable[[], Any] | None = None\n)\n</code></pre> <p>               Bases: <code>Representation</code></p> <p>A descriptor for private attributes in class models.</p> <p>Warning</p> <p>You generally shouldn't be creating <code>ModelPrivateAttr</code> instances directly, instead use <code>pydantic.fields.PrivateAttr</code>. (This is similar to <code>FieldInfo</code> vs. <code>Field</code>.)</p> <p>Attributes:</p> Name Type Description <code>default</code> <p>The default value of the attribute if not provided.</p> <code>default_factory</code> <p>A callable function that generates the default value of the attribute if not provided.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def __init__(\n    self, default: Any = PydanticUndefined, *, default_factory: typing.Callable[[], Any] | None = None\n) -&gt; None:\n    self.default = default\n    self.default_factory = default_factory\n</code></pre>"},{"location":"api/fields/#pydantic.fields.ModelPrivateAttr.get_default","title":"get_default","text":"<pre><code>get_default() -&gt; Any\n</code></pre> <p>Retrieve the default value of the object.</p> <p>If <code>self.default_factory</code> is <code>None</code>, the method will return a deep copy of the <code>self.default</code> object.</p> <p>If <code>self.default_factory</code> is not <code>None</code>, it will call <code>self.default_factory</code> and return the value returned.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The default value of the object.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def get_default(self) -&gt; Any:\n    \"\"\"Retrieve the default value of the object.\n\n    If `self.default_factory` is `None`, the method will return a deep copy of the `self.default` object.\n\n    If `self.default_factory` is not `None`, it will call `self.default_factory` and return the value returned.\n\n    Returns:\n        The default value of the object.\n    \"\"\"\n    return _utils.smart_deepcopy(self.default) if self.default_factory is None else self.default_factory()\n</code></pre>"},{"location":"api/fields/#pydantic.fields.computed_field","title":"computed_field","text":"<pre><code>computed_field(\n    func: PropertyT | None = None,\n    /,\n    *,\n    alias: str | None = None,\n    alias_priority: int | None = None,\n    title: str | None = None,\n    field_title_generator: (\n        Callable[[str, ComputedFieldInfo], str] | None\n    ) = None,\n    description: str | None = None,\n    deprecated: Deprecated | str | bool | None = None,\n    examples: list[Any] | None = None,\n    json_schema_extra: (\n        JsonDict | Callable[[JsonDict], None] | None\n    ) = None,\n    repr: bool | None = None,\n    return_type: Any = PydanticUndefined,\n) -&gt; PropertyT | Callable[[PropertyT], PropertyT]\n</code></pre> <p>Usage Documentation</p> <p>The <code>computed_field</code> decorator</p> <p>Decorator to include <code>property</code> and <code>cached_property</code> when serializing models or dataclasses.</p> <p>This is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.</p> <pre><code>from pydantic import BaseModel, computed_field\n\nclass Rectangle(BaseModel):\n    width: int\n    length: int\n\n    @computed_field\n    @property\n    def area(self) -&gt; int:\n        return self.width * self.length\n\nprint(Rectangle(width=3, length=2).model_dump())\n#&gt; {'width': 3, 'length': 2, 'area': 6}\n</code></pre> <p>If applied to functions not yet decorated with <code>@property</code> or <code>@cached_property</code>, the function is automatically wrapped with <code>property</code>. Although this is more concise, you will lose IntelliSense in your IDE, and confuse static type checkers, thus explicit use of <code>@property</code> is recommended.</p> <p>Mypy Warning</p> <p>Even with the <code>@property</code> or <code>@cached_property</code> applied to your function before <code>@computed_field</code>, mypy may throw a <code>Decorated property not supported</code> error. See mypy issue #1362, for more information. To avoid this error message, add <code># type: ignore[misc]</code> to the <code>@computed_field</code> line.</p> <p>pyright supports <code>@computed_field</code> without error.</p> <pre><code>import random\n\nfrom pydantic import BaseModel, computed_field\n\nclass Square(BaseModel):\n    width: float\n\n    @computed_field\n    def area(self) -&gt; float:  # converted to a `property` by `computed_field`\n        return round(self.width**2, 2)\n\n    @area.setter\n    def area(self, new_area: float) -&gt; None:\n        self.width = new_area**0.5\n\n    @computed_field(alias='the magic number', repr=False)\n    def random_number(self) -&gt; int:\n        return random.randint(0, 1_000)\n\nsquare = Square(width=1.3)\n\n# `random_number` does not appear in representation\nprint(repr(square))\n#&gt; Square(width=1.3, area=1.69)\n\nprint(square.random_number)\n#&gt; 3\n\nsquare.area = 4\n\nprint(square.model_dump_json(by_alias=True))\n#&gt; {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\n</code></pre> <p>Overriding with <code>computed_field</code></p> <p>You can't override a field from a parent class with a <code>computed_field</code> in the child class. <code>mypy</code> complains about this behavior if allowed, and <code>dataclasses</code> doesn't allow this pattern either. See the example below:</p> <pre><code>from pydantic import BaseModel, computed_field\n\nclass Parent(BaseModel):\n    a: str\n\ntry:\n\n    class Child(Parent):\n        @computed_field\n        @property\n        def a(self) -&gt; str:\n            return 'new a'\n\nexcept ValueError as e:\n    print(repr(e))\n    #&gt; ValueError(\"you can't override a field with a computed field\")\n</code></pre> <p>Private properties decorated with <code>@computed_field</code> have <code>repr=False</code> by default.</p> <pre><code>from functools import cached_property\n\nfrom pydantic import BaseModel, computed_field\n\nclass Model(BaseModel):\n    foo: int\n\n    @computed_field\n    @cached_property\n    def _private_cached_property(self) -&gt; int:\n        return -self.foo\n\n    @computed_field\n    @property\n    def _private_property(self) -&gt; int:\n        return -self.foo\n\nm = Model(foo=1)\nprint(repr(m))\n#&gt; M(foo=1)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>PropertyT | None</code> <p>the function to wrap.</p> <code>None</code> <code>alias</code> <code>str | None</code> <p>alias to use when serializing this computed field, only used when <code>by_alias=True</code></p> <code>None</code> <code>alias_priority</code> <code>int | None</code> <p>priority of the alias. This affects whether an alias generator is used</p> <code>None</code> <code>title</code> <code>str | None</code> <p>Title to use when including this computed field in JSON Schema</p> <code>None</code> <code>field_title_generator</code> <code>Callable[[str, ComputedFieldInfo], str] | None</code> <p>A callable that takes a field name and returns title for it.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>Description to use when including this computed field in JSON Schema, defaults to the function's docstring</p> <code>None</code> <code>deprecated</code> <code>Deprecated | str | bool | None</code> <p>A deprecation message (or an instance of <code>warnings.deprecated</code> or the <code>typing_extensions.deprecated</code> backport). to be emitted when accessing the field. Or a boolean. This will automatically be set if the property is decorated with the <code>deprecated</code> decorator.</p> <code>None</code> <code>examples</code> <code>list[Any] | None</code> <p>Example values to use when including this computed field in JSON Schema</p> <code>None</code> <code>json_schema_extra</code> <code>JsonDict | Callable[[JsonDict], None] | None</code> <p>A dict or callable to provide extra JSON schema properties.</p> <code>None</code> <code>repr</code> <code>bool | None</code> <p>whether to include this computed field in model repr. Default is <code>False</code> for private properties and <code>True</code> for public properties.</p> <code>None</code> <code>return_type</code> <code>Any</code> <p>optional return for serialization logic to expect when serializing to JSON, if included this must be correct, otherwise a <code>TypeError</code> is raised. If you don't include a return type Any is used, which does runtime introspection to handle arbitrary objects.</p> <code>PydanticUndefined</code> <p>Returns:</p> Type Description <code>PropertyT | Callable[[PropertyT], PropertyT]</code> <p>A proxy wrapper for the property.</p> Source code in <code>pydantic/fields.py</code> <pre><code>def computed_field(\n    func: PropertyT | None = None,\n    /,\n    *,\n    alias: str | None = None,\n    alias_priority: int | None = None,\n    title: str | None = None,\n    field_title_generator: typing.Callable[[str, ComputedFieldInfo], str] | None = None,\n    description: str | None = None,\n    deprecated: Deprecated | str | bool | None = None,\n    examples: list[Any] | None = None,\n    json_schema_extra: JsonDict | typing.Callable[[JsonDict], None] | None = None,\n    repr: bool | None = None,\n    return_type: Any = PydanticUndefined,\n) -&gt; PropertyT | typing.Callable[[PropertyT], PropertyT]:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/fields#the-computed_field-decorator\n\n    Decorator to include `property` and `cached_property` when serializing models or dataclasses.\n\n    This is useful for fields that are computed from other fields, or for fields that are expensive to compute and should be cached.\n\n    ```py\n    from pydantic import BaseModel, computed_field\n\n    class Rectangle(BaseModel):\n        width: int\n        length: int\n\n        @computed_field\n        @property\n        def area(self) -&gt; int:\n            return self.width * self.length\n\n    print(Rectangle(width=3, length=2).model_dump())\n    #&gt; {'width': 3, 'length': 2, 'area': 6}\n    ```\n\n    If applied to functions not yet decorated with `@property` or `@cached_property`, the function is\n    automatically wrapped with `property`. Although this is more concise, you will lose IntelliSense in your IDE,\n    and confuse static type checkers, thus explicit use of `@property` is recommended.\n\n    !!! warning \"Mypy Warning\"\n        Even with the `@property` or `@cached_property` applied to your function before `@computed_field`,\n        mypy may throw a `Decorated property not supported` error.\n        See [mypy issue #1362](https://github.com/python/mypy/issues/1362), for more information.\n        To avoid this error message, add `# type: ignore[misc]` to the `@computed_field` line.\n\n        [pyright](https://github.com/microsoft/pyright) supports `@computed_field` without error.\n\n    ```py\n    import random\n\n    from pydantic import BaseModel, computed_field\n\n    class Square(BaseModel):\n        width: float\n\n        @computed_field\n        def area(self) -&gt; float:  # converted to a `property` by `computed_field`\n            return round(self.width**2, 2)\n\n        @area.setter\n        def area(self, new_area: float) -&gt; None:\n            self.width = new_area**0.5\n\n        @computed_field(alias='the magic number', repr=False)\n        def random_number(self) -&gt; int:\n            return random.randint(0, 1_000)\n\n    square = Square(width=1.3)\n\n    # `random_number` does not appear in representation\n    print(repr(square))\n    #&gt; Square(width=1.3, area=1.69)\n\n    print(square.random_number)\n    #&gt; 3\n\n    square.area = 4\n\n    print(square.model_dump_json(by_alias=True))\n    #&gt; {\"width\":2.0,\"area\":4.0,\"the magic number\":3}\n    ```\n\n    !!! warning \"Overriding with `computed_field`\"\n        You can't override a field from a parent class with a `computed_field` in the child class.\n        `mypy` complains about this behavior if allowed, and `dataclasses` doesn't allow this pattern either.\n        See the example below:\n\n    ```py\n    from pydantic import BaseModel, computed_field\n\n    class Parent(BaseModel):\n        a: str\n\n    try:\n\n        class Child(Parent):\n            @computed_field\n            @property\n            def a(self) -&gt; str:\n                return 'new a'\n\n    except ValueError as e:\n        print(repr(e))\n        #&gt; ValueError(\"you can't override a field with a computed field\")\n    ```\n\n    Private properties decorated with `@computed_field` have `repr=False` by default.\n\n    ```py\n    from functools import cached_property\n\n    from pydantic import BaseModel, computed_field\n\n    class Model(BaseModel):\n        foo: int\n\n        @computed_field\n        @cached_property\n        def _private_cached_property(self) -&gt; int:\n            return -self.foo\n\n        @computed_field\n        @property\n        def _private_property(self) -&gt; int:\n            return -self.foo\n\n    m = Model(foo=1)\n    print(repr(m))\n    #&gt; M(foo=1)\n    ```\n\n    Args:\n        func: the function to wrap.\n        alias: alias to use when serializing this computed field, only used when `by_alias=True`\n        alias_priority: priority of the alias. This affects whether an alias generator is used\n        title: Title to use when including this computed field in JSON Schema\n        field_title_generator: A callable that takes a field name and returns title for it.\n        description: Description to use when including this computed field in JSON Schema, defaults to the function's\n            docstring\n        deprecated: A deprecation message (or an instance of `warnings.deprecated` or the `typing_extensions.deprecated` backport).\n            to be emitted when accessing the field. Or a boolean. This will automatically be set if the property is decorated with the\n            `deprecated` decorator.\n        examples: Example values to use when including this computed field in JSON Schema\n        json_schema_extra: A dict or callable to provide extra JSON schema properties.\n        repr: whether to include this computed field in model repr.\n            Default is `False` for private properties and `True` for public properties.\n        return_type: optional return for serialization logic to expect when serializing to JSON, if included\n            this must be correct, otherwise a `TypeError` is raised.\n            If you don't include a return type Any is used, which does runtime introspection to handle arbitrary\n            objects.\n\n    Returns:\n        A proxy wrapper for the property.\n    \"\"\"\n\n    def dec(f: Any) -&gt; Any:\n        nonlocal description, deprecated, return_type, alias_priority\n        unwrapped = _decorators.unwrap_wrapped_function(f)\n\n        if description is None and unwrapped.__doc__:\n            description = inspect.cleandoc(unwrapped.__doc__)\n\n        if deprecated is None and hasattr(unwrapped, '__deprecated__'):\n            deprecated = unwrapped.__deprecated__\n\n        # if the function isn't already decorated with `@property` (or another descriptor), then we wrap it now\n        f = _decorators.ensure_property(f)\n        alias_priority = (alias_priority or 2) if alias is not None else None\n\n        if repr is None:\n            repr_: bool = not _wrapped_property_is_private(property_=f)\n        else:\n            repr_ = repr\n\n        dec_info = ComputedFieldInfo(\n            f,\n            return_type,\n            alias,\n            alias_priority,\n            title,\n            field_title_generator,\n            description,\n            deprecated,\n            examples,\n            json_schema_extra,\n            repr_,\n        )\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    if func is None:\n        return dec\n    else:\n        return dec(func)\n</code></pre>"},{"location":"api/fields/#pydantic.fields.ComputedFieldInfo","title":"ComputedFieldInfo  <code>dataclass</code>","text":"<pre><code>ComputedFieldInfo(\n    wrapped_property: property,\n    return_type: Any,\n    alias: str | None,\n    alias_priority: int | None,\n    title: str | None,\n    field_title_generator: (\n        Callable[[str, ComputedFieldInfo], str] | None\n    ),\n    description: str | None,\n    deprecated: Deprecated | str | bool | None,\n    examples: list[Any] | None,\n    json_schema_extra: (\n        JsonDict | Callable[[JsonDict], None] | None\n    ),\n    repr: bool,\n)\n</code></pre> <p>A container for data from <code>@computed_field</code> so that we can access it while building the pydantic-core schema.</p> <p>Attributes:</p> Name Type Description <code>decorator_repr</code> <code>str</code> <p>A class variable representing the decorator string, '@computed_field'.</p> <code>wrapped_property</code> <code>property</code> <p>The wrapped computed field property.</p> <code>return_type</code> <code>Any</code> <p>The type of the computed field property's return value.</p> <code>alias</code> <code>str | None</code> <p>The alias of the property to be used during serialization.</p> <code>alias_priority</code> <code>int | None</code> <p>The priority of the alias. This affects whether an alias generator is used.</p> <code>title</code> <code>str | None</code> <p>Title of the computed field to include in the serialization JSON schema.</p> <code>field_title_generator</code> <code>Callable[[str, ComputedFieldInfo], str] | None</code> <p>A callable that takes a field name and returns title for it.</p> <code>description</code> <code>str | None</code> <p>Description of the computed field to include in the serialization JSON schema.</p> <code>deprecated</code> <code>Deprecated | str | bool | None</code> <p>A deprecation message, an instance of <code>warnings.deprecated</code> or the <code>typing_extensions.deprecated</code> backport, or a boolean. If <code>True</code>, a default deprecation message will be emitted when accessing the field.</p> <code>examples</code> <code>list[Any] | None</code> <p>Example values of the computed field to include in the serialization JSON schema.</p> <code>json_schema_extra</code> <code>JsonDict | Callable[[JsonDict], None] | None</code> <p>A dict or callable to provide extra JSON schema properties.</p> <code>repr</code> <code>bool</code> <p>A boolean indicating whether to include the field in the repr output.</p>"},{"location":"api/fields/#pydantic.fields.ComputedFieldInfo.deprecation_message","title":"deprecation_message  <code>property</code>","text":"<pre><code>deprecation_message: str | None\n</code></pre> <p>The deprecation message to be emitted, or <code>None</code> if not set.</p>"},{"location":"api/functional_serializers/","title":"Functional Serializers","text":"<p>This module contains related classes and functions for serialization.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.FieldPlainSerializer","title":"FieldPlainSerializer  <code>module-attribute</code>","text":"<pre><code>FieldPlainSerializer: TypeAlias = (\n    \"core_schema.SerializerFunction | _Partial\"\n)\n</code></pre> <p>A field serializer method or function in <code>plain</code> mode.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.FieldWrapSerializer","title":"FieldWrapSerializer  <code>module-attribute</code>","text":"<pre><code>FieldWrapSerializer: TypeAlias = (\n    \"core_schema.WrapSerializerFunction | _Partial\"\n)\n</code></pre> <p>A field serializer method or function in <code>wrap</code> mode.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.FieldSerializer","title":"FieldSerializer  <code>module-attribute</code>","text":"<pre><code>FieldSerializer: TypeAlias = (\n    \"FieldPlainSerializer | FieldWrapSerializer\"\n)\n</code></pre> <p>A field serializer method or function.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.ModelPlainSerializerWithInfo","title":"ModelPlainSerializerWithInfo  <code>module-attribute</code>","text":"<pre><code>ModelPlainSerializerWithInfo: TypeAlias = Callable[\n    [Any, SerializationInfo], Any\n]\n</code></pre> <p>A model serializer method with the <code>info</code> argument, in <code>plain</code> mode.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.ModelPlainSerializerWithoutInfo","title":"ModelPlainSerializerWithoutInfo  <code>module-attribute</code>","text":"<pre><code>ModelPlainSerializerWithoutInfo: TypeAlias = Callable[\n    [Any], Any\n]\n</code></pre> <p>A model serializer method without the <code>info</code> argument, in <code>plain</code> mode.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.ModelPlainSerializer","title":"ModelPlainSerializer  <code>module-attribute</code>","text":"<pre><code>ModelPlainSerializer: TypeAlias = (\n    \"ModelPlainSerializerWithInfo | ModelPlainSerializerWithoutInfo\"\n)\n</code></pre> <p>A model serializer method in <code>plain</code> mode.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.ModelWrapSerializerWithInfo","title":"ModelWrapSerializerWithInfo  <code>module-attribute</code>","text":"<pre><code>ModelWrapSerializerWithInfo: TypeAlias = Callable[\n    [Any, SerializerFunctionWrapHandler, SerializationInfo],\n    Any,\n]\n</code></pre> <p>A model serializer method with the <code>info</code> argument, in <code>wrap</code> mode.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.ModelWrapSerializerWithoutInfo","title":"ModelWrapSerializerWithoutInfo  <code>module-attribute</code>","text":"<pre><code>ModelWrapSerializerWithoutInfo: TypeAlias = Callable[\n    [Any, SerializerFunctionWrapHandler], Any\n]\n</code></pre> <p>A model serializer method without the <code>info</code> argument, in <code>wrap</code> mode.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.ModelWrapSerializer","title":"ModelWrapSerializer  <code>module-attribute</code>","text":"<pre><code>ModelWrapSerializer: TypeAlias = (\n    \"ModelWrapSerializerWithInfo | ModelWrapSerializerWithoutInfo\"\n)\n</code></pre> <p>A model serializer method in <code>wrap</code> mode.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.PlainSerializer","title":"PlainSerializer  <code>dataclass</code>","text":"<pre><code>PlainSerializer(\n    func: SerializerFunction,\n    return_type: Any = PydanticUndefined,\n    when_used: WhenUsed = \"always\",\n)\n</code></pre> <p>Plain serializers use a function to modify the output of serialization.</p> <p>This is particularly helpful when you want to customize the serialization for annotated types. Consider an input of <code>list</code>, which will be serialized into a space-delimited string.</p> <pre><code>from typing import List\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, PlainSerializer\n\nCustomStr = Annotated[\n    List, PlainSerializer(lambda x: ' '.join(x), return_type=str)\n]\n\nclass StudentModel(BaseModel):\n    courses: CustomStr\n\nstudent = StudentModel(courses=['Math', 'Chemistry', 'English'])\nprint(student.model_dump())\n#&gt; {'courses': 'Math Chemistry English'}\n</code></pre> <p>Attributes:</p> Name Type Description <code>func</code> <code>SerializerFunction</code> <p>The serializer function.</p> <code>return_type</code> <code>Any</code> <p>The return type for the function. If omitted it will be inferred from the type annotation.</p> <code>when_used</code> <code>WhenUsed</code> <p>Determines when this serializer should be used. Accepts a string with values <code>'always'</code>, <code>'unless-none'</code>, <code>'json'</code>, and <code>'json-unless-none'</code>. Defaults to 'always'.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.WrapSerializer","title":"WrapSerializer  <code>dataclass</code>","text":"<pre><code>WrapSerializer(\n    func: WrapSerializerFunction,\n    return_type: Any = PydanticUndefined,\n    when_used: WhenUsed = \"always\",\n)\n</code></pre> <p>Wrap serializers receive the raw inputs along with a handler function that applies the standard serialization logic, and can modify the resulting value before returning it as the final output of serialization.</p> <p>For example, here's a scenario in which a wrap serializer transforms timezones to UTC and utilizes the existing <code>datetime</code> serialization logic.</p> <pre><code>from datetime import datetime, timezone\nfrom typing import Any, Dict\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, WrapSerializer\n\nclass EventDatetime(BaseModel):\n    start: datetime\n    end: datetime\n\ndef convert_to_utc(value: Any, handler, info) -&gt; Dict[str, datetime]:\n    # Note that `handler` can actually help serialize the `value` for\n    # further custom serialization in case it's a subclass.\n    partial_result = handler(value, info)\n    if info.mode == 'json':\n        return {\n            k: datetime.fromisoformat(v).astimezone(timezone.utc)\n            for k, v in partial_result.items()\n        }\n    return {k: v.astimezone(timezone.utc) for k, v in partial_result.items()}\n\nUTCEventDatetime = Annotated[EventDatetime, WrapSerializer(convert_to_utc)]\n\nclass EventModel(BaseModel):\n    event_datetime: UTCEventDatetime\n\ndt = EventDatetime(\n    start='2024-01-01T07:00:00-08:00', end='2024-01-03T20:00:00+06:00'\n)\nevent = EventModel(event_datetime=dt)\nprint(event.model_dump())\n'''\n{\n    'event_datetime': {\n        'start': datetime.datetime(\n            2024, 1, 1, 15, 0, tzinfo=datetime.timezone.utc\n        ),\n        'end': datetime.datetime(\n            2024, 1, 3, 14, 0, tzinfo=datetime.timezone.utc\n        ),\n    }\n}\n'''\n\nprint(event.model_dump_json())\n'''\n{\"event_datetime\":{\"start\":\"2024-01-01T15:00:00Z\",\"end\":\"2024-01-03T14:00:00Z\"}}\n'''\n</code></pre> <p>Attributes:</p> Name Type Description <code>func</code> <code>WrapSerializerFunction</code> <p>The serializer function to be wrapped.</p> <code>return_type</code> <code>Any</code> <p>The return type for the function. If omitted it will be inferred from the type annotation.</p> <code>when_used</code> <code>WhenUsed</code> <p>Determines when this serializer should be used. Accepts a string with values <code>'always'</code>, <code>'unless-none'</code>, <code>'json'</code>, and <code>'json-unless-none'</code>. Defaults to 'always'.</p>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.field_serializer","title":"field_serializer","text":"<pre><code>field_serializer(\n    *fields: str,\n    mode: Literal[\"plain\", \"wrap\"] = \"plain\",\n    return_type: Any = PydanticUndefined,\n    when_used: WhenUsed = \"always\",\n    check_fields: bool | None = None\n) -&gt; (\n    Callable[[_FieldWrapSerializerT], _FieldWrapSerializerT]\n    | Callable[\n        [_FieldPlainSerializerT], _FieldPlainSerializerT\n    ]\n)\n</code></pre> <p>Decorator that enables custom field serialization.</p> <p>In the below example, a field of type <code>set</code> is used to mitigate duplication. A <code>field_serializer</code> is used to serialize the data as a sorted list.</p> <pre><code>from typing import Set\n\nfrom pydantic import BaseModel, field_serializer\n\nclass StudentModel(BaseModel):\n    name: str = 'Jane'\n    courses: Set[str]\n\n    @field_serializer('courses', when_used='json')\n    def serialize_courses_in_order(self, courses: Set[str]):\n        return sorted(courses)\n\nstudent = StudentModel(courses={'Math', 'Chemistry', 'English'})\nprint(student.model_dump_json())\n#&gt; {\"name\":\"Jane\",\"courses\":[\"Chemistry\",\"English\",\"Math\"]}\n</code></pre> <p>See Custom serializers for more information.</p> <p>Four signatures are supported:</p> <ul> <li><code>(self, value: Any, info: FieldSerializationInfo)</code></li> <li><code>(self, value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo)</code></li> <li><code>(value: Any, info: SerializationInfo)</code></li> <li><code>(value: Any, nxt: SerializerFunctionWrapHandler, info: SerializationInfo)</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>str</code> <p>Which field(s) the method should be called on.</p> <code>()</code> <code>mode</code> <code>Literal['plain', 'wrap']</code> <p>The serialization mode.</p> <ul> <li><code>plain</code> means the function will be called instead of the default serialization logic,</li> <li><code>wrap</code> means the function will be called with an argument to optionally call the    default serialization logic.</li> </ul> <code>'plain'</code> <code>return_type</code> <code>Any</code> <p>Optional return type for the function, if omitted it will be inferred from the type annotation.</p> <code>PydanticUndefined</code> <code>when_used</code> <code>WhenUsed</code> <p>Determines the serializer will be used for serialization.</p> <code>'always'</code> <code>check_fields</code> <code>bool | None</code> <p>Whether to check that the fields actually exist on the model.</p> <code>None</code> <p>Returns:</p> Type Description <code>Callable[[_FieldWrapSerializerT], _FieldWrapSerializerT] | Callable[[_FieldPlainSerializerT], _FieldPlainSerializerT]</code> <p>The decorator function.</p> Source code in <code>pydantic/functional_serializers.py</code> <pre><code>def field_serializer(\n    *fields: str,\n    mode: Literal['plain', 'wrap'] = 'plain',\n    return_type: Any = PydanticUndefined,\n    when_used: WhenUsed = 'always',\n    check_fields: bool | None = None,\n) -&gt; (\n    Callable[[_FieldWrapSerializerT], _FieldWrapSerializerT]\n    | Callable[[_FieldPlainSerializerT], _FieldPlainSerializerT]\n):\n    \"\"\"Decorator that enables custom field serialization.\n\n    In the below example, a field of type `set` is used to mitigate duplication. A `field_serializer` is used to serialize the data as a sorted list.\n\n    ```python\n    from typing import Set\n\n    from pydantic import BaseModel, field_serializer\n\n    class StudentModel(BaseModel):\n        name: str = 'Jane'\n        courses: Set[str]\n\n        @field_serializer('courses', when_used='json')\n        def serialize_courses_in_order(self, courses: Set[str]):\n            return sorted(courses)\n\n    student = StudentModel(courses={'Math', 'Chemistry', 'English'})\n    print(student.model_dump_json())\n    #&gt; {\"name\":\"Jane\",\"courses\":[\"Chemistry\",\"English\",\"Math\"]}\n    ```\n\n    See [Custom serializers](../concepts/serialization.md#custom-serializers) for more information.\n\n    Four signatures are supported:\n\n    - `(self, value: Any, info: FieldSerializationInfo)`\n    - `(self, value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo)`\n    - `(value: Any, info: SerializationInfo)`\n    - `(value: Any, nxt: SerializerFunctionWrapHandler, info: SerializationInfo)`\n\n    Args:\n        fields: Which field(s) the method should be called on.\n        mode: The serialization mode.\n\n            - `plain` means the function will be called instead of the default serialization logic,\n            - `wrap` means the function will be called with an argument to optionally call the\n               default serialization logic.\n        return_type: Optional return type for the function, if omitted it will be inferred from the type annotation.\n        when_used: Determines the serializer will be used for serialization.\n        check_fields: Whether to check that the fields actually exist on the model.\n\n    Returns:\n        The decorator function.\n    \"\"\"\n\n    def dec(f: FieldSerializer) -&gt; _decorators.PydanticDescriptorProxy[Any]:\n        dec_info = _decorators.FieldSerializerDecoratorInfo(\n            fields=fields,\n            mode=mode,\n            return_type=return_type,\n            when_used=when_used,\n            check_fields=check_fields,\n        )\n        return _decorators.PydanticDescriptorProxy(f, dec_info)  # pyright: ignore[reportArgumentType]\n\n    return dec  # pyright: ignore[reportReturnType]\n</code></pre>"},{"location":"api/functional_serializers/#pydantic.functional_serializers.model_serializer","title":"model_serializer","text":"<pre><code>model_serializer(\n    f: (\n        _ModelPlainSerializerT\n        | _ModelWrapSerializerT\n        | None\n    ) = None,\n    /,\n    *,\n    mode: Literal[\"plain\", \"wrap\"] = \"plain\",\n    when_used: WhenUsed = \"always\",\n    return_type: Any = PydanticUndefined,\n) -&gt; (\n    _ModelPlainSerializerT\n    | Callable[\n        [_ModelWrapSerializerT], _ModelWrapSerializerT\n    ]\n    | Callable[\n        [_ModelPlainSerializerT], _ModelPlainSerializerT\n    ]\n)\n</code></pre> <p>Decorator that enables custom model serialization.</p> <p>This is useful when a model need to be serialized in a customized manner, allowing for flexibility beyond just specific fields.</p> <p>An example would be to serialize temperature to the same temperature scale, such as degrees Celsius.</p> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, model_serializer\n\nclass TemperatureModel(BaseModel):\n    unit: Literal['C', 'F']\n    value: int\n\n    @model_serializer()\n    def serialize_model(self):\n        if self.unit == 'F':\n            return {'unit': 'C', 'value': int((self.value - 32) / 1.8)}\n        return {'unit': self.unit, 'value': self.value}\n\ntemperature = TemperatureModel(unit='F', value=212)\nprint(temperature.model_dump())\n#&gt; {'unit': 'C', 'value': 100}\n</code></pre> <p>Two signatures are supported for <code>mode='plain'</code>, which is the default:</p> <ul> <li><code>(self)</code></li> <li><code>(self, info: SerializationInfo)</code></li> </ul> <p>And two other signatures for <code>mode='wrap'</code>:</p> <ul> <li><code>(self, nxt: SerializerFunctionWrapHandler)</code></li> <li> <p><code>(self, nxt: SerializerFunctionWrapHandler, info: SerializationInfo)</code></p> <p>See Custom serializers for more information.</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>_ModelPlainSerializerT | _ModelWrapSerializerT | None</code> <p>The function to be decorated.</p> <code>None</code> <code>mode</code> <code>Literal['plain', 'wrap']</code> <p>The serialization mode.</p> <ul> <li><code>'plain'</code> means the function will be called instead of the default serialization logic</li> <li><code>'wrap'</code> means the function will be called with an argument to optionally call the default     serialization logic.</li> </ul> <code>'plain'</code> <code>when_used</code> <code>WhenUsed</code> <p>Determines when this serializer should be used.</p> <code>'always'</code> <code>return_type</code> <code>Any</code> <p>The return type for the function. If omitted it will be inferred from the type annotation.</p> <code>PydanticUndefined</code> <p>Returns:</p> Type Description <code>_ModelPlainSerializerT | Callable[[_ModelWrapSerializerT], _ModelWrapSerializerT] | Callable[[_ModelPlainSerializerT], _ModelPlainSerializerT]</code> <p>The decorator function.</p> Source code in <code>pydantic/functional_serializers.py</code> <pre><code>def model_serializer(\n    f: _ModelPlainSerializerT | _ModelWrapSerializerT | None = None,\n    /,\n    *,\n    mode: Literal['plain', 'wrap'] = 'plain',\n    when_used: WhenUsed = 'always',\n    return_type: Any = PydanticUndefined,\n) -&gt; (\n    _ModelPlainSerializerT\n    | Callable[[_ModelWrapSerializerT], _ModelWrapSerializerT]\n    | Callable[[_ModelPlainSerializerT], _ModelPlainSerializerT]\n):\n    \"\"\"Decorator that enables custom model serialization.\n\n    This is useful when a model need to be serialized in a customized manner, allowing for flexibility beyond just specific fields.\n\n    An example would be to serialize temperature to the same temperature scale, such as degrees Celsius.\n\n    ```python\n    from typing import Literal\n\n    from pydantic import BaseModel, model_serializer\n\n    class TemperatureModel(BaseModel):\n        unit: Literal['C', 'F']\n        value: int\n\n        @model_serializer()\n        def serialize_model(self):\n            if self.unit == 'F':\n                return {'unit': 'C', 'value': int((self.value - 32) / 1.8)}\n            return {'unit': self.unit, 'value': self.value}\n\n    temperature = TemperatureModel(unit='F', value=212)\n    print(temperature.model_dump())\n    #&gt; {'unit': 'C', 'value': 100}\n    ```\n\n    Two signatures are supported for `mode='plain'`, which is the default:\n\n    - `(self)`\n    - `(self, info: SerializationInfo)`\n\n    And two other signatures for `mode='wrap'`:\n\n    - `(self, nxt: SerializerFunctionWrapHandler)`\n    - `(self, nxt: SerializerFunctionWrapHandler, info: SerializationInfo)`\n\n        See [Custom serializers](../concepts/serialization.md#custom-serializers) for more information.\n\n    Args:\n        f: The function to be decorated.\n        mode: The serialization mode.\n\n            - `'plain'` means the function will be called instead of the default serialization logic\n            - `'wrap'` means the function will be called with an argument to optionally call the default\n                serialization logic.\n        when_used: Determines when this serializer should be used.\n        return_type: The return type for the function. If omitted it will be inferred from the type annotation.\n\n    Returns:\n        The decorator function.\n    \"\"\"\n\n    def dec(f: ModelSerializer) -&gt; _decorators.PydanticDescriptorProxy[Any]:\n        dec_info = _decorators.ModelSerializerDecoratorInfo(mode=mode, return_type=return_type, when_used=when_used)\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    if f is None:\n        return dec  # pyright: ignore[reportReturnType]\n    else:\n        return dec(f)  # pyright: ignore[reportReturnType]\n</code></pre>"},{"location":"api/functional_validators/","title":"Functional Validators","text":"<p>This module contains related classes and functions for validation.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelAfterValidatorWithoutInfo","title":"ModelAfterValidatorWithoutInfo  <code>module-attribute</code>","text":"<pre><code>ModelAfterValidatorWithoutInfo = Callable[\n    [_ModelType], _ModelType\n]\n</code></pre> <p>A <code>@model_validator</code> decorated function signature. This is used when <code>mode='after'</code> and the function does not have info argument.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelAfterValidator","title":"ModelAfterValidator  <code>module-attribute</code>","text":"<pre><code>ModelAfterValidator = Callable[\n    [_ModelType, ValidationInfo], _ModelType\n]\n</code></pre> <p>A <code>@model_validator</code> decorated function signature. This is used when <code>mode='after'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.AfterValidator","title":"AfterValidator  <code>dataclass</code>","text":"<pre><code>AfterValidator(\n    func: (\n        NoInfoValidatorFunction | WithInfoValidatorFunction\n    ),\n)\n</code></pre> <p>Usage Documentation</p> <p>Annotated Validators</p> <p>A metadata class that indicates that a validation should be applied after the inner validation logic.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>NoInfoValidatorFunction | WithInfoValidatorFunction</code> <p>The validator function.</p> Example <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import AfterValidator, BaseModel, ValidationError\n\nMyInt = Annotated[int, AfterValidator(lambda v: v + 1)]\n\nclass Model(BaseModel):\n    a: MyInt\n\nprint(Model(a=1).a)\n#&gt; 2\n\ntry:\n    Model(a='a')\nexcept ValidationError as e:\n    print(e.json(indent=2))\n    '''\n    [\n      {\n        \"type\": \"int_parsing\",\n        \"loc\": [\n          \"a\"\n        ],\n        \"msg\": \"Input should be a valid integer, unable to parse string as an integer\",\n        \"input\": \"a\",\n        \"url\": \"https://errors.pydantic.dev/2/v/int_parsing\"\n      }\n    ]\n    '''\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.BeforeValidator","title":"BeforeValidator  <code>dataclass</code>","text":"<pre><code>BeforeValidator(\n    func: (\n        NoInfoValidatorFunction | WithInfoValidatorFunction\n    ),\n    json_schema_input_type: Any = PydanticUndefined,\n)\n</code></pre> <p>Usage Documentation</p> <p>Annotated Validators</p> <p>A metadata class that indicates that a validation should be applied before the inner validation logic.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>NoInfoValidatorFunction | WithInfoValidatorFunction</code> <p>The validator function.</p> <code>json_schema_input_type</code> <code>Any</code> <p>The input type of the function. This is only used to generate the appropriate JSON Schema (in validation mode).</p> Example <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, BeforeValidator\n\nMyInt = Annotated[int, BeforeValidator(lambda v: v + 1)]\n\nclass Model(BaseModel):\n    a: MyInt\n\nprint(Model(a=1).a)\n#&gt; 2\n\ntry:\n    Model(a='a')\nexcept TypeError as e:\n    print(e)\n    #&gt; can only concatenate str (not \"int\") to str\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.PlainValidator","title":"PlainValidator  <code>dataclass</code>","text":"<pre><code>PlainValidator(\n    func: (\n        NoInfoValidatorFunction | WithInfoValidatorFunction\n    ),\n    json_schema_input_type: Any = Any,\n)\n</code></pre> <p>Usage Documentation</p> <p>Annotated Validators</p> <p>A metadata class that indicates that a validation should be applied instead of the inner validation logic.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>NoInfoValidatorFunction | WithInfoValidatorFunction</code> <p>The validator function.</p> <code>json_schema_input_type</code> <code>Any</code> <p>The input type of the function. This is only used to generate the appropriate JSON Schema (in validation mode). If not provided, will default to <code>Any</code>.</p> Example <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, PlainValidator\n\nMyInt = Annotated[int, PlainValidator(lambda v: int(v) + 1)]\n\nclass Model(BaseModel):\n    a: MyInt\n\nprint(Model(a='1').a)\n#&gt; 2\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.WrapValidator","title":"WrapValidator  <code>dataclass</code>","text":"<pre><code>WrapValidator(\n    func: (\n        NoInfoWrapValidatorFunction\n        | WithInfoWrapValidatorFunction\n    ),\n    json_schema_input_type: Any = PydanticUndefined,\n)\n</code></pre> <p>Usage Documentation</p> <p>Annotated Validators</p> <p>A metadata class that indicates that a validation should be applied around the inner validation logic.</p> <p>Attributes:</p> Name Type Description <code>func</code> <code>NoInfoWrapValidatorFunction | WithInfoWrapValidatorFunction</code> <p>The validator function.</p> <code>json_schema_input_type</code> <code>Any</code> <p>The input type of the function. This is only used to generate the appropriate JSON Schema (in validation mode).</p> <pre><code>from datetime import datetime\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, ValidationError, WrapValidator\n\ndef validate_timestamp(v, handler):\n    if v == 'now':\n        # we don't want to bother with further validation, just return the new value\n        return datetime.now()\n    try:\n        return handler(v)\n    except ValidationError:\n        # validation failed, in this case we want to return a default value\n        return datetime(2000, 1, 1)\n\nMyTimestamp = Annotated[datetime, WrapValidator(validate_timestamp)]\n\nclass Model(BaseModel):\n    a: MyTimestamp\n\nprint(Model(a='now').a)\n#&gt; 2032-01-02 03:04:05.000006\nprint(Model(a='invalid').a)\n#&gt; 2000-01-01 00:00:00\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelWrapValidatorHandler","title":"ModelWrapValidatorHandler","text":"<p>               Bases: <code>ValidatorFunctionWrapHandler</code>, <code>Protocol[_ModelTypeCo]</code></p> <p><code>@model_validator</code> decorated function handler argument type. This is used when <code>mode='wrap'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelWrapValidatorWithoutInfo","title":"ModelWrapValidatorWithoutInfo","text":"<p>               Bases: <code>Protocol[_ModelType]</code></p> <p>A <code>@model_validator</code> decorated function signature. This is used when <code>mode='wrap'</code> and the function does not have info argument.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelWrapValidator","title":"ModelWrapValidator","text":"<p>               Bases: <code>Protocol[_ModelType]</code></p> <p>A <code>@model_validator</code> decorated function signature. This is used when <code>mode='wrap'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.FreeModelBeforeValidatorWithoutInfo","title":"FreeModelBeforeValidatorWithoutInfo","text":"<p>               Bases: <code>Protocol</code></p> <p>A <code>@model_validator</code> decorated function signature. This is used when <code>mode='before'</code> and the function does not have info argument.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelBeforeValidatorWithoutInfo","title":"ModelBeforeValidatorWithoutInfo","text":"<p>               Bases: <code>Protocol</code></p> <p>A <code>@model_validator</code> decorated function signature. This is used when <code>mode='before'</code> and the function does not have info argument.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.FreeModelBeforeValidator","title":"FreeModelBeforeValidator","text":"<p>               Bases: <code>Protocol</code></p> <p>A <code>@model_validator</code> decorated function signature. This is used when <code>mode='before'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.ModelBeforeValidator","title":"ModelBeforeValidator","text":"<p>               Bases: <code>Protocol</code></p> <p>A <code>@model_validator</code> decorated function signature. This is used when <code>mode='before'</code>.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.InstanceOf","title":"InstanceOf  <code>dataclass</code>","text":"<pre><code>InstanceOf()\n</code></pre> <p>Generic type for annotating a type that is an instance of a given class.</p> Example <pre><code>from pydantic import BaseModel, InstanceOf\n\nclass Foo:\n    ...\n\nclass Bar(BaseModel):\n    foo: InstanceOf[Foo]\n\nBar(foo=Foo())\ntry:\n    Bar(foo=42)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    [\n    \u2502   {\n    \u2502   \u2502   'type': 'is_instance_of',\n    \u2502   \u2502   'loc': ('foo',),\n    \u2502   \u2502   'msg': 'Input should be an instance of Foo',\n    \u2502   \u2502   'input': 42,\n    \u2502   \u2502   'ctx': {'class': 'Foo'},\n    \u2502   \u2502   'url': 'https://errors.pydantic.dev/0.38.0/v/is_instance_of'\n    \u2502   }\n    ]\n    \"\"\"\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.SkipValidation","title":"SkipValidation  <code>dataclass</code>","text":"<pre><code>SkipValidation()\n</code></pre> <p>If this is applied as an annotation (e.g., via <code>x: Annotated[int, SkipValidation]</code>), validation will be     skipped. You can also use <code>SkipValidation[int]</code> as a shorthand for <code>Annotated[int, SkipValidation]</code>.</p> <p>This can be useful if you want to use a type annotation for documentation/IDE/type-checking purposes, and know that it is safe to skip validation for one or more of the fields.</p> <p>Because this converts the validation schema to <code>any_schema</code>, subsequent annotation-applied transformations may not have the expected effects. Therefore, when used, this annotation should generally be the final annotation applied to a type.</p>"},{"location":"api/functional_validators/#pydantic.functional_validators.field_validator","title":"field_validator","text":"<pre><code>field_validator(\n    field: str,\n    /,\n    *fields: str,\n    mode: FieldValidatorModes = \"after\",\n    check_fields: bool | None = None,\n    json_schema_input_type: Any = PydanticUndefined,\n) -&gt; Callable[[Any], Any]\n</code></pre> <p>Usage Documentation</p> <p>Field validators</p> <p>Decorate methods on the class indicating that they should be used to validate fields.</p> <p>Example usage: <pre><code>from typing import Any\n\nfrom pydantic import (\n    BaseModel,\n    ValidationError,\n    field_validator,\n)\n\nclass Model(BaseModel):\n    a: str\n\n    @field_validator('a')\n    @classmethod\n    def ensure_foobar(cls, v: Any):\n        if 'foobar' not in v:\n            raise ValueError('\"foobar\" not found in a')\n        return v\n\nprint(repr(Model(a='this is foobar good')))\n#&gt; Model(a='this is foobar good')\n\ntry:\n    Model(a='snap')\nexcept ValidationError as exc_info:\n    print(exc_info)\n    '''\n    1 validation error for Model\n    a\n      Value error, \"foobar\" not found in a [type=value_error, input_value='snap', input_type=str]\n    '''\n</code></pre></p> <p>For more in depth examples, see Field Validators.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>str</code> <p>The first field the <code>field_validator</code> should be called on; this is separate from <code>fields</code> to ensure an error is raised if you don't pass at least one.</p> required <code>*fields</code> <code>str</code> <p>Additional field(s) the <code>field_validator</code> should be called on.</p> <code>()</code> <code>mode</code> <code>FieldValidatorModes</code> <p>Specifies whether to validate the fields before or after validation.</p> <code>'after'</code> <code>check_fields</code> <code>bool | None</code> <p>Whether to check that the fields actually exist on the model.</p> <code>None</code> <code>json_schema_input_type</code> <code>Any</code> <p>The input type of the function. This is only used to generate the appropriate JSON Schema (in validation mode) and can only specified when <code>mode</code> is either <code>'before'</code>, <code>'plain'</code> or <code>'wrap'</code>.</p> <code>PydanticUndefined</code> <p>Returns:</p> Type Description <code>Callable[[Any], Any]</code> <p>A decorator that can be used to decorate a function to be used as a field_validator.</p> <p>Raises:</p> Type Description <code>PydanticUserError</code> <ul> <li>If <code>@field_validator</code> is used bare (with no fields).</li> <li>If the args passed to <code>@field_validator</code> as fields are not strings.</li> <li>If <code>@field_validator</code> applied to instance methods.</li> </ul> Source code in <code>pydantic/functional_validators.py</code> <pre><code>def field_validator(\n    field: str,\n    /,\n    *fields: str,\n    mode: FieldValidatorModes = 'after',\n    check_fields: bool | None = None,\n    json_schema_input_type: Any = PydanticUndefined,\n) -&gt; Callable[[Any], Any]:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/validators/#field-validators\n\n    Decorate methods on the class indicating that they should be used to validate fields.\n\n    Example usage:\n    ```py\n    from typing import Any\n\n    from pydantic import (\n        BaseModel,\n        ValidationError,\n        field_validator,\n    )\n\n    class Model(BaseModel):\n        a: str\n\n        @field_validator('a')\n        @classmethod\n        def ensure_foobar(cls, v: Any):\n            if 'foobar' not in v:\n                raise ValueError('\"foobar\" not found in a')\n            return v\n\n    print(repr(Model(a='this is foobar good')))\n    #&gt; Model(a='this is foobar good')\n\n    try:\n        Model(a='snap')\n    except ValidationError as exc_info:\n        print(exc_info)\n        '''\n        1 validation error for Model\n        a\n          Value error, \"foobar\" not found in a [type=value_error, input_value='snap', input_type=str]\n        '''\n    ```\n\n    For more in depth examples, see [Field Validators](../concepts/validators.md#field-validators).\n\n    Args:\n        field: The first field the `field_validator` should be called on; this is separate\n            from `fields` to ensure an error is raised if you don't pass at least one.\n        *fields: Additional field(s) the `field_validator` should be called on.\n        mode: Specifies whether to validate the fields before or after validation.\n        check_fields: Whether to check that the fields actually exist on the model.\n        json_schema_input_type: The input type of the function. This is only used to generate\n            the appropriate JSON Schema (in validation mode) and can only specified\n            when `mode` is either `'before'`, `'plain'` or `'wrap'`.\n\n    Returns:\n        A decorator that can be used to decorate a function to be used as a field_validator.\n\n    Raises:\n        PydanticUserError:\n            - If `@field_validator` is used bare (with no fields).\n            - If the args passed to `@field_validator` as fields are not strings.\n            - If `@field_validator` applied to instance methods.\n    \"\"\"\n    if isinstance(field, FunctionType):\n        raise PydanticUserError(\n            '`@field_validator` should be used with fields and keyword arguments, not bare. '\n            \"E.g. usage should be `@validator('&lt;field_name&gt;', ...)`\",\n            code='validator-no-fields',\n        )\n\n    if mode not in ('before', 'plain', 'wrap') and json_schema_input_type is not PydanticUndefined:\n        raise PydanticUserError(\n            f\"`json_schema_input_type` can't be used when mode is set to {mode!r}\",\n            code='validator-input-type',\n        )\n\n    if json_schema_input_type is PydanticUndefined and mode == 'plain':\n        json_schema_input_type = Any\n\n    fields = field, *fields\n    if not all(isinstance(field, str) for field in fields):\n        raise PydanticUserError(\n            '`@field_validator` fields should be passed as separate string args. '\n            \"E.g. usage should be `@validator('&lt;field_name_1&gt;', '&lt;field_name_2&gt;', ...)`\",\n            code='validator-invalid-fields',\n        )\n\n    def dec(\n        f: Callable[..., Any] | staticmethod[Any, Any] | classmethod[Any, Any, Any],\n    ) -&gt; _decorators.PydanticDescriptorProxy[Any]:\n        if _decorators.is_instance_method_from_sig(f):\n            raise PydanticUserError(\n                '`@field_validator` cannot be applied to instance methods', code='validator-instance-method'\n            )\n\n        # auto apply the @classmethod decorator\n        f = _decorators.ensure_classmethod_based_on_signature(f)\n\n        dec_info = _decorators.FieldValidatorDecoratorInfo(\n            fields=fields, mode=mode, check_fields=check_fields, json_schema_input_type=json_schema_input_type\n        )\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    return dec\n</code></pre>"},{"location":"api/functional_validators/#pydantic.functional_validators.model_validator","title":"model_validator","text":"<pre><code>model_validator(\n    *, mode: Literal[\"wrap\", \"before\", \"after\"]\n) -&gt; Any\n</code></pre> <p>Usage Documentation</p> <p>Model validators</p> <p>Decorate model methods for validation purposes.</p> <p>Example usage: <pre><code>from typing_extensions import Self\n\nfrom pydantic import BaseModel, ValidationError, model_validator\n\nclass Square(BaseModel):\n    width: float\n    height: float\n\n    @model_validator(mode='after')\n    def verify_square(self) -&gt; Self:\n        if self.width != self.height:\n            raise ValueError('width and height do not match')\n        return self\n\ns = Square(width=1, height=1)\nprint(repr(s))\n#&gt; Square(width=1.0, height=1.0)\n\ntry:\n    Square(width=1, height=2)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Square\n      Value error, width and height do not match [type=value_error, input_value={'width': 1, 'height': 2}, input_type=dict]\n    '''\n</code></pre></p> <p>For more in depth examples, see Model Validators.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>Literal['wrap', 'before', 'after']</code> <p>A required string literal that specifies the validation mode. It can be one of the following: 'wrap', 'before', or 'after'.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>A decorator that can be used to decorate a function to be used as a model validator.</p> Source code in <code>pydantic/functional_validators.py</code> <pre><code>def model_validator(\n    *,\n    mode: Literal['wrap', 'before', 'after'],\n) -&gt; Any:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/validators/#model-validators\n\n    Decorate model methods for validation purposes.\n\n    Example usage:\n    ```py\n    from typing_extensions import Self\n\n    from pydantic import BaseModel, ValidationError, model_validator\n\n    class Square(BaseModel):\n        width: float\n        height: float\n\n        @model_validator(mode='after')\n        def verify_square(self) -&gt; Self:\n            if self.width != self.height:\n                raise ValueError('width and height do not match')\n            return self\n\n    s = Square(width=1, height=1)\n    print(repr(s))\n    #&gt; Square(width=1.0, height=1.0)\n\n    try:\n        Square(width=1, height=2)\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Square\n          Value error, width and height do not match [type=value_error, input_value={'width': 1, 'height': 2}, input_type=dict]\n        '''\n    ```\n\n    For more in depth examples, see [Model Validators](../concepts/validators.md#model-validators).\n\n    Args:\n        mode: A required string literal that specifies the validation mode.\n            It can be one of the following: 'wrap', 'before', or 'after'.\n\n    Returns:\n        A decorator that can be used to decorate a function to be used as a model validator.\n    \"\"\"\n\n    def dec(f: Any) -&gt; _decorators.PydanticDescriptorProxy[Any]:\n        # auto apply the @classmethod decorator\n        f = _decorators.ensure_classmethod_based_on_signature(f)\n        dec_info = _decorators.ModelValidatorDecoratorInfo(mode=mode)\n        return _decorators.PydanticDescriptorProxy(f, dec_info)\n\n    return dec\n</code></pre>"},{"location":"api/json_schema/","title":"JSON Schema","text":"<p>Usage Documentation</p> <p>Json Schema</p> <p>The <code>json_schema</code> module contains classes and functions to allow the way JSON Schema is generated to be customized.</p> <p>In general you shouldn't need to use this module directly; instead, you can use <code>BaseModel.model_json_schema</code> and <code>TypeAdapter.json_schema</code>.</p>"},{"location":"api/json_schema/#pydantic.json_schema.CoreSchemaOrFieldType","title":"CoreSchemaOrFieldType  <code>module-attribute</code>","text":"<pre><code>CoreSchemaOrFieldType = Literal[\n    CoreSchemaType, CoreSchemaFieldType\n]\n</code></pre> <p>A type alias for defined schema types that represents a union of <code>core_schema.CoreSchemaType</code> and <code>core_schema.CoreSchemaFieldType</code>.</p>"},{"location":"api/json_schema/#pydantic.json_schema.JsonSchemaValue","title":"JsonSchemaValue  <code>module-attribute</code>","text":"<pre><code>JsonSchemaValue = Dict[str, Any]\n</code></pre> <p>A type alias for a JSON schema value. This is a dictionary of string keys to arbitrary JSON values.</p>"},{"location":"api/json_schema/#pydantic.json_schema.JsonSchemaMode","title":"JsonSchemaMode  <code>module-attribute</code>","text":"<pre><code>JsonSchemaMode = Literal['validation', 'serialization']\n</code></pre> <p>A type alias that represents the mode of a JSON schema; either 'validation' or 'serialization'.</p> <p>For some types, the inputs to validation differ from the outputs of serialization. For example, computed fields will only be present when serializing, and should not be provided when validating. This flag provides a way to indicate whether you want the JSON schema required for validation inputs, or that will be matched by serialization outputs.</p>"},{"location":"api/json_schema/#pydantic.json_schema.JsonSchemaWarningKind","title":"JsonSchemaWarningKind  <code>module-attribute</code>","text":"<pre><code>JsonSchemaWarningKind = Literal[\n    \"skipped-choice\", \"non-serializable-default\"\n]\n</code></pre> <p>A type alias representing the kinds of warnings that can be emitted during JSON schema generation.</p> <p>See <code>GenerateJsonSchema.render_warning_message</code> for more details.</p>"},{"location":"api/json_schema/#pydantic.json_schema.DEFAULT_REF_TEMPLATE","title":"DEFAULT_REF_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>DEFAULT_REF_TEMPLATE = '#/$defs/{model}'\n</code></pre> <p>The default format string used to generate reference names.</p>"},{"location":"api/json_schema/#pydantic.json_schema.PydanticJsonSchemaWarning","title":"PydanticJsonSchemaWarning","text":"<p>               Bases: <code>UserWarning</code></p> <p>This class is used to emit warnings produced during JSON schema generation. See the <code>GenerateJsonSchema.emit_warning</code> and <code>GenerateJsonSchema.render_warning_message</code> methods for more details; these can be overridden to control warning behavior.</p>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema","title":"GenerateJsonSchema","text":"<pre><code>GenerateJsonSchema(\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n)\n</code></pre> <p>Usage Documentation</p> <p>Customizing the JSON Schema Generation Process</p> <p>A class for generating JSON schemas.</p> <p>This class generates JSON schemas based on configured parameters. The default schema dialect is https://json-schema.org/draft/2020-12/schema. The class uses <code>by_alias</code> to configure how fields with multiple names are handled and <code>ref_template</code> to format reference names.</p> <p>Attributes:</p> Name Type Description <code>schema_dialect</code> <p>The JSON schema dialect used to generate the schema. See Declaring a Dialect in the JSON Schema documentation for more information about dialects.</p> <code>ignored_warning_kinds</code> <code>set[JsonSchemaWarningKind]</code> <p>Warnings to ignore when generating the schema. <code>self.render_warning_message</code> will do nothing if its argument <code>kind</code> is in <code>ignored_warning_kinds</code>; this value can be modified on subclasses to easily control which warnings are emitted.</p> <code>by_alias</code> <p>Whether to use field aliases when generating the schema.</p> <code>ref_template</code> <p>The format string used when generating reference names.</p> <code>core_to_json_refs</code> <code>dict[CoreModeRef, JsonRef]</code> <p>A mapping of core refs to JSON refs.</p> <code>core_to_defs_refs</code> <code>dict[CoreModeRef, DefsRef]</code> <p>A mapping of core refs to definition refs.</p> <code>defs_to_core_refs</code> <code>dict[DefsRef, CoreModeRef]</code> <p>A mapping of definition refs to core refs.</p> <code>json_to_defs_refs</code> <code>dict[JsonRef, DefsRef]</code> <p>A mapping of JSON refs to definition refs.</p> <code>definitions</code> <code>dict[DefsRef, JsonSchemaValue]</code> <p>Definitions in the schema.</p> <p>Parameters:</p> Name Type Description Default <code>by_alias</code> <code>bool</code> <p>Whether to use field aliases in the generated schemas.</p> <code>True</code> <code>ref_template</code> <code>str</code> <p>The format string to use when generating reference names.</p> <code>DEFAULT_REF_TEMPLATE</code> <p>Raises:</p> Type Description <code>JsonSchemaError</code> <p>If the instance of the class is inadvertently re-used after generating a schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def __init__(self, by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE):\n    self.by_alias = by_alias\n    self.ref_template = ref_template\n\n    self.core_to_json_refs: dict[CoreModeRef, JsonRef] = {}\n    self.core_to_defs_refs: dict[CoreModeRef, DefsRef] = {}\n    self.defs_to_core_refs: dict[DefsRef, CoreModeRef] = {}\n    self.json_to_defs_refs: dict[JsonRef, DefsRef] = {}\n\n    self.definitions: dict[DefsRef, JsonSchemaValue] = {}\n    self._config_wrapper_stack = _config.ConfigWrapperStack(_config.ConfigWrapper({}))\n\n    self._mode: JsonSchemaMode = 'validation'\n\n    # The following includes a mapping of a fully-unique defs ref choice to a list of preferred\n    # alternatives, which are generally simpler, such as only including the class name.\n    # At the end of schema generation, we use these to produce a JSON schema with more human-readable\n    # definitions, which would also work better in a generated OpenAPI client, etc.\n    self._prioritized_defsref_choices: dict[DefsRef, list[DefsRef]] = {}\n    self._collision_counter: dict[str, int] = defaultdict(int)\n    self._collision_index: dict[str, int] = {}\n\n    self._schema_type_to_method = self.build_schema_type_to_method()\n\n    # When we encounter definitions we need to try to build them immediately\n    # so that they are available schemas that reference them\n    # But it's possible that CoreSchema was never going to be used\n    # (e.g. because the CoreSchema that references short circuits is JSON schema generation without needing\n    #  the reference) so instead of failing altogether if we can't build a definition we\n    # store the error raised and re-throw it if we end up needing that def\n    self._core_defs_invalid_for_json_schema: dict[DefsRef, PydanticInvalidForJsonSchema] = {}\n\n    # This changes to True after generating a schema, to prevent issues caused by accidental re-use\n    # of a single instance of a schema generator\n    self._used = False\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.ValidationsMapping","title":"ValidationsMapping","text":"<p>This class just contains mappings from core_schema attribute names to the corresponding JSON schema attribute names. While I suspect it is unlikely to be necessary, you can in principle override this class in a subclass of GenerateJsonSchema (by inheriting from GenerateJsonSchema.ValidationsMapping) to change these mappings.</p>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.build_schema_type_to_method","title":"build_schema_type_to_method","text":"<pre><code>build_schema_type_to_method() -&gt; dict[\n    CoreSchemaOrFieldType,\n    Callable[[CoreSchemaOrField], JsonSchemaValue],\n]\n</code></pre> <p>Builds a dictionary mapping fields to methods for generating JSON schemas.</p> <p>Returns:</p> Type Description <code>dict[CoreSchemaOrFieldType, Callable[[CoreSchemaOrField], JsonSchemaValue]]</code> <p>A dictionary containing the mapping of <code>CoreSchemaOrFieldType</code> to a handler method.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If no method has been defined for generating a JSON schema for a given pydantic core schema type.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def build_schema_type_to_method(\n    self,\n) -&gt; dict[CoreSchemaOrFieldType, Callable[[CoreSchemaOrField], JsonSchemaValue]]:\n    \"\"\"Builds a dictionary mapping fields to methods for generating JSON schemas.\n\n    Returns:\n        A dictionary containing the mapping of `CoreSchemaOrFieldType` to a handler method.\n\n    Raises:\n        TypeError: If no method has been defined for generating a JSON schema for a given pydantic core schema type.\n    \"\"\"\n    mapping: dict[CoreSchemaOrFieldType, Callable[[CoreSchemaOrField], JsonSchemaValue]] = {}\n    core_schema_types: list[CoreSchemaOrFieldType] = _typing_extra.all_literal_values(\n        CoreSchemaOrFieldType  # type: ignore\n    )\n    for key in core_schema_types:\n        method_name = f\"{key.replace('-', '_')}_schema\"\n        try:\n            mapping[key] = getattr(self, method_name)\n        except AttributeError as e:  # pragma: no cover\n            raise TypeError(\n                f'No method for generating JsonSchema for core_schema.type={key!r} '\n                f'(expected: {type(self).__name__}.{method_name})'\n            ) from e\n    return mapping\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.generate_definitions","title":"generate_definitions","text":"<pre><code>generate_definitions(\n    inputs: Sequence[\n        tuple[JsonSchemaKeyT, JsonSchemaMode, CoreSchema]\n    ]\n) -&gt; tuple[\n    dict[\n        tuple[JsonSchemaKeyT, JsonSchemaMode],\n        JsonSchemaValue,\n    ],\n    dict[DefsRef, JsonSchemaValue],\n]\n</code></pre> <p>Generates JSON schema definitions from a list of core schemas, pairing the generated definitions with a mapping that links the input keys to the definition references.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Sequence[tuple[JsonSchemaKeyT, JsonSchemaMode, CoreSchema]]</code> <p>A sequence of tuples, where:</p> <ul> <li>The first element is a JSON schema key type.</li> <li>The second element is the JSON mode: either 'validation' or 'serialization'.</li> <li>The third element is a core schema.</li> </ul> required <p>Returns:</p> Type Description <code>tuple[dict[tuple[JsonSchemaKeyT, JsonSchemaMode], JsonSchemaValue], dict[DefsRef, JsonSchemaValue]]</code> <p>A tuple where:</p> <ul> <li>The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and     whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have     JsonRef references to definitions that are defined in the second returned element.)</li> <li>The second element is a dictionary whose keys are definition references for the JSON schemas     from the first returned element, and whose values are the actual JSON schema definitions.</li> </ul> <p>Raises:</p> Type Description <code>PydanticUserError</code> <p>Raised if the JSON schema generator has already been used to generate a JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def generate_definitions(\n    self, inputs: Sequence[tuple[JsonSchemaKeyT, JsonSchemaMode, core_schema.CoreSchema]]\n) -&gt; tuple[dict[tuple[JsonSchemaKeyT, JsonSchemaMode], JsonSchemaValue], dict[DefsRef, JsonSchemaValue]]:\n    \"\"\"Generates JSON schema definitions from a list of core schemas, pairing the generated definitions with a\n    mapping that links the input keys to the definition references.\n\n    Args:\n        inputs: A sequence of tuples, where:\n\n            - The first element is a JSON schema key type.\n            - The second element is the JSON mode: either 'validation' or 'serialization'.\n            - The third element is a core schema.\n\n    Returns:\n        A tuple where:\n\n            - The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and\n                whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have\n                JsonRef references to definitions that are defined in the second returned element.)\n            - The second element is a dictionary whose keys are definition references for the JSON schemas\n                from the first returned element, and whose values are the actual JSON schema definitions.\n\n    Raises:\n        PydanticUserError: Raised if the JSON schema generator has already been used to generate a JSON schema.\n    \"\"\"\n    if self._used:\n        raise PydanticUserError(\n            'This JSON schema generator has already been used to generate a JSON schema. '\n            f'You must create a new instance of {type(self).__name__} to generate a new JSON schema.',\n            code='json-schema-already-used',\n        )\n\n    for _, mode, schema in inputs:\n        self._mode = mode\n        self.generate_inner(schema)\n\n    definitions_remapping = self._build_definitions_remapping()\n\n    json_schemas_map: dict[tuple[JsonSchemaKeyT, JsonSchemaMode], DefsRef] = {}\n    for key, mode, schema in inputs:\n        self._mode = mode\n        json_schema = self.generate_inner(schema)\n        json_schemas_map[(key, mode)] = definitions_remapping.remap_json_schema(json_schema)\n\n    json_schema = {'$defs': self.definitions}\n    json_schema = definitions_remapping.remap_json_schema(json_schema)\n    self._used = True\n    return json_schemas_map, _sort_json_schema(json_schema['$defs'])  # type: ignore\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.generate","title":"generate","text":"<pre><code>generate(\n    schema: CoreSchema, mode: JsonSchemaMode = \"validation\"\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema for a specified schema in a specified mode.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>A Pydantic model.</p> required <code>mode</code> <code>JsonSchemaMode</code> <p>The mode in which to generate the schema. Defaults to 'validation'.</p> <code>'validation'</code> <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>A JSON schema representing the specified schema.</p> <p>Raises:</p> Type Description <code>PydanticUserError</code> <p>If the JSON schema generator has already been used to generate a JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def generate(self, schema: CoreSchema, mode: JsonSchemaMode = 'validation') -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema for a specified schema in a specified mode.\n\n    Args:\n        schema: A Pydantic model.\n        mode: The mode in which to generate the schema. Defaults to 'validation'.\n\n    Returns:\n        A JSON schema representing the specified schema.\n\n    Raises:\n        PydanticUserError: If the JSON schema generator has already been used to generate a JSON schema.\n    \"\"\"\n    self._mode = mode\n    if self._used:\n        raise PydanticUserError(\n            'This JSON schema generator has already been used to generate a JSON schema. '\n            f'You must create a new instance of {type(self).__name__} to generate a new JSON schema.',\n            code='json-schema-already-used',\n        )\n\n    json_schema: JsonSchemaValue = self.generate_inner(schema)\n    json_ref_counts = self.get_json_ref_counts(json_schema)\n\n    ref = cast(JsonRef, json_schema.get('$ref'))\n    while ref is not None:  # may need to unpack multiple levels\n        ref_json_schema = self.get_schema_from_definitions(ref)\n        if json_ref_counts[ref] == 1 and ref_json_schema is not None and len(json_schema) == 1:\n            # \"Unpack\" the ref since this is the only reference and there are no sibling keys\n            json_schema = ref_json_schema.copy()  # copy to prevent recursive dict reference\n            json_ref_counts[ref] -= 1\n            ref = cast(JsonRef, json_schema.get('$ref'))\n        ref = None\n\n    self._garbage_collect_definitions(json_schema)\n    definitions_remapping = self._build_definitions_remapping()\n\n    if self.definitions:\n        json_schema['$defs'] = self.definitions\n\n    json_schema = definitions_remapping.remap_json_schema(json_schema)\n\n    # For now, we will not set the $schema key. However, if desired, this can be easily added by overriding\n    # this method and adding the following line after a call to super().generate(schema):\n    # json_schema['$schema'] = self.schema_dialect\n\n    self._used = True\n    return _sort_json_schema(json_schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.generate_inner","title":"generate_inner","text":"<pre><code>generate_inner(\n    schema: CoreSchemaOrField,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema for a given core schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchemaOrField</code> <p>The given core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def generate_inner(self, schema: CoreSchemaOrField) -&gt; JsonSchemaValue:  # noqa: C901\n    \"\"\"Generates a JSON schema for a given core schema.\n\n    Args:\n        schema: The given core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    # If a schema with the same CoreRef has been handled, just return a reference to it\n    # Note that this assumes that it will _never_ be the case that the same CoreRef is used\n    # on types that should have different JSON schemas\n    if 'ref' in schema:\n        core_ref = CoreRef(schema['ref'])  # type: ignore[typeddict-item]\n        core_mode_ref = (core_ref, self.mode)\n        if core_mode_ref in self.core_to_defs_refs and self.core_to_defs_refs[core_mode_ref] in self.definitions:\n            return {'$ref': self.core_to_json_refs[core_mode_ref]}\n\n    # Generate the JSON schema, accounting for the json_schema_override and core_schema_override\n    metadata_handler = _core_metadata.CoreMetadataHandler(schema)\n\n    def populate_defs(core_schema: CoreSchema, json_schema: JsonSchemaValue) -&gt; JsonSchemaValue:\n        if 'ref' in core_schema:\n            core_ref = CoreRef(core_schema['ref'])  # type: ignore[typeddict-item]\n            defs_ref, ref_json_schema = self.get_cache_defs_ref_schema(core_ref)\n            json_ref = JsonRef(ref_json_schema['$ref'])\n            self.json_to_defs_refs[json_ref] = defs_ref\n            # Replace the schema if it's not a reference to itself\n            # What we want to avoid is having the def be just a ref to itself\n            # which is what would happen if we blindly assigned any\n            if json_schema.get('$ref', None) != json_ref:\n                self.definitions[defs_ref] = json_schema\n                self._core_defs_invalid_for_json_schema.pop(defs_ref, None)\n            json_schema = ref_json_schema\n        return json_schema\n\n    def handler_func(schema_or_field: CoreSchemaOrField) -&gt; JsonSchemaValue:\n        \"\"\"Generate a JSON schema based on the input schema.\n\n        Args:\n            schema_or_field: The core schema to generate a JSON schema from.\n\n        Returns:\n            The generated JSON schema.\n\n        Raises:\n            TypeError: If an unexpected schema type is encountered.\n        \"\"\"\n        # Generate the core-schema-type-specific bits of the schema generation:\n        json_schema: JsonSchemaValue | None = None\n        if self.mode == 'serialization' and 'serialization' in schema_or_field:\n            # In this case, we skip the JSON Schema generation of the schema\n            # and use the `'serialization'` schema instead (canonical example:\n            # `Annotated[int, PlainSerializer(str)]`).\n            ser_schema = schema_or_field['serialization']  # type: ignore\n            json_schema = self.ser_schema(ser_schema)\n\n            # It might be that the 'serialization'` is skipped depending on `when_used`.\n            # This is only relevant for `nullable` schemas though, so we special case here.\n            if (\n                json_schema is not None\n                and ser_schema.get('when_used') in ('unless-none', 'json-unless-none')\n                and schema_or_field['type'] == 'nullable'\n            ):\n                json_schema = self.get_flattened_anyof([{'type': 'null'}, json_schema])\n        if json_schema is None:\n            if _core_utils.is_core_schema(schema_or_field) or _core_utils.is_core_schema_field(schema_or_field):\n                generate_for_schema_type = self._schema_type_to_method[schema_or_field['type']]\n                json_schema = generate_for_schema_type(schema_or_field)\n            else:\n                raise TypeError(f'Unexpected schema type: schema={schema_or_field}')\n        if _core_utils.is_core_schema(schema_or_field):\n            json_schema = populate_defs(schema_or_field, json_schema)\n        return json_schema\n\n    current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(self, handler_func)\n\n    for js_modify_function in metadata_handler.metadata.get('pydantic_js_functions', ()):\n\n        def new_handler_func(\n            schema_or_field: CoreSchemaOrField,\n            current_handler: GetJsonSchemaHandler = current_handler,\n            js_modify_function: GetJsonSchemaFunction = js_modify_function,\n        ) -&gt; JsonSchemaValue:\n            json_schema = js_modify_function(schema_or_field, current_handler)\n            if _core_utils.is_core_schema(schema_or_field):\n                json_schema = populate_defs(schema_or_field, json_schema)\n            original_schema = current_handler.resolve_ref_schema(json_schema)\n            ref = json_schema.pop('$ref', None)\n            if ref and json_schema:\n                original_schema.update(json_schema)\n            return original_schema\n\n        current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(self, new_handler_func)\n\n    for js_modify_function in metadata_handler.metadata.get('pydantic_js_annotation_functions', ()):\n\n        def new_handler_func(\n            schema_or_field: CoreSchemaOrField,\n            current_handler: GetJsonSchemaHandler = current_handler,\n            js_modify_function: GetJsonSchemaFunction = js_modify_function,\n        ) -&gt; JsonSchemaValue:\n            json_schema = js_modify_function(schema_or_field, current_handler)\n            if _core_utils.is_core_schema(schema_or_field):\n                json_schema = populate_defs(schema_or_field, json_schema)\n            return json_schema\n\n        current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(self, new_handler_func)\n\n    json_schema = current_handler(schema)\n    if _core_utils.is_core_schema(schema):\n        json_schema = populate_defs(schema, json_schema)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.any_schema","title":"any_schema","text":"<pre><code>any_schema(schema: AnySchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches any value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>AnySchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def any_schema(self, schema: core_schema.AnySchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches any value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.none_schema","title":"none_schema","text":"<pre><code>none_schema(schema: NoneSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>NoneSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def none_schema(self, schema: core_schema.NoneSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches `None`.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'null'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.bool_schema","title":"bool_schema","text":"<pre><code>bool_schema(schema: BoolSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a bool value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>BoolSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def bool_schema(self, schema: core_schema.BoolSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a bool value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'boolean'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.int_schema","title":"int_schema","text":"<pre><code>int_schema(schema: IntSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches an int value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>IntSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def int_schema(self, schema: core_schema.IntSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches an int value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema: dict[str, Any] = {'type': 'integer'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.numeric)\n    json_schema = {k: v for k, v in json_schema.items() if v not in {math.inf, -math.inf}}\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.float_schema","title":"float_schema","text":"<pre><code>float_schema(schema: FloatSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a float value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>FloatSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def float_schema(self, schema: core_schema.FloatSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a float value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema: dict[str, Any] = {'type': 'number'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.numeric)\n    json_schema = {k: v for k, v in json_schema.items() if v not in {math.inf, -math.inf}}\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.decimal_schema","title":"decimal_schema","text":"<pre><code>decimal_schema(schema: DecimalSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a decimal value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DecimalSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def decimal_schema(self, schema: core_schema.DecimalSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a decimal value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema = self.str_schema(core_schema.str_schema())\n    if self.mode == 'validation':\n        multiple_of = schema.get('multiple_of')\n        le = schema.get('le')\n        ge = schema.get('ge')\n        lt = schema.get('lt')\n        gt = schema.get('gt')\n        json_schema = {\n            'anyOf': [\n                self.float_schema(\n                    core_schema.float_schema(\n                        allow_inf_nan=schema.get('allow_inf_nan'),\n                        multiple_of=None if multiple_of is None else float(multiple_of),\n                        le=None if le is None else float(le),\n                        ge=None if ge is None else float(ge),\n                        lt=None if lt is None else float(lt),\n                        gt=None if gt is None else float(gt),\n                    )\n                ),\n                json_schema,\n            ],\n        }\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.str_schema","title":"str_schema","text":"<pre><code>str_schema(schema: StringSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a string value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>StringSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def str_schema(self, schema: core_schema.StringSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a string value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema = {'type': 'string'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.string)\n    if isinstance(json_schema.get('pattern'), Pattern):\n        # TODO: should we add regex flags to the pattern?\n        json_schema['pattern'] = json_schema.get('pattern').pattern  # type: ignore\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.bytes_schema","title":"bytes_schema","text":"<pre><code>bytes_schema(schema: BytesSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a bytes value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>BytesSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def bytes_schema(self, schema: core_schema.BytesSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a bytes value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema = {'type': 'string', 'format': 'base64url' if self._config.ser_json_bytes == 'base64' else 'binary'}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.bytes)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.date_schema","title":"date_schema","text":"<pre><code>date_schema(schema: DateSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a date value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DateSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def date_schema(self, schema: core_schema.DateSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a date value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'string', 'format': 'date'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.time_schema","title":"time_schema","text":"<pre><code>time_schema(schema: TimeSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a time value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>TimeSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def time_schema(self, schema: core_schema.TimeSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a time value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'string', 'format': 'time'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.datetime_schema","title":"datetime_schema","text":"<pre><code>datetime_schema(schema: DatetimeSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a datetime value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DatetimeSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def datetime_schema(self, schema: core_schema.DatetimeSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a datetime value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'string', 'format': 'date-time'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.timedelta_schema","title":"timedelta_schema","text":"<pre><code>timedelta_schema(\n    schema: TimedeltaSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a timedelta value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>TimedeltaSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def timedelta_schema(self, schema: core_schema.TimedeltaSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a timedelta value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    if self._config.ser_json_timedelta == 'float':\n        return {'type': 'number'}\n    return {'type': 'string', 'format': 'duration'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.literal_schema","title":"literal_schema","text":"<pre><code>literal_schema(schema: LiteralSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a literal value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>LiteralSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def literal_schema(self, schema: core_schema.LiteralSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a literal value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    expected = [v.value if isinstance(v, Enum) else v for v in schema['expected']]\n    # jsonify the expected values\n    expected = [to_jsonable_python(v) for v in expected]\n\n    result: dict[str, Any] = {'enum': expected}\n    if len(expected) == 1:\n        result['const'] = expected[0]\n\n    types = {type(e) for e in expected}\n    if types == {str}:\n        result['type'] = 'string'\n    elif types == {int}:\n        result['type'] = 'integer'\n    elif types == {float}:\n        result['type'] = 'number'\n    elif types == {bool}:\n        result['type'] = 'boolean'\n    elif types == {list}:\n        result['type'] = 'array'\n    elif types == {type(None)}:\n        result['type'] = 'null'\n    return result\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.enum_schema","title":"enum_schema","text":"<pre><code>enum_schema(schema: EnumSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches an Enum value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>EnumSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def enum_schema(self, schema: core_schema.EnumSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches an Enum value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    enum_type = schema['cls']\n    description = None if not enum_type.__doc__ else inspect.cleandoc(enum_type.__doc__)\n    if (\n        description == 'An enumeration.'\n    ):  # This is the default value provided by enum.EnumMeta.__new__; don't use it\n        description = None\n    result: dict[str, Any] = {'title': enum_type.__name__, 'description': description}\n    result = {k: v for k, v in result.items() if v is not None}\n\n    expected = [to_jsonable_python(v.value) for v in schema['members']]\n\n    result['enum'] = expected\n    if len(expected) == 1:\n        result['const'] = expected[0]\n\n    types = {type(e) for e in expected}\n    if isinstance(enum_type, str) or types == {str}:\n        result['type'] = 'string'\n    elif isinstance(enum_type, int) or types == {int}:\n        result['type'] = 'integer'\n    elif isinstance(enum_type, float) or types == {float}:\n        result['type'] = 'number'\n    elif types == {bool}:\n        result['type'] = 'boolean'\n    elif types == {list}:\n        result['type'] = 'array'\n\n    return result\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.is_instance_schema","title":"is_instance_schema","text":"<pre><code>is_instance_schema(\n    schema: IsInstanceSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Handles JSON schema generation for a core schema that checks if a value is an instance of a class.</p> <p>Unless overridden in a subclass, this raises an error.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>IsInstanceSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def is_instance_schema(self, schema: core_schema.IsInstanceSchema) -&gt; JsonSchemaValue:\n    \"\"\"Handles JSON schema generation for a core schema that checks if a value is an instance of a class.\n\n    Unless overridden in a subclass, this raises an error.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.handle_invalid_for_json_schema(schema, f'core_schema.IsInstanceSchema ({schema[\"cls\"]})')\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.is_subclass_schema","title":"is_subclass_schema","text":"<pre><code>is_subclass_schema(\n    schema: IsSubclassSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Handles JSON schema generation for a core schema that checks if a value is a subclass of a class.</p> <p>For backwards compatibility with v1, this does not raise an error, but can be overridden to change this.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>IsSubclassSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def is_subclass_schema(self, schema: core_schema.IsSubclassSchema) -&gt; JsonSchemaValue:\n    \"\"\"Handles JSON schema generation for a core schema that checks if a value is a subclass of a class.\n\n    For backwards compatibility with v1, this does not raise an error, but can be overridden to change this.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    # Note: This is for compatibility with V1; you can override if you want different behavior.\n    return {}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.callable_schema","title":"callable_schema","text":"<pre><code>callable_schema(schema: CallableSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a callable value.</p> <p>Unless overridden in a subclass, this raises an error.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CallableSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def callable_schema(self, schema: core_schema.CallableSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a callable value.\n\n    Unless overridden in a subclass, this raises an error.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.handle_invalid_for_json_schema(schema, 'core_schema.CallableSchema')\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.list_schema","title":"list_schema","text":"<pre><code>list_schema(schema: ListSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Returns a schema that matches a list schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ListSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def list_schema(self, schema: core_schema.ListSchema) -&gt; JsonSchemaValue:\n    \"\"\"Returns a schema that matches a list schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    items_schema = {} if 'items_schema' not in schema else self.generate_inner(schema['items_schema'])\n    json_schema = {'type': 'array', 'items': items_schema}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.array)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.tuple_positional_schema","title":"tuple_positional_schema","text":"<pre><code>tuple_positional_schema(\n    schema: TupleSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Replaced by <code>tuple_schema</code>.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>@deprecated('`tuple_positional_schema` is deprecated. Use `tuple_schema` instead.', category=None)\n@final\ndef tuple_positional_schema(self, schema: core_schema.TupleSchema) -&gt; JsonSchemaValue:\n    \"\"\"Replaced by `tuple_schema`.\"\"\"\n    warnings.warn(\n        '`tuple_positional_schema` is deprecated. Use `tuple_schema` instead.',\n        PydanticDeprecatedSince26,\n        stacklevel=2,\n    )\n    return self.tuple_schema(schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.tuple_variable_schema","title":"tuple_variable_schema","text":"<pre><code>tuple_variable_schema(\n    schema: TupleSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Replaced by <code>tuple_schema</code>.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>@deprecated('`tuple_variable_schema` is deprecated. Use `tuple_schema` instead.', category=None)\n@final\ndef tuple_variable_schema(self, schema: core_schema.TupleSchema) -&gt; JsonSchemaValue:\n    \"\"\"Replaced by `tuple_schema`.\"\"\"\n    warnings.warn(\n        '`tuple_variable_schema` is deprecated. Use `tuple_schema` instead.',\n        PydanticDeprecatedSince26,\n        stacklevel=2,\n    )\n    return self.tuple_schema(schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.tuple_schema","title":"tuple_schema","text":"<pre><code>tuple_schema(schema: TupleSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a tuple schema e.g. <code>Tuple[int, str, bool]</code> or <code>Tuple[int, ...]</code>.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>TupleSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def tuple_schema(self, schema: core_schema.TupleSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a tuple schema e.g. `Tuple[int,\n    str, bool]` or `Tuple[int, ...]`.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema: JsonSchemaValue = {'type': 'array'}\n    if 'variadic_item_index' in schema:\n        variadic_item_index = schema['variadic_item_index']\n        if variadic_item_index &gt; 0:\n            json_schema['minItems'] = variadic_item_index\n            json_schema['prefixItems'] = [\n                self.generate_inner(item) for item in schema['items_schema'][:variadic_item_index]\n            ]\n        if variadic_item_index + 1 == len(schema['items_schema']):\n            # if the variadic item is the last item, then represent it faithfully\n            json_schema['items'] = self.generate_inner(schema['items_schema'][variadic_item_index])\n        else:\n            # otherwise, 'items' represents the schema for the variadic\n            # item plus the suffix, so just allow anything for simplicity\n            # for now\n            json_schema['items'] = True\n    else:\n        prefixItems = [self.generate_inner(item) for item in schema['items_schema']]\n        if prefixItems:\n            json_schema['prefixItems'] = prefixItems\n        json_schema['minItems'] = len(prefixItems)\n        json_schema['maxItems'] = len(prefixItems)\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.array)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.set_schema","title":"set_schema","text":"<pre><code>set_schema(schema: SetSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a set schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>SetSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def set_schema(self, schema: core_schema.SetSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a set schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self._common_set_schema(schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.frozenset_schema","title":"frozenset_schema","text":"<pre><code>frozenset_schema(\n    schema: FrozenSetSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a frozenset schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>FrozenSetSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def frozenset_schema(self, schema: core_schema.FrozenSetSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a frozenset schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self._common_set_schema(schema)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.generator_schema","title":"generator_schema","text":"<pre><code>generator_schema(\n    schema: GeneratorSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Returns a JSON schema that represents the provided GeneratorSchema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>GeneratorSchema</code> <p>The schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def generator_schema(self, schema: core_schema.GeneratorSchema) -&gt; JsonSchemaValue:\n    \"\"\"Returns a JSON schema that represents the provided GeneratorSchema.\n\n    Args:\n        schema: The schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    items_schema = {} if 'items_schema' not in schema else self.generate_inner(schema['items_schema'])\n    json_schema = {'type': 'array', 'items': items_schema}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.array)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.dict_schema","title":"dict_schema","text":"<pre><code>dict_schema(schema: DictSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a dict schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DictSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def dict_schema(self, schema: core_schema.DictSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a dict schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema: JsonSchemaValue = {'type': 'object'}\n\n    keys_schema = self.generate_inner(schema['keys_schema']).copy() if 'keys_schema' in schema else {}\n    keys_pattern = keys_schema.pop('pattern', None)\n\n    values_schema = self.generate_inner(schema['values_schema']).copy() if 'values_schema' in schema else {}\n    values_schema.pop('title', None)  # don't give a title to the additionalProperties\n    if values_schema or keys_pattern is not None:  # don't add additionalProperties if it's empty\n        if keys_pattern is None:\n            json_schema['additionalProperties'] = values_schema\n        else:\n            json_schema['patternProperties'] = {keys_pattern: values_schema}\n\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.object)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.function_before_schema","title":"function_before_schema","text":"<pre><code>function_before_schema(\n    schema: BeforeValidatorFunctionSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a function-before schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>BeforeValidatorFunctionSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def function_before_schema(self, schema: core_schema.BeforeValidatorFunctionSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a function-before schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    metadata = _core_metadata.CoreMetadataHandler(schema).metadata\n    if self._mode == 'validation' and (input_schema := metadata.get('pydantic_js_input_core_schema')):\n        return self.generate_inner(input_schema)\n\n    return self.generate_inner(schema['schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.function_after_schema","title":"function_after_schema","text":"<pre><code>function_after_schema(\n    schema: AfterValidatorFunctionSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a function-after schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>AfterValidatorFunctionSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def function_after_schema(self, schema: core_schema.AfterValidatorFunctionSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a function-after schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.generate_inner(schema['schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.function_plain_schema","title":"function_plain_schema","text":"<pre><code>function_plain_schema(\n    schema: PlainValidatorFunctionSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a function-plain schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>PlainValidatorFunctionSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def function_plain_schema(self, schema: core_schema.PlainValidatorFunctionSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a function-plain schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    metadata = _core_metadata.CoreMetadataHandler(schema).metadata\n    if self._mode == 'validation' and (input_schema := metadata.get('pydantic_js_input_core_schema')):\n        return self.generate_inner(input_schema)\n\n    return self.handle_invalid_for_json_schema(\n        schema, f'core_schema.PlainValidatorFunctionSchema ({schema[\"function\"]})'\n    )\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.function_wrap_schema","title":"function_wrap_schema","text":"<pre><code>function_wrap_schema(\n    schema: WrapValidatorFunctionSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a function-wrap schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>WrapValidatorFunctionSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def function_wrap_schema(self, schema: core_schema.WrapValidatorFunctionSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a function-wrap schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    metadata = _core_metadata.CoreMetadataHandler(schema).metadata\n    if self._mode == 'validation' and (input_schema := metadata.get('pydantic_js_input_core_schema')):\n        return self.generate_inner(input_schema)\n\n    return self.generate_inner(schema['schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.default_schema","title":"default_schema","text":"<pre><code>default_schema(\n    schema: WithDefaultSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema with a default value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>WithDefaultSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def default_schema(self, schema: core_schema.WithDefaultSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema with a default value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema = self.generate_inner(schema['schema'])\n\n    if 'default' not in schema:\n        return json_schema\n    default = schema['default']\n    # Note: if you want to include the value returned by the default_factory,\n    # override this method and replace the code above with:\n    # if 'default' in schema:\n    #     default = schema['default']\n    # elif 'default_factory' in schema:\n    #     default = schema['default_factory']()\n    # else:\n    #     return json_schema\n\n    # we reflect the application of custom plain, no-info serializers to defaults for\n    # JSON Schemas viewed in serialization mode:\n    # TODO: improvements along with https://github.com/pydantic/pydantic/issues/8208\n    if (\n        self.mode == 'serialization'\n        and (ser_schema := schema['schema'].get('serialization'))\n        and (ser_func := ser_schema.get('function'))\n        and ser_schema.get('type') == 'function-plain'\n        and not ser_schema.get('info_arg')\n        and not (default is None and ser_schema.get('when_used') in ('unless-none', 'json-unless-none'))\n    ):\n        try:\n            default = ser_func(default)  # type: ignore\n        except Exception:\n            # It might be that the provided default needs to be validated (read: parsed) first\n            # (assuming `validate_default` is enabled). However, we can't perform\n            # such validation during JSON Schema generation so we don't support\n            # this pattern for now.\n            # (One example is when using `foo: ByteSize = '1MB'`, which validates and\n            # serializes as an int. In this case, `ser_func` is `int` and `int('1MB')` fails).\n            self.emit_warning(\n                'non-serializable-default',\n                f'Unable to serialize value {default!r} with the plain serializer; excluding default from JSON schema',\n            )\n            return json_schema\n\n    try:\n        encoded_default = self.encode_default(default)\n    except pydantic_core.PydanticSerializationError:\n        self.emit_warning(\n            'non-serializable-default',\n            f'Default value {default} is not JSON serializable; excluding default from JSON schema',\n        )\n        # Return the inner schema, as though there was no default\n        return json_schema\n\n    json_schema['default'] = encoded_default\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.nullable_schema","title":"nullable_schema","text":"<pre><code>nullable_schema(schema: NullableSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that allows null values.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>NullableSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def nullable_schema(self, schema: core_schema.NullableSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that allows null values.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    null_schema = {'type': 'null'}\n    inner_json_schema = self.generate_inner(schema['schema'])\n\n    if inner_json_schema == null_schema:\n        return null_schema\n    else:\n        # Thanks to the equality check against `null_schema` above, I think 'oneOf' would also be valid here;\n        # I'll use 'anyOf' for now, but it could be changed it if it would work better with some external tooling\n        return self.get_flattened_anyof([inner_json_schema, null_schema])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.union_schema","title":"union_schema","text":"<pre><code>union_schema(schema: UnionSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that allows values matching any of the given schemas.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>UnionSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def union_schema(self, schema: core_schema.UnionSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that allows values matching any of the given schemas.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    generated: list[JsonSchemaValue] = []\n\n    choices = schema['choices']\n    for choice in choices:\n        # choice will be a tuple if an explicit label was provided\n        choice_schema = choice[0] if isinstance(choice, tuple) else choice\n        try:\n            generated.append(self.generate_inner(choice_schema))\n        except PydanticOmit:\n            continue\n        except PydanticInvalidForJsonSchema as exc:\n            self.emit_warning('skipped-choice', exc.message)\n    if len(generated) == 1:\n        return generated[0]\n    return self.get_flattened_anyof(generated)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.tagged_union_schema","title":"tagged_union_schema","text":"<pre><code>tagged_union_schema(\n    schema: TaggedUnionSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that allows values matching any of the given schemas, where the schemas are tagged with a discriminator field that indicates which schema should be used to validate the value.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>TaggedUnionSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def tagged_union_schema(self, schema: core_schema.TaggedUnionSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that allows values matching any of the given schemas, where\n    the schemas are tagged with a discriminator field that indicates which schema should be used to validate\n    the value.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    generated: dict[str, JsonSchemaValue] = {}\n    for k, v in schema['choices'].items():\n        if isinstance(k, Enum):\n            k = k.value\n        try:\n            # Use str(k) since keys must be strings for json; while not technically correct,\n            # it's the closest that can be represented in valid JSON\n            generated[str(k)] = self.generate_inner(v).copy()\n        except PydanticOmit:\n            continue\n        except PydanticInvalidForJsonSchema as exc:\n            self.emit_warning('skipped-choice', exc.message)\n\n    one_of_choices = _deduplicate_schemas(generated.values())\n    json_schema: JsonSchemaValue = {'oneOf': one_of_choices}\n\n    # This reflects the v1 behavior; TODO: we should make it possible to exclude OpenAPI stuff from the JSON schema\n    openapi_discriminator = self._extract_discriminator(schema, one_of_choices)\n    if openapi_discriminator is not None:\n        json_schema['discriminator'] = {\n            'propertyName': openapi_discriminator,\n            'mapping': {k: v.get('$ref', v) for k, v in generated.items()},\n        }\n\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.chain_schema","title":"chain_schema","text":"<pre><code>chain_schema(schema: ChainSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a core_schema.ChainSchema.</p> <p>When generating a schema for validation, we return the validation JSON schema for the first step in the chain. For serialization, we return the serialization JSON schema for the last step in the chain.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ChainSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def chain_schema(self, schema: core_schema.ChainSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a core_schema.ChainSchema.\n\n    When generating a schema for validation, we return the validation JSON schema for the first step in the chain.\n    For serialization, we return the serialization JSON schema for the last step in the chain.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    step_index = 0 if self.mode == 'validation' else -1  # use first step for validation, last for serialization\n    return self.generate_inner(schema['steps'][step_index])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.lax_or_strict_schema","title":"lax_or_strict_schema","text":"<pre><code>lax_or_strict_schema(\n    schema: LaxOrStrictSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that allows values matching either the lax schema or the strict schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>LaxOrStrictSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def lax_or_strict_schema(self, schema: core_schema.LaxOrStrictSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that allows values matching either the lax schema or the\n    strict schema.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    # TODO: Need to read the default value off of model config or whatever\n    use_strict = schema.get('strict', False)  # TODO: replace this default False\n    # If your JSON schema fails to generate it is probably\n    # because one of the following two branches failed.\n    if use_strict:\n        return self.generate_inner(schema['strict_schema'])\n    else:\n        return self.generate_inner(schema['lax_schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.json_or_python_schema","title":"json_or_python_schema","text":"<pre><code>json_or_python_schema(\n    schema: JsonOrPythonSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that allows values matching either the JSON schema or the Python schema.</p> <p>The JSON schema is used instead of the Python schema. If you want to use the Python schema, you should override this method.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>JsonOrPythonSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def json_or_python_schema(self, schema: core_schema.JsonOrPythonSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that allows values matching either the JSON schema or the\n    Python schema.\n\n    The JSON schema is used instead of the Python schema. If you want to use the Python schema, you should override\n    this method.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.generate_inner(schema['json_schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.typed_dict_schema","title":"typed_dict_schema","text":"<pre><code>typed_dict_schema(\n    schema: TypedDictSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a typed dict.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>TypedDictSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def typed_dict_schema(self, schema: core_schema.TypedDictSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a typed dict.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    total = schema.get('total', True)\n    named_required_fields: list[tuple[str, bool, CoreSchemaField]] = [\n        (name, self.field_is_required(field, total), field)\n        for name, field in schema['fields'].items()\n        if self.field_is_present(field)\n    ]\n    if self.mode == 'serialization':\n        named_required_fields.extend(self._name_required_computed_fields(schema.get('computed_fields', [])))\n    cls = schema.get('cls')\n    config = _get_typed_dict_config(cls)\n    with self._config_wrapper_stack.push(config):\n        json_schema = self._named_required_fields_schema(named_required_fields)\n\n    json_schema_extra = config.get('json_schema_extra')\n    extra = schema.get('extra_behavior')\n    if extra is None:\n        extra = config.get('extra', 'ignore')\n\n    if cls is not None:\n        title = config.get('title') or cls.__name__\n        json_schema = self._update_class_schema(json_schema, title, extra, cls, json_schema_extra)\n    else:\n        if extra == 'forbid':\n            json_schema['additionalProperties'] = False\n        elif extra == 'allow':\n            json_schema['additionalProperties'] = True\n\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.typed_dict_field_schema","title":"typed_dict_field_schema","text":"<pre><code>typed_dict_field_schema(\n    schema: TypedDictField,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a typed dict field.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>TypedDictField</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def typed_dict_field_schema(self, schema: core_schema.TypedDictField) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a typed dict field.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.generate_inner(schema['schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.dataclass_field_schema","title":"dataclass_field_schema","text":"<pre><code>dataclass_field_schema(\n    schema: DataclassField,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a dataclass field.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DataclassField</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def dataclass_field_schema(self, schema: core_schema.DataclassField) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a dataclass field.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.generate_inner(schema['schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.model_field_schema","title":"model_field_schema","text":"<pre><code>model_field_schema(schema: ModelField) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a model field.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelField</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def model_field_schema(self, schema: core_schema.ModelField) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a model field.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.generate_inner(schema['schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.computed_field_schema","title":"computed_field_schema","text":"<pre><code>computed_field_schema(\n    schema: ComputedField,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a computed field.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ComputedField</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def computed_field_schema(self, schema: core_schema.ComputedField) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a computed field.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.generate_inner(schema['return_schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.model_schema","title":"model_schema","text":"<pre><code>model_schema(schema: ModelSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a model.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def model_schema(self, schema: core_schema.ModelSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a model.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    # We do not use schema['model'].model_json_schema() here\n    # because it could lead to inconsistent refs handling, etc.\n    cls = cast('type[BaseModel]', schema['cls'])\n    config = cls.model_config\n    title = config.get('title')\n\n    with self._config_wrapper_stack.push(config):\n        json_schema = self.generate_inner(schema['schema'])\n\n    json_schema_extra = config.get('json_schema_extra')\n    if cls.__pydantic_root_model__:\n        root_json_schema_extra = cls.model_fields['root'].json_schema_extra\n        if json_schema_extra and root_json_schema_extra:\n            raise ValueError(\n                '\"model_config[\\'json_schema_extra\\']\" and \"Field.json_schema_extra\" on \"RootModel.root\"'\n                ' field must not be set simultaneously'\n            )\n        if root_json_schema_extra:\n            json_schema_extra = root_json_schema_extra\n\n    json_schema = self._update_class_schema(json_schema, title, config.get('extra', None), cls, json_schema_extra)\n\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.resolve_schema_to_update","title":"resolve_schema_to_update","text":"<pre><code>resolve_schema_to_update(\n    json_schema: JsonSchemaValue,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Resolve a JsonSchemaValue to the non-ref schema if it is a $ref schema.</p> <p>Parameters:</p> Name Type Description Default <code>json_schema</code> <code>JsonSchemaValue</code> <p>The schema to resolve.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The resolved schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def resolve_schema_to_update(self, json_schema: JsonSchemaValue) -&gt; JsonSchemaValue:\n    \"\"\"Resolve a JsonSchemaValue to the non-ref schema if it is a $ref schema.\n\n    Args:\n        json_schema: The schema to resolve.\n\n    Returns:\n        The resolved schema.\n    \"\"\"\n    if '$ref' in json_schema:\n        schema_to_update = self.get_schema_from_definitions(JsonRef(json_schema['$ref']))\n        if schema_to_update is None:\n            raise RuntimeError(f'Cannot update undefined schema for $ref={json_schema[\"$ref\"]}')\n        return self.resolve_schema_to_update(schema_to_update)\n    else:\n        schema_to_update = json_schema\n    return schema_to_update\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.model_fields_schema","title":"model_fields_schema","text":"<pre><code>model_fields_schema(\n    schema: ModelFieldsSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a model's fields.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ModelFieldsSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def model_fields_schema(self, schema: core_schema.ModelFieldsSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a model's fields.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    named_required_fields: list[tuple[str, bool, CoreSchemaField]] = [\n        (name, self.field_is_required(field, total=True), field)\n        for name, field in schema['fields'].items()\n        if self.field_is_present(field)\n    ]\n    if self.mode == 'serialization':\n        named_required_fields.extend(self._name_required_computed_fields(schema.get('computed_fields', [])))\n    json_schema = self._named_required_fields_schema(named_required_fields)\n    extras_schema = schema.get('extras_schema', None)\n    if extras_schema is not None:\n        schema_to_update = self.resolve_schema_to_update(json_schema)\n        schema_to_update['additionalProperties'] = self.generate_inner(extras_schema)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.field_is_present","title":"field_is_present","text":"<pre><code>field_is_present(field: CoreSchemaField) -&gt; bool\n</code></pre> <p>Whether the field should be included in the generated JSON schema.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>CoreSchemaField</code> <p>The schema for the field itself.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the field should be included in the generated JSON schema, <code>False</code> otherwise.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def field_is_present(self, field: CoreSchemaField) -&gt; bool:\n    \"\"\"Whether the field should be included in the generated JSON schema.\n\n    Args:\n        field: The schema for the field itself.\n\n    Returns:\n        `True` if the field should be included in the generated JSON schema, `False` otherwise.\n    \"\"\"\n    if self.mode == 'serialization':\n        # If you still want to include the field in the generated JSON schema,\n        # override this method and return True\n        return not field.get('serialization_exclude')\n    elif self.mode == 'validation':\n        return True\n    else:\n        assert_never(self.mode)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.field_is_required","title":"field_is_required","text":"<pre><code>field_is_required(\n    field: ModelField | DataclassField | TypedDictField,\n    total: bool,\n) -&gt; bool\n</code></pre> <p>Whether the field should be marked as required in the generated JSON schema. (Note that this is irrelevant if the field is not present in the JSON schema.).</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>ModelField | DataclassField | TypedDictField</code> <p>The schema for the field itself.</p> required <code>total</code> <code>bool</code> <p>Only applies to <code>TypedDictField</code>s. Indicates if the <code>TypedDict</code> this field belongs to is total, in which case any fields that don't explicitly specify <code>required=False</code> are required.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the field should be marked as required in the generated JSON schema, <code>False</code> otherwise.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def field_is_required(\n    self,\n    field: core_schema.ModelField | core_schema.DataclassField | core_schema.TypedDictField,\n    total: bool,\n) -&gt; bool:\n    \"\"\"Whether the field should be marked as required in the generated JSON schema.\n    (Note that this is irrelevant if the field is not present in the JSON schema.).\n\n    Args:\n        field: The schema for the field itself.\n        total: Only applies to `TypedDictField`s.\n            Indicates if the `TypedDict` this field belongs to is total, in which case any fields that don't\n            explicitly specify `required=False` are required.\n\n    Returns:\n        `True` if the field should be marked as required in the generated JSON schema, `False` otherwise.\n    \"\"\"\n    if self.mode == 'serialization' and self._config.json_schema_serialization_defaults_required:\n        return not field.get('serialization_exclude')\n    else:\n        if field['type'] == 'typed-dict-field':\n            return field.get('required', total)\n        else:\n            return field['schema']['type'] != 'default'\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.dataclass_args_schema","title":"dataclass_args_schema","text":"<pre><code>dataclass_args_schema(\n    schema: DataclassArgsSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a dataclass's constructor arguments.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DataclassArgsSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def dataclass_args_schema(self, schema: core_schema.DataclassArgsSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a dataclass's constructor arguments.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    named_required_fields: list[tuple[str, bool, CoreSchemaField]] = [\n        (field['name'], self.field_is_required(field, total=True), field)\n        for field in schema['fields']\n        if self.field_is_present(field)\n    ]\n    if self.mode == 'serialization':\n        named_required_fields.extend(self._name_required_computed_fields(schema.get('computed_fields', [])))\n    return self._named_required_fields_schema(named_required_fields)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.dataclass_schema","title":"dataclass_schema","text":"<pre><code>dataclass_schema(\n    schema: DataclassSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a dataclass.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DataclassSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def dataclass_schema(self, schema: core_schema.DataclassSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a dataclass.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    cls = schema['cls']\n    config: ConfigDict = getattr(cls, '__pydantic_config__', cast('ConfigDict', {}))\n    title = config.get('title') or cls.__name__\n\n    with self._config_wrapper_stack.push(config):\n        json_schema = self.generate_inner(schema['schema']).copy()\n\n    json_schema_extra = config.get('json_schema_extra')\n    json_schema = self._update_class_schema(json_schema, title, config.get('extra', None), cls, json_schema_extra)\n\n    # Dataclass-specific handling of description\n    if is_dataclass(cls) and not hasattr(cls, '__pydantic_validator__'):\n        # vanilla dataclass; don't use cls.__doc__ as it will contain the class signature by default\n        description = None\n    else:\n        description = None if cls.__doc__ is None else inspect.cleandoc(cls.__doc__)\n    if description:\n        json_schema['description'] = description\n\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.arguments_schema","title":"arguments_schema","text":"<pre><code>arguments_schema(\n    schema: ArgumentsSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a function's arguments.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ArgumentsSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def arguments_schema(self, schema: core_schema.ArgumentsSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a function's arguments.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    metadata = _core_metadata.CoreMetadataHandler(schema).metadata\n    prefer_positional = metadata.get('pydantic_js_prefer_positional_arguments')\n\n    arguments = schema['arguments_schema']\n    kw_only_arguments = [a for a in arguments if a.get('mode') == 'keyword_only']\n    kw_or_p_arguments = [a for a in arguments if a.get('mode') in {'positional_or_keyword', None}]\n    p_only_arguments = [a for a in arguments if a.get('mode') == 'positional_only']\n    var_args_schema = schema.get('var_args_schema')\n    var_kwargs_schema = schema.get('var_kwargs_schema')\n\n    if prefer_positional:\n        positional_possible = not kw_only_arguments and not var_kwargs_schema\n        if positional_possible:\n            return self.p_arguments_schema(p_only_arguments + kw_or_p_arguments, var_args_schema)\n\n    keyword_possible = not p_only_arguments and not var_args_schema\n    if keyword_possible:\n        return self.kw_arguments_schema(kw_or_p_arguments + kw_only_arguments, var_kwargs_schema)\n\n    if not prefer_positional:\n        positional_possible = not kw_only_arguments and not var_kwargs_schema\n        if positional_possible:\n            return self.p_arguments_schema(p_only_arguments + kw_or_p_arguments, var_args_schema)\n\n    raise PydanticInvalidForJsonSchema(\n        'Unable to generate JSON schema for arguments validator with positional-only and keyword-only arguments'\n    )\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.kw_arguments_schema","title":"kw_arguments_schema","text":"<pre><code>kw_arguments_schema(\n    arguments: list[ArgumentsParameter],\n    var_kwargs_schema: CoreSchema | None,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a function's keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>arguments</code> <code>list[ArgumentsParameter]</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def kw_arguments_schema(\n    self, arguments: list[core_schema.ArgumentsParameter], var_kwargs_schema: CoreSchema | None\n) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a function's keyword arguments.\n\n    Args:\n        arguments: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    properties: dict[str, JsonSchemaValue] = {}\n    required: list[str] = []\n    for argument in arguments:\n        name = self.get_argument_name(argument)\n        argument_schema = self.generate_inner(argument['schema']).copy()\n        argument_schema['title'] = self.get_title_from_name(name)\n        properties[name] = argument_schema\n\n        if argument['schema']['type'] != 'default':\n            # This assumes that if the argument has a default value,\n            # the inner schema must be of type WithDefaultSchema.\n            # I believe this is true, but I am not 100% sure\n            required.append(name)\n\n    json_schema: JsonSchemaValue = {'type': 'object', 'properties': properties}\n    if required:\n        json_schema['required'] = required\n\n    if var_kwargs_schema:\n        additional_properties_schema = self.generate_inner(var_kwargs_schema)\n        if additional_properties_schema:\n            json_schema['additionalProperties'] = additional_properties_schema\n    else:\n        json_schema['additionalProperties'] = False\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.p_arguments_schema","title":"p_arguments_schema","text":"<pre><code>p_arguments_schema(\n    arguments: list[ArgumentsParameter],\n    var_args_schema: CoreSchema | None,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a function's positional arguments.</p> <p>Parameters:</p> Name Type Description Default <code>arguments</code> <code>list[ArgumentsParameter]</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def p_arguments_schema(\n    self, arguments: list[core_schema.ArgumentsParameter], var_args_schema: CoreSchema | None\n) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a function's positional arguments.\n\n    Args:\n        arguments: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    prefix_items: list[JsonSchemaValue] = []\n    min_items = 0\n\n    for argument in arguments:\n        name = self.get_argument_name(argument)\n\n        argument_schema = self.generate_inner(argument['schema']).copy()\n        argument_schema['title'] = self.get_title_from_name(name)\n        prefix_items.append(argument_schema)\n\n        if argument['schema']['type'] != 'default':\n            # This assumes that if the argument has a default value,\n            # the inner schema must be of type WithDefaultSchema.\n            # I believe this is true, but I am not 100% sure\n            min_items += 1\n\n    json_schema: JsonSchemaValue = {'type': 'array'}\n    if prefix_items:\n        json_schema['prefixItems'] = prefix_items\n    if min_items:\n        json_schema['minItems'] = min_items\n\n    if var_args_schema:\n        items_schema = self.generate_inner(var_args_schema)\n        if items_schema:\n            json_schema['items'] = items_schema\n    else:\n        json_schema['maxItems'] = len(prefix_items)\n\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.get_argument_name","title":"get_argument_name","text":"<pre><code>get_argument_name(argument: ArgumentsParameter) -&gt; str\n</code></pre> <p>Retrieves the name of an argument.</p> <p>Parameters:</p> Name Type Description Default <code>argument</code> <code>ArgumentsParameter</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The name of the argument.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def get_argument_name(self, argument: core_schema.ArgumentsParameter) -&gt; str:\n    \"\"\"Retrieves the name of an argument.\n\n    Args:\n        argument: The core schema.\n\n    Returns:\n        The name of the argument.\n    \"\"\"\n    name = argument['name']\n    if self.by_alias:\n        alias = argument.get('alias')\n        if isinstance(alias, str):\n            name = alias\n        else:\n            pass  # might want to do something else?\n    return name\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.call_schema","title":"call_schema","text":"<pre><code>call_schema(schema: CallSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a function call.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CallSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def call_schema(self, schema: core_schema.CallSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a function call.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.generate_inner(schema['arguments_schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.custom_error_schema","title":"custom_error_schema","text":"<pre><code>custom_error_schema(\n    schema: CustomErrorSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a custom error.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CustomErrorSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def custom_error_schema(self, schema: core_schema.CustomErrorSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a custom error.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return self.generate_inner(schema['schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.json_schema","title":"json_schema","text":"<pre><code>json_schema(schema: JsonSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a JSON object.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>JsonSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def json_schema(self, schema: core_schema.JsonSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a JSON object.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    content_core_schema = schema.get('schema') or core_schema.any_schema()\n    content_json_schema = self.generate_inner(content_core_schema)\n    if self.mode == 'validation':\n        return {'type': 'string', 'contentMediaType': 'application/json', 'contentSchema': content_json_schema}\n    else:\n        # self.mode == 'serialization'\n        return content_json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.url_schema","title":"url_schema","text":"<pre><code>url_schema(schema: UrlSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a URL.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>UrlSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def url_schema(self, schema: core_schema.UrlSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a URL.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    json_schema = {'type': 'string', 'format': 'uri', 'minLength': 1}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.string)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.multi_host_url_schema","title":"multi_host_url_schema","text":"<pre><code>multi_host_url_schema(\n    schema: MultiHostUrlSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a URL that can be used with multiple hosts.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>MultiHostUrlSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def multi_host_url_schema(self, schema: core_schema.MultiHostUrlSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a URL that can be used with multiple hosts.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    # Note: 'multi-host-uri' is a custom/pydantic-specific format, not part of the JSON Schema spec\n    json_schema = {'type': 'string', 'format': 'multi-host-uri', 'minLength': 1}\n    self.update_with_validations(json_schema, schema, self.ValidationsMapping.string)\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.uuid_schema","title":"uuid_schema","text":"<pre><code>uuid_schema(schema: UuidSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a UUID.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>UuidSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def uuid_schema(self, schema: core_schema.UuidSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a UUID.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'string', 'format': 'uuid'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.definitions_schema","title":"definitions_schema","text":"<pre><code>definitions_schema(\n    schema: DefinitionsSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a JSON object with definitions.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DefinitionsSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def definitions_schema(self, schema: core_schema.DefinitionsSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that defines a JSON object with definitions.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    for definition in schema['definitions']:\n        try:\n            self.generate_inner(definition)\n        except PydanticInvalidForJsonSchema as e:\n            core_ref: CoreRef = CoreRef(definition['ref'])  # type: ignore\n            self._core_defs_invalid_for_json_schema[self.get_defs_ref((core_ref, self.mode))] = e\n            continue\n    return self.generate_inner(schema['schema'])\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.definition_ref_schema","title":"definition_ref_schema","text":"<pre><code>definition_ref_schema(\n    schema: DefinitionReferenceSchema,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a schema that references a definition.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>DefinitionReferenceSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def definition_ref_schema(self, schema: core_schema.DefinitionReferenceSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a schema that references a definition.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    core_ref = CoreRef(schema['schema_ref'])\n    _, ref_json_schema = self.get_cache_defs_ref_schema(core_ref)\n    return ref_json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.ser_schema","title":"ser_schema","text":"<pre><code>ser_schema(\n    schema: (\n        SerSchema | IncExSeqSerSchema | IncExDictSerSchema\n    ),\n) -&gt; JsonSchemaValue | None\n</code></pre> <p>Generates a JSON schema that matches a schema that defines a serialized object.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>SerSchema | IncExSeqSerSchema | IncExDictSerSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue | None</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def ser_schema(\n    self, schema: core_schema.SerSchema | core_schema.IncExSeqSerSchema | core_schema.IncExDictSerSchema\n) -&gt; JsonSchemaValue | None:\n    \"\"\"Generates a JSON schema that matches a schema that defines a serialized object.\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    schema_type = schema['type']\n    if schema_type == 'function-plain' or schema_type == 'function-wrap':\n        # PlainSerializerFunctionSerSchema or WrapSerializerFunctionSerSchema\n        return_schema = schema.get('return_schema')\n        if return_schema is not None:\n            return self.generate_inner(return_schema)\n    elif schema_type == 'format' or schema_type == 'to-string':\n        # FormatSerSchema or ToStringSerSchema\n        return self.str_schema(core_schema.str_schema())\n    elif schema['type'] == 'model':\n        # ModelSerSchema\n        return self.generate_inner(schema['schema'])\n    return None\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.complex_schema","title":"complex_schema","text":"<pre><code>complex_schema(schema: ComplexSchema) -&gt; JsonSchemaValue\n</code></pre> <p>Generates a JSON schema that matches a complex number.</p> <p>JSON has no standard way to represent complex numbers. Complex number is not a numeric type. Here we represent complex number as strings following the rule defined by Python. For instance, '1+2j' is an accepted complex string. Details can be found in Python's <code>complex</code> documentation.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>ComplexSchema</code> <p>The core schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The generated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def complex_schema(self, schema: core_schema.ComplexSchema) -&gt; JsonSchemaValue:\n    \"\"\"Generates a JSON schema that matches a complex number.\n\n    JSON has no standard way to represent complex numbers. Complex number is not a numeric\n    type. Here we represent complex number as strings following the rule defined by Python.\n    For instance, '1+2j' is an accepted complex string. Details can be found in\n    [Python's `complex` documentation][complex].\n\n    Args:\n        schema: The core schema.\n\n    Returns:\n        The generated JSON schema.\n    \"\"\"\n    return {'type': 'string'}\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.get_title_from_name","title":"get_title_from_name","text":"<pre><code>get_title_from_name(name: str) -&gt; str\n</code></pre> <p>Retrieves a title from a name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to retrieve a title from.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The title.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def get_title_from_name(self, name: str) -&gt; str:\n    \"\"\"Retrieves a title from a name.\n\n    Args:\n        name: The name to retrieve a title from.\n\n    Returns:\n        The title.\n    \"\"\"\n    return name.title().replace('_', ' ')\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.field_title_should_be_set","title":"field_title_should_be_set","text":"<pre><code>field_title_should_be_set(\n    schema: CoreSchemaOrField,\n) -&gt; bool\n</code></pre> <p>Returns true if a field with the given schema should have a title set based on the field name.</p> <p>Intuitively, we want this to return true for schemas that wouldn't otherwise provide their own title (e.g., int, float, str), and false for those that would (e.g., BaseModel subclasses).</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchemaOrField</code> <p>The schema to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the field should have a title set, <code>False</code> otherwise.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def field_title_should_be_set(self, schema: CoreSchemaOrField) -&gt; bool:\n    \"\"\"Returns true if a field with the given schema should have a title set based on the field name.\n\n    Intuitively, we want this to return true for schemas that wouldn't otherwise provide their own title\n    (e.g., int, float, str), and false for those that would (e.g., BaseModel subclasses).\n\n    Args:\n        schema: The schema to check.\n\n    Returns:\n        `True` if the field should have a title set, `False` otherwise.\n    \"\"\"\n    if _core_utils.is_core_schema_field(schema):\n        if schema['type'] == 'computed-field':\n            field_schema = schema['return_schema']\n        else:\n            field_schema = schema['schema']\n        return self.field_title_should_be_set(field_schema)\n\n    elif _core_utils.is_core_schema(schema):\n        if schema.get('ref'):  # things with refs, such as models and enums, should not have titles set\n            return False\n        if schema['type'] in {'default', 'nullable', 'definitions'}:\n            return self.field_title_should_be_set(schema['schema'])  # type: ignore[typeddict-item]\n        if _core_utils.is_function_with_inner_schema(schema):\n            return self.field_title_should_be_set(schema['schema'])\n        if schema['type'] == 'definition-ref':\n            # Referenced schemas should not have titles set for the same reason\n            # schemas with refs should not\n            return False\n        return True  # anything else should have title set\n\n    else:\n        raise PydanticInvalidForJsonSchema(f'Unexpected schema type: schema={schema}')  # pragma: no cover\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.normalize_name","title":"normalize_name","text":"<pre><code>normalize_name(name: str) -&gt; str\n</code></pre> <p>Normalizes a name to be used as a key in a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to normalize.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The normalized name.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def normalize_name(self, name: str) -&gt; str:\n    \"\"\"Normalizes a name to be used as a key in a dictionary.\n\n    Args:\n        name: The name to normalize.\n\n    Returns:\n        The normalized name.\n    \"\"\"\n    return re.sub(r'[^a-zA-Z0-9.\\-_]', '_', name).replace('.', '__')\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.get_defs_ref","title":"get_defs_ref","text":"<pre><code>get_defs_ref(core_mode_ref: CoreModeRef) -&gt; DefsRef\n</code></pre> <p>Override this method to change the way that definitions keys are generated from a core reference.</p> <p>Parameters:</p> Name Type Description Default <code>core_mode_ref</code> <code>CoreModeRef</code> <p>The core reference.</p> required <p>Returns:</p> Type Description <code>DefsRef</code> <p>The definitions key.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def get_defs_ref(self, core_mode_ref: CoreModeRef) -&gt; DefsRef:\n    \"\"\"Override this method to change the way that definitions keys are generated from a core reference.\n\n    Args:\n        core_mode_ref: The core reference.\n\n    Returns:\n        The definitions key.\n    \"\"\"\n    # Split the core ref into \"components\"; generic origins and arguments are each separate components\n    core_ref, mode = core_mode_ref\n    components = re.split(r'([\\][,])', core_ref)\n    # Remove IDs from each component\n    components = [x.rsplit(':', 1)[0] for x in components]\n    core_ref_no_id = ''.join(components)\n    # Remove everything before the last period from each \"component\"\n    components = [re.sub(r'(?:[^.[\\]]+\\.)+((?:[^.[\\]]+))', r'\\1', x) for x in components]\n    short_ref = ''.join(components)\n\n    mode_title = _MODE_TITLE_MAPPING[mode]\n\n    # It is important that the generated defs_ref values be such that at least one choice will not\n    # be generated for any other core_ref. Currently, this should be the case because we include\n    # the id of the source type in the core_ref\n    name = DefsRef(self.normalize_name(short_ref))\n    name_mode = DefsRef(self.normalize_name(short_ref) + f'-{mode_title}')\n    module_qualname = DefsRef(self.normalize_name(core_ref_no_id))\n    module_qualname_mode = DefsRef(f'{module_qualname}-{mode_title}')\n    module_qualname_id = DefsRef(self.normalize_name(core_ref))\n    occurrence_index = self._collision_index.get(module_qualname_id)\n    if occurrence_index is None:\n        self._collision_counter[module_qualname] += 1\n        occurrence_index = self._collision_index[module_qualname_id] = self._collision_counter[module_qualname]\n\n    module_qualname_occurrence = DefsRef(f'{module_qualname}__{occurrence_index}')\n    module_qualname_occurrence_mode = DefsRef(f'{module_qualname_mode}__{occurrence_index}')\n\n    self._prioritized_defsref_choices[module_qualname_occurrence_mode] = [\n        name,\n        name_mode,\n        module_qualname,\n        module_qualname_mode,\n        module_qualname_occurrence,\n        module_qualname_occurrence_mode,\n    ]\n\n    return module_qualname_occurrence_mode\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.get_cache_defs_ref_schema","title":"get_cache_defs_ref_schema","text":"<pre><code>get_cache_defs_ref_schema(\n    core_ref: CoreRef,\n) -&gt; tuple[DefsRef, JsonSchemaValue]\n</code></pre> <p>This method wraps the get_defs_ref method with some cache-lookup/population logic, and returns both the produced defs_ref and the JSON schema that will refer to the right definition.</p> <p>Parameters:</p> Name Type Description Default <code>core_ref</code> <code>CoreRef</code> <p>The core reference to get the definitions reference for.</p> required <p>Returns:</p> Type Description <code>tuple[DefsRef, JsonSchemaValue]</code> <p>A tuple of the definitions reference and the JSON schema that will refer to it.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def get_cache_defs_ref_schema(self, core_ref: CoreRef) -&gt; tuple[DefsRef, JsonSchemaValue]:\n    \"\"\"This method wraps the get_defs_ref method with some cache-lookup/population logic,\n    and returns both the produced defs_ref and the JSON schema that will refer to the right definition.\n\n    Args:\n        core_ref: The core reference to get the definitions reference for.\n\n    Returns:\n        A tuple of the definitions reference and the JSON schema that will refer to it.\n    \"\"\"\n    core_mode_ref = (core_ref, self.mode)\n    maybe_defs_ref = self.core_to_defs_refs.get(core_mode_ref)\n    if maybe_defs_ref is not None:\n        json_ref = self.core_to_json_refs[core_mode_ref]\n        return maybe_defs_ref, {'$ref': json_ref}\n\n    defs_ref = self.get_defs_ref(core_mode_ref)\n\n    # populate the ref translation mappings\n    self.core_to_defs_refs[core_mode_ref] = defs_ref\n    self.defs_to_core_refs[defs_ref] = core_mode_ref\n\n    json_ref = JsonRef(self.ref_template.format(model=defs_ref))\n    self.core_to_json_refs[core_mode_ref] = json_ref\n    self.json_to_defs_refs[json_ref] = defs_ref\n    ref_json_schema = {'$ref': json_ref}\n    return defs_ref, ref_json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.handle_ref_overrides","title":"handle_ref_overrides","text":"<pre><code>handle_ref_overrides(\n    json_schema: JsonSchemaValue,\n) -&gt; JsonSchemaValue\n</code></pre> <p>Remove any sibling keys that are redundant with the referenced schema.</p> <p>Parameters:</p> Name Type Description Default <code>json_schema</code> <code>JsonSchemaValue</code> <p>The schema to remove redundant sibling keys from.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The schema with redundant sibling keys removed.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def handle_ref_overrides(self, json_schema: JsonSchemaValue) -&gt; JsonSchemaValue:\n    \"\"\"Remove any sibling keys that are redundant with the referenced schema.\n\n    Args:\n        json_schema: The schema to remove redundant sibling keys from.\n\n    Returns:\n        The schema with redundant sibling keys removed.\n    \"\"\"\n    if '$ref' in json_schema:\n        # prevent modifications to the input; this copy may be safe to drop if there is significant overhead\n        json_schema = json_schema.copy()\n\n        referenced_json_schema = self.get_schema_from_definitions(JsonRef(json_schema['$ref']))\n        if referenced_json_schema is None:\n            # This can happen when building schemas for models with not-yet-defined references.\n            # It may be a good idea to do a recursive pass at the end of the generation to remove\n            # any redundant override keys.\n            return json_schema\n        for k, v in list(json_schema.items()):\n            if k == '$ref':\n                continue\n            if k in referenced_json_schema and referenced_json_schema[k] == v:\n                del json_schema[k]  # redundant key\n\n    return json_schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.encode_default","title":"encode_default","text":"<pre><code>encode_default(dft: Any) -&gt; Any\n</code></pre> <p>Encode a default value to a JSON-serializable value.</p> <p>This is used to encode default values for fields in the generated JSON schema.</p> <p>Parameters:</p> Name Type Description Default <code>dft</code> <code>Any</code> <p>The default value to encode.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The encoded default value.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def encode_default(self, dft: Any) -&gt; Any:\n    \"\"\"Encode a default value to a JSON-serializable value.\n\n    This is used to encode default values for fields in the generated JSON schema.\n\n    Args:\n        dft: The default value to encode.\n\n    Returns:\n        The encoded default value.\n    \"\"\"\n    from .type_adapter import TypeAdapter, _type_has_config\n\n    config = self._config\n    try:\n        default = (\n            dft\n            if _type_has_config(type(dft))\n            else TypeAdapter(type(dft), config=config.config_dict).dump_python(dft, mode='json')\n        )\n    except PydanticSchemaGenerationError:\n        raise pydantic_core.PydanticSerializationError(f'Unable to encode default value {dft}')\n\n    return pydantic_core.to_jsonable_python(\n        default,\n        timedelta_mode=config.ser_json_timedelta,\n        bytes_mode=config.ser_json_bytes,\n    )\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.update_with_validations","title":"update_with_validations","text":"<pre><code>update_with_validations(\n    json_schema: JsonSchemaValue,\n    core_schema: CoreSchema,\n    mapping: dict[str, str],\n) -&gt; None\n</code></pre> <p>Update the json_schema with the corresponding validations specified in the core_schema, using the provided mapping to translate keys in core_schema to the appropriate keys for a JSON schema.</p> <p>Parameters:</p> Name Type Description Default <code>json_schema</code> <code>JsonSchemaValue</code> <p>The JSON schema to update.</p> required <code>core_schema</code> <code>CoreSchema</code> <p>The core schema to get the validations from.</p> required <code>mapping</code> <code>dict[str, str]</code> <p>A mapping from core_schema attribute names to the corresponding JSON schema attribute names.</p> required Source code in <code>pydantic/json_schema.py</code> <pre><code>def update_with_validations(\n    self, json_schema: JsonSchemaValue, core_schema: CoreSchema, mapping: dict[str, str]\n) -&gt; None:\n    \"\"\"Update the json_schema with the corresponding validations specified in the core_schema,\n    using the provided mapping to translate keys in core_schema to the appropriate keys for a JSON schema.\n\n    Args:\n        json_schema: The JSON schema to update.\n        core_schema: The core schema to get the validations from.\n        mapping: A mapping from core_schema attribute names to the corresponding JSON schema attribute names.\n    \"\"\"\n    for core_key, json_schema_key in mapping.items():\n        if core_key in core_schema:\n            json_schema[json_schema_key] = core_schema[core_key]\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.get_json_ref_counts","title":"get_json_ref_counts","text":"<pre><code>get_json_ref_counts(\n    json_schema: JsonSchemaValue,\n) -&gt; dict[JsonRef, int]\n</code></pre> <p>Get all values corresponding to the key '$ref' anywhere in the json_schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def get_json_ref_counts(self, json_schema: JsonSchemaValue) -&gt; dict[JsonRef, int]:\n    \"\"\"Get all values corresponding to the key '$ref' anywhere in the json_schema.\"\"\"\n    json_refs: dict[JsonRef, int] = Counter()\n\n    def _add_json_refs(schema: Any) -&gt; None:\n        if isinstance(schema, dict):\n            if '$ref' in schema:\n                json_ref = JsonRef(schema['$ref'])\n                if not isinstance(json_ref, str):\n                    return  # in this case, '$ref' might have been the name of a property\n                already_visited = json_ref in json_refs\n                json_refs[json_ref] += 1\n                if already_visited:\n                    return  # prevent recursion on a definition that was already visited\n                try:\n                    defs_ref = self.json_to_defs_refs[json_ref]\n                    if defs_ref in self._core_defs_invalid_for_json_schema:\n                        raise self._core_defs_invalid_for_json_schema[defs_ref]\n                    _add_json_refs(self.definitions[defs_ref])\n                except KeyError:\n                    if not json_ref.startswith(('http://', 'https://')):\n                        raise\n\n            for v in schema.values():\n                _add_json_refs(v)\n        elif isinstance(schema, list):\n            for v in schema:\n                _add_json_refs(v)\n\n    _add_json_refs(json_schema)\n    return json_refs\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.emit_warning","title":"emit_warning","text":"<pre><code>emit_warning(\n    kind: JsonSchemaWarningKind, detail: str\n) -&gt; None\n</code></pre> <p>This method simply emits PydanticJsonSchemaWarnings based on handling in the <code>warning_message</code> method.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def emit_warning(self, kind: JsonSchemaWarningKind, detail: str) -&gt; None:\n    \"\"\"This method simply emits PydanticJsonSchemaWarnings based on handling in the `warning_message` method.\"\"\"\n    message = self.render_warning_message(kind, detail)\n    if message is not None:\n        warnings.warn(message, PydanticJsonSchemaWarning)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.GenerateJsonSchema.render_warning_message","title":"render_warning_message","text":"<pre><code>render_warning_message(\n    kind: JsonSchemaWarningKind, detail: str\n) -&gt; str | None\n</code></pre> <p>This method is responsible for ignoring warnings as desired, and for formatting the warning messages.</p> <p>You can override the value of <code>ignored_warning_kinds</code> in a subclass of GenerateJsonSchema to modify what warnings are generated. If you want more control, you can override this method; just return None in situations where you don't want warnings to be emitted.</p> <p>Parameters:</p> Name Type Description Default <code>kind</code> <code>JsonSchemaWarningKind</code> <p>The kind of warning to render. It can be one of the following:</p> <ul> <li>'skipped-choice': A choice field was skipped because it had no valid choices.</li> <li>'non-serializable-default': A default value was skipped because it was not JSON-serializable.</li> </ul> required <code>detail</code> <code>str</code> <p>A string with additional details about the warning.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>The formatted warning message, or <code>None</code> if no warning should be emitted.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def render_warning_message(self, kind: JsonSchemaWarningKind, detail: str) -&gt; str | None:\n    \"\"\"This method is responsible for ignoring warnings as desired, and for formatting the warning messages.\n\n    You can override the value of `ignored_warning_kinds` in a subclass of GenerateJsonSchema\n    to modify what warnings are generated. If you want more control, you can override this method;\n    just return None in situations where you don't want warnings to be emitted.\n\n    Args:\n        kind: The kind of warning to render. It can be one of the following:\n\n            - 'skipped-choice': A choice field was skipped because it had no valid choices.\n            - 'non-serializable-default': A default value was skipped because it was not JSON-serializable.\n        detail: A string with additional details about the warning.\n\n    Returns:\n        The formatted warning message, or `None` if no warning should be emitted.\n    \"\"\"\n    if kind in self.ignored_warning_kinds:\n        return None\n    return f'{detail} [{kind}]'\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.WithJsonSchema","title":"WithJsonSchema  <code>dataclass</code>","text":"<pre><code>WithJsonSchema(\n    json_schema: JsonSchemaValue | None,\n    mode: (\n        Literal[\"validation\", \"serialization\"] | None\n    ) = None,\n)\n</code></pre> <p>Usage Documentation</p> <p><code>WithJsonSchema</code> annotation</p> <p>Add this as an annotation on a field to override the (base) JSON schema that would be generated for that field. This provides a way to set a JSON schema for types that would otherwise raise errors when producing a JSON schema, such as Callable, or types that have an is-instance core schema, without needing to go so far as creating a custom subclass of pydantic.json_schema.GenerateJsonSchema. Note that any modifications to the schema that would normally be made (such as setting the title for model fields) will still be performed.</p> <p>If <code>mode</code> is set this will only apply to that schema generation mode, allowing you to set different json schemas for validation and serialization.</p>"},{"location":"api/json_schema/#pydantic.json_schema.Examples","title":"Examples","text":"<pre><code>Examples(\n    examples: dict[str, Any] | list[Any],\n    mode: (\n        Literal[\"validation\", \"serialization\"] | None\n    ) = None,\n)\n</code></pre> <p>Add examples to a JSON schema.</p> <p>If the JSON Schema already contains examples, the provided examples will be appended.</p> <p>If <code>mode</code> is set this will only apply to that schema generation mode, allowing you to add different examples for validation and serialization.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def __init__(\n    self, examples: dict[str, Any] | list[Any], mode: Literal['validation', 'serialization'] | None = None\n) -&gt; None:\n    if isinstance(examples, dict):\n        warnings.warn(\n            'Using a dict for `examples` is deprecated, use a list instead.',\n            PydanticDeprecatedSince29,\n            stacklevel=2,\n        )\n    self.examples = examples\n    self.mode = mode\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.SkipJsonSchema","title":"SkipJsonSchema  <code>dataclass</code>","text":"<pre><code>SkipJsonSchema()\n</code></pre> <p>Usage Documentation</p> <p><code>SkipJsonSchema</code> annotation</p> <p>Add this as an annotation on a field to skip generating a JSON schema for that field.</p> Example <pre><code>from typing import Union\n\nfrom pydantic import BaseModel\nfrom pydantic.json_schema import SkipJsonSchema\n\nfrom pprint import pprint\n\n\nclass Model(BaseModel):\n    a: Union[int, None] = None  # (1)!\n    b: Union[int, SkipJsonSchema[None]] = None  # (2)!\n    c: SkipJsonSchema[Union[int, None]] = None  # (3)!\n\n\npprint(Model.model_json_schema())\n'''\n{\n    'properties': {\n        'a': {\n            'anyOf': [\n                {'type': 'integer'},\n                {'type': 'null'}\n            ],\n            'default': None,\n            'title': 'A'\n        },\n        'b': {\n            'default': None,\n            'title': 'B',\n            'type': 'integer'\n        }\n    },\n    'title': 'Model',\n    'type': 'object'\n}\n'''\n</code></pre> <ol> <li>The integer and null types are both included in the schema for <code>a</code>.</li> <li>The integer type is the only type included in the schema for <code>b</code>.</li> <li>The entirety of the <code>c</code> field is omitted from the schema.</li> </ol>"},{"location":"api/json_schema/#pydantic.json_schema.update_json_schema","title":"update_json_schema","text":"<pre><code>update_json_schema(\n    schema: JsonSchemaValue, updates: dict[str, Any]\n) -&gt; JsonSchemaValue\n</code></pre> <p>Update a JSON schema in-place by providing a dictionary of updates.</p> <p>This function sets the provided key-value pairs in the schema and returns the updated schema.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>JsonSchemaValue</code> <p>The JSON schema to update.</p> required <code>updates</code> <code>dict[str, Any]</code> <p>A dictionary of key-value pairs to set in the schema.</p> required <p>Returns:</p> Type Description <code>JsonSchemaValue</code> <p>The updated JSON schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>@deprecated(\n    '`update_json_schema` is deprecated, use a simple `my_dict.update(update_dict)` call instead.',\n    category=None,\n)\ndef update_json_schema(schema: JsonSchemaValue, updates: dict[str, Any]) -&gt; JsonSchemaValue:\n    \"\"\"Update a JSON schema in-place by providing a dictionary of updates.\n\n    This function sets the provided key-value pairs in the schema and returns the updated schema.\n\n    Args:\n        schema: The JSON schema to update.\n        updates: A dictionary of key-value pairs to set in the schema.\n\n    Returns:\n        The updated JSON schema.\n    \"\"\"\n    schema.update(updates)\n    return schema\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.model_json_schema","title":"model_json_schema","text":"<pre><code>model_json_schema(\n    cls: type[BaseModel] | type[PydanticDataclass],\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[\n        GenerateJsonSchema\n    ] = GenerateJsonSchema,\n    mode: JsonSchemaMode = \"validation\",\n) -&gt; dict[str, Any]\n</code></pre> <p>Utility function to generate a JSON Schema for a model.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>type[BaseModel] | type[PydanticDataclass]</code> <p>The model class to generate a JSON Schema for.</p> required <code>by_alias</code> <code>bool</code> <p>If <code>True</code> (the default), fields will be serialized according to their alias. If <code>False</code>, fields will be serialized according to their attribute name.</p> <code>True</code> <code>ref_template</code> <code>str</code> <p>The template to use for generating JSON Schema references.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>The class to use for generating the JSON Schema.</p> <code>GenerateJsonSchema</code> <code>mode</code> <code>JsonSchemaMode</code> <p>The mode to use for generating the JSON Schema. It can be one of the following:</p> <ul> <li>'validation': Generate a JSON Schema for validating data.</li> <li>'serialization': Generate a JSON Schema for serializing data.</li> </ul> <code>'validation'</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The generated JSON Schema.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def model_json_schema(\n    cls: type[BaseModel] | type[PydanticDataclass],\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n    mode: JsonSchemaMode = 'validation',\n) -&gt; dict[str, Any]:\n    \"\"\"Utility function to generate a JSON Schema for a model.\n\n    Args:\n        cls: The model class to generate a JSON Schema for.\n        by_alias: If `True` (the default), fields will be serialized according to their alias.\n            If `False`, fields will be serialized according to their attribute name.\n        ref_template: The template to use for generating JSON Schema references.\n        schema_generator: The class to use for generating the JSON Schema.\n        mode: The mode to use for generating the JSON Schema. It can be one of the following:\n\n            - 'validation': Generate a JSON Schema for validating data.\n            - 'serialization': Generate a JSON Schema for serializing data.\n\n    Returns:\n        The generated JSON Schema.\n    \"\"\"\n    from .main import BaseModel\n\n    schema_generator_instance = schema_generator(by_alias=by_alias, ref_template=ref_template)\n\n    if isinstance(cls.__pydantic_core_schema__, _mock_val_ser.MockCoreSchema):\n        cls.__pydantic_core_schema__.rebuild()\n\n    if cls is BaseModel:\n        raise AttributeError('model_json_schema() must be called on a subclass of BaseModel, not BaseModel itself.')\n\n    assert not isinstance(cls.__pydantic_core_schema__, _mock_val_ser.MockCoreSchema), 'this is a bug! please report it'\n    return schema_generator_instance.generate(cls.__pydantic_core_schema__, mode=mode)\n</code></pre>"},{"location":"api/json_schema/#pydantic.json_schema.models_json_schema","title":"models_json_schema","text":"<pre><code>models_json_schema(\n    models: Sequence[\n        tuple[\n            type[BaseModel] | type[PydanticDataclass],\n            JsonSchemaMode,\n        ]\n    ],\n    *,\n    by_alias: bool = True,\n    title: str | None = None,\n    description: str | None = None,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[\n        GenerateJsonSchema\n    ] = GenerateJsonSchema\n) -&gt; tuple[\n    dict[\n        tuple[\n            type[BaseModel] | type[PydanticDataclass],\n            JsonSchemaMode,\n        ],\n        JsonSchemaValue,\n    ],\n    JsonSchemaValue,\n]\n</code></pre> <p>Utility function to generate a JSON Schema for multiple models.</p> <p>Parameters:</p> Name Type Description Default <code>models</code> <code>Sequence[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode]]</code> <p>A sequence of tuples of the form (model, mode).</p> required <code>by_alias</code> <code>bool</code> <p>Whether field aliases should be used as keys in the generated JSON Schema.</p> <code>True</code> <code>title</code> <code>str | None</code> <p>The title of the generated JSON Schema.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>The description of the generated JSON Schema.</p> <code>None</code> <code>ref_template</code> <code>str</code> <p>The reference template to use for generating JSON Schema references.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>The schema generator to use for generating the JSON Schema.</p> <code>GenerateJsonSchema</code> <p>Returns:</p> Type Description <code>tuple[dict[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode], JsonSchemaValue], JsonSchemaValue]</code> <p>A tuple where: - The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and     whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have     JsonRef references to definitions that are defined in the second returned element.) - The second element is a JSON schema containing all definitions referenced in the first returned         element, along with the optional title and description keys.</p> Source code in <code>pydantic/json_schema.py</code> <pre><code>def models_json_schema(\n    models: Sequence[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode]],\n    *,\n    by_alias: bool = True,\n    title: str | None = None,\n    description: str | None = None,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n) -&gt; tuple[dict[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode], JsonSchemaValue], JsonSchemaValue]:\n    \"\"\"Utility function to generate a JSON Schema for multiple models.\n\n    Args:\n        models: A sequence of tuples of the form (model, mode).\n        by_alias: Whether field aliases should be used as keys in the generated JSON Schema.\n        title: The title of the generated JSON Schema.\n        description: The description of the generated JSON Schema.\n        ref_template: The reference template to use for generating JSON Schema references.\n        schema_generator: The schema generator to use for generating the JSON Schema.\n\n    Returns:\n        A tuple where:\n            - The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and\n                whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have\n                JsonRef references to definitions that are defined in the second returned element.)\n            - The second element is a JSON schema containing all definitions referenced in the first returned\n                    element, along with the optional title and description keys.\n    \"\"\"\n    for cls, _ in models:\n        if isinstance(cls.__pydantic_core_schema__, _mock_val_ser.MockCoreSchema):\n            cls.__pydantic_core_schema__.rebuild()\n\n    instance = schema_generator(by_alias=by_alias, ref_template=ref_template)\n    inputs: list[tuple[type[BaseModel] | type[PydanticDataclass], JsonSchemaMode, CoreSchema]] = [\n        (m, mode, m.__pydantic_core_schema__) for m, mode in models\n    ]\n    json_schemas_map, definitions = instance.generate_definitions(inputs)\n\n    json_schema: dict[str, Any] = {}\n    if definitions:\n        json_schema['$defs'] = definitions\n    if title:\n        json_schema['title'] = title\n    if description:\n        json_schema['description'] = description\n\n    return json_schemas_map, json_schema\n</code></pre>"},{"location":"api/networks/","title":"Network Types","text":"<p>The networks module contains types for common network-related fields.</p>"},{"location":"api/networks/#pydantic.networks.AnyUrl","title":"AnyUrl  <code>module-attribute</code>","text":"<pre><code>AnyUrl = Url\n</code></pre> <p>Base type for all URLs.</p> <ul> <li>Any scheme allowed</li> <li>Top-level domain (TLD) not required</li> <li>Host required</li> </ul> <p>Assuming an input URL of <code>http://samuel:pass@example.com:8000/the/path/?query=here#fragment=is;this=bit</code>, the types export the following properties:</p> <ul> <li><code>scheme</code>: the URL scheme (<code>http</code>), always set.</li> <li><code>host</code>: the URL host (<code>example.com</code>), always set.</li> <li><code>username</code>: optional username if included (<code>samuel</code>).</li> <li><code>password</code>: optional password if included (<code>pass</code>).</li> <li><code>port</code>: optional port (<code>8000</code>).</li> <li><code>path</code>: optional path (<code>/the/path/</code>).</li> <li><code>query</code>: optional URL query (for example, <code>GET</code> arguments or \"search string\", such as <code>query=here</code>).</li> <li><code>fragment</code>: optional fragment (<code>fragment=is;this=bit</code>).</li> </ul>"},{"location":"api/networks/#pydantic.networks.AnyHttpUrl","title":"AnyHttpUrl  <code>module-attribute</code>","text":"<pre><code>AnyHttpUrl = Annotated[\n    Url, UrlConstraints(allowed_schemes=[\"http\", \"https\"])\n]\n</code></pre> <p>A type that will accept any http or https URL.</p> <ul> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.HttpUrl","title":"HttpUrl  <code>module-attribute</code>","text":"<pre><code>HttpUrl = Annotated[\n    Url,\n    UrlConstraints(\n        max_length=2083, allowed_schemes=[\"http\", \"https\"]\n    ),\n]\n</code></pre> <p>A type that will accept any http or https URL.</p> <ul> <li>TLD not required</li> <li>Host required</li> <li>Max length 2083</li> </ul> <pre><code>from pydantic import BaseModel, HttpUrl, ValidationError\n\nclass MyModel(BaseModel):\n    url: HttpUrl\n\nm = MyModel(url='http://www.example.com')  # (1)!\nprint(m.url)\n#&gt; http://www.example.com/\n\ntry:\n    MyModel(url='ftp://invalid.url')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for MyModel\n    url\n      URL scheme should be 'http' or 'https' [type=url_scheme, input_value='ftp://invalid.url', input_type=str]\n    '''\n\ntry:\n    MyModel(url='not a url')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for MyModel\n    url\n      Input should be a valid URL, relative URL without a base [type=url_parsing, input_value='not a url', input_type=str]\n    '''\n</code></pre> <ol> <li>Note: mypy would prefer <code>m = MyModel(url=HttpUrl('http://www.example.com'))</code>, but Pydantic will convert the string to an HttpUrl instance anyway.</li> </ol> <p>\"International domains\" (e.g. a URL where the host or TLD includes non-ascii characters) will be encoded via punycode (see this article for a good description of why this is important):</p> <pre><code>from pydantic import BaseModel, HttpUrl\n\nclass MyModel(BaseModel):\n    url: HttpUrl\n\nm1 = MyModel(url='http://puny\u00a3code.com')\nprint(m1.url)\n#&gt; http://xn--punycode-eja.com/\nm2 = MyModel(url='https://www.\u0430\u0440\u0440\u04cf\u0435.com/')\nprint(m2.url)\n#&gt; https://www.xn--80ak6aa92e.com/\nm3 = MyModel(url='https://www.example.\u73e0\u5b9d/')\nprint(m3.url)\n#&gt; https://www.example.xn--pbt977c/\n</code></pre> <p>Underscores in Hostnames</p> <p>In Pydantic, underscores are allowed in all parts of a domain except the TLD. Technically this might be wrong - in theory the hostname cannot have underscores, but subdomains can.</p> <p>To explain this; consider the following two cases:</p> <ul> <li><code>exam_ple.co.uk</code>: the hostname is <code>exam_ple</code>, which should not be allowed since it contains an underscore.</li> <li><code>foo_bar.example.com</code> the hostname is <code>example</code>, which should be allowed since the underscore is in the subdomain.</li> </ul> <p>Without having an exhaustive list of TLDs, it would be impossible to differentiate between these two. Therefore underscores are allowed, but you can always do further validation in a validator if desired.</p> <p>Also, Chrome, Firefox, and Safari all currently accept <code>http://exam_ple.com</code> as a URL, so we're in good (or at least big) company.</p>"},{"location":"api/networks/#pydantic.networks.AnyWebsocketUrl","title":"AnyWebsocketUrl  <code>module-attribute</code>","text":"<pre><code>AnyWebsocketUrl = Annotated[\n    Url, UrlConstraints(allowed_schemes=[\"ws\", \"wss\"])\n]\n</code></pre> <p>A type that will accept any ws or wss URL.</p> <ul> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.WebsocketUrl","title":"WebsocketUrl  <code>module-attribute</code>","text":"<pre><code>WebsocketUrl = Annotated[\n    Url,\n    UrlConstraints(\n        max_length=2083, allowed_schemes=[\"ws\", \"wss\"]\n    ),\n]\n</code></pre> <p>A type that will accept any ws or wss URL.</p> <ul> <li>TLD not required</li> <li>Host required</li> <li>Max length 2083</li> </ul>"},{"location":"api/networks/#pydantic.networks.FileUrl","title":"FileUrl  <code>module-attribute</code>","text":"<pre><code>FileUrl = Annotated[\n    Url, UrlConstraints(allowed_schemes=[\"file\"])\n]\n</code></pre> <p>A type that will accept any file URL.</p> <ul> <li>Host not required</li> </ul>"},{"location":"api/networks/#pydantic.networks.FtpUrl","title":"FtpUrl  <code>module-attribute</code>","text":"<pre><code>FtpUrl = Annotated[\n    Url, UrlConstraints(allowed_schemes=[\"ftp\"])\n]\n</code></pre> <p>A type that will accept ftp URL.</p> <ul> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.PostgresDsn","title":"PostgresDsn  <code>module-attribute</code>","text":"<pre><code>PostgresDsn = Annotated[\n    MultiHostUrl,\n    UrlConstraints(\n        host_required=True,\n        allowed_schemes=[\n            \"postgres\",\n            \"postgresql\",\n            \"postgresql+asyncpg\",\n            \"postgresql+pg8000\",\n            \"postgresql+psycopg\",\n            \"postgresql+psycopg2\",\n            \"postgresql+psycopg2cffi\",\n            \"postgresql+py-postgresql\",\n            \"postgresql+pygresql\",\n        ],\n    ),\n]\n</code></pre> <p>A type that will accept any Postgres DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required</li> <li>Supports multiple hosts</li> </ul> <p>If further validation is required, these properties can be used by validators to enforce specific behaviour:</p> <pre><code>from pydantic import (\n    BaseModel,\n    HttpUrl,\n    PostgresDsn,\n    ValidationError,\n    field_validator,\n)\n\nclass MyModel(BaseModel):\n    url: HttpUrl\n\nm = MyModel(url='http://www.example.com')\n\n# the repr() method for a url will display all properties of the url\nprint(repr(m.url))\n#&gt; Url('http://www.example.com/')\nprint(m.url.scheme)\n#&gt; http\nprint(m.url.host)\n#&gt; www.example.com\nprint(m.url.port)\n#&gt; 80\n\nclass MyDatabaseModel(BaseModel):\n    db: PostgresDsn\n\n    @field_validator('db')\n    def check_db_name(cls, v):\n        assert v.path and len(v.path) &gt; 1, 'database must be provided'\n        return v\n\nm = MyDatabaseModel(db='postgres://user:pass@localhost:5432/foobar')\nprint(m.db)\n#&gt; postgres://user:pass@localhost:5432/foobar\n\ntry:\n    MyDatabaseModel(db='postgres://user:pass@localhost:5432')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for MyDatabaseModel\n    db\n      Assertion failed, database must be provided\n    assert (None)\n     +  where None = MultiHostUrl('postgres://user:pass@localhost:5432').path [type=assertion_error, input_value='postgres://user:pass@localhost:5432', input_type=str]\n    '''\n</code></pre>"},{"location":"api/networks/#pydantic.networks.CockroachDsn","title":"CockroachDsn  <code>module-attribute</code>","text":"<pre><code>CockroachDsn = Annotated[\n    Url,\n    UrlConstraints(\n        host_required=True,\n        allowed_schemes=[\n            \"cockroachdb\",\n            \"cockroachdb+psycopg2\",\n            \"cockroachdb+asyncpg\",\n        ],\n    ),\n]\n</code></pre> <p>A type that will accept any Cockroach DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.AmqpDsn","title":"AmqpDsn  <code>module-attribute</code>","text":"<pre><code>AmqpDsn = Annotated[\n    Url, UrlConstraints(allowed_schemes=[\"amqp\", \"amqps\"])\n]\n</code></pre> <p>A type that will accept any AMQP DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.RedisDsn","title":"RedisDsn  <code>module-attribute</code>","text":"<pre><code>RedisDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\"redis\", \"rediss\"],\n        default_host=\"localhost\",\n        default_port=6379,\n        default_path=\"/0\",\n    ),\n]\n</code></pre> <p>A type that will accept any Redis DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required (e.g., <code>rediss://:pass@localhost</code>)</li> </ul>"},{"location":"api/networks/#pydantic.networks.MongoDsn","title":"MongoDsn  <code>module-attribute</code>","text":"<pre><code>MongoDsn = Annotated[\n    MultiHostUrl,\n    UrlConstraints(\n        allowed_schemes=[\"mongodb\", \"mongodb+srv\"],\n        default_port=27017,\n    ),\n]\n</code></pre> <p>A type that will accept any MongoDB DSN.</p> <ul> <li>User info not required</li> <li>Database name not required</li> <li>Port not required</li> <li>User info may be passed without user part (e.g., <code>mongodb://mongodb0.example.com:27017</code>).</li> </ul>"},{"location":"api/networks/#pydantic.networks.KafkaDsn","title":"KafkaDsn  <code>module-attribute</code>","text":"<pre><code>KafkaDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\"kafka\"],\n        default_host=\"localhost\",\n        default_port=9092,\n    ),\n]\n</code></pre> <p>A type that will accept any Kafka DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.NatsDsn","title":"NatsDsn  <code>module-attribute</code>","text":"<pre><code>NatsDsn = Annotated[\n    MultiHostUrl,\n    UrlConstraints(\n        allowed_schemes=[\"nats\", \"tls\", \"ws\", \"wss\"],\n        default_host=\"localhost\",\n        default_port=4222,\n    ),\n]\n</code></pre> <p>A type that will accept any NATS DSN.</p> <p>NATS is a connective technology built for the ever increasingly hyper-connected world. It is a single technology that enables applications to securely communicate across any combination of cloud vendors, on-premise, edge, web and mobile, and devices. More: https://nats.io</p>"},{"location":"api/networks/#pydantic.networks.MySQLDsn","title":"MySQLDsn  <code>module-attribute</code>","text":"<pre><code>MySQLDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\n            \"mysql\",\n            \"mysql+mysqlconnector\",\n            \"mysql+aiomysql\",\n            \"mysql+asyncmy\",\n            \"mysql+mysqldb\",\n            \"mysql+pymysql\",\n            \"mysql+cymysql\",\n            \"mysql+pyodbc\",\n        ],\n        default_port=3306,\n    ),\n]\n</code></pre> <p>A type that will accept any MySQL DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.MariaDBDsn","title":"MariaDBDsn  <code>module-attribute</code>","text":"<pre><code>MariaDBDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\n            \"mariadb\",\n            \"mariadb+mariadbconnector\",\n            \"mariadb+pymysql\",\n        ],\n        default_port=3306,\n    ),\n]\n</code></pre> <p>A type that will accept any MariaDB DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.ClickHouseDsn","title":"ClickHouseDsn  <code>module-attribute</code>","text":"<pre><code>ClickHouseDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\n            \"clickhouse+native\",\n            \"clickhouse+asynch\",\n        ],\n        default_host=\"localhost\",\n        default_port=9000,\n    ),\n]\n</code></pre> <p>A type that will accept any ClickHouse DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.SnowflakeDsn","title":"SnowflakeDsn  <code>module-attribute</code>","text":"<pre><code>SnowflakeDsn = Annotated[\n    Url,\n    UrlConstraints(\n        allowed_schemes=[\"snowflake\"], host_required=True\n    ),\n]\n</code></pre> <p>A type that will accept any Snowflake DSN.</p> <ul> <li>User info required</li> <li>TLD not required</li> <li>Host required</li> </ul>"},{"location":"api/networks/#pydantic.networks.MAX_EMAIL_LENGTH","title":"MAX_EMAIL_LENGTH  <code>module-attribute</code>","text":"<pre><code>MAX_EMAIL_LENGTH = 2048\n</code></pre> <p>Maximum length for an email. A somewhat arbitrary but very generous number compared to what is allowed by most implementations.</p>"},{"location":"api/networks/#pydantic.networks.UrlConstraints","title":"UrlConstraints  <code>dataclass</code>","text":"<pre><code>UrlConstraints(\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n)\n</code></pre> <p>               Bases: <code>PydanticMetadata</code></p> <p>Url constraints.</p> <p>Attributes:</p> Name Type Description <code>max_length</code> <code>int | None</code> <p>The maximum length of the url. Defaults to <code>None</code>.</p> <code>allowed_schemes</code> <code>list[str] | None</code> <p>The allowed schemes. Defaults to <code>None</code>.</p> <code>host_required</code> <code>bool | None</code> <p>Whether the host is required. Defaults to <code>None</code>.</p> <code>default_host</code> <code>str | None</code> <p>The default host. Defaults to <code>None</code>.</p> <code>default_port</code> <code>int | None</code> <p>The default port. Defaults to <code>None</code>.</p> <code>default_path</code> <code>str | None</code> <p>The default path. Defaults to <code>None</code>.</p>"},{"location":"api/networks/#pydantic.networks.EmailStr","title":"EmailStr","text":"Info <p>To use this type, you need to install the optional <code>email-validator</code> package:</p> <pre><code>pip install email-validator\n</code></pre> <p>Validate email addresses.</p> <pre><code>from pydantic import BaseModel, EmailStr\n\nclass Model(BaseModel):\n    email: EmailStr\n\nprint(Model(email='contact@mail.com'))\n#&gt; email='contact@mail.com'\n</code></pre>"},{"location":"api/networks/#pydantic.networks.NameEmail","title":"NameEmail","text":"<pre><code>NameEmail(name: str, email: str)\n</code></pre> <p>               Bases: <code>Representation</code></p> Info <p>To use this type, you need to install the optional <code>email-validator</code> package:</p> <pre><code>pip install email-validator\n</code></pre> <p>Validate a name and email address combination, as specified by RFC 5322.</p> <p>The <code>NameEmail</code> has two properties: <code>name</code> and <code>email</code>. In case the <code>name</code> is not provided, it's inferred from the email address.</p> <pre><code>from pydantic import BaseModel, NameEmail\n\nclass User(BaseModel):\n    email: NameEmail\n\nuser = User(email='Fred Bloggs &lt;fred.bloggs@example.com&gt;')\nprint(user.email)\n#&gt; Fred Bloggs &lt;fred.bloggs@example.com&gt;\nprint(user.email.name)\n#&gt; Fred Bloggs\n\nuser = User(email='fred.bloggs@example.com')\nprint(user.email)\n#&gt; fred.bloggs &lt;fred.bloggs@example.com&gt;\nprint(user.email.name)\n#&gt; fred.bloggs\n</code></pre> Source code in <code>pydantic/networks.py</code> <pre><code>def __init__(self, name: str, email: str):\n    self.name = name\n    self.email = email\n</code></pre>"},{"location":"api/networks/#pydantic.networks.IPvAnyAddress","title":"IPvAnyAddress","text":"<p>Validate an IPv4 or IPv6 address.</p> <pre><code>from pydantic import BaseModel\nfrom pydantic.networks import IPvAnyAddress\n\nclass IpModel(BaseModel):\n    ip: IPvAnyAddress\n\nprint(IpModel(ip='127.0.0.1'))\n#&gt; ip=IPv4Address('127.0.0.1')\n\ntry:\n    IpModel(ip='http://www.example.com')\nexcept ValueError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'ip_any_address',\n            'loc': ('ip',),\n            'msg': 'value is not a valid IPv4 or IPv6 address',\n            'input': 'http://www.example.com',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/networks/#pydantic.networks.IPvAnyInterface","title":"IPvAnyInterface","text":"<p>Validate an IPv4 or IPv6 interface.</p>"},{"location":"api/networks/#pydantic.networks.IPvAnyNetwork","title":"IPvAnyNetwork","text":"<p>Validate an IPv4 or IPv6 network.</p>"},{"location":"api/networks/#pydantic.networks.validate_email","title":"validate_email","text":"<pre><code>validate_email(value: str) -&gt; tuple[str, str]\n</code></pre> <p>Email address validation using email-validator.</p> Note <p>Note that:</p> <ul> <li>Raw IP address (literal) domain parts are not allowed.</li> <li><code>\"John Doe &lt;local_part@domain.com&gt;\"</code> style \"pretty\" email addresses are processed.</li> <li>Spaces are striped from the beginning and end of addresses, but no error is raised.</li> </ul> Source code in <code>pydantic/networks.py</code> <pre><code>def validate_email(value: str) -&gt; tuple[str, str]:\n    \"\"\"Email address validation using [email-validator](https://pypi.org/project/email-validator/).\n\n    Note:\n        Note that:\n\n        * Raw IP address (literal) domain parts are not allowed.\n        * `\"John Doe &lt;local_part@domain.com&gt;\"` style \"pretty\" email addresses are processed.\n        * Spaces are striped from the beginning and end of addresses, but no error is raised.\n    \"\"\"\n    if email_validator is None:\n        import_email_validator()\n\n    if len(value) &gt; MAX_EMAIL_LENGTH:\n        raise PydanticCustomError(\n            'value_error',\n            'value is not a valid email address: {reason}',\n            {'reason': f'Length must not exceed {MAX_EMAIL_LENGTH} characters'},\n        )\n\n    m = pretty_email_regex.fullmatch(value)\n    name: str | None = None\n    if m:\n        unquoted_name, quoted_name, value = m.groups()\n        name = unquoted_name or quoted_name\n\n    email = value.strip()\n\n    try:\n        parts = email_validator.validate_email(email, check_deliverability=False)\n    except email_validator.EmailNotValidError as e:\n        raise PydanticCustomError(\n            'value_error', 'value is not a valid email address: {reason}', {'reason': str(e.args[0])}\n        ) from e\n\n    email = parts.normalized\n    assert email is not None\n    name = name or parts.local_part\n    return name, email\n</code></pre>"},{"location":"api/pydantic_core/","title":"pydantic_core","text":""},{"location":"api/pydantic_core/#pydantic_core.__version__","title":"__version__  <code>module-attribute</code>","text":"<pre><code>__version__: str\n</code></pre>"},{"location":"api/pydantic_core/#pydantic_core.SchemaValidator","title":"SchemaValidator","text":"<p><code>SchemaValidator</code> is the Python wrapper for <code>pydantic-core</code>'s Rust validation logic, internally it owns one <code>CombinedValidator</code> which may in turn own more <code>CombinedValidator</code>s which make up the full schema validator.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaValidator.title","title":"title  <code>property</code>","text":"<pre><code>title: str\n</code></pre> <p>The title of the schema, as used in the heading of <code>ValidationError.__str__()</code>.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaValidator.validate_python","title":"validate_python","text":"<pre><code>validate_python(\n    input: Any,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: Any | None = None,\n    self_instance: Any | None = None\n) -&gt; Any\n</code></pre> <p>Validate a Python object against the schema and return the validated object.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The Python object to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to validate the object in strict mode. If <code>None</code>, the value of <code>CoreConfig.strict</code> is used.</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to validate objects as inputs to models by extracting attributes. If <code>None</code>, the value of <code>CoreConfig.from_attributes</code> is used.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>The context to use for validation, this is passed to functional validators as <code>info.context</code>.</p> <code>None</code> <code>self_instance</code> <code>Any | None</code> <p>An instance of a model set attributes on from validation, this is used when running validation from the <code>__init__</code> method of a model.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails.</p> <code>Exception</code> <p>Other error types maybe raised if internal errors occur.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The validated object.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaValidator.isinstance_python","title":"isinstance_python","text":"<pre><code>isinstance_python(\n    input: Any,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: Any | None = None,\n    self_instance: Any | None = None\n) -&gt; bool\n</code></pre> <p>Similar to <code>validate_python()</code> but returns a boolean.</p> <p>Arguments match <code>validate_python()</code>. This method will not raise <code>ValidationError</code>s but will raise internal errors.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if validation succeeds, <code>False</code> if validation fails.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaValidator.validate_json","title":"validate_json","text":"<pre><code>validate_json(\n    input: str | bytes | bytearray,\n    *,\n    strict: bool | None = None,\n    context: Any | None = None,\n    self_instance: Any | None = None\n) -&gt; Any\n</code></pre> <p>Validate JSON data directly against the schema and return the validated Python object.</p> <p>This method should be significantly faster than <code>validate_python(json.loads(json_data))</code> as it avoids the need to create intermediate Python objects</p> <p>It also handles constructing the correct Python type even in strict mode, where <code>validate_python(json.loads(json_data))</code> would fail validation.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str | bytes | bytearray</code> <p>The JSON data to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to validate the object in strict mode. If <code>None</code>, the value of <code>CoreConfig.strict</code> is used.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>The context to use for validation, this is passed to functional validators as <code>info.context</code>.</p> <code>None</code> <code>self_instance</code> <code>Any | None</code> <p>An instance of a model set attributes on from validation.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails or if the JSON data is invalid.</p> <code>Exception</code> <p>Other error types maybe raised if internal errors occur.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The validated Python object.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaValidator.validate_strings","title":"validate_strings","text":"<pre><code>validate_strings(\n    input: _StringInput,\n    *,\n    strict: bool | None = None,\n    context: Any | None = None\n) -&gt; Any\n</code></pre> <p>Validate a string against the schema and return the validated Python object.</p> <p>This is similar to <code>validate_json</code> but applies to scenarios where the input will be a string but not JSON data, e.g. URL fragments, query parameters, etc.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>_StringInput</code> <p>The input as a string, or bytes/bytearray if <code>strict=False</code>.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to validate the object in strict mode. If <code>None</code>, the value of <code>CoreConfig.strict</code> is used.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>The context to use for validation, this is passed to functional validators as <code>info.context</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails or if the JSON data is invalid.</p> <code>Exception</code> <p>Other error types maybe raised if internal errors occur.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The validated Python object.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaValidator.validate_assignment","title":"validate_assignment","text":"<pre><code>validate_assignment(\n    obj: Any,\n    field_name: str,\n    field_value: Any,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: Any | None = None\n) -&gt; (\n    dict[str, Any]\n    | tuple[dict[str, Any], dict[str, Any] | None, set[str]]\n)\n</code></pre> <p>Validate an assignment to a field on a model.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The model instance being assigned to.</p> required <code>field_name</code> <code>str</code> <p>The name of the field to validate assignment for.</p> required <code>field_value</code> <code>Any</code> <p>The value to assign to the field.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to validate the object in strict mode. If <code>None</code>, the value of <code>CoreConfig.strict</code> is used.</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to validate objects as inputs to models by extracting attributes. If <code>None</code>, the value of <code>CoreConfig.from_attributes</code> is used.</p> <code>None</code> <code>context</code> <code>Any | None</code> <p>The context to use for validation, this is passed to functional validators as <code>info.context</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails.</p> <code>Exception</code> <p>Other error types maybe raised if internal errors occur.</p> <p>Returns:</p> Type Description <code>dict[str, Any] | tuple[dict[str, Any], dict[str, Any] | None, set[str]]</code> <p>Either the model dict or a tuple of <code>(model_data, model_extra, fields_set)</code></p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaValidator.get_default_value","title":"get_default_value","text":"<pre><code>get_default_value(\n    *, strict: bool | None = None, context: Any = None\n) -&gt; Some | None\n</code></pre> <p>Get the default value for the schema, including running default value validation.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the default value in strict mode. If <code>None</code>, the value of <code>CoreConfig.strict</code> is used.</p> <code>None</code> <code>context</code> <code>Any</code> <p>The context to use for validation, this is passed to functional validators as <code>info.context</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValidationError</code> <p>If validation fails.</p> <code>Exception</code> <p>Other error types maybe raised if internal errors occur.</p> <p>Returns:</p> Type Description <code>Some | None</code> <p><code>None</code> if the schema has no default value, otherwise a <code>Some</code> containing the default.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaSerializer","title":"SchemaSerializer","text":"<p><code>SchemaSerializer</code> is the Python wrapper for <code>pydantic-core</code>'s Rust serialization logic, internally it owns one <code>CombinedSerializer</code> which may in turn own more <code>CombinedSerializer</code>s which make up the full schema serializer.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaSerializer.to_python","title":"to_python","text":"<pre><code>to_python(\n    value: Any,\n    *,\n    mode: str | None = None,\n    include: _IncEx = None,\n    exclude: _IncEx = None,\n    by_alias: bool = True,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: (\n        bool | Literal[\"none\", \"warn\", \"error\"]\n    ) = True,\n    fallback: Callable[[Any], Any] | None = None,\n    serialize_as_any: bool = False,\n    context: Any | None = None\n) -&gt; Any\n</code></pre> <p>Serialize/marshal a Python object to a Python object including transforming and filtering data.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The Python object to serialize.</p> required <code>mode</code> <code>str | None</code> <p>The serialization mode to use, either <code>'python'</code> or <code>'json'</code>, defaults to <code>'python'</code>. In JSON mode, all values are converted to JSON compatible types, e.g. <code>None</code>, <code>int</code>, <code>float</code>, <code>str</code>, <code>list</code>, <code>dict</code>.</p> <code>None</code> <code>include</code> <code>_IncEx</code> <p>A set of fields to include, if <code>None</code> all fields are included.</p> <code>None</code> <code>exclude</code> <code>_IncEx</code> <p>A set of fields to exclude, if <code>None</code> no fields are excluded.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use the alias names of fields.</p> <code>True</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that are not set, e.g. are not included in <code>__pydantic_fields_set__</code>.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that are equal to their default value.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to enable serialization and validation round-trip support.</p> <code>False</code> <code>warnings</code> <code>bool | Literal['none', 'warn', 'error']</code> <p>How to handle invalid fields. False/\"none\" ignores them, True/\"warn\" logs errors, \"error\" raises a <code>PydanticSerializationError</code>.</p> <code>True</code> <code>fallback</code> <code>Callable[[Any], Any] | None</code> <p>A function to call when an unknown value is encountered, if <code>None</code> a <code>PydanticSerializationError</code> error is raised.</p> <code>None</code> <code>serialize_as_any</code> <code>bool</code> <p>Whether to serialize fields with duck-typing serialization behavior.</p> <code>False</code> <code>context</code> <code>Any | None</code> <p>The context to use for serialization, this is passed to functional serializers as <code>info.context</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>PydanticSerializationError</code> <p>If serialization fails and no <code>fallback</code> function is provided.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The serialized Python object.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaSerializer.to_json","title":"to_json","text":"<pre><code>to_json(\n    value: Any,\n    *,\n    indent: int | None = None,\n    include: _IncEx = None,\n    exclude: _IncEx = None,\n    by_alias: bool = True,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: (\n        bool | Literal[\"none\", \"warn\", \"error\"]\n    ) = True,\n    fallback: Callable[[Any], Any] | None = None,\n    serialize_as_any: bool = False,\n    context: Any | None = None\n) -&gt; bytes\n</code></pre> <p>Serialize a Python object to JSON including transforming and filtering data.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The Python object to serialize.</p> required <code>indent</code> <code>int | None</code> <p>If <code>None</code>, the JSON will be compact, otherwise it will be pretty-printed with the indent provided.</p> <code>None</code> <code>include</code> <code>_IncEx</code> <p>A set of fields to include, if <code>None</code> all fields are included.</p> <code>None</code> <code>exclude</code> <code>_IncEx</code> <p>A set of fields to exclude, if <code>None</code> no fields are excluded.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use the alias names of fields.</p> <code>True</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that are not set, e.g. are not included in <code>__pydantic_fields_set__</code>.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that are equal to their default value.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to enable serialization and validation round-trip support.</p> <code>False</code> <code>warnings</code> <code>bool | Literal['none', 'warn', 'error']</code> <p>How to handle invalid fields. False/\"none\" ignores them, True/\"warn\" logs errors, \"error\" raises a <code>PydanticSerializationError</code>.</p> <code>True</code> <code>fallback</code> <code>Callable[[Any], Any] | None</code> <p>A function to call when an unknown value is encountered, if <code>None</code> a <code>PydanticSerializationError</code> error is raised.</p> <code>None</code> <code>serialize_as_any</code> <code>bool</code> <p>Whether to serialize fields with duck-typing serialization behavior.</p> <code>False</code> <code>context</code> <code>Any | None</code> <p>The context to use for serialization, this is passed to functional serializers as <code>info.context</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>PydanticSerializationError</code> <p>If serialization fails and no <code>fallback</code> function is provided.</p> <p>Returns:</p> Type Description <code>bytes</code> <p>JSON bytes.</p>"},{"location":"api/pydantic_core/#pydantic_core.ValidationError","title":"ValidationError","text":"<p>               Bases: <code>ValueError</code></p> <p><code>ValidationError</code> is the exception raised by <code>pydantic-core</code> when validation fails, it contains a list of errors which detail why validation failed.</p>"},{"location":"api/pydantic_core/#pydantic_core.ValidationError.title","title":"title  <code>property</code>","text":"<pre><code>title: str\n</code></pre> <p>The title of the error, as used in the heading of <code>str(validation_error)</code>.</p>"},{"location":"api/pydantic_core/#pydantic_core.ValidationError.from_exception_data","title":"from_exception_data  <code>staticmethod</code>","text":"<pre><code>from_exception_data(\n    title: str,\n    line_errors: list[InitErrorDetails],\n    input_type: Literal[\"python\", \"json\"] = \"python\",\n    hide_input: bool = False,\n) -&gt; ValidationError\n</code></pre> <p>Python constructor for a Validation Error.</p> <p>The API for constructing validation errors will probably change in the future, hence the static method rather than <code>__init__</code>.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>The title of the error, as used in the heading of <code>str(validation_error)</code></p> required <code>line_errors</code> <code>list[InitErrorDetails]</code> <p>A list of <code>InitErrorDetails</code> which contain information about errors that occurred during validation.</p> required <code>input_type</code> <code>Literal['python', 'json']</code> <p>Whether the error is for a Python object or JSON.</p> <code>'python'</code> <code>hide_input</code> <code>bool</code> <p>Whether to hide the input value in the error message.</p> <code>False</code>"},{"location":"api/pydantic_core/#pydantic_core.ValidationError.error_count","title":"error_count","text":"<pre><code>error_count() -&gt; int\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>The number of errors in the validation error.</p>"},{"location":"api/pydantic_core/#pydantic_core.ValidationError.errors","title":"errors","text":"<pre><code>errors(\n    *,\n    include_url: bool = True,\n    include_context: bool = True,\n    include_input: bool = True\n) -&gt; list[ErrorDetails]\n</code></pre> <p>Details about each error in the validation error.</p> <p>Parameters:</p> Name Type Description Default <code>include_url</code> <code>bool</code> <p>Whether to include a URL to documentation on the error each error.</p> <code>True</code> <code>include_context</code> <code>bool</code> <p>Whether to include the context of each error.</p> <code>True</code> <code>include_input</code> <code>bool</code> <p>Whether to include the input value of each error.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[ErrorDetails]</code> <p>A list of <code>ErrorDetails</code> for each error in the validation error.</p>"},{"location":"api/pydantic_core/#pydantic_core.ValidationError.json","title":"json","text":"<pre><code>json(\n    *,\n    indent: int | None = None,\n    include_url: bool = True,\n    include_context: bool = True,\n    include_input: bool = True\n) -&gt; str\n</code></pre> <p>Same as <code>errors()</code> but returns a JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>indent</code> <code>int | None</code> <p>The number of spaces to indent the JSON by, or <code>None</code> for no indentation - compact JSON.</p> <code>None</code> <code>include_url</code> <code>bool</code> <p>Whether to include a URL to documentation on the error each error.</p> <code>True</code> <code>include_context</code> <code>bool</code> <p>Whether to include the context of each error.</p> <code>True</code> <code>include_input</code> <code>bool</code> <p>Whether to include the input value of each error.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>a JSON string.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorDetails","title":"ErrorDetails","text":"<p>               Bases: <code>TypedDict</code></p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorDetails.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: str\n</code></pre> <p>The type of error that occurred, this is an identifier designed for programmatic use that will change rarely or never.</p> <p><code>type</code> is unique for each error message, and can hence be used as an identifier to build custom error messages.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorDetails.loc","title":"loc  <code>instance-attribute</code>","text":"<pre><code>loc: tuple[int | str, ...]\n</code></pre> <p>Tuple of strings and ints identifying where in the schema the error occurred.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorDetails.msg","title":"msg  <code>instance-attribute</code>","text":"<pre><code>msg: str\n</code></pre> <p>A human readable error message.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorDetails.input","title":"input  <code>instance-attribute</code>","text":"<pre><code>input: Any\n</code></pre> <p>The input data at this <code>loc</code> that caused the error.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorDetails.ctx","title":"ctx  <code>instance-attribute</code>","text":"<pre><code>ctx: NotRequired[dict[str, Any]]\n</code></pre> <p>Values which are required to render the error message, and could hence be useful in rendering custom error messages. Also useful for passing custom error data forward.</p>"},{"location":"api/pydantic_core/#pydantic_core.InitErrorDetails","title":"InitErrorDetails","text":"<p>               Bases: <code>TypedDict</code></p>"},{"location":"api/pydantic_core/#pydantic_core.InitErrorDetails.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: str | PydanticCustomError\n</code></pre> <p>The type of error that occurred, this should a \"slug\" identifier that changes rarely or never.</p>"},{"location":"api/pydantic_core/#pydantic_core.InitErrorDetails.loc","title":"loc  <code>instance-attribute</code>","text":"<pre><code>loc: NotRequired[tuple[int | str, ...]]\n</code></pre> <p>Tuple of strings and ints identifying where in the schema the error occurred.</p>"},{"location":"api/pydantic_core/#pydantic_core.InitErrorDetails.input","title":"input  <code>instance-attribute</code>","text":"<pre><code>input: Any\n</code></pre> <p>The input data at this <code>loc</code> that caused the error.</p>"},{"location":"api/pydantic_core/#pydantic_core.InitErrorDetails.ctx","title":"ctx  <code>instance-attribute</code>","text":"<pre><code>ctx: NotRequired[dict[str, Any]]\n</code></pre> <p>Values which are required to render the error message, and could hence be useful in rendering custom error messages. Also useful for passing custom error data forward.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaError","title":"SchemaError","text":"<p>               Bases: <code>Exception</code></p> <p>Information about errors that occur while building a <code>SchemaValidator</code> or <code>SchemaSerializer</code>.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaError.error_count","title":"error_count","text":"<pre><code>error_count() -&gt; int\n</code></pre> <p>Returns:</p> Type Description <code>int</code> <p>The number of errors in the schema.</p>"},{"location":"api/pydantic_core/#pydantic_core.SchemaError.errors","title":"errors","text":"<pre><code>errors() -&gt; list[ErrorDetails]\n</code></pre> <p>Returns:</p> Type Description <code>list[ErrorDetails]</code> <p>A list of <code>ErrorDetails</code> for each error in the schema.</p>"},{"location":"api/pydantic_core/#pydantic_core.PydanticCustomError","title":"PydanticCustomError","text":"<p>               Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core/#pydantic_core.PydanticKnownError","title":"PydanticKnownError","text":"<p>               Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core/#pydantic_core.PydanticOmit","title":"PydanticOmit","text":"<p>               Bases: <code>Exception</code></p>"},{"location":"api/pydantic_core/#pydantic_core.PydanticSerializationError","title":"PydanticSerializationError","text":"<p>               Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core/#pydantic_core.PydanticSerializationUnexpectedValue","title":"PydanticSerializationUnexpectedValue","text":"<p>               Bases: <code>ValueError</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url","title":"Url","text":"<p>               Bases: <code>SupportsAllComparisons</code></p> <p>A URL type, internal logic uses the url rust crate originally developed by Mozilla.</p>"},{"location":"api/pydantic_core/#pydantic_core.Url.scheme","title":"scheme  <code>property</code>","text":"<pre><code>scheme: str\n</code></pre> <p>The scheme part of the URL.</p> <p>e.g. <code>https</code> in <code>https://user:pass@host:port/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.username","title":"username  <code>property</code>","text":"<pre><code>username: str | None\n</code></pre> <p>The username part of the URL, or <code>None</code>.</p> <p>e.g. <code>user</code> in <code>https://user:pass@host:port/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.password","title":"password  <code>property</code>","text":"<pre><code>password: str | None\n</code></pre> <p>The password part of the URL, or <code>None</code>.</p> <p>e.g. <code>pass</code> in <code>https://user:pass@host:port/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.host","title":"host  <code>property</code>","text":"<pre><code>host: str | None\n</code></pre> <p>The host part of the URL, or <code>None</code>.</p> <p>If the URL must be punycode encoded, this is the encoded host, e.g if the input URL is <code>https://\u00a3\u00a3\u00a3.com</code>, <code>host</code> will be <code>xn--9aaa.com</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.port","title":"port  <code>property</code>","text":"<pre><code>port: int | None\n</code></pre> <p>The port part of the URL, or <code>None</code>.</p> <p>e.g. <code>port</code> in <code>https://user:pass@host:port/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.path","title":"path  <code>property</code>","text":"<pre><code>path: str | None\n</code></pre> <p>The path part of the URL, or <code>None</code>.</p> <p>e.g. <code>/path</code> in <code>https://user:pass@host:port/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.query","title":"query  <code>property</code>","text":"<pre><code>query: str | None\n</code></pre> <p>The query part of the URL, or <code>None</code>.</p> <p>e.g. <code>query</code> in <code>https://user:pass@host:port/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.fragment","title":"fragment  <code>property</code>","text":"<pre><code>fragment: str | None\n</code></pre> <p>The fragment part of the URL, or <code>None</code>.</p> <p>e.g. <code>fragment</code> in <code>https://user:pass@host:port/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.unicode_host","title":"unicode_host","text":"<pre><code>unicode_host() -&gt; str | None\n</code></pre> <p>The host part of the URL as a unicode string, or <code>None</code>.</p> <p>e.g. <code>host</code> in <code>https://user:pass@host:port/path?query#fragment</code></p> <p>If the URL must be punycode encoded, this is the decoded host, e.g if the input URL is <code>https://\u00a3\u00a3\u00a3.com</code>, <code>unicode_host()</code> will be <code>\u00a3\u00a3\u00a3.com</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.query_params","title":"query_params","text":"<pre><code>query_params() -&gt; list[tuple[str, str]]\n</code></pre> <p>The query part of the URL as a list of key-value pairs.</p> <p>e.g. <code>[('foo', 'bar')]</code> in <code>https://user:pass@host:port/path?foo=bar#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.unicode_string","title":"unicode_string","text":"<pre><code>unicode_string() -&gt; str\n</code></pre> <p>The URL as a unicode string, unlike <code>__str__()</code> this will not punycode encode the host.</p> <p>If the URL must be punycode encoded, this is the decoded string, e.g if the input URL is <code>https://\u00a3\u00a3\u00a3.com</code>, <code>unicode_string()</code> will be <code>https://\u00a3\u00a3\u00a3.com</code></p>"},{"location":"api/pydantic_core/#pydantic_core.Url.build","title":"build  <code>classmethod</code>","text":"<pre><code>build(\n    *,\n    scheme: str,\n    username: str | None = None,\n    password: str | None = None,\n    host: str,\n    port: int | None = None,\n    path: str | None = None,\n    query: str | None = None,\n    fragment: str | None = None\n) -&gt; Self\n</code></pre> <p>Build a new <code>Url</code> instance from its component parts.</p> <p>Parameters:</p> Name Type Description Default <code>scheme</code> <code>str</code> <p>The scheme part of the URL.</p> required <code>username</code> <code>str | None</code> <p>The username part of the URL, or omit for no username.</p> <code>None</code> <code>password</code> <code>str | None</code> <p>The password part of the URL, or omit for no password.</p> <code>None</code> <code>host</code> <code>str</code> <p>The host part of the URL.</p> required <code>port</code> <code>int | None</code> <p>The port part of the URL, or omit for no port.</p> <code>None</code> <code>path</code> <code>str | None</code> <p>The path part of the URL, or omit for no path.</p> <code>None</code> <code>query</code> <code>str | None</code> <p>The query part of the URL, or omit for no query.</p> <code>None</code> <code>fragment</code> <code>str | None</code> <p>The fragment part of the URL, or omit for no fragment.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>An instance of URL</p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl","title":"MultiHostUrl","text":"<p>               Bases: <code>SupportsAllComparisons</code></p> <p>A URL type with support for multiple hosts, as used by some databases for DSNs, e.g. <code>https://foo.com,bar.com/path</code>.</p> <p>Internal URL logic uses the url rust crate originally developed by Mozilla.</p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl.scheme","title":"scheme  <code>property</code>","text":"<pre><code>scheme: str\n</code></pre> <p>The scheme part of the URL.</p> <p>e.g. <code>https</code> in <code>https://foo.com,bar.com/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl.path","title":"path  <code>property</code>","text":"<pre><code>path: str | None\n</code></pre> <p>The path part of the URL, or <code>None</code>.</p> <p>e.g. <code>/path</code> in <code>https://foo.com,bar.com/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl.query","title":"query  <code>property</code>","text":"<pre><code>query: str | None\n</code></pre> <p>The query part of the URL, or <code>None</code>.</p> <p>e.g. <code>query</code> in <code>https://foo.com,bar.com/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl.fragment","title":"fragment  <code>property</code>","text":"<pre><code>fragment: str | None\n</code></pre> <p>The fragment part of the URL, or <code>None</code>.</p> <p>e.g. <code>fragment</code> in <code>https://foo.com,bar.com/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl.query_params","title":"query_params","text":"<pre><code>query_params() -&gt; list[tuple[str, str]]\n</code></pre> <p>The query part of the URL as a list of key-value pairs.</p> <p>e.g. <code>[('foo', 'bar')]</code> in <code>https://foo.com,bar.com/path?query#fragment</code></p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl.hosts","title":"hosts","text":"<pre><code>hosts() -&gt; list[MultiHostHost]\n</code></pre> <p>The hosts of the <code>MultiHostUrl</code> as <code>MultiHostHost</code> typed dicts.</p> <p><pre><code>from pydantic_core import MultiHostUrl\n\nmhu = MultiHostUrl('https://foo.com:123,foo:bar@bar.com/path')\nprint(mhu.hosts())\n\"\"\"\n[\n    {'username': None, 'password': None, 'host': 'foo.com', 'port': 123},\n    {'username': 'foo', 'password': 'bar', 'host': 'bar.com', 'port': 443}\n]\n</code></pre> Returns:     A list of dicts, each representing a host.</p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl.unicode_string","title":"unicode_string","text":"<pre><code>unicode_string() -&gt; str\n</code></pre> <p>The URL as a unicode string, unlike <code>__str__()</code> this will not punycode encode the hosts.</p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostUrl.build","title":"build  <code>classmethod</code>","text":"<pre><code>build(\n    *,\n    scheme: str,\n    hosts: list[MultiHostHost] | None = None,\n    username: str | None = None,\n    password: str | None = None,\n    host: str | None = None,\n    port: int | None = None,\n    path: str | None = None,\n    query: str | None = None,\n    fragment: str | None = None\n) -&gt; Self\n</code></pre> <p>Build a new <code>MultiHostUrl</code> instance from its component parts.</p> <p>This method takes either <code>hosts</code> - a list of <code>MultiHostHost</code> typed dicts, or the individual components <code>username</code>, <code>password</code>, <code>host</code> and <code>port</code>.</p> <p>Parameters:</p> Name Type Description Default <code>scheme</code> <code>str</code> <p>The scheme part of the URL.</p> required <code>hosts</code> <code>list[MultiHostHost] | None</code> <p>Multiple hosts to build the URL from.</p> <code>None</code> <code>username</code> <code>str | None</code> <p>The username part of the URL.</p> <code>None</code> <code>password</code> <code>str | None</code> <p>The password part of the URL.</p> <code>None</code> <code>host</code> <code>str | None</code> <p>The host part of the URL.</p> <code>None</code> <code>port</code> <code>int | None</code> <p>The port part of the URL.</p> <code>None</code> <code>path</code> <code>str | None</code> <p>The path part of the URL.</p> <code>None</code> <code>query</code> <code>str | None</code> <p>The query part of the URL, or omit for no query.</p> <code>None</code> <code>fragment</code> <code>str | None</code> <p>The fragment part of the URL, or omit for no fragment.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>An instance of <code>MultiHostUrl</code></p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostHost","title":"MultiHostHost","text":"<p>               Bases: <code>TypedDict</code></p> <p>A host part of a multi-host URL.</p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostHost.username","title":"username  <code>instance-attribute</code>","text":"<pre><code>username: str | None\n</code></pre> <p>The username part of this host, or <code>None</code>.</p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostHost.password","title":"password  <code>instance-attribute</code>","text":"<pre><code>password: str | None\n</code></pre> <p>The password part of this host, or <code>None</code>.</p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostHost.host","title":"host  <code>instance-attribute</code>","text":"<pre><code>host: str | None\n</code></pre> <p>The host part of this host, or <code>None</code>.</p>"},{"location":"api/pydantic_core/#pydantic_core.MultiHostHost.port","title":"port  <code>instance-attribute</code>","text":"<pre><code>port: int | None\n</code></pre> <p>The port part of this host, or <code>None</code>.</p>"},{"location":"api/pydantic_core/#pydantic_core.ArgsKwargs","title":"ArgsKwargs","text":""},{"location":"api/pydantic_core/#pydantic_core.Some","title":"Some","text":"<p>               Bases: <code>Generic[_T]</code></p> <p>Similar to Rust's <code>Option::Some</code> type, this identifies a value as being present, and provides a way to access it.</p> <p>Generally used in a union with <code>None</code> to different between \"some value which could be None\" and no value.</p>"},{"location":"api/pydantic_core/#pydantic_core.Some.value","title":"value  <code>property</code>","text":"<pre><code>value: _T\n</code></pre> <p>Returns the value wrapped by <code>Some</code>.</p>"},{"location":"api/pydantic_core/#pydantic_core.TzInfo","title":"TzInfo","text":"<p>               Bases: <code>tzinfo</code></p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorTypeInfo","title":"ErrorTypeInfo","text":"<p>               Bases: <code>TypedDict</code></p> <p>Gives information about errors.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorTypeInfo.type","title":"type  <code>instance-attribute</code>","text":"<pre><code>type: ErrorType\n</code></pre> <p>The type of error that occurred, this should a \"slug\" identifier that changes rarely or never.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorTypeInfo.message_template_python","title":"message_template_python  <code>instance-attribute</code>","text":"<pre><code>message_template_python: str\n</code></pre> <p>String template to render a human readable error message from using context, when the input is Python.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorTypeInfo.example_message_python","title":"example_message_python  <code>instance-attribute</code>","text":"<pre><code>example_message_python: str\n</code></pre> <p>Example of a human readable error message, when the input is Python.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorTypeInfo.message_template_json","title":"message_template_json  <code>instance-attribute</code>","text":"<pre><code>message_template_json: NotRequired[str]\n</code></pre> <p>String template to render a human readable error message from using context, when the input is JSON data.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorTypeInfo.example_message_json","title":"example_message_json  <code>instance-attribute</code>","text":"<pre><code>example_message_json: NotRequired[str]\n</code></pre> <p>Example of a human readable error message, when the input is JSON data.</p>"},{"location":"api/pydantic_core/#pydantic_core.ErrorTypeInfo.example_context","title":"example_context  <code>instance-attribute</code>","text":"<pre><code>example_context: dict[str, Any] | None\n</code></pre> <p>Example of context values.</p>"},{"location":"api/pydantic_core/#pydantic_core.to_json","title":"to_json","text":"<pre><code>to_json(\n    value: Any,\n    *,\n    indent: int | None = None,\n    include: _IncEx = None,\n    exclude: _IncEx = None,\n    by_alias: bool = True,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    timedelta_mode: Literal[\"iso8601\", \"float\"] = \"iso8601\",\n    bytes_mode: Literal[\"utf8\", \"base64\", \"hex\"] = \"utf8\",\n    inf_nan_mode: Literal[\n        \"null\", \"constants\", \"strings\"\n    ] = \"constants\",\n    serialize_unknown: bool = False,\n    fallback: Callable[[Any], Any] | None = None,\n    serialize_as_any: bool = False,\n    context: Any | None = None\n) -&gt; bytes\n</code></pre> <p>Serialize a Python object to JSON including transforming and filtering data.</p> <p>This is effectively a standalone version of <code>SchemaSerializer.to_json</code>.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The Python object to serialize.</p> required <code>indent</code> <code>int | None</code> <p>If <code>None</code>, the JSON will be compact, otherwise it will be pretty-printed with the indent provided.</p> <code>None</code> <code>include</code> <code>_IncEx</code> <p>A set of fields to include, if <code>None</code> all fields are included.</p> <code>None</code> <code>exclude</code> <code>_IncEx</code> <p>A set of fields to exclude, if <code>None</code> no fields are excluded.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use the alias names of fields.</p> <code>True</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to enable serialization and validation round-trip support.</p> <code>False</code> <code>timedelta_mode</code> <code>Literal['iso8601', 'float']</code> <p>How to serialize <code>timedelta</code> objects, either <code>'iso8601'</code> or <code>'float'</code>.</p> <code>'iso8601'</code> <code>bytes_mode</code> <code>Literal['utf8', 'base64', 'hex']</code> <p>How to serialize <code>bytes</code> objects, either <code>'utf8'</code>, <code>'base64'</code>, or <code>'hex'</code>.</p> <code>'utf8'</code> <code>inf_nan_mode</code> <code>Literal['null', 'constants', 'strings']</code> <p>How to serialize <code>Infinity</code>, <code>-Infinity</code> and <code>NaN</code> values, either <code>'null'</code>, <code>'constants'</code>, or <code>'strings'</code>.</p> <code>'constants'</code> <code>serialize_unknown</code> <code>bool</code> <p>Attempt to serialize unknown types, <code>str(value)</code> will be used, if that fails <code>\"&lt;Unserializable {value_type} object&gt;\"</code> will be used.</p> <code>False</code> <code>fallback</code> <code>Callable[[Any], Any] | None</code> <p>A function to call when an unknown value is encountered, if <code>None</code> a <code>PydanticSerializationError</code> error is raised.</p> <code>None</code> <code>serialize_as_any</code> <code>bool</code> <p>Whether to serialize fields with duck-typing serialization behavior.</p> <code>False</code> <code>context</code> <code>Any | None</code> <p>The context to use for serialization, this is passed to functional serializers as <code>info.context</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>PydanticSerializationError</code> <p>If serialization fails and no <code>fallback</code> function is provided.</p> <p>Returns:</p> Type Description <code>bytes</code> <p>JSON bytes.</p>"},{"location":"api/pydantic_core/#pydantic_core.from_json","title":"from_json","text":"<pre><code>from_json(\n    data: str | bytes | bytearray,\n    *,\n    allow_inf_nan: bool = True,\n    cache_strings: (\n        bool | Literal[\"all\", \"keys\", \"none\"]\n    ) = True,\n    allow_partial: (\n        bool | Literal[\"off\", \"on\", \"trailing-strings\"]\n    ) = False\n) -&gt; Any\n</code></pre> <p>Deserialize JSON data to a Python object.</p> <p>This is effectively a faster version of <code>json.loads()</code>, with some extra functionality.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | bytes | bytearray</code> <p>The JSON data to deserialize.</p> required <code>allow_inf_nan</code> <code>bool</code> <p>Whether to allow <code>Infinity</code>, <code>-Infinity</code> and <code>NaN</code> values as <code>json.loads()</code> does by default.</p> <code>True</code> <code>cache_strings</code> <code>bool | Literal['all', 'keys', 'none']</code> <p>Whether to cache strings to avoid constructing new Python objects, this should have a significant impact on performance while increasing memory usage slightly, <code>all/True</code> means cache all strings, <code>keys</code> means cache only dict keys, <code>none/False</code> means no caching.</p> <code>True</code> <code>allow_partial</code> <code>bool | Literal['off', 'on', 'trailing-strings']</code> <p>Whether to allow partial deserialization, if <code>True</code> JSON data is returned if the end of the input is reached before the full object is deserialized, e.g. <code>[\"aa\", \"bb\", \"c</code> would return <code>['aa', 'bb']</code>.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If deserialization fails.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The deserialized Python object.</p>"},{"location":"api/pydantic_core/#pydantic_core.to_jsonable_python","title":"to_jsonable_python","text":"<pre><code>to_jsonable_python(\n    value: Any,\n    *,\n    include: _IncEx = None,\n    exclude: _IncEx = None,\n    by_alias: bool = True,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    timedelta_mode: Literal[\"iso8601\", \"float\"] = \"iso8601\",\n    bytes_mode: Literal[\"utf8\", \"base64\", \"hex\"] = \"utf8\",\n    inf_nan_mode: Literal[\n        \"null\", \"constants\", \"strings\"\n    ] = \"constants\",\n    serialize_unknown: bool = False,\n    fallback: Callable[[Any], Any] | None = None,\n    serialize_as_any: bool = False,\n    context: Any | None = None\n) -&gt; Any\n</code></pre> <p>Serialize/marshal a Python object to a JSON-serializable Python object including transforming and filtering data.</p> <p>This is effectively a standalone version of <code>SchemaSerializer.to_python(mode='json')</code>.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The Python object to serialize.</p> required <code>include</code> <code>_IncEx</code> <p>A set of fields to include, if <code>None</code> all fields are included.</p> <code>None</code> <code>exclude</code> <code>_IncEx</code> <p>A set of fields to exclude, if <code>None</code> no fields are excluded.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use the alias names of fields.</p> <code>True</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to enable serialization and validation round-trip support.</p> <code>False</code> <code>timedelta_mode</code> <code>Literal['iso8601', 'float']</code> <p>How to serialize <code>timedelta</code> objects, either <code>'iso8601'</code> or <code>'float'</code>.</p> <code>'iso8601'</code> <code>bytes_mode</code> <code>Literal['utf8', 'base64', 'hex']</code> <p>How to serialize <code>bytes</code> objects, either <code>'utf8'</code>, <code>'base64'</code>, or <code>'hex'</code>.</p> <code>'utf8'</code> <code>inf_nan_mode</code> <code>Literal['null', 'constants', 'strings']</code> <p>How to serialize <code>Infinity</code>, <code>-Infinity</code> and <code>NaN</code> values, either <code>'null'</code>, <code>'constants'</code>, or <code>'strings'</code>.</p> <code>'constants'</code> <code>serialize_unknown</code> <code>bool</code> <p>Attempt to serialize unknown types, <code>str(value)</code> will be used, if that fails <code>\"&lt;Unserializable {value_type} object&gt;\"</code> will be used.</p> <code>False</code> <code>fallback</code> <code>Callable[[Any], Any] | None</code> <p>A function to call when an unknown value is encountered, if <code>None</code> a <code>PydanticSerializationError</code> error is raised.</p> <code>None</code> <code>serialize_as_any</code> <code>bool</code> <p>Whether to serialize fields with duck-typing serialization behavior.</p> <code>False</code> <code>context</code> <code>Any | None</code> <p>The context to use for serialization, this is passed to functional serializers as <code>info.context</code>.</p> <code>None</code> <p>Raises:</p> Type Description <code>PydanticSerializationError</code> <p>If serialization fails and no <code>fallback</code> function is provided.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The serialized Python object.</p>"},{"location":"api/pydantic_core_schema/","title":"pydantic_core.core_schema","text":"<p>This module contains definitions to build schemas which <code>pydantic_core</code> can validate and serialize.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.WhenUsed","title":"WhenUsed  <code>module-attribute</code>","text":"<pre><code>WhenUsed = Literal[\n    \"always\", \"unless-none\", \"json\", \"json-unless-none\"\n]\n</code></pre> <p>Values have the following meanings:</p> <ul> <li><code>'always'</code> means always use</li> <li><code>'unless-none'</code> means use unless the value is <code>None</code></li> <li><code>'json'</code> means use when serializing to JSON</li> <li><code>'json-unless-none'</code> means use when serializing to JSON and the value is not <code>None</code></li> </ul>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.CoreConfig","title":"CoreConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Base class for schema configuration options.</p> <p>Attributes:</p> Name Type Description <code>title</code> <code>str</code> <p>The name of the configuration.</p> <code>strict</code> <code>bool</code> <p>Whether the configuration should strictly adhere to specified rules.</p> <code>extra_fields_behavior</code> <code>ExtraBehavior</code> <p>The behavior for handling extra fields.</p> <code>typed_dict_total</code> <code>bool</code> <p>Whether the TypedDict should be considered total. Default is <code>True</code>.</p> <code>from_attributes</code> <code>bool</code> <p>Whether to use attributes for models, dataclasses, and tagged union keys.</p> <code>loc_by_alias</code> <code>bool</code> <p>Whether to use the used alias (or first alias for \"field required\" errors) instead of <code>field_names</code> to construct error <code>loc</code>s. Default is <code>True</code>.</p> <code>revalidate_instances</code> <code>Literal['always', 'never', 'subclass-instances']</code> <p>Whether instances of models and dataclasses should re-validate. Default is 'never'.</p> <code>validate_default</code> <code>bool</code> <p>Whether to validate default values during validation. Default is <code>False</code>.</p> <code>populate_by_name</code> <code>bool</code> <p>Whether an aliased field may be populated by its name as given by the model attribute, as well as the alias. (Replaces 'allow_population_by_field_name' in Pydantic v1.) Default is <code>False</code>.</p> <code>str_max_length</code> <code>int</code> <p>The maximum length for string fields.</p> <code>str_min_length</code> <code>int</code> <p>The minimum length for string fields.</p> <code>str_strip_whitespace</code> <code>bool</code> <p>Whether to strip whitespace from string fields.</p> <code>str_to_lower</code> <code>bool</code> <p>Whether to convert string fields to lowercase.</p> <code>str_to_upper</code> <code>bool</code> <p>Whether to convert string fields to uppercase.</p> <code>allow_inf_nan</code> <code>bool</code> <p>Whether to allow infinity and NaN values for float fields. Default is <code>True</code>.</p> <code>ser_json_timedelta</code> <code>Literal['iso8601', 'float']</code> <p>The serialization option for <code>timedelta</code> values. Default is 'iso8601'.</p> <code>ser_json_bytes</code> <code>Literal['utf8', 'base64', 'hex']</code> <p>The serialization option for <code>bytes</code> values. Default is 'utf8'.</p> <code>ser_json_inf_nan</code> <code>Literal['null', 'constants', 'strings']</code> <p>The serialization option for infinity and NaN values in float fields. Default is 'null'.</p> <code>val_json_bytes</code> <code>Literal['utf8', 'base64', 'hex']</code> <p>The validation option for <code>bytes</code> values, complementing ser_json_bytes. Default is 'utf8'.</p> <code>hide_input_in_errors</code> <code>bool</code> <p>Whether to hide input data from <code>ValidationError</code> representation.</p> <code>validation_error_cause</code> <code>bool</code> <p>Whether to add user-python excs to the cause of a ValidationError. Requires exceptiongroup backport pre Python 3.11.</p> <code>coerce_numbers_to_str</code> <code>bool</code> <p>Whether to enable coercion of any <code>Number</code> type to <code>str</code> (not applicable in <code>strict</code> mode).</p> <code>regex_engine</code> <code>Literal['rust-regex', 'python-re']</code> <p>The regex engine to use for regex pattern validation. Default is 'rust-regex'. See <code>StringSchema</code>.</p> <code>cache_strings</code> <code>Union[bool, Literal['all', 'keys', 'none']]</code> <p>Whether to cache strings. Default is <code>True</code>, <code>True</code> or <code>'all'</code> is required to cache strings during general validation since validators don't know if they're in a key or a value.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.SerializationInfo","title":"SerializationInfo","text":"<p>               Bases: <code>Protocol</code></p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.SerializationInfo.context","title":"context  <code>property</code>","text":"<pre><code>context: Any | None\n</code></pre> <p>Current serialization context.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo","title":"ValidationInfo","text":"<p>               Bases: <code>Protocol</code></p> <p>Argument passed to validation functions.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo.context","title":"context  <code>property</code>","text":"<pre><code>context: Any | None\n</code></pre> <p>Current validation context.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo.config","title":"config  <code>property</code>","text":"<pre><code>config: CoreConfig | None\n</code></pre> <p>The CoreConfig that applies to this validation.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo.mode","title":"mode  <code>property</code>","text":"<pre><code>mode: Literal['python', 'json']\n</code></pre> <p>The type of input data we are currently validating</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo.data","title":"data  <code>property</code>","text":"<pre><code>data: Dict[str, Any]\n</code></pre> <p>The data being validated for this model.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.ValidationInfo.field_name","title":"field_name  <code>property</code>","text":"<pre><code>field_name: str | None\n</code></pre> <p>The name of the current field being validated if this validator is attached to a model field.</p>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.simple_ser_schema","title":"simple_ser_schema","text":"<pre><code>simple_ser_schema(\n    type: ExpectedSerializationTypes,\n) -&gt; SimpleSerSchema\n</code></pre> <p>Returns a schema for serialization with a custom type.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>ExpectedSerializationTypes</code> <p>The type to use for serialization</p> required Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def simple_ser_schema(type: ExpectedSerializationTypes) -&gt; SimpleSerSchema:\n    \"\"\"\n    Returns a schema for serialization with a custom type.\n\n    Args:\n        type: The type to use for serialization\n    \"\"\"\n    return SimpleSerSchema(type=type)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.plain_serializer_function_ser_schema","title":"plain_serializer_function_ser_schema","text":"<pre><code>plain_serializer_function_ser_schema(\n    function: SerializerFunction,\n    *,\n    is_field_serializer: bool | None = None,\n    info_arg: bool | None = None,\n    return_schema: CoreSchema | None = None,\n    when_used: WhenUsed = \"always\"\n) -&gt; PlainSerializerFunctionSerSchema\n</code></pre> <p>Returns a schema for serialization with a function, can be either a \"general\" or \"field\" function.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>SerializerFunction</code> <p>The function to use for serialization</p> required <code>is_field_serializer</code> <code>bool | None</code> <p>Whether the serializer is for a field, e.g. takes <code>model</code> as the first argument, and <code>info</code> includes <code>field_name</code></p> <code>None</code> <code>info_arg</code> <code>bool | None</code> <p>Whether the function takes an <code>info</code> argument</p> <code>None</code> <code>return_schema</code> <code>CoreSchema | None</code> <p>Schema to use for serializing return value</p> <code>None</code> <code>when_used</code> <code>WhenUsed</code> <p>When the function should be called</p> <code>'always'</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def plain_serializer_function_ser_schema(\n    function: SerializerFunction,\n    *,\n    is_field_serializer: bool | None = None,\n    info_arg: bool | None = None,\n    return_schema: CoreSchema | None = None,\n    when_used: WhenUsed = 'always',\n) -&gt; PlainSerializerFunctionSerSchema:\n    \"\"\"\n    Returns a schema for serialization with a function, can be either a \"general\" or \"field\" function.\n\n    Args:\n        function: The function to use for serialization\n        is_field_serializer: Whether the serializer is for a field, e.g. takes `model` as the first argument,\n            and `info` includes `field_name`\n        info_arg: Whether the function takes an `info` argument\n        return_schema: Schema to use for serializing return value\n        when_used: When the function should be called\n    \"\"\"\n    if when_used == 'always':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return _dict_not_none(\n        type='function-plain',\n        function=function,\n        is_field_serializer=is_field_serializer,\n        info_arg=info_arg,\n        return_schema=return_schema,\n        when_used=when_used,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.wrap_serializer_function_ser_schema","title":"wrap_serializer_function_ser_schema","text":"<pre><code>wrap_serializer_function_ser_schema(\n    function: WrapSerializerFunction,\n    *,\n    is_field_serializer: bool | None = None,\n    info_arg: bool | None = None,\n    schema: CoreSchema | None = None,\n    return_schema: CoreSchema | None = None,\n    when_used: WhenUsed = \"always\"\n) -&gt; WrapSerializerFunctionSerSchema\n</code></pre> <p>Returns a schema for serialization with a wrap function, can be either a \"general\" or \"field\" function.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>WrapSerializerFunction</code> <p>The function to use for serialization</p> required <code>is_field_serializer</code> <code>bool | None</code> <p>Whether the serializer is for a field, e.g. takes <code>model</code> as the first argument, and <code>info</code> includes <code>field_name</code></p> <code>None</code> <code>info_arg</code> <code>bool | None</code> <p>Whether the function takes an <code>info</code> argument</p> <code>None</code> <code>schema</code> <code>CoreSchema | None</code> <p>The schema to use for the inner serialization</p> <code>None</code> <code>return_schema</code> <code>CoreSchema | None</code> <p>Schema to use for serializing return value</p> <code>None</code> <code>when_used</code> <code>WhenUsed</code> <p>When the function should be called</p> <code>'always'</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def wrap_serializer_function_ser_schema(\n    function: WrapSerializerFunction,\n    *,\n    is_field_serializer: bool | None = None,\n    info_arg: bool | None = None,\n    schema: CoreSchema | None = None,\n    return_schema: CoreSchema | None = None,\n    when_used: WhenUsed = 'always',\n) -&gt; WrapSerializerFunctionSerSchema:\n    \"\"\"\n    Returns a schema for serialization with a wrap function, can be either a \"general\" or \"field\" function.\n\n    Args:\n        function: The function to use for serialization\n        is_field_serializer: Whether the serializer is for a field, e.g. takes `model` as the first argument,\n            and `info` includes `field_name`\n        info_arg: Whether the function takes an `info` argument\n        schema: The schema to use for the inner serialization\n        return_schema: Schema to use for serializing return value\n        when_used: When the function should be called\n    \"\"\"\n    if when_used == 'always':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return _dict_not_none(\n        type='function-wrap',\n        function=function,\n        is_field_serializer=is_field_serializer,\n        info_arg=info_arg,\n        schema=schema,\n        return_schema=return_schema,\n        when_used=when_used,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.format_ser_schema","title":"format_ser_schema","text":"<pre><code>format_ser_schema(\n    formatting_string: str,\n    *,\n    when_used: WhenUsed = \"json-unless-none\"\n) -&gt; FormatSerSchema\n</code></pre> <p>Returns a schema for serialization using python's <code>format</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>formatting_string</code> <code>str</code> <p>String defining the format to use</p> required <code>when_used</code> <code>WhenUsed</code> <p>Same meaning as for [general_function_plain_ser_schema], but with a different default</p> <code>'json-unless-none'</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def format_ser_schema(formatting_string: str, *, when_used: WhenUsed = 'json-unless-none') -&gt; FormatSerSchema:\n    \"\"\"\n    Returns a schema for serialization using python's `format` method.\n\n    Args:\n        formatting_string: String defining the format to use\n        when_used: Same meaning as for [general_function_plain_ser_schema], but with a different default\n    \"\"\"\n    if when_used == 'json-unless-none':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        when_used = None  # type: ignore\n    return _dict_not_none(type='format', formatting_string=formatting_string, when_used=when_used)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.to_string_ser_schema","title":"to_string_ser_schema","text":"<pre><code>to_string_ser_schema(\n    *, when_used: WhenUsed = \"json-unless-none\"\n) -&gt; ToStringSerSchema\n</code></pre> <p>Returns a schema for serialization using python's <code>str()</code> / <code>__str__</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>when_used</code> <code>WhenUsed</code> <p>Same meaning as for [general_function_plain_ser_schema], but with a different default</p> <code>'json-unless-none'</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def to_string_ser_schema(*, when_used: WhenUsed = 'json-unless-none') -&gt; ToStringSerSchema:\n    \"\"\"\n    Returns a schema for serialization using python's `str()` / `__str__` method.\n\n    Args:\n        when_used: Same meaning as for [general_function_plain_ser_schema], but with a different default\n    \"\"\"\n    s = dict(type='to-string')\n    if when_used != 'json-unless-none':\n        # just to avoid extra elements in schema, and to use the actual default defined in rust\n        s['when_used'] = when_used\n    return s  # type: ignore\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.model_ser_schema","title":"model_ser_schema","text":"<pre><code>model_ser_schema(\n    cls: Type[Any], schema: CoreSchema\n) -&gt; ModelSerSchema\n</code></pre> <p>Returns a schema for serialization using a model.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Any]</code> <p>The expected class type, used to generate warnings if the wrong type is passed</p> required <code>schema</code> <code>CoreSchema</code> <p>Internal schema to use to serialize the model dict</p> required Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def model_ser_schema(cls: Type[Any], schema: CoreSchema) -&gt; ModelSerSchema:\n    \"\"\"\n    Returns a schema for serialization using a model.\n\n    Args:\n        cls: The expected class type, used to generate warnings if the wrong type is passed\n        schema: Internal schema to use to serialize the model dict\n    \"\"\"\n    return ModelSerSchema(type='model', cls=cls, schema=schema)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.computed_field","title":"computed_field","text":"<pre><code>computed_field(\n    property_name: str,\n    return_schema: CoreSchema,\n    *,\n    alias: str | None = None,\n    metadata: Dict[str, Any] | None = None\n) -&gt; ComputedField\n</code></pre> <p>ComputedFields are properties of a model or dataclass that are included in serialization.</p> <p>Parameters:</p> Name Type Description Default <code>property_name</code> <code>str</code> <p>The name of the property on the model or dataclass</p> required <code>return_schema</code> <code>CoreSchema</code> <p>The schema used for the type returned by the computed field</p> required <code>alias</code> <code>str | None</code> <p>The name to use in the serialized output</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def computed_field(\n    property_name: str, return_schema: CoreSchema, *, alias: str | None = None, metadata: Dict[str, Any] | None = None\n) -&gt; ComputedField:\n    \"\"\"\n    ComputedFields are properties of a model or dataclass that are included in serialization.\n\n    Args:\n        property_name: The name of the property on the model or dataclass\n        return_schema: The schema used for the type returned by the computed field\n        alias: The name to use in the serialized output\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return _dict_not_none(\n        type='computed-field', property_name=property_name, return_schema=return_schema, alias=alias, metadata=metadata\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.any_schema","title":"any_schema","text":"<pre><code>any_schema(\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; AnySchema\n</code></pre> <p>Returns a schema that matches any value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.any_schema()\nv = SchemaValidator(schema)\nassert v.validate_python(1) == 1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def any_schema(\n    *, ref: str | None = None, metadata: Dict[str, Any] | None = None, serialization: SerSchema | None = None\n) -&gt; AnySchema:\n    \"\"\"\n    Returns a schema that matches any value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.any_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python(1) == 1\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='any', ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.none_schema","title":"none_schema","text":"<pre><code>none_schema(\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; NoneSchema\n</code></pre> <p>Returns a schema that matches a None value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.none_schema()\nv = SchemaValidator(schema)\nassert v.validate_python(None) is None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def none_schema(\n    *, ref: str | None = None, metadata: Dict[str, Any] | None = None, serialization: SerSchema | None = None\n) -&gt; NoneSchema:\n    \"\"\"\n    Returns a schema that matches a None value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.none_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python(None) is None\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='none', ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.bool_schema","title":"bool_schema","text":"<pre><code>bool_schema(\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; BoolSchema\n</code></pre> <p>Returns a schema that matches a bool value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.bool_schema()\nv = SchemaValidator(schema)\nassert v.validate_python('True') is True\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a bool or a value that can be converted to a bool</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def bool_schema(\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; BoolSchema:\n    \"\"\"\n    Returns a schema that matches a bool value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.bool_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python('True') is True\n    ```\n\n    Args:\n        strict: Whether the value should be a bool or a value that can be converted to a bool\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='bool', strict=strict, ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.int_schema","title":"int_schema","text":"<pre><code>int_schema(\n    *,\n    multiple_of: int | None = None,\n    le: int | None = None,\n    ge: int | None = None,\n    lt: int | None = None,\n    gt: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; IntSchema\n</code></pre> <p>Returns a schema that matches a int value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.int_schema(multiple_of=2, le=6, ge=2)\nv = SchemaValidator(schema)\nassert v.validate_python('4') == 4\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>multiple_of</code> <code>int | None</code> <p>The value must be a multiple of this number</p> <code>None</code> <code>le</code> <code>int | None</code> <p>The value must be less than or equal to this number</p> <code>None</code> <code>ge</code> <code>int | None</code> <p>The value must be greater than or equal to this number</p> <code>None</code> <code>lt</code> <code>int | None</code> <p>The value must be strictly less than this number</p> <code>None</code> <code>gt</code> <code>int | None</code> <p>The value must be strictly greater than this number</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a int or a value that can be converted to a int</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def int_schema(\n    *,\n    multiple_of: int | None = None,\n    le: int | None = None,\n    ge: int | None = None,\n    lt: int | None = None,\n    gt: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; IntSchema:\n    \"\"\"\n    Returns a schema that matches a int value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.int_schema(multiple_of=2, le=6, ge=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('4') == 4\n    ```\n\n    Args:\n        multiple_of: The value must be a multiple of this number\n        le: The value must be less than or equal to this number\n        ge: The value must be greater than or equal to this number\n        lt: The value must be strictly less than this number\n        gt: The value must be strictly greater than this number\n        strict: Whether the value should be a int or a value that can be converted to a int\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='int',\n        multiple_of=multiple_of,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.float_schema","title":"float_schema","text":"<pre><code>float_schema(\n    *,\n    allow_inf_nan: bool | None = None,\n    multiple_of: float | None = None,\n    le: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    gt: float | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; FloatSchema\n</code></pre> <p>Returns a schema that matches a float value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.float_schema(le=0.8, ge=0.2)\nv = SchemaValidator(schema)\nassert v.validate_python('0.5') == 0.5\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>allow_inf_nan</code> <code>bool | None</code> <p>Whether to allow inf and nan values</p> <code>None</code> <code>multiple_of</code> <code>float | None</code> <p>The value must be a multiple of this number</p> <code>None</code> <code>le</code> <code>float | None</code> <p>The value must be less than or equal to this number</p> <code>None</code> <code>ge</code> <code>float | None</code> <p>The value must be greater than or equal to this number</p> <code>None</code> <code>lt</code> <code>float | None</code> <p>The value must be strictly less than this number</p> <code>None</code> <code>gt</code> <code>float | None</code> <p>The value must be strictly greater than this number</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a float or a value that can be converted to a float</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def float_schema(\n    *,\n    allow_inf_nan: bool | None = None,\n    multiple_of: float | None = None,\n    le: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    gt: float | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; FloatSchema:\n    \"\"\"\n    Returns a schema that matches a float value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.float_schema(le=0.8, ge=0.2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('0.5') == 0.5\n    ```\n\n    Args:\n        allow_inf_nan: Whether to allow inf and nan values\n        multiple_of: The value must be a multiple of this number\n        le: The value must be less than or equal to this number\n        ge: The value must be greater than or equal to this number\n        lt: The value must be strictly less than this number\n        gt: The value must be strictly greater than this number\n        strict: Whether the value should be a float or a value that can be converted to a float\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='float',\n        allow_inf_nan=allow_inf_nan,\n        multiple_of=multiple_of,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.decimal_schema","title":"decimal_schema","text":"<pre><code>decimal_schema(\n    *,\n    allow_inf_nan: bool = None,\n    multiple_of: Decimal | None = None,\n    le: Decimal | None = None,\n    ge: Decimal | None = None,\n    lt: Decimal | None = None,\n    gt: Decimal | None = None,\n    max_digits: int | None = None,\n    decimal_places: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; DecimalSchema\n</code></pre> <p>Returns a schema that matches a decimal value, e.g.:</p> <pre><code>from decimal import Decimal\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.decimal_schema(le=0.8, ge=0.2)\nv = SchemaValidator(schema)\nassert v.validate_python('0.5') == Decimal('0.5')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>allow_inf_nan</code> <code>bool</code> <p>Whether to allow inf and nan values</p> <code>None</code> <code>multiple_of</code> <code>Decimal | None</code> <p>The value must be a multiple of this number</p> <code>None</code> <code>le</code> <code>Decimal | None</code> <p>The value must be less than or equal to this number</p> <code>None</code> <code>ge</code> <code>Decimal | None</code> <p>The value must be greater than or equal to this number</p> <code>None</code> <code>lt</code> <code>Decimal | None</code> <p>The value must be strictly less than this number</p> <code>None</code> <code>gt</code> <code>Decimal | None</code> <p>The value must be strictly greater than this number</p> <code>None</code> <code>max_digits</code> <code>int | None</code> <p>The maximum number of decimal digits allowed</p> <code>None</code> <code>decimal_places</code> <code>int | None</code> <p>The maximum number of decimal places allowed</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a float or a value that can be converted to a float</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def decimal_schema(\n    *,\n    allow_inf_nan: bool = None,\n    multiple_of: Decimal | None = None,\n    le: Decimal | None = None,\n    ge: Decimal | None = None,\n    lt: Decimal | None = None,\n    gt: Decimal | None = None,\n    max_digits: int | None = None,\n    decimal_places: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; DecimalSchema:\n    \"\"\"\n    Returns a schema that matches a decimal value, e.g.:\n\n    ```py\n    from decimal import Decimal\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.decimal_schema(le=0.8, ge=0.2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('0.5') == Decimal('0.5')\n    ```\n\n    Args:\n        allow_inf_nan: Whether to allow inf and nan values\n        multiple_of: The value must be a multiple of this number\n        le: The value must be less than or equal to this number\n        ge: The value must be greater than or equal to this number\n        lt: The value must be strictly less than this number\n        gt: The value must be strictly greater than this number\n        max_digits: The maximum number of decimal digits allowed\n        decimal_places: The maximum number of decimal places allowed\n        strict: Whether the value should be a float or a value that can be converted to a float\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='decimal',\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n        multiple_of=multiple_of,\n        allow_inf_nan=allow_inf_nan,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.complex_schema","title":"complex_schema","text":"<pre><code>complex_schema(\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; ComplexSchema\n</code></pre> <p>Returns a schema that matches a complex value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.complex_schema()\nv = SchemaValidator(schema)\nassert v.validate_python('1+2j') == complex(1, 2)\nassert v.validate_python(complex(1, 2)) == complex(1, 2)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a complex object instance or a value that can be converted to a complex object</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def complex_schema(\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; ComplexSchema:\n    \"\"\"\n    Returns a schema that matches a complex value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.complex_schema()\n    v = SchemaValidator(schema)\n    assert v.validate_python('1+2j') == complex(1, 2)\n    assert v.validate_python(complex(1, 2)) == complex(1, 2)\n    ```\n\n    Args:\n        strict: Whether the value should be a complex object instance or a value that can be converted to a complex object\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='complex',\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.str_schema","title":"str_schema","text":"<pre><code>str_schema(\n    *,\n    pattern: str | Pattern[str] | None = None,\n    max_length: int | None = None,\n    min_length: int | None = None,\n    strip_whitespace: bool | None = None,\n    to_lower: bool | None = None,\n    to_upper: bool | None = None,\n    regex_engine: (\n        Literal[\"rust-regex\", \"python-re\"] | None\n    ) = None,\n    strict: bool | None = None,\n    coerce_numbers_to_str: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; StringSchema\n</code></pre> <p>Returns a schema that matches a string value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.str_schema(max_length=10, min_length=2)\nv = SchemaValidator(schema)\nassert v.validate_python('hello') == 'hello'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str | Pattern[str] | None</code> <p>A regex pattern that the value must match</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be at most this length</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be at least this length</p> <code>None</code> <code>strip_whitespace</code> <code>bool | None</code> <p>Whether to strip whitespace from the value</p> <code>None</code> <code>to_lower</code> <code>bool | None</code> <p>Whether to convert the value to lowercase</p> <code>None</code> <code>to_upper</code> <code>bool | None</code> <p>Whether to convert the value to uppercase</p> <code>None</code> <code>regex_engine</code> <code>Literal['rust-regex', 'python-re'] | None</code> <p>The regex engine to use for pattern validation. Default is 'rust-regex'. - <code>rust-regex</code> uses the <code>regex</code> Rust   crate, which is non-backtracking and therefore more DDoS   resistant, but does not support all regex features. - <code>python-re</code> use the <code>re</code> module,   which supports all regex features, but may be slower.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a string or a value that can be converted to a string</p> <code>None</code> <code>coerce_numbers_to_str</code> <code>bool | None</code> <p>Whether to enable coercion of any <code>Number</code> type to <code>str</code> (not applicable in <code>strict</code> mode).</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def str_schema(\n    *,\n    pattern: str | Pattern[str] | None = None,\n    max_length: int | None = None,\n    min_length: int | None = None,\n    strip_whitespace: bool | None = None,\n    to_lower: bool | None = None,\n    to_upper: bool | None = None,\n    regex_engine: Literal['rust-regex', 'python-re'] | None = None,\n    strict: bool | None = None,\n    coerce_numbers_to_str: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; StringSchema:\n    \"\"\"\n    Returns a schema that matches a string value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.str_schema(max_length=10, min_length=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    ```\n\n    Args:\n        pattern: A regex pattern that the value must match\n        max_length: The value must be at most this length\n        min_length: The value must be at least this length\n        strip_whitespace: Whether to strip whitespace from the value\n        to_lower: Whether to convert the value to lowercase\n        to_upper: Whether to convert the value to uppercase\n        regex_engine: The regex engine to use for pattern validation. Default is 'rust-regex'.\n            - `rust-regex` uses the [`regex`](https://docs.rs/regex) Rust\n              crate, which is non-backtracking and therefore more DDoS\n              resistant, but does not support all regex features.\n            - `python-re` use the [`re`](https://docs.python.org/3/library/re.html) module,\n              which supports all regex features, but may be slower.\n        strict: Whether the value should be a string or a value that can be converted to a string\n        coerce_numbers_to_str: Whether to enable coercion of any `Number` type to `str` (not applicable in `strict` mode).\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='str',\n        pattern=pattern,\n        max_length=max_length,\n        min_length=min_length,\n        strip_whitespace=strip_whitespace,\n        to_lower=to_lower,\n        to_upper=to_upper,\n        regex_engine=regex_engine,\n        strict=strict,\n        coerce_numbers_to_str=coerce_numbers_to_str,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.bytes_schema","title":"bytes_schema","text":"<pre><code>bytes_schema(\n    *,\n    max_length: int | None = None,\n    min_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; BytesSchema\n</code></pre> <p>Returns a schema that matches a bytes value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.bytes_schema(max_length=10, min_length=2)\nv = SchemaValidator(schema)\nassert v.validate_python(b'hello') == b'hello'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>max_length</code> <code>int | None</code> <p>The value must be at most this length</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be at least this length</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the value should be a bytes or a value that can be converted to a bytes</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def bytes_schema(\n    *,\n    max_length: int | None = None,\n    min_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; BytesSchema:\n    \"\"\"\n    Returns a schema that matches a bytes value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.bytes_schema(max_length=10, min_length=2)\n    v = SchemaValidator(schema)\n    assert v.validate_python(b'hello') == b'hello'\n    ```\n\n    Args:\n        max_length: The value must be at most this length\n        min_length: The value must be at least this length\n        strict: Whether the value should be a bytes or a value that can be converted to a bytes\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='bytes',\n        max_length=max_length,\n        min_length=min_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.date_schema","title":"date_schema","text":"<pre><code>date_schema(\n    *,\n    strict: bool | None = None,\n    le: date | None = None,\n    ge: date | None = None,\n    lt: date | None = None,\n    gt: date | None = None,\n    now_op: Literal[\"past\", \"future\"] | None = None,\n    now_utc_offset: int | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; DateSchema\n</code></pre> <p>Returns a schema that matches a date value, e.g.:</p> <pre><code>from datetime import date\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.date_schema(le=date(2020, 1, 1), ge=date(2019, 1, 1))\nv = SchemaValidator(schema)\nassert v.validate_python(date(2019, 6, 1)) == date(2019, 6, 1)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a date or a value that can be converted to a date</p> <code>None</code> <code>le</code> <code>date | None</code> <p>The value must be less than or equal to this date</p> <code>None</code> <code>ge</code> <code>date | None</code> <p>The value must be greater than or equal to this date</p> <code>None</code> <code>lt</code> <code>date | None</code> <p>The value must be strictly less than this date</p> <code>None</code> <code>gt</code> <code>date | None</code> <p>The value must be strictly greater than this date</p> <code>None</code> <code>now_op</code> <code>Literal['past', 'future'] | None</code> <p>The value must be in the past or future relative to the current date</p> <code>None</code> <code>now_utc_offset</code> <code>int | None</code> <p>The value must be in the past or future relative to the current date with this utc offset</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def date_schema(\n    *,\n    strict: bool | None = None,\n    le: date | None = None,\n    ge: date | None = None,\n    lt: date | None = None,\n    gt: date | None = None,\n    now_op: Literal['past', 'future'] | None = None,\n    now_utc_offset: int | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; DateSchema:\n    \"\"\"\n    Returns a schema that matches a date value, e.g.:\n\n    ```py\n    from datetime import date\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.date_schema(le=date(2020, 1, 1), ge=date(2019, 1, 1))\n    v = SchemaValidator(schema)\n    assert v.validate_python(date(2019, 6, 1)) == date(2019, 6, 1)\n    ```\n\n    Args:\n        strict: Whether the value should be a date or a value that can be converted to a date\n        le: The value must be less than or equal to this date\n        ge: The value must be greater than or equal to this date\n        lt: The value must be strictly less than this date\n        gt: The value must be strictly greater than this date\n        now_op: The value must be in the past or future relative to the current date\n        now_utc_offset: The value must be in the past or future relative to the current date with this utc offset\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='date',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        now_op=now_op,\n        now_utc_offset=now_utc_offset,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.time_schema","title":"time_schema","text":"<pre><code>time_schema(\n    *,\n    strict: bool | None = None,\n    le: time | None = None,\n    ge: time | None = None,\n    lt: time | None = None,\n    gt: time | None = None,\n    tz_constraint: (\n        Literal[\"aware\", \"naive\"] | int | None\n    ) = None,\n    microseconds_precision: Literal[\n        \"truncate\", \"error\"\n    ] = \"truncate\",\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; TimeSchema\n</code></pre> <p>Returns a schema that matches a time value, e.g.:</p> <pre><code>from datetime import time\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.time_schema(le=time(12, 0, 0), ge=time(6, 0, 0))\nv = SchemaValidator(schema)\nassert v.validate_python(time(9, 0, 0)) == time(9, 0, 0)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a time or a value that can be converted to a time</p> <code>None</code> <code>le</code> <code>time | None</code> <p>The value must be less than or equal to this time</p> <code>None</code> <code>ge</code> <code>time | None</code> <p>The value must be greater than or equal to this time</p> <code>None</code> <code>lt</code> <code>time | None</code> <p>The value must be strictly less than this time</p> <code>None</code> <code>gt</code> <code>time | None</code> <p>The value must be strictly greater than this time</p> <code>None</code> <code>tz_constraint</code> <code>Literal['aware', 'naive'] | int | None</code> <p>The value must be timezone aware or naive, or an int to indicate required tz offset</p> <code>None</code> <code>microseconds_precision</code> <code>Literal['truncate', 'error']</code> <p>The behavior when seconds have more than 6 digits or microseconds is too large</p> <code>'truncate'</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def time_schema(\n    *,\n    strict: bool | None = None,\n    le: time | None = None,\n    ge: time | None = None,\n    lt: time | None = None,\n    gt: time | None = None,\n    tz_constraint: Literal['aware', 'naive'] | int | None = None,\n    microseconds_precision: Literal['truncate', 'error'] = 'truncate',\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; TimeSchema:\n    \"\"\"\n    Returns a schema that matches a time value, e.g.:\n\n    ```py\n    from datetime import time\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.time_schema(le=time(12, 0, 0), ge=time(6, 0, 0))\n    v = SchemaValidator(schema)\n    assert v.validate_python(time(9, 0, 0)) == time(9, 0, 0)\n    ```\n\n    Args:\n        strict: Whether the value should be a time or a value that can be converted to a time\n        le: The value must be less than or equal to this time\n        ge: The value must be greater than or equal to this time\n        lt: The value must be strictly less than this time\n        gt: The value must be strictly greater than this time\n        tz_constraint: The value must be timezone aware or naive, or an int to indicate required tz offset\n        microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='time',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        tz_constraint=tz_constraint,\n        microseconds_precision=microseconds_precision,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.datetime_schema","title":"datetime_schema","text":"<pre><code>datetime_schema(\n    *,\n    strict: bool | None = None,\n    le: datetime | None = None,\n    ge: datetime | None = None,\n    lt: datetime | None = None,\n    gt: datetime | None = None,\n    now_op: Literal[\"past\", \"future\"] | None = None,\n    tz_constraint: (\n        Literal[\"aware\", \"naive\"] | int | None\n    ) = None,\n    now_utc_offset: int | None = None,\n    microseconds_precision: Literal[\n        \"truncate\", \"error\"\n    ] = \"truncate\",\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; DatetimeSchema\n</code></pre> <p>Returns a schema that matches a datetime value, e.g.:</p> <pre><code>from datetime import datetime\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.datetime_schema()\nv = SchemaValidator(schema)\nnow = datetime.now()\nassert v.validate_python(str(now)) == now\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a datetime or a value that can be converted to a datetime</p> <code>None</code> <code>le</code> <code>datetime | None</code> <p>The value must be less than or equal to this datetime</p> <code>None</code> <code>ge</code> <code>datetime | None</code> <p>The value must be greater than or equal to this datetime</p> <code>None</code> <code>lt</code> <code>datetime | None</code> <p>The value must be strictly less than this datetime</p> <code>None</code> <code>gt</code> <code>datetime | None</code> <p>The value must be strictly greater than this datetime</p> <code>None</code> <code>now_op</code> <code>Literal['past', 'future'] | None</code> <p>The value must be in the past or future relative to the current datetime</p> <code>None</code> <code>tz_constraint</code> <code>Literal['aware', 'naive'] | int | None</code> <p>The value must be timezone aware or naive, or an int to indicate required tz offset TODO: use of a tzinfo where offset changes based on the datetime is not yet supported</p> <code>None</code> <code>now_utc_offset</code> <code>int | None</code> <p>The value must be in the past or future relative to the current datetime with this utc offset</p> <code>None</code> <code>microseconds_precision</code> <code>Literal['truncate', 'error']</code> <p>The behavior when seconds have more than 6 digits or microseconds is too large</p> <code>'truncate'</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def datetime_schema(\n    *,\n    strict: bool | None = None,\n    le: datetime | None = None,\n    ge: datetime | None = None,\n    lt: datetime | None = None,\n    gt: datetime | None = None,\n    now_op: Literal['past', 'future'] | None = None,\n    tz_constraint: Literal['aware', 'naive'] | int | None = None,\n    now_utc_offset: int | None = None,\n    microseconds_precision: Literal['truncate', 'error'] = 'truncate',\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; DatetimeSchema:\n    \"\"\"\n    Returns a schema that matches a datetime value, e.g.:\n\n    ```py\n    from datetime import datetime\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.datetime_schema()\n    v = SchemaValidator(schema)\n    now = datetime.now()\n    assert v.validate_python(str(now)) == now\n    ```\n\n    Args:\n        strict: Whether the value should be a datetime or a value that can be converted to a datetime\n        le: The value must be less than or equal to this datetime\n        ge: The value must be greater than or equal to this datetime\n        lt: The value must be strictly less than this datetime\n        gt: The value must be strictly greater than this datetime\n        now_op: The value must be in the past or future relative to the current datetime\n        tz_constraint: The value must be timezone aware or naive, or an int to indicate required tz offset\n            TODO: use of a tzinfo where offset changes based on the datetime is not yet supported\n        now_utc_offset: The value must be in the past or future relative to the current datetime with this utc offset\n        microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='datetime',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        now_op=now_op,\n        tz_constraint=tz_constraint,\n        now_utc_offset=now_utc_offset,\n        microseconds_precision=microseconds_precision,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.timedelta_schema","title":"timedelta_schema","text":"<pre><code>timedelta_schema(\n    *,\n    strict: bool | None = None,\n    le: timedelta | None = None,\n    ge: timedelta | None = None,\n    lt: timedelta | None = None,\n    gt: timedelta | None = None,\n    microseconds_precision: Literal[\n        \"truncate\", \"error\"\n    ] = \"truncate\",\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; TimedeltaSchema\n</code></pre> <p>Returns a schema that matches a timedelta value, e.g.:</p> <pre><code>from datetime import timedelta\nfrom pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.timedelta_schema(le=timedelta(days=1), ge=timedelta(days=0))\nv = SchemaValidator(schema)\nassert v.validate_python(timedelta(hours=12)) == timedelta(hours=12)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether the value should be a timedelta or a value that can be converted to a timedelta</p> <code>None</code> <code>le</code> <code>timedelta | None</code> <p>The value must be less than or equal to this timedelta</p> <code>None</code> <code>ge</code> <code>timedelta | None</code> <p>The value must be greater than or equal to this timedelta</p> <code>None</code> <code>lt</code> <code>timedelta | None</code> <p>The value must be strictly less than this timedelta</p> <code>None</code> <code>gt</code> <code>timedelta | None</code> <p>The value must be strictly greater than this timedelta</p> <code>None</code> <code>microseconds_precision</code> <code>Literal['truncate', 'error']</code> <p>The behavior when seconds have more than 6 digits or microseconds is too large</p> <code>'truncate'</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def timedelta_schema(\n    *,\n    strict: bool | None = None,\n    le: timedelta | None = None,\n    ge: timedelta | None = None,\n    lt: timedelta | None = None,\n    gt: timedelta | None = None,\n    microseconds_precision: Literal['truncate', 'error'] = 'truncate',\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; TimedeltaSchema:\n    \"\"\"\n    Returns a schema that matches a timedelta value, e.g.:\n\n    ```py\n    from datetime import timedelta\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.timedelta_schema(le=timedelta(days=1), ge=timedelta(days=0))\n    v = SchemaValidator(schema)\n    assert v.validate_python(timedelta(hours=12)) == timedelta(hours=12)\n    ```\n\n    Args:\n        strict: Whether the value should be a timedelta or a value that can be converted to a timedelta\n        le: The value must be less than or equal to this timedelta\n        ge: The value must be greater than or equal to this timedelta\n        lt: The value must be strictly less than this timedelta\n        gt: The value must be strictly greater than this timedelta\n        microseconds_precision: The behavior when seconds have more than 6 digits or microseconds is too large\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='timedelta',\n        strict=strict,\n        le=le,\n        ge=ge,\n        lt=lt,\n        gt=gt,\n        microseconds_precision=microseconds_precision,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.literal_schema","title":"literal_schema","text":"<pre><code>literal_schema(\n    expected: list[Any],\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; LiteralSchema\n</code></pre> <p>Returns a schema that matches a literal value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.literal_schema(['hello', 'world'])\nv = SchemaValidator(schema)\nassert v.validate_python('hello') == 'hello'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expected</code> <code>list[Any]</code> <p>The value must be one of these values</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def literal_schema(\n    expected: list[Any],\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; LiteralSchema:\n    \"\"\"\n    Returns a schema that matches a literal value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.literal_schema(['hello', 'world'])\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    ```\n\n    Args:\n        expected: The value must be one of these values\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='literal', expected=expected, ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.enum_schema","title":"enum_schema","text":"<pre><code>enum_schema(\n    cls: Any,\n    members: list[Any],\n    *,\n    sub_type: Literal[\"str\", \"int\", \"float\"] | None = None,\n    missing: Callable[[Any], Any] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; EnumSchema\n</code></pre> <p>Returns a schema that matches an enum value, e.g.:</p> <pre><code>from enum import Enum\nfrom pydantic_core import SchemaValidator, core_schema\n\nclass Color(Enum):\n    RED = 1\n    GREEN = 2\n    BLUE = 3\n\nschema = core_schema.enum_schema(Color, list(Color.__members__.values()))\nv = SchemaValidator(schema)\nassert v.validate_python(2) is Color.GREEN\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Any</code> <p>The enum class</p> required <code>members</code> <code>list[Any]</code> <p>The members of the enum, generally <code>list(MyEnum.__members__.values())</code></p> required <code>sub_type</code> <code>Literal['str', 'int', 'float'] | None</code> <p>The type of the enum, either 'str' or 'int' or None for plain enums</p> <code>None</code> <code>missing</code> <code>Callable[[Any], Any] | None</code> <p>A function to use when the value is not found in the enum, from <code>_missing_</code></p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to use strict mode, defaults to False</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def enum_schema(\n    cls: Any,\n    members: list[Any],\n    *,\n    sub_type: Literal['str', 'int', 'float'] | None = None,\n    missing: Callable[[Any], Any] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; EnumSchema:\n    \"\"\"\n    Returns a schema that matches an enum value, e.g.:\n\n    ```py\n    from enum import Enum\n    from pydantic_core import SchemaValidator, core_schema\n\n    class Color(Enum):\n        RED = 1\n        GREEN = 2\n        BLUE = 3\n\n    schema = core_schema.enum_schema(Color, list(Color.__members__.values()))\n    v = SchemaValidator(schema)\n    assert v.validate_python(2) is Color.GREEN\n    ```\n\n    Args:\n        cls: The enum class\n        members: The members of the enum, generally `list(MyEnum.__members__.values())`\n        sub_type: The type of the enum, either 'str' or 'int' or None for plain enums\n        missing: A function to use when the value is not found in the enum, from `_missing_`\n        strict: Whether to use strict mode, defaults to False\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='enum',\n        cls=cls,\n        members=members,\n        sub_type=sub_type,\n        missing=missing,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.is_instance_schema","title":"is_instance_schema","text":"<pre><code>is_instance_schema(\n    cls: Any,\n    *,\n    cls_repr: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; IsInstanceSchema\n</code></pre> <p>Returns a schema that checks if a value is an instance of a class, equivalent to python's <code>isinstance</code> method, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nclass A:\n    pass\n\nschema = core_schema.is_instance_schema(cls=A)\nv = SchemaValidator(schema)\nv.validate_python(A())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Any</code> <p>The value must be an instance of this class</p> required <code>cls_repr</code> <code>str | None</code> <p>If provided this string is used in the validator name instead of <code>repr(cls)</code></p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def is_instance_schema(\n    cls: Any,\n    *,\n    cls_repr: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; IsInstanceSchema:\n    \"\"\"\n    Returns a schema that checks if a value is an instance of a class, equivalent to python's `isinstance` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    class A:\n        pass\n\n    schema = core_schema.is_instance_schema(cls=A)\n    v = SchemaValidator(schema)\n    v.validate_python(A())\n    ```\n\n    Args:\n        cls: The value must be an instance of this class\n        cls_repr: If provided this string is used in the validator name instead of `repr(cls)`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='is-instance', cls=cls, cls_repr=cls_repr, ref=ref, metadata=metadata, serialization=serialization\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.is_subclass_schema","title":"is_subclass_schema","text":"<pre><code>is_subclass_schema(\n    cls: Type[Any],\n    *,\n    cls_repr: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; IsInstanceSchema\n</code></pre> <p>Returns a schema that checks if a value is a subtype of a class, equivalent to python's <code>issubclass</code> method, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nclass A:\n    pass\n\nclass B(A):\n    pass\n\nschema = core_schema.is_subclass_schema(cls=A)\nv = SchemaValidator(schema)\nv.validate_python(B)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Any]</code> <p>The value must be a subclass of this class</p> required <code>cls_repr</code> <code>str | None</code> <p>If provided this string is used in the validator name instead of <code>repr(cls)</code></p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def is_subclass_schema(\n    cls: Type[Any],\n    *,\n    cls_repr: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; IsInstanceSchema:\n    \"\"\"\n    Returns a schema that checks if a value is a subtype of a class, equivalent to python's `issubclass` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    class A:\n        pass\n\n    class B(A):\n        pass\n\n    schema = core_schema.is_subclass_schema(cls=A)\n    v = SchemaValidator(schema)\n    v.validate_python(B)\n    ```\n\n    Args:\n        cls: The value must be a subclass of this class\n        cls_repr: If provided this string is used in the validator name instead of `repr(cls)`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='is-subclass', cls=cls, cls_repr=cls_repr, ref=ref, metadata=metadata, serialization=serialization\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.callable_schema","title":"callable_schema","text":"<pre><code>callable_schema(\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; CallableSchema\n</code></pre> <p>Returns a schema that checks if a value is callable, equivalent to python's <code>callable</code> method, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.callable_schema()\nv = SchemaValidator(schema)\nv.validate_python(min)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def callable_schema(\n    *, ref: str | None = None, metadata: Dict[str, Any] | None = None, serialization: SerSchema | None = None\n) -&gt; CallableSchema:\n    \"\"\"\n    Returns a schema that checks if a value is callable, equivalent to python's `callable` method, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.callable_schema()\n    v = SchemaValidator(schema)\n    v.validate_python(min)\n    ```\n\n    Args:\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='callable', ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.list_schema","title":"list_schema","text":"<pre><code>list_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None\n) -&gt; ListSchema\n</code></pre> <p>Returns a schema that matches a list value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.list_schema(core_schema.int_schema(), min_length=0, max_length=10)\nv = SchemaValidator(schema)\nassert v.validate_python(['4']) == [4]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a list of items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a list with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a list with at most this many items</p> <code>None</code> <code>fail_fast</code> <code>bool | None</code> <p>Stop validation on the first error</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a list with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def list_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; ListSchema:\n    \"\"\"\n    Returns a schema that matches a list value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.list_schema(core_schema.int_schema(), min_length=0, max_length=10)\n    v = SchemaValidator(schema)\n    assert v.validate_python(['4']) == [4]\n    ```\n\n    Args:\n        items_schema: The value must be a list of items that match this schema\n        min_length: The value must be a list with at least this many items\n        max_length: The value must be a list with at most this many items\n        fail_fast: Stop validation on the first error\n        strict: The value must be a list with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='list',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        fail_fast=fail_fast,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.tuple_positional_schema","title":"tuple_positional_schema","text":"<pre><code>tuple_positional_schema(\n    items_schema: list[CoreSchema],\n    *,\n    extras_schema: CoreSchema | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None\n) -&gt; TupleSchema\n</code></pre> <p>Returns a schema that matches a tuple of schemas, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.tuple_positional_schema(\n    [core_schema.int_schema(), core_schema.str_schema()]\n)\nv = SchemaValidator(schema)\nassert v.validate_python((1, 'hello')) == (1, 'hello')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>list[CoreSchema]</code> <p>The value must be a tuple with items that match these schemas</p> required <code>extras_schema</code> <code>CoreSchema | None</code> <p>The value must be a tuple with items that match this schema This was inspired by JSON schema's <code>prefixItems</code> and <code>items</code> fields. In python's <code>typing.Tuple</code>, you can't specify a type for \"extra\" items -- they must all be the same type if the length is variable. So this field won't be set from a <code>typing.Tuple</code> annotation on a pydantic model.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a tuple with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def tuple_positional_schema(\n    items_schema: list[CoreSchema],\n    *,\n    extras_schema: CoreSchema | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; TupleSchema:\n    \"\"\"\n    Returns a schema that matches a tuple of schemas, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.tuple_positional_schema(\n        [core_schema.int_schema(), core_schema.str_schema()]\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python((1, 'hello')) == (1, 'hello')\n    ```\n\n    Args:\n        items_schema: The value must be a tuple with items that match these schemas\n        extras_schema: The value must be a tuple with items that match this schema\n            This was inspired by JSON schema's `prefixItems` and `items` fields.\n            In python's `typing.Tuple`, you can't specify a type for \"extra\" items -- they must all be the same type\n            if the length is variable. So this field won't be set from a `typing.Tuple` annotation on a pydantic model.\n        strict: The value must be a tuple with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    if extras_schema is not None:\n        variadic_item_index = len(items_schema)\n        items_schema = items_schema + [extras_schema]\n    else:\n        variadic_item_index = None\n    return tuple_schema(\n        items_schema=items_schema,\n        variadic_item_index=variadic_item_index,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.tuple_variable_schema","title":"tuple_variable_schema","text":"<pre><code>tuple_variable_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None\n) -&gt; TupleSchema\n</code></pre> <p>Returns a schema that matches a tuple of a given schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.tuple_variable_schema(\n    items_schema=core_schema.int_schema(), min_length=0, max_length=10\n)\nv = SchemaValidator(schema)\nassert v.validate_python(('1', 2, 3)) == (1, 2, 3)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a tuple with items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a tuple with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a tuple with at most this many items</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a tuple with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>Optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def tuple_variable_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; TupleSchema:\n    \"\"\"\n    Returns a schema that matches a tuple of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.tuple_variable_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(('1', 2, 3)) == (1, 2, 3)\n    ```\n\n    Args:\n        items_schema: The value must be a tuple with items that match this schema\n        min_length: The value must be a tuple with at least this many items\n        max_length: The value must be a tuple with at most this many items\n        strict: The value must be a tuple with exactly this many items\n        ref: Optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return tuple_schema(\n        items_schema=[items_schema or any_schema()],\n        variadic_item_index=0,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.tuple_schema","title":"tuple_schema","text":"<pre><code>tuple_schema(\n    items_schema: list[CoreSchema],\n    *,\n    variadic_item_index: int | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None\n) -&gt; TupleSchema\n</code></pre> <p>Returns a schema that matches a tuple of schemas, with an optional variadic item, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.tuple_schema(\n    [core_schema.int_schema(), core_schema.str_schema(), core_schema.float_schema()],\n    variadic_item_index=1,\n)\nv = SchemaValidator(schema)\nassert v.validate_python((1, 'hello', 'world', 1.5)) == (1, 'hello', 'world', 1.5)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>list[CoreSchema]</code> <p>The value must be a tuple with items that match these schemas</p> required <code>variadic_item_index</code> <code>int | None</code> <p>The index of the schema in <code>items_schema</code> to be treated as variadic (following PEP 646)</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a tuple with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a tuple with at most this many items</p> <code>None</code> <code>fail_fast</code> <code>bool | None</code> <p>Stop validation on the first error</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a tuple with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>Optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def tuple_schema(\n    items_schema: list[CoreSchema],\n    *,\n    variadic_item_index: int | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; TupleSchema:\n    \"\"\"\n    Returns a schema that matches a tuple of schemas, with an optional variadic item, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.tuple_schema(\n        [core_schema.int_schema(), core_schema.str_schema(), core_schema.float_schema()],\n        variadic_item_index=1,\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python((1, 'hello', 'world', 1.5)) == (1, 'hello', 'world', 1.5)\n    ```\n\n    Args:\n        items_schema: The value must be a tuple with items that match these schemas\n        variadic_item_index: The index of the schema in `items_schema` to be treated as variadic (following PEP 646)\n        min_length: The value must be a tuple with at least this many items\n        max_length: The value must be a tuple with at most this many items\n        fail_fast: Stop validation on the first error\n        strict: The value must be a tuple with exactly this many items\n        ref: Optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='tuple',\n        items_schema=items_schema,\n        variadic_item_index=variadic_item_index,\n        min_length=min_length,\n        max_length=max_length,\n        fail_fast=fail_fast,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.set_schema","title":"set_schema","text":"<pre><code>set_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; SetSchema\n</code></pre> <p>Returns a schema that matches a set of a given schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.set_schema(\n    items_schema=core_schema.int_schema(), min_length=0, max_length=10\n)\nv = SchemaValidator(schema)\nassert v.validate_python({1, '2', 3}) == {1, 2, 3}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a set with items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a set with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a set with at most this many items</p> <code>None</code> <code>fail_fast</code> <code>bool | None</code> <p>Stop validation on the first error</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a set with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def set_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; SetSchema:\n    \"\"\"\n    Returns a schema that matches a set of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.set_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({1, '2', 3}) == {1, 2, 3}\n    ```\n\n    Args:\n        items_schema: The value must be a set with items that match this schema\n        min_length: The value must be a set with at least this many items\n        max_length: The value must be a set with at most this many items\n        fail_fast: Stop validation on the first error\n        strict: The value must be a set with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='set',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        fail_fast=fail_fast,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.frozenset_schema","title":"frozenset_schema","text":"<pre><code>frozenset_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; FrozenSetSchema\n</code></pre> <p>Returns a schema that matches a frozenset of a given schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.frozenset_schema(\n    items_schema=core_schema.int_schema(), min_length=0, max_length=10\n)\nv = SchemaValidator(schema)\nassert v.validate_python(frozenset(range(3))) == frozenset({0, 1, 2})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a frozenset with items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a frozenset with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a frozenset with at most this many items</p> <code>None</code> <code>fail_fast</code> <code>bool | None</code> <p>Stop validation on the first error</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>The value must be a frozenset with exactly this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def frozenset_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    fail_fast: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; FrozenSetSchema:\n    \"\"\"\n    Returns a schema that matches a frozenset of a given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.frozenset_schema(\n        items_schema=core_schema.int_schema(), min_length=0, max_length=10\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(frozenset(range(3))) == frozenset({0, 1, 2})\n    ```\n\n    Args:\n        items_schema: The value must be a frozenset with items that match this schema\n        min_length: The value must be a frozenset with at least this many items\n        max_length: The value must be a frozenset with at most this many items\n        fail_fast: Stop validation on the first error\n        strict: The value must be a frozenset with exactly this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='frozenset',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        fail_fast=fail_fast,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.generator_schema","title":"generator_schema","text":"<pre><code>generator_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None\n) -&gt; GeneratorSchema\n</code></pre> <p>Returns a schema that matches a generator value, e.g.:</p> <pre><code>from typing import Iterator\nfrom pydantic_core import SchemaValidator, core_schema\n\ndef gen() -&gt; Iterator[int]:\n    yield 1\n\nschema = core_schema.generator_schema(items_schema=core_schema.int_schema())\nv = SchemaValidator(schema)\nv.validate_python(gen())\n</code></pre> <p>Unlike other types, validated generators do not raise ValidationErrors eagerly, but instead will raise a ValidationError when a violating value is actually read from the generator. This is to ensure that \"validated\" generators retain the benefit of lazy evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>items_schema</code> <code>CoreSchema | None</code> <p>The value must be a generator with items that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a generator that yields at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a generator that yields at most this many items</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>IncExSeqOrElseSerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def generator_schema(\n    items_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: IncExSeqOrElseSerSchema | None = None,\n) -&gt; GeneratorSchema:\n    \"\"\"\n    Returns a schema that matches a generator value, e.g.:\n\n    ```py\n    from typing import Iterator\n    from pydantic_core import SchemaValidator, core_schema\n\n    def gen() -&gt; Iterator[int]:\n        yield 1\n\n    schema = core_schema.generator_schema(items_schema=core_schema.int_schema())\n    v = SchemaValidator(schema)\n    v.validate_python(gen())\n    ```\n\n    Unlike other types, validated generators do not raise ValidationErrors eagerly,\n    but instead will raise a ValidationError when a violating value is actually read from the generator.\n    This is to ensure that \"validated\" generators retain the benefit of lazy evaluation.\n\n    Args:\n        items_schema: The value must be a generator with items that match this schema\n        min_length: The value must be a generator that yields at least this many items\n        max_length: The value must be a generator that yields at most this many items\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='generator',\n        items_schema=items_schema,\n        min_length=min_length,\n        max_length=max_length,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.dict_schema","title":"dict_schema","text":"<pre><code>dict_schema(\n    keys_schema: CoreSchema | None = None,\n    values_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; DictSchema\n</code></pre> <p>Returns a schema that matches a dict value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.dict_schema(\n    keys_schema=core_schema.str_schema(), values_schema=core_schema.int_schema()\n)\nv = SchemaValidator(schema)\nassert v.validate_python({'a': '1', 'b': 2}) == {'a': 1, 'b': 2}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>keys_schema</code> <code>CoreSchema | None</code> <p>The value must be a dict with keys that match this schema</p> <code>None</code> <code>values_schema</code> <code>CoreSchema | None</code> <p>The value must be a dict with values that match this schema</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The value must be a dict with at least this many items</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The value must be a dict with at most this many items</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the keys and values should be validated with strict mode</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def dict_schema(\n    keys_schema: CoreSchema | None = None,\n    values_schema: CoreSchema | None = None,\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; DictSchema:\n    \"\"\"\n    Returns a schema that matches a dict value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.dict_schema(\n        keys_schema=core_schema.str_schema(), values_schema=core_schema.int_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': '1', 'b': 2}) == {'a': 1, 'b': 2}\n    ```\n\n    Args:\n        keys_schema: The value must be a dict with keys that match this schema\n        values_schema: The value must be a dict with values that match this schema\n        min_length: The value must be a dict with at least this many items\n        max_length: The value must be a dict with at most this many items\n        strict: Whether the keys and values should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='dict',\n        keys_schema=keys_schema,\n        values_schema=values_schema,\n        min_length=min_length,\n        max_length=max_length,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.no_info_before_validator_function","title":"no_info_before_validator_function","text":"<pre><code>no_info_before_validator_function(\n    function: NoInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; BeforeValidatorFunctionSchema\n</code></pre> <p>Returns a schema that calls a validator function before validating, no <code>info</code> argument is provided, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: bytes) -&gt; str:\n    return v.decode() + 'world'\n\nfunc_schema = core_schema.no_info_before_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>NoInfoValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def no_info_before_validator_function(\n    function: NoInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; BeforeValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that calls a validator function before validating, no `info` argument is provided, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: bytes) -&gt; str:\n        return v.decode() + 'world'\n\n    func_schema = core_schema.no_info_before_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-before',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.with_info_before_validator_function","title":"with_info_before_validator_function","text":"<pre><code>with_info_before_validator_function(\n    function: WithInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; BeforeValidatorFunctionSchema\n</code></pre> <p>Returns a schema that calls a validator function before validation, the function is called with an <code>info</code> argument, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: bytes, info: core_schema.ValidationInfo) -&gt; str:\n    assert info.data is not None\n    assert info.field_name is not None\n    return v.decode() + 'world'\n\nfunc_schema = core_schema.with_info_before_validator_function(\n    function=fn, schema=core_schema.str_schema(), field_name='a'\n)\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>WithInfoValidatorFunction</code> <p>The validator function to call</p> required <code>field_name</code> <code>str | None</code> <p>The name of the field</p> <code>None</code> <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def with_info_before_validator_function(\n    function: WithInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; BeforeValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that calls a validator function before validation, the function is called with\n    an `info` argument, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: bytes, info: core_schema.ValidationInfo) -&gt; str:\n        assert info.data is not None\n        assert info.field_name is not None\n        return v.decode() + 'world'\n\n    func_schema = core_schema.with_info_before_validator_function(\n        function=fn, schema=core_schema.str_schema(), field_name='a'\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call\n        field_name: The name of the field\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-before',\n        function=_dict_not_none(type='with-info', function=function, field_name=field_name),\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.no_info_after_validator_function","title":"no_info_after_validator_function","text":"<pre><code>no_info_after_validator_function(\n    function: NoInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; AfterValidatorFunctionSchema\n</code></pre> <p>Returns a schema that calls a validator function after validating, no <code>info</code> argument is provided, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str) -&gt; str:\n    return v + 'world'\n\nfunc_schema = core_schema.no_info_after_validator_function(fn, core_schema.str_schema())\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>NoInfoValidatorFunction</code> <p>The validator function to call after the schema is validated</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate before the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def no_info_after_validator_function(\n    function: NoInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; AfterValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that calls a validator function after validating, no `info` argument is provided, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str) -&gt; str:\n        return v + 'world'\n\n    func_schema = core_schema.no_info_after_validator_function(fn, core_schema.str_schema())\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call after the schema is validated\n        schema: The schema to validate before the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-after',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.with_info_after_validator_function","title":"with_info_after_validator_function","text":"<pre><code>with_info_after_validator_function(\n    function: WithInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; AfterValidatorFunctionSchema\n</code></pre> <p>Returns a schema that calls a validator function after validation, the function is called with an <code>info</code> argument, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n    assert info.data is not None\n    assert info.field_name is not None\n    return v + 'world'\n\nfunc_schema = core_schema.with_info_after_validator_function(\n    function=fn, schema=core_schema.str_schema(), field_name='a'\n)\nschema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\nv = SchemaValidator(schema)\nassert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>WithInfoValidatorFunction</code> <p>The validator function to call after the schema is validated</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate before the validator function</p> required <code>field_name</code> <code>str | None</code> <p>The name of the field this validators is applied to, if any</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def with_info_after_validator_function(\n    function: WithInfoValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; AfterValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that calls a validator function after validation, the function is called with\n    an `info` argument, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n        assert info.data is not None\n        assert info.field_name is not None\n        return v + 'world'\n\n    func_schema = core_schema.with_info_after_validator_function(\n        function=fn, schema=core_schema.str_schema(), field_name='a'\n    )\n    schema = core_schema.typed_dict_schema({'a': core_schema.typed_dict_field(func_schema)})\n\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': b'hello '}) == {'a': 'hello world'}\n    ```\n\n    Args:\n        function: The validator function to call after the schema is validated\n        schema: The schema to validate before the validator function\n        field_name: The name of the field this validators is applied to, if any\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-after',\n        function=_dict_not_none(type='with-info', function=function, field_name=field_name),\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.no_info_wrap_validator_function","title":"no_info_wrap_validator_function","text":"<pre><code>no_info_wrap_validator_function(\n    function: NoInfoWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; WrapValidatorFunctionSchema\n</code></pre> <p>Returns a schema which calls a function with a <code>validator</code> callable argument which can optionally be used to call inner validation with the function logic, this is much like the \"onion\" implementation of middleware in many popular web frameworks, no <code>info</code> argument is passed, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(\n    v: str,\n    validator: core_schema.ValidatorFunctionWrapHandler,\n) -&gt; str:\n    return validator(input_value=v) + 'world'\n\nschema = core_schema.no_info_wrap_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>NoInfoWrapValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def no_info_wrap_validator_function(\n    function: NoInfoWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; WrapValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema which calls a function with a `validator` callable argument which can\n    optionally be used to call inner validation with the function logic, this is much like the\n    \"onion\" implementation of middleware in many popular web frameworks, no `info` argument is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(\n        v: str,\n        validator: core_schema.ValidatorFunctionWrapHandler,\n    ) -&gt; str:\n        return validator(input_value=v) + 'world'\n\n    schema = core_schema.no_info_wrap_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-wrap',\n        function={'type': 'no-info', 'function': function},\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.with_info_wrap_validator_function","title":"with_info_wrap_validator_function","text":"<pre><code>with_info_wrap_validator_function(\n    function: WithInfoWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; WrapValidatorFunctionSchema\n</code></pre> <p>Returns a schema which calls a function with a <code>validator</code> callable argument which can optionally be used to call inner validation with the function logic, this is much like the \"onion\" implementation of middleware in many popular web frameworks, an <code>info</code> argument is also passed, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(\n    v: str,\n    validator: core_schema.ValidatorFunctionWrapHandler,\n    info: core_schema.ValidationInfo,\n) -&gt; str:\n    return validator(input_value=v) + 'world'\n\nschema = core_schema.with_info_wrap_validator_function(\n    function=fn, schema=core_schema.str_schema()\n)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>WithInfoWrapValidatorFunction</code> <p>The validator function to call</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to validate the output of the validator function</p> required <code>field_name</code> <code>str | None</code> <p>The name of the field this validators is applied to, if any</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def with_info_wrap_validator_function(\n    function: WithInfoWrapValidatorFunction,\n    schema: CoreSchema,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; WrapValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema which calls a function with a `validator` callable argument which can\n    optionally be used to call inner validation with the function logic, this is much like the\n    \"onion\" implementation of middleware in many popular web frameworks, an `info` argument is also passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(\n        v: str,\n        validator: core_schema.ValidatorFunctionWrapHandler,\n        info: core_schema.ValidationInfo,\n    ) -&gt; str:\n        return validator(input_value=v) + 'world'\n\n    schema = core_schema.with_info_wrap_validator_function(\n        function=fn, schema=core_schema.str_schema()\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        schema: The schema to validate the output of the validator function\n        field_name: The name of the field this validators is applied to, if any\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-wrap',\n        function=_dict_not_none(type='with-info', function=function, field_name=field_name),\n        schema=schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.no_info_plain_validator_function","title":"no_info_plain_validator_function","text":"<pre><code>no_info_plain_validator_function(\n    function: NoInfoValidatorFunction,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; PlainValidatorFunctionSchema\n</code></pre> <p>Returns a schema that uses the provided function for validation, no <code>info</code> argument is passed, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str) -&gt; str:\n    assert 'hello' in v\n    return v + 'world'\n\nschema = core_schema.no_info_plain_validator_function(function=fn)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>NoInfoValidatorFunction</code> <p>The validator function to call</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def no_info_plain_validator_function(\n    function: NoInfoValidatorFunction,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; PlainValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that uses the provided function for validation, no `info` argument is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str) -&gt; str:\n        assert 'hello' in v\n        return v + 'world'\n\n    schema = core_schema.no_info_plain_validator_function(function=fn)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-plain',\n        function={'type': 'no-info', 'function': function},\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.with_info_plain_validator_function","title":"with_info_plain_validator_function","text":"<pre><code>with_info_plain_validator_function(\n    function: WithInfoValidatorFunction,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; PlainValidatorFunctionSchema\n</code></pre> <p>Returns a schema that uses the provided function for validation, an <code>info</code> argument is passed, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n    assert 'hello' in v\n    return v + 'world'\n\nschema = core_schema.with_info_plain_validator_function(function=fn)\nv = SchemaValidator(schema)\nassert v.validate_python('hello ') == 'hello world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>WithInfoValidatorFunction</code> <p>The validator function to call</p> required <code>field_name</code> <code>str | None</code> <p>The name of the field this validators is applied to, if any</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def with_info_plain_validator_function(\n    function: WithInfoValidatorFunction,\n    *,\n    field_name: str | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; PlainValidatorFunctionSchema:\n    \"\"\"\n    Returns a schema that uses the provided function for validation, an `info` argument is passed, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n        assert 'hello' in v\n        return v + 'world'\n\n    schema = core_schema.with_info_plain_validator_function(function=fn)\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello ') == 'hello world'\n    ```\n\n    Args:\n        function: The validator function to call\n        field_name: The name of the field this validators is applied to, if any\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='function-plain',\n        function=_dict_not_none(type='with-info', function=function, field_name=field_name),\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.with_default_schema","title":"with_default_schema","text":"<pre><code>with_default_schema(\n    schema: CoreSchema,\n    *,\n    default: Any = PydanticUndefined,\n    default_factory: Callable[[], Any] | None = None,\n    on_error: (\n        Literal[\"raise\", \"omit\", \"default\"] | None\n    ) = None,\n    validate_default: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; WithDefaultSchema\n</code></pre> <p>Returns a schema that adds a default value to the given schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.with_default_schema(core_schema.str_schema(), default='hello')\nwrapper_schema = core_schema.typed_dict_schema(\n    {'a': core_schema.typed_dict_field(schema)}\n)\nv = SchemaValidator(wrapper_schema)\nassert v.validate_python({}) == v.validate_python({'a': 'hello'})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to add a default value to</p> required <code>default</code> <code>Any</code> <p>The default value to use</p> <code>PydanticUndefined</code> <code>default_factory</code> <code>Callable[[], Any] | None</code> <p>A function that returns the default value to use</p> <code>None</code> <code>on_error</code> <code>Literal['raise', 'omit', 'default'] | None</code> <p>What to do if the schema validation fails. One of 'raise', 'omit', 'default'</p> <code>None</code> <code>validate_default</code> <code>bool | None</code> <p>Whether the default value should be validated</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the underlying schema should be validated with strict mode</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def with_default_schema(\n    schema: CoreSchema,\n    *,\n    default: Any = PydanticUndefined,\n    default_factory: Callable[[], Any] | None = None,\n    on_error: Literal['raise', 'omit', 'default'] | None = None,\n    validate_default: bool | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; WithDefaultSchema:\n    \"\"\"\n    Returns a schema that adds a default value to the given schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.with_default_schema(core_schema.str_schema(), default='hello')\n    wrapper_schema = core_schema.typed_dict_schema(\n        {'a': core_schema.typed_dict_field(schema)}\n    )\n    v = SchemaValidator(wrapper_schema)\n    assert v.validate_python({}) == v.validate_python({'a': 'hello'})\n    ```\n\n    Args:\n        schema: The schema to add a default value to\n        default: The default value to use\n        default_factory: A function that returns the default value to use\n        on_error: What to do if the schema validation fails. One of 'raise', 'omit', 'default'\n        validate_default: Whether the default value should be validated\n        strict: Whether the underlying schema should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    s = _dict_not_none(\n        type='default',\n        schema=schema,\n        default_factory=default_factory,\n        on_error=on_error,\n        validate_default=validate_default,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n    if default is not PydanticUndefined:\n        s['default'] = default\n    return s\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.nullable_schema","title":"nullable_schema","text":"<pre><code>nullable_schema(\n    schema: CoreSchema,\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; NullableSchema\n</code></pre> <p>Returns a schema that matches a nullable value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.nullable_schema(core_schema.str_schema())\nv = SchemaValidator(schema)\nassert v.validate_python(None) is None\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to wrap</p> required <code>strict</code> <code>bool | None</code> <p>Whether the underlying schema should be validated with strict mode</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def nullable_schema(\n    schema: CoreSchema,\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; NullableSchema:\n    \"\"\"\n    Returns a schema that matches a nullable value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.nullable_schema(core_schema.str_schema())\n    v = SchemaValidator(schema)\n    assert v.validate_python(None) is None\n    ```\n\n    Args:\n        schema: The schema to wrap\n        strict: Whether the underlying schema should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='nullable', schema=schema, strict=strict, ref=ref, metadata=metadata, serialization=serialization\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.union_schema","title":"union_schema","text":"<pre><code>union_schema(\n    choices: list[CoreSchema | tuple[CoreSchema, str]],\n    *,\n    auto_collapse: bool | None = None,\n    custom_error_type: str | None = None,\n    custom_error_message: str | None = None,\n    custom_error_context: (\n        dict[str, str | int] | None\n    ) = None,\n    mode: Literal[\"smart\", \"left_to_right\"] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; UnionSchema\n</code></pre> <p>Returns a schema that matches a union value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.union_schema([core_schema.str_schema(), core_schema.int_schema()])\nv = SchemaValidator(schema)\nassert v.validate_python('hello') == 'hello'\nassert v.validate_python(1) == 1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>choices</code> <code>list[CoreSchema | tuple[CoreSchema, str]]</code> <p>The schemas to match. If a tuple, the second item is used as the label for the case.</p> required <code>auto_collapse</code> <code>bool | None</code> <p>whether to automatically collapse unions with one element to the inner validator, default true</p> <code>None</code> <code>custom_error_type</code> <code>str | None</code> <p>The custom error type to use if the validation fails</p> <code>None</code> <code>custom_error_message</code> <code>str | None</code> <p>The custom error message to use if the validation fails</p> <code>None</code> <code>custom_error_context</code> <code>dict[str, str | int] | None</code> <p>The custom error context to use if the validation fails</p> <code>None</code> <code>mode</code> <code>Literal['smart', 'left_to_right'] | None</code> <p>How to select which choice to return * <code>smart</code> (default) will try to return the choice which is the closest match to the input value * <code>left_to_right</code> will return the first choice in <code>choices</code> which succeeds validation</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the underlying schemas should be validated with strict mode</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def union_schema(\n    choices: list[CoreSchema | tuple[CoreSchema, str]],\n    *,\n    auto_collapse: bool | None = None,\n    custom_error_type: str | None = None,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, str | int] | None = None,\n    mode: Literal['smart', 'left_to_right'] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; UnionSchema:\n    \"\"\"\n    Returns a schema that matches a union value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.union_schema([core_schema.str_schema(), core_schema.int_schema()])\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello'\n    assert v.validate_python(1) == 1\n    ```\n\n    Args:\n        choices: The schemas to match. If a tuple, the second item is used as the label for the case.\n        auto_collapse: whether to automatically collapse unions with one element to the inner validator, default true\n        custom_error_type: The custom error type to use if the validation fails\n        custom_error_message: The custom error message to use if the validation fails\n        custom_error_context: The custom error context to use if the validation fails\n        mode: How to select which choice to return\n            * `smart` (default) will try to return the choice which is the closest match to the input value\n            * `left_to_right` will return the first choice in `choices` which succeeds validation\n        strict: Whether the underlying schemas should be validated with strict mode\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='union',\n        choices=choices,\n        auto_collapse=auto_collapse,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        mode=mode,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.tagged_union_schema","title":"tagged_union_schema","text":"<pre><code>tagged_union_schema(\n    choices: Dict[Any, CoreSchema],\n    discriminator: (\n        str\n        | list[str | int]\n        | list[list[str | int]]\n        | Callable[[Any], Any]\n    ),\n    *,\n    custom_error_type: str | None = None,\n    custom_error_message: str | None = None,\n    custom_error_context: (\n        dict[str, int | str | float] | None\n    ) = None,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; TaggedUnionSchema\n</code></pre> <p>Returns a schema that matches a tagged union value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\napple_schema = core_schema.typed_dict_schema(\n    {\n        'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n        'bar': core_schema.typed_dict_field(core_schema.int_schema()),\n    }\n)\nbanana_schema = core_schema.typed_dict_schema(\n    {\n        'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n        'spam': core_schema.typed_dict_field(\n            core_schema.list_schema(items_schema=core_schema.int_schema())\n        ),\n    }\n)\nschema = core_schema.tagged_union_schema(\n    choices={\n        'apple': apple_schema,\n        'banana': banana_schema,\n    },\n    discriminator='foo',\n)\nv = SchemaValidator(schema)\nassert v.validate_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123}\nassert v.validate_python({'foo': 'banana', 'spam': [1, 2, 3]}) == {\n    'foo': 'banana',\n    'spam': [1, 2, 3],\n}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>choices</code> <code>Dict[Any, CoreSchema]</code> <p>The schemas to match When retrieving a schema from <code>choices</code> using the discriminator value, if the value is a str, it should be fed back into the <code>choices</code> map until a schema is obtained (This approach is to prevent multiple ownership of a single schema in Rust)</p> required <code>discriminator</code> <code>str | list[str | int] | list[list[str | int]] | Callable[[Any], Any]</code> <p>The discriminator to use to determine the schema to use * If <code>discriminator</code> is a str, it is the name of the attribute to use as the discriminator * If <code>discriminator</code> is a list of int/str, it should be used as a \"path\" to access the discriminator * If <code>discriminator</code> is a list of lists, each inner list is a path, and the first path that exists is used * If <code>discriminator</code> is a callable, it should return the discriminator when called on the value to validate;   the callable can return <code>None</code> to indicate that there is no matching discriminator present on the input</p> required <code>custom_error_type</code> <code>str | None</code> <p>The custom error type to use if the validation fails</p> <code>None</code> <code>custom_error_message</code> <code>str | None</code> <p>The custom error message to use if the validation fails</p> <code>None</code> <code>custom_error_context</code> <code>dict[str, int | str | float] | None</code> <p>The custom error context to use if the validation fails</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the underlying schemas should be validated with strict mode</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to use the attributes of the object to retrieve the discriminator value</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def tagged_union_schema(\n    choices: Dict[Any, CoreSchema],\n    discriminator: str | list[str | int] | list[list[str | int]] | Callable[[Any], Any],\n    *,\n    custom_error_type: str | None = None,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, int | str | float] | None = None,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; TaggedUnionSchema:\n    \"\"\"\n    Returns a schema that matches a tagged union value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    apple_schema = core_schema.typed_dict_schema(\n        {\n            'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n            'bar': core_schema.typed_dict_field(core_schema.int_schema()),\n        }\n    )\n    banana_schema = core_schema.typed_dict_schema(\n        {\n            'foo': core_schema.typed_dict_field(core_schema.str_schema()),\n            'spam': core_schema.typed_dict_field(\n                core_schema.list_schema(items_schema=core_schema.int_schema())\n            ),\n        }\n    )\n    schema = core_schema.tagged_union_schema(\n        choices={\n            'apple': apple_schema,\n            'banana': banana_schema,\n        },\n        discriminator='foo',\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python({'foo': 'apple', 'bar': '123'}) == {'foo': 'apple', 'bar': 123}\n    assert v.validate_python({'foo': 'banana', 'spam': [1, 2, 3]}) == {\n        'foo': 'banana',\n        'spam': [1, 2, 3],\n    }\n    ```\n\n    Args:\n        choices: The schemas to match\n            When retrieving a schema from `choices` using the discriminator value, if the value is a str,\n            it should be fed back into the `choices` map until a schema is obtained\n            (This approach is to prevent multiple ownership of a single schema in Rust)\n        discriminator: The discriminator to use to determine the schema to use\n            * If `discriminator` is a str, it is the name of the attribute to use as the discriminator\n            * If `discriminator` is a list of int/str, it should be used as a \"path\" to access the discriminator\n            * If `discriminator` is a list of lists, each inner list is a path, and the first path that exists is used\n            * If `discriminator` is a callable, it should return the discriminator when called on the value to validate;\n              the callable can return `None` to indicate that there is no matching discriminator present on the input\n        custom_error_type: The custom error type to use if the validation fails\n        custom_error_message: The custom error message to use if the validation fails\n        custom_error_context: The custom error context to use if the validation fails\n        strict: Whether the underlying schemas should be validated with strict mode\n        from_attributes: Whether to use the attributes of the object to retrieve the discriminator value\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='tagged-union',\n        choices=choices,\n        discriminator=discriminator,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        strict=strict,\n        from_attributes=from_attributes,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.chain_schema","title":"chain_schema","text":"<pre><code>chain_schema(\n    steps: list[CoreSchema],\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; ChainSchema\n</code></pre> <p>Returns a schema that chains the provided validation schemas, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n    assert 'hello' in v\n    return v + ' world'\n\nfn_schema = core_schema.with_info_plain_validator_function(function=fn)\nschema = core_schema.chain_schema(\n    [fn_schema, fn_schema, fn_schema, core_schema.str_schema()]\n)\nv = SchemaValidator(schema)\nassert v.validate_python('hello') == 'hello world world world'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>steps</code> <code>list[CoreSchema]</code> <p>The schemas to chain</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def chain_schema(\n    steps: list[CoreSchema],\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; ChainSchema:\n    \"\"\"\n    Returns a schema that chains the provided validation schemas, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n        assert 'hello' in v\n        return v + ' world'\n\n    fn_schema = core_schema.with_info_plain_validator_function(function=fn)\n    schema = core_schema.chain_schema(\n        [fn_schema, fn_schema, fn_schema, core_schema.str_schema()]\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('hello') == 'hello world world world'\n    ```\n\n    Args:\n        steps: The schemas to chain\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='chain', steps=steps, ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.lax_or_strict_schema","title":"lax_or_strict_schema","text":"<pre><code>lax_or_strict_schema(\n    lax_schema: CoreSchema,\n    strict_schema: CoreSchema,\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; LaxOrStrictSchema\n</code></pre> <p>Returns a schema that uses the lax or strict schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndef fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n    assert 'hello' in v\n    return v + ' world'\n\nlax_schema = core_schema.int_schema(strict=False)\nstrict_schema = core_schema.int_schema(strict=True)\n\nschema = core_schema.lax_or_strict_schema(\n    lax_schema=lax_schema, strict_schema=strict_schema, strict=True\n)\nv = SchemaValidator(schema)\nassert v.validate_python(123) == 123\n\nschema = core_schema.lax_or_strict_schema(\n    lax_schema=lax_schema, strict_schema=strict_schema, strict=False\n)\nv = SchemaValidator(schema)\nassert v.validate_python('123') == 123\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>lax_schema</code> <code>CoreSchema</code> <p>The lax schema to use</p> required <code>strict_schema</code> <code>CoreSchema</code> <p>The strict schema to use</p> required <code>strict</code> <code>bool | None</code> <p>Whether the strict schema should be used</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def lax_or_strict_schema(\n    lax_schema: CoreSchema,\n    strict_schema: CoreSchema,\n    *,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; LaxOrStrictSchema:\n    \"\"\"\n    Returns a schema that uses the lax or strict schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    def fn(v: str, info: core_schema.ValidationInfo) -&gt; str:\n        assert 'hello' in v\n        return v + ' world'\n\n    lax_schema = core_schema.int_schema(strict=False)\n    strict_schema = core_schema.int_schema(strict=True)\n\n    schema = core_schema.lax_or_strict_schema(\n        lax_schema=lax_schema, strict_schema=strict_schema, strict=True\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python(123) == 123\n\n    schema = core_schema.lax_or_strict_schema(\n        lax_schema=lax_schema, strict_schema=strict_schema, strict=False\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python('123') == 123\n    ```\n\n    Args:\n        lax_schema: The lax schema to use\n        strict_schema: The strict schema to use\n        strict: Whether the strict schema should be used\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='lax-or-strict',\n        lax_schema=lax_schema,\n        strict_schema=strict_schema,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.json_or_python_schema","title":"json_or_python_schema","text":"<pre><code>json_or_python_schema(\n    json_schema: CoreSchema,\n    python_schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; JsonOrPythonSchema\n</code></pre> <p>Returns a schema that uses the Json or Python schema depending on the input:</p> <pre><code>from pydantic_core import SchemaValidator, ValidationError, core_schema\n\nv = SchemaValidator(\n    core_schema.json_or_python_schema(\n        json_schema=core_schema.int_schema(),\n        python_schema=core_schema.int_schema(strict=True),\n    )\n)\n\nassert v.validate_json('\"123\"') == 123\n\ntry:\n    v.validate_python('123')\nexcept ValidationError:\n    pass\nelse:\n    raise AssertionError('Validation should have failed')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>json_schema</code> <code>CoreSchema</code> <p>The schema to use for Json inputs</p> required <code>python_schema</code> <code>CoreSchema</code> <p>The schema to use for Python inputs</p> required <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def json_or_python_schema(\n    json_schema: CoreSchema,\n    python_schema: CoreSchema,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; JsonOrPythonSchema:\n    \"\"\"\n    Returns a schema that uses the Json or Python schema depending on the input:\n\n    ```py\n    from pydantic_core import SchemaValidator, ValidationError, core_schema\n\n    v = SchemaValidator(\n        core_schema.json_or_python_schema(\n            json_schema=core_schema.int_schema(),\n            python_schema=core_schema.int_schema(strict=True),\n        )\n    )\n\n    assert v.validate_json('\"123\"') == 123\n\n    try:\n        v.validate_python('123')\n    except ValidationError:\n        pass\n    else:\n        raise AssertionError('Validation should have failed')\n    ```\n\n    Args:\n        json_schema: The schema to use for Json inputs\n        python_schema: The schema to use for Python inputs\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='json-or-python',\n        json_schema=json_schema,\n        python_schema=python_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.typed_dict_field","title":"typed_dict_field","text":"<pre><code>typed_dict_field(\n    schema: CoreSchema,\n    *,\n    required: bool | None = None,\n    validation_alias: (\n        str | list[str | int] | list[list[str | int]] | None\n    ) = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    metadata: Dict[str, Any] | None = None\n) -&gt; TypedDictField\n</code></pre> <p>Returns a schema that matches a typed dict field, e.g.:</p> <pre><code>from pydantic_core import core_schema\n\nfield = core_schema.typed_dict_field(schema=core_schema.int_schema(), required=True)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the field</p> required <code>required</code> <code>bool | None</code> <p>Whether the field is required</p> <code>None</code> <code>validation_alias</code> <code>str | list[str | int] | list[list[str | int]] | None</code> <p>The alias(es) to use to find the field in the validation data</p> <code>None</code> <code>serialization_alias</code> <code>str | None</code> <p>The alias to use as a key when serializing</p> <code>None</code> <code>serialization_exclude</code> <code>bool | None</code> <p>Whether to exclude the field when serializing</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def typed_dict_field(\n    schema: CoreSchema,\n    *,\n    required: bool | None = None,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    metadata: Dict[str, Any] | None = None,\n) -&gt; TypedDictField:\n    \"\"\"\n    Returns a schema that matches a typed dict field, e.g.:\n\n    ```py\n    from pydantic_core import core_schema\n\n    field = core_schema.typed_dict_field(schema=core_schema.int_schema(), required=True)\n    ```\n\n    Args:\n        schema: The schema to use for the field\n        required: Whether the field is required\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return _dict_not_none(\n        type='typed-dict-field',\n        schema=schema,\n        required=required,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.typed_dict_schema","title":"typed_dict_schema","text":"<pre><code>typed_dict_schema(\n    fields: Dict[str, TypedDictField],\n    *,\n    cls: Type[TypedDict] | None = None,\n    computed_fields: list[ComputedField] | None = None,\n    strict: bool | None = None,\n    extras_schema: CoreSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    total: bool | None = None,\n    populate_by_name: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n    config: CoreConfig | None = None\n) -&gt; TypedDictSchema\n</code></pre> <p>Returns a schema that matches a typed dict, e.g.:</p> <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic_core import SchemaValidator, core_schema\n\nclass MyTypedDict(TypedDict):\n    a: str\n\nwrapper_schema = core_schema.typed_dict_schema(\n    {'a': core_schema.typed_dict_field(core_schema.str_schema())}, cls=MyTypedDict\n)\nv = SchemaValidator(wrapper_schema)\nassert v.validate_python({'a': 'hello'}) == {'a': 'hello'}\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>Dict[str, TypedDictField]</code> <p>The fields to use for the typed dict</p> required <code>cls</code> <code>Type[TypedDict] | None</code> <p>The class to use for the typed dict</p> <code>None</code> <code>computed_fields</code> <code>list[ComputedField] | None</code> <p>Computed fields to use when serializing the model, only applies when directly inside a model</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the typed dict is strict</p> <code>None</code> <code>extras_schema</code> <code>CoreSchema | None</code> <p>The extra validator to use for the typed dict</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>extra_behavior</code> <code>ExtraBehavior | None</code> <p>The extra behavior to use for the typed dict</p> <code>None</code> <code>total</code> <code>bool | None</code> <p>Whether the typed dict is total</p> <code>None</code> <code>populate_by_name</code> <code>bool | None</code> <p>Whether the typed dict should populate by name</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def typed_dict_schema(\n    fields: Dict[str, TypedDictField],\n    *,\n    cls: Type[TypedDict] | None = None,\n    computed_fields: list[ComputedField] | None = None,\n    strict: bool | None = None,\n    extras_schema: CoreSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    total: bool | None = None,\n    populate_by_name: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n    config: CoreConfig | None = None,\n) -&gt; TypedDictSchema:\n    \"\"\"\n    Returns a schema that matches a typed dict, e.g.:\n\n    ```py\n    from typing_extensions import TypedDict\n\n    from pydantic_core import SchemaValidator, core_schema\n\n    class MyTypedDict(TypedDict):\n        a: str\n\n    wrapper_schema = core_schema.typed_dict_schema(\n        {'a': core_schema.typed_dict_field(core_schema.str_schema())}, cls=MyTypedDict\n    )\n    v = SchemaValidator(wrapper_schema)\n    assert v.validate_python({'a': 'hello'}) == {'a': 'hello'}\n    ```\n\n    Args:\n        fields: The fields to use for the typed dict\n        cls: The class to use for the typed dict\n        computed_fields: Computed fields to use when serializing the model, only applies when directly inside a model\n        strict: Whether the typed dict is strict\n        extras_schema: The extra validator to use for the typed dict\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        extra_behavior: The extra behavior to use for the typed dict\n        total: Whether the typed dict is total\n        populate_by_name: Whether the typed dict should populate by name\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='typed-dict',\n        fields=fields,\n        cls=cls,\n        computed_fields=computed_fields,\n        strict=strict,\n        extras_schema=extras_schema,\n        extra_behavior=extra_behavior,\n        total=total,\n        populate_by_name=populate_by_name,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        config=config,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.model_field","title":"model_field","text":"<pre><code>model_field(\n    schema: CoreSchema,\n    *,\n    validation_alias: (\n        str | list[str | int] | list[list[str | int]] | None\n    ) = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    frozen: bool | None = None,\n    metadata: Dict[str, Any] | None = None\n) -&gt; ModelField\n</code></pre> <p>Returns a schema for a model field, e.g.:</p> <pre><code>from pydantic_core import core_schema\n\nfield = core_schema.model_field(schema=core_schema.int_schema())\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the field</p> required <code>validation_alias</code> <code>str | list[str | int] | list[list[str | int]] | None</code> <p>The alias(es) to use to find the field in the validation data</p> <code>None</code> <code>serialization_alias</code> <code>str | None</code> <p>The alias to use as a key when serializing</p> <code>None</code> <code>serialization_exclude</code> <code>bool | None</code> <p>Whether to exclude the field when serializing</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the field is frozen</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def model_field(\n    schema: CoreSchema,\n    *,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    frozen: bool | None = None,\n    metadata: Dict[str, Any] | None = None,\n) -&gt; ModelField:\n    \"\"\"\n    Returns a schema for a model field, e.g.:\n\n    ```py\n    from pydantic_core import core_schema\n\n    field = core_schema.model_field(schema=core_schema.int_schema())\n    ```\n\n    Args:\n        schema: The schema to use for the field\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        frozen: Whether the field is frozen\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n    \"\"\"\n    return _dict_not_none(\n        type='model-field',\n        schema=schema,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        frozen=frozen,\n        metadata=metadata,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.model_fields_schema","title":"model_fields_schema","text":"<pre><code>model_fields_schema(\n    fields: Dict[str, ModelField],\n    *,\n    model_name: str | None = None,\n    computed_fields: list[ComputedField] | None = None,\n    strict: bool | None = None,\n    extras_schema: CoreSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    populate_by_name: bool | None = None,\n    from_attributes: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; ModelFieldsSchema\n</code></pre> <p>Returns a schema that matches a typed dict, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nwrapper_schema = core_schema.model_fields_schema(\n    {'a': core_schema.model_field(core_schema.str_schema())}\n)\nv = SchemaValidator(wrapper_schema)\nprint(v.validate_python({'a': 'hello'}))\n#&gt; ({'a': 'hello'}, None, {'a'})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>Dict[str, ModelField]</code> <p>The fields to use for the typed dict</p> required <code>model_name</code> <code>str | None</code> <p>The name of the model, used for error messages, defaults to \"Model\"</p> <code>None</code> <code>computed_fields</code> <code>list[ComputedField] | None</code> <p>Computed fields to use when serializing the model, only applies when directly inside a model</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the typed dict is strict</p> <code>None</code> <code>extras_schema</code> <code>CoreSchema | None</code> <p>The extra validator to use for the typed dict</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>extra_behavior</code> <code>ExtraBehavior | None</code> <p>The extra behavior to use for the typed dict</p> <code>None</code> <code>populate_by_name</code> <code>bool | None</code> <p>Whether the typed dict should populate by name</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether the typed dict should be populated from attributes</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def model_fields_schema(\n    fields: Dict[str, ModelField],\n    *,\n    model_name: str | None = None,\n    computed_fields: list[ComputedField] | None = None,\n    strict: bool | None = None,\n    extras_schema: CoreSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    populate_by_name: bool | None = None,\n    from_attributes: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; ModelFieldsSchema:\n    \"\"\"\n    Returns a schema that matches a typed dict, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    wrapper_schema = core_schema.model_fields_schema(\n        {'a': core_schema.model_field(core_schema.str_schema())}\n    )\n    v = SchemaValidator(wrapper_schema)\n    print(v.validate_python({'a': 'hello'}))\n    #&gt; ({'a': 'hello'}, None, {'a'})\n    ```\n\n    Args:\n        fields: The fields to use for the typed dict\n        model_name: The name of the model, used for error messages, defaults to \"Model\"\n        computed_fields: Computed fields to use when serializing the model, only applies when directly inside a model\n        strict: Whether the typed dict is strict\n        extras_schema: The extra validator to use for the typed dict\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        extra_behavior: The extra behavior to use for the typed dict\n        populate_by_name: Whether the typed dict should populate by name\n        from_attributes: Whether the typed dict should be populated from attributes\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='model-fields',\n        fields=fields,\n        model_name=model_name,\n        computed_fields=computed_fields,\n        strict=strict,\n        extras_schema=extras_schema,\n        extra_behavior=extra_behavior,\n        populate_by_name=populate_by_name,\n        from_attributes=from_attributes,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.model_schema","title":"model_schema","text":"<pre><code>model_schema(\n    cls: Type[Any],\n    schema: CoreSchema,\n    *,\n    custom_init: bool | None = None,\n    root_model: bool | None = None,\n    post_init: str | None = None,\n    revalidate_instances: (\n        Literal[\"always\", \"never\", \"subclass-instances\"]\n        | None\n    ) = None,\n    strict: bool | None = None,\n    frozen: bool | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    config: CoreConfig | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; ModelSchema\n</code></pre> <p>A model schema generally contains a typed-dict schema. It will run the typed dict validator, then create a new class and set the dict and fields set returned from the typed dict validator to <code>__dict__</code> and <code>__pydantic_fields_set__</code> respectively.</p> <p>Example:</p> <pre><code>from pydantic_core import CoreConfig, SchemaValidator, core_schema\n\nclass MyModel:\n    __slots__ = (\n        '__dict__',\n        '__pydantic_fields_set__',\n        '__pydantic_extra__',\n        '__pydantic_private__',\n    )\n\nschema = core_schema.model_schema(\n    cls=MyModel,\n    config=CoreConfig(str_max_length=5),\n    schema=core_schema.model_fields_schema(\n        fields={'a': core_schema.model_field(core_schema.str_schema())},\n    ),\n)\nv = SchemaValidator(schema)\nassert v.isinstance_python({'a': 'hello'}) is True\nassert v.isinstance_python({'a': 'too long'}) is False\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Any]</code> <p>The class to use for the model</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the model</p> required <code>custom_init</code> <code>bool | None</code> <p>Whether the model has a custom init method</p> <code>None</code> <code>root_model</code> <code>bool | None</code> <p>Whether the model is a <code>RootModel</code></p> <code>None</code> <code>post_init</code> <code>str | None</code> <p>The call after init to use for the model</p> <code>None</code> <code>revalidate_instances</code> <code>Literal['always', 'never', 'subclass-instances'] | None</code> <p>whether instances of models and dataclasses (including subclass instances) should re-validate defaults to config.revalidate_instances, else 'never'</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether the model is strict</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the model is frozen</p> <code>None</code> <code>extra_behavior</code> <code>ExtraBehavior | None</code> <p>The extra behavior to use for the model, used in serialization</p> <code>None</code> <code>config</code> <code>CoreConfig | None</code> <p>The config to use for the model</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def model_schema(\n    cls: Type[Any],\n    schema: CoreSchema,\n    *,\n    custom_init: bool | None = None,\n    root_model: bool | None = None,\n    post_init: str | None = None,\n    revalidate_instances: Literal['always', 'never', 'subclass-instances'] | None = None,\n    strict: bool | None = None,\n    frozen: bool | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n    config: CoreConfig | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; ModelSchema:\n    \"\"\"\n    A model schema generally contains a typed-dict schema.\n    It will run the typed dict validator, then create a new class\n    and set the dict and fields set returned from the typed dict validator\n    to `__dict__` and `__pydantic_fields_set__` respectively.\n\n    Example:\n\n    ```py\n    from pydantic_core import CoreConfig, SchemaValidator, core_schema\n\n    class MyModel:\n        __slots__ = (\n            '__dict__',\n            '__pydantic_fields_set__',\n            '__pydantic_extra__',\n            '__pydantic_private__',\n        )\n\n    schema = core_schema.model_schema(\n        cls=MyModel,\n        config=CoreConfig(str_max_length=5),\n        schema=core_schema.model_fields_schema(\n            fields={'a': core_schema.model_field(core_schema.str_schema())},\n        ),\n    )\n    v = SchemaValidator(schema)\n    assert v.isinstance_python({'a': 'hello'}) is True\n    assert v.isinstance_python({'a': 'too long'}) is False\n    ```\n\n    Args:\n        cls: The class to use for the model\n        schema: The schema to use for the model\n        custom_init: Whether the model has a custom init method\n        root_model: Whether the model is a `RootModel`\n        post_init: The call after init to use for the model\n        revalidate_instances: whether instances of models and dataclasses (including subclass instances)\n            should re-validate defaults to config.revalidate_instances, else 'never'\n        strict: Whether the model is strict\n        frozen: Whether the model is frozen\n        extra_behavior: The extra behavior to use for the model, used in serialization\n        config: The config to use for the model\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='model',\n        cls=cls,\n        schema=schema,\n        custom_init=custom_init,\n        root_model=root_model,\n        post_init=post_init,\n        revalidate_instances=revalidate_instances,\n        strict=strict,\n        frozen=frozen,\n        extra_behavior=extra_behavior,\n        config=config,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.dataclass_field","title":"dataclass_field","text":"<pre><code>dataclass_field(\n    name: str,\n    schema: CoreSchema,\n    *,\n    kw_only: bool | None = None,\n    init: bool | None = None,\n    init_only: bool | None = None,\n    validation_alias: (\n        str | list[str | int] | list[list[str | int]] | None\n    ) = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    metadata: Dict[str, Any] | None = None,\n    frozen: bool | None = None\n) -&gt; DataclassField\n</code></pre> <p>Returns a schema for a dataclass field, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nfield = core_schema.dataclass_field(\n    name='a', schema=core_schema.str_schema(), kw_only=False\n)\nschema = core_schema.dataclass_args_schema('Foobar', [field])\nv = SchemaValidator(schema)\nassert v.validate_python({'a': 'hello'}) == ({'a': 'hello'}, None)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to use for the argument parameter</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the argument parameter</p> required <code>kw_only</code> <code>bool | None</code> <p>Whether the field can be set with a positional argument as well as a keyword argument</p> <code>None</code> <code>init</code> <code>bool | None</code> <p>Whether the field should be validated during initialization</p> <code>None</code> <code>init_only</code> <code>bool | None</code> <p>Whether the field should be omitted  from <code>__dict__</code> and passed to <code>__post_init__</code></p> <code>None</code> <code>validation_alias</code> <code>str | list[str | int] | list[list[str | int]] | None</code> <p>The alias(es) to use to find the field in the validation data</p> <code>None</code> <code>serialization_alias</code> <code>str | None</code> <p>The alias to use as a key when serializing</p> <code>None</code> <code>serialization_exclude</code> <code>bool | None</code> <p>Whether to exclude the field when serializing</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the field is frozen</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def dataclass_field(\n    name: str,\n    schema: CoreSchema,\n    *,\n    kw_only: bool | None = None,\n    init: bool | None = None,\n    init_only: bool | None = None,\n    validation_alias: str | list[str | int] | list[list[str | int]] | None = None,\n    serialization_alias: str | None = None,\n    serialization_exclude: bool | None = None,\n    metadata: Dict[str, Any] | None = None,\n    frozen: bool | None = None,\n) -&gt; DataclassField:\n    \"\"\"\n    Returns a schema for a dataclass field, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    field = core_schema.dataclass_field(\n        name='a', schema=core_schema.str_schema(), kw_only=False\n    )\n    schema = core_schema.dataclass_args_schema('Foobar', [field])\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': 'hello'}) == ({'a': 'hello'}, None)\n    ```\n\n    Args:\n        name: The name to use for the argument parameter\n        schema: The schema to use for the argument parameter\n        kw_only: Whether the field can be set with a positional argument as well as a keyword argument\n        init: Whether the field should be validated during initialization\n        init_only: Whether the field should be omitted  from `__dict__` and passed to `__post_init__`\n        validation_alias: The alias(es) to use to find the field in the validation data\n        serialization_alias: The alias to use as a key when serializing\n        serialization_exclude: Whether to exclude the field when serializing\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        frozen: Whether the field is frozen\n    \"\"\"\n    return _dict_not_none(\n        type='dataclass-field',\n        name=name,\n        schema=schema,\n        kw_only=kw_only,\n        init=init,\n        init_only=init_only,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        serialization_exclude=serialization_exclude,\n        metadata=metadata,\n        frozen=frozen,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.dataclass_args_schema","title":"dataclass_args_schema","text":"<pre><code>dataclass_args_schema(\n    dataclass_name: str,\n    fields: list[DataclassField],\n    *,\n    computed_fields: List[ComputedField] | None = None,\n    populate_by_name: bool | None = None,\n    collect_init_only: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None\n) -&gt; DataclassArgsSchema\n</code></pre> <p>Returns a schema for validating dataclass arguments, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nfield_a = core_schema.dataclass_field(\n    name='a', schema=core_schema.str_schema(), kw_only=False\n)\nfield_b = core_schema.dataclass_field(\n    name='b', schema=core_schema.bool_schema(), kw_only=False\n)\nschema = core_schema.dataclass_args_schema('Foobar', [field_a, field_b])\nv = SchemaValidator(schema)\nassert v.validate_python({'a': 'hello', 'b': True}) == ({'a': 'hello', 'b': True}, None)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>dataclass_name</code> <code>str</code> <p>The name of the dataclass being validated</p> required <code>fields</code> <code>list[DataclassField]</code> <p>The fields to use for the dataclass</p> required <code>computed_fields</code> <code>List[ComputedField] | None</code> <p>Computed fields to use when serializing the dataclass</p> <code>None</code> <code>populate_by_name</code> <code>bool | None</code> <p>Whether to populate by name</p> <code>None</code> <code>collect_init_only</code> <code>bool | None</code> <p>Whether to collect init only fields into a dict to pass to <code>__post_init__</code></p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> <code>extra_behavior</code> <code>ExtraBehavior | None</code> <p>How to handle extra fields</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def dataclass_args_schema(\n    dataclass_name: str,\n    fields: list[DataclassField],\n    *,\n    computed_fields: List[ComputedField] | None = None,\n    populate_by_name: bool | None = None,\n    collect_init_only: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n    extra_behavior: ExtraBehavior | None = None,\n) -&gt; DataclassArgsSchema:\n    \"\"\"\n    Returns a schema for validating dataclass arguments, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    field_a = core_schema.dataclass_field(\n        name='a', schema=core_schema.str_schema(), kw_only=False\n    )\n    field_b = core_schema.dataclass_field(\n        name='b', schema=core_schema.bool_schema(), kw_only=False\n    )\n    schema = core_schema.dataclass_args_schema('Foobar', [field_a, field_b])\n    v = SchemaValidator(schema)\n    assert v.validate_python({'a': 'hello', 'b': True}) == ({'a': 'hello', 'b': True}, None)\n    ```\n\n    Args:\n        dataclass_name: The name of the dataclass being validated\n        fields: The fields to use for the dataclass\n        computed_fields: Computed fields to use when serializing the dataclass\n        populate_by_name: Whether to populate by name\n        collect_init_only: Whether to collect init only fields into a dict to pass to `__post_init__`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n        extra_behavior: How to handle extra fields\n    \"\"\"\n    return _dict_not_none(\n        type='dataclass-args',\n        dataclass_name=dataclass_name,\n        fields=fields,\n        computed_fields=computed_fields,\n        populate_by_name=populate_by_name,\n        collect_init_only=collect_init_only,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        extra_behavior=extra_behavior,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.dataclass_schema","title":"dataclass_schema","text":"<pre><code>dataclass_schema(\n    cls: Type[Any],\n    schema: CoreSchema,\n    fields: List[str],\n    *,\n    cls_name: str | None = None,\n    post_init: bool | None = None,\n    revalidate_instances: (\n        Literal[\"always\", \"never\", \"subclass-instances\"]\n        | None\n    ) = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n    frozen: bool | None = None,\n    slots: bool | None = None,\n    config: CoreConfig | None = None\n) -&gt; DataclassSchema\n</code></pre> <p>Returns a schema for a dataclass. As with <code>ModelSchema</code>, this schema can only be used as a field within another schema, not as the root type.</p> <p>Parameters:</p> Name Type Description Default <code>cls</code> <code>Type[Any]</code> <p>The dataclass type, used to perform subclass checks</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the dataclass fields</p> required <code>fields</code> <code>List[str]</code> <p>Fields of the dataclass, this is used in serialization and in validation during re-validation and while validating assignment</p> required <code>cls_name</code> <code>str | None</code> <p>The name to use in error locs, etc; this is useful for generics (default: <code>cls.__name__</code>)</p> <code>None</code> <code>post_init</code> <code>bool | None</code> <p>Whether to call <code>__post_init__</code> after validation</p> <code>None</code> <code>revalidate_instances</code> <code>Literal['always', 'never', 'subclass-instances'] | None</code> <p>whether instances of models and dataclasses (including subclass instances) should re-validate defaults to config.revalidate_instances, else 'never'</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to require an exact instance of <code>cls</code></p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> <code>frozen</code> <code>bool | None</code> <p>Whether the dataclass is frozen</p> <code>None</code> <code>slots</code> <code>bool | None</code> <p>Whether <code>slots=True</code> on the dataclass, means each field is assigned independently, rather than simply setting <code>__dict__</code>, default false</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def dataclass_schema(\n    cls: Type[Any],\n    schema: CoreSchema,\n    fields: List[str],\n    *,\n    cls_name: str | None = None,\n    post_init: bool | None = None,\n    revalidate_instances: Literal['always', 'never', 'subclass-instances'] | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n    frozen: bool | None = None,\n    slots: bool | None = None,\n    config: CoreConfig | None = None,\n) -&gt; DataclassSchema:\n    \"\"\"\n    Returns a schema for a dataclass. As with `ModelSchema`, this schema can only be used as a field within\n    another schema, not as the root type.\n\n    Args:\n        cls: The dataclass type, used to perform subclass checks\n        schema: The schema to use for the dataclass fields\n        fields: Fields of the dataclass, this is used in serialization and in validation during re-validation\n            and while validating assignment\n        cls_name: The name to use in error locs, etc; this is useful for generics (default: `cls.__name__`)\n        post_init: Whether to call `__post_init__` after validation\n        revalidate_instances: whether instances of models and dataclasses (including subclass instances)\n            should re-validate defaults to config.revalidate_instances, else 'never'\n        strict: Whether to require an exact instance of `cls`\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n        frozen: Whether the dataclass is frozen\n        slots: Whether `slots=True` on the dataclass, means each field is assigned independently, rather than\n            simply setting `__dict__`, default false\n    \"\"\"\n    return _dict_not_none(\n        type='dataclass',\n        cls=cls,\n        fields=fields,\n        cls_name=cls_name,\n        schema=schema,\n        post_init=post_init,\n        revalidate_instances=revalidate_instances,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n        frozen=frozen,\n        slots=slots,\n        config=config,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.arguments_parameter","title":"arguments_parameter","text":"<pre><code>arguments_parameter(\n    name: str,\n    schema: CoreSchema,\n    *,\n    mode: (\n        Literal[\n            \"positional_only\",\n            \"positional_or_keyword\",\n            \"keyword_only\",\n        ]\n        | None\n    ) = None,\n    alias: (\n        str | list[str | int] | list[list[str | int]] | None\n    ) = None\n) -&gt; ArgumentsParameter\n</code></pre> <p>Returns a schema that matches an argument parameter, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nparam = core_schema.arguments_parameter(\n    name='a', schema=core_schema.str_schema(), mode='positional_only'\n)\nschema = core_schema.arguments_schema([param])\nv = SchemaValidator(schema)\nassert v.validate_python(('hello',)) == (('hello',), {})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name to use for the argument parameter</p> required <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the argument parameter</p> required <code>mode</code> <code>Literal['positional_only', 'positional_or_keyword', 'keyword_only'] | None</code> <p>The mode to use for the argument parameter</p> <code>None</code> <code>alias</code> <code>str | list[str | int] | list[list[str | int]] | None</code> <p>The alias to use for the argument parameter</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def arguments_parameter(\n    name: str,\n    schema: CoreSchema,\n    *,\n    mode: Literal['positional_only', 'positional_or_keyword', 'keyword_only'] | None = None,\n    alias: str | list[str | int] | list[list[str | int]] | None = None,\n) -&gt; ArgumentsParameter:\n    \"\"\"\n    Returns a schema that matches an argument parameter, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    schema = core_schema.arguments_schema([param])\n    v = SchemaValidator(schema)\n    assert v.validate_python(('hello',)) == (('hello',), {})\n    ```\n\n    Args:\n        name: The name to use for the argument parameter\n        schema: The schema to use for the argument parameter\n        mode: The mode to use for the argument parameter\n        alias: The alias to use for the argument parameter\n    \"\"\"\n    return _dict_not_none(name=name, schema=schema, mode=mode, alias=alias)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.arguments_schema","title":"arguments_schema","text":"<pre><code>arguments_schema(\n    arguments: list[ArgumentsParameter],\n    *,\n    populate_by_name: bool | None = None,\n    var_args_schema: CoreSchema | None = None,\n    var_kwargs_schema: CoreSchema | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; ArgumentsSchema\n</code></pre> <p>Returns a schema that matches an arguments schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nparam_a = core_schema.arguments_parameter(\n    name='a', schema=core_schema.str_schema(), mode='positional_only'\n)\nparam_b = core_schema.arguments_parameter(\n    name='b', schema=core_schema.bool_schema(), mode='positional_only'\n)\nschema = core_schema.arguments_schema([param_a, param_b])\nv = SchemaValidator(schema)\nassert v.validate_python(('hello', True)) == (('hello', True), {})\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>arguments</code> <code>list[ArgumentsParameter]</code> <p>The arguments to use for the arguments schema</p> required <code>populate_by_name</code> <code>bool | None</code> <p>Whether to populate by name</p> <code>None</code> <code>var_args_schema</code> <code>CoreSchema | None</code> <p>The variable args schema to use for the arguments schema</p> <code>None</code> <code>var_kwargs_schema</code> <code>CoreSchema | None</code> <p>The variable kwargs schema to use for the arguments schema</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def arguments_schema(\n    arguments: list[ArgumentsParameter],\n    *,\n    populate_by_name: bool | None = None,\n    var_args_schema: CoreSchema | None = None,\n    var_kwargs_schema: CoreSchema | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; ArgumentsSchema:\n    \"\"\"\n    Returns a schema that matches an arguments schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param_a = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    param_b = core_schema.arguments_parameter(\n        name='b', schema=core_schema.bool_schema(), mode='positional_only'\n    )\n    schema = core_schema.arguments_schema([param_a, param_b])\n    v = SchemaValidator(schema)\n    assert v.validate_python(('hello', True)) == (('hello', True), {})\n    ```\n\n    Args:\n        arguments: The arguments to use for the arguments schema\n        populate_by_name: Whether to populate by name\n        var_args_schema: The variable args schema to use for the arguments schema\n        var_kwargs_schema: The variable kwargs schema to use for the arguments schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='arguments',\n        arguments_schema=arguments,\n        populate_by_name=populate_by_name,\n        var_args_schema=var_args_schema,\n        var_kwargs_schema=var_kwargs_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.call_schema","title":"call_schema","text":"<pre><code>call_schema(\n    arguments: CoreSchema,\n    function: Callable[..., Any],\n    *,\n    function_name: str | None = None,\n    return_schema: CoreSchema | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; CallSchema\n</code></pre> <p>Returns a schema that matches an arguments schema, then calls a function, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nparam_a = core_schema.arguments_parameter(\n    name='a', schema=core_schema.str_schema(), mode='positional_only'\n)\nparam_b = core_schema.arguments_parameter(\n    name='b', schema=core_schema.bool_schema(), mode='positional_only'\n)\nargs_schema = core_schema.arguments_schema([param_a, param_b])\n\nschema = core_schema.call_schema(\n    arguments=args_schema,\n    function=lambda a, b: a + str(not b),\n    return_schema=core_schema.str_schema(),\n)\nv = SchemaValidator(schema)\nassert v.validate_python((('hello', True))) == 'helloFalse'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>arguments</code> <code>CoreSchema</code> <p>The arguments to use for the arguments schema</p> required <code>function</code> <code>Callable[..., Any]</code> <p>The function to use for the call schema</p> required <code>function_name</code> <code>str | None</code> <p>The function name to use for the call schema, if not provided <code>function.__name__</code> is used</p> <code>None</code> <code>return_schema</code> <code>CoreSchema | None</code> <p>The return schema to use for the call schema</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def call_schema(\n    arguments: CoreSchema,\n    function: Callable[..., Any],\n    *,\n    function_name: str | None = None,\n    return_schema: CoreSchema | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; CallSchema:\n    \"\"\"\n    Returns a schema that matches an arguments schema, then calls a function, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    param_a = core_schema.arguments_parameter(\n        name='a', schema=core_schema.str_schema(), mode='positional_only'\n    )\n    param_b = core_schema.arguments_parameter(\n        name='b', schema=core_schema.bool_schema(), mode='positional_only'\n    )\n    args_schema = core_schema.arguments_schema([param_a, param_b])\n\n    schema = core_schema.call_schema(\n        arguments=args_schema,\n        function=lambda a, b: a + str(not b),\n        return_schema=core_schema.str_schema(),\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python((('hello', True))) == 'helloFalse'\n    ```\n\n    Args:\n        arguments: The arguments to use for the arguments schema\n        function: The function to use for the call schema\n        function_name: The function name to use for the call schema, if not provided `function.__name__` is used\n        return_schema: The return schema to use for the call schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='call',\n        arguments_schema=arguments,\n        function=function,\n        function_name=function_name,\n        return_schema=return_schema,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.custom_error_schema","title":"custom_error_schema","text":"<pre><code>custom_error_schema(\n    schema: CoreSchema,\n    custom_error_type: str,\n    *,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, Any] | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; CustomErrorSchema\n</code></pre> <p>Returns a schema that matches a custom error value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.custom_error_schema(\n    schema=core_schema.int_schema(),\n    custom_error_type='MyError',\n    custom_error_message='Error msg',\n)\nv = SchemaValidator(schema)\nv.validate_python(1)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The schema to use for the custom error schema</p> required <code>custom_error_type</code> <code>str</code> <p>The custom error type to use for the custom error schema</p> required <code>custom_error_message</code> <code>str | None</code> <p>The custom error message to use for the custom error schema</p> <code>None</code> <code>custom_error_context</code> <code>dict[str, Any] | None</code> <p>The custom error context to use for the custom error schema</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def custom_error_schema(\n    schema: CoreSchema,\n    custom_error_type: str,\n    *,\n    custom_error_message: str | None = None,\n    custom_error_context: dict[str, Any] | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; CustomErrorSchema:\n    \"\"\"\n    Returns a schema that matches a custom error value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.custom_error_schema(\n        schema=core_schema.int_schema(),\n        custom_error_type='MyError',\n        custom_error_message='Error msg',\n    )\n    v = SchemaValidator(schema)\n    v.validate_python(1)\n    ```\n\n    Args:\n        schema: The schema to use for the custom error schema\n        custom_error_type: The custom error type to use for the custom error schema\n        custom_error_message: The custom error message to use for the custom error schema\n        custom_error_context: The custom error context to use for the custom error schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='custom-error',\n        schema=schema,\n        custom_error_type=custom_error_type,\n        custom_error_message=custom_error_message,\n        custom_error_context=custom_error_context,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.json_schema","title":"json_schema","text":"<pre><code>json_schema(\n    schema: CoreSchema | None = None,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; JsonSchema\n</code></pre> <p>Returns a schema that matches a JSON value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\ndict_schema = core_schema.model_fields_schema(\n    {\n        'field_a': core_schema.model_field(core_schema.str_schema()),\n        'field_b': core_schema.model_field(core_schema.bool_schema()),\n    },\n)\n\nclass MyModel:\n    __slots__ = (\n        '__dict__',\n        '__pydantic_fields_set__',\n        '__pydantic_extra__',\n        '__pydantic_private__',\n    )\n    field_a: str\n    field_b: bool\n\njson_schema = core_schema.json_schema(schema=dict_schema)\nschema = core_schema.model_schema(cls=MyModel, schema=json_schema)\nv = SchemaValidator(schema)\nm = v.validate_python('{\"field_a\": \"hello\", \"field_b\": true}')\nassert isinstance(m, MyModel)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema | None</code> <p>The schema to use for the JSON schema</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def json_schema(\n    schema: CoreSchema | None = None,\n    *,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; JsonSchema:\n    \"\"\"\n    Returns a schema that matches a JSON value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    dict_schema = core_schema.model_fields_schema(\n        {\n            'field_a': core_schema.model_field(core_schema.str_schema()),\n            'field_b': core_schema.model_field(core_schema.bool_schema()),\n        },\n    )\n\n    class MyModel:\n        __slots__ = (\n            '__dict__',\n            '__pydantic_fields_set__',\n            '__pydantic_extra__',\n            '__pydantic_private__',\n        )\n        field_a: str\n        field_b: bool\n\n    json_schema = core_schema.json_schema(schema=dict_schema)\n    schema = core_schema.model_schema(cls=MyModel, schema=json_schema)\n    v = SchemaValidator(schema)\n    m = v.validate_python('{\"field_a\": \"hello\", \"field_b\": true}')\n    assert isinstance(m, MyModel)\n    ```\n\n    Args:\n        schema: The schema to use for the JSON schema\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(type='json', schema=schema, ref=ref, metadata=metadata, serialization=serialization)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.url_schema","title":"url_schema","text":"<pre><code>url_schema(\n    *,\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; UrlSchema\n</code></pre> <p>Returns a schema that matches a URL value, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.url_schema()\nv = SchemaValidator(schema)\nprint(v.validate_python('https://example.com'))\n#&gt; https://example.com/\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>max_length</code> <code>int | None</code> <p>The maximum length of the URL</p> <code>None</code> <code>allowed_schemes</code> <code>list[str] | None</code> <p>The allowed URL schemes</p> <code>None</code> <code>host_required</code> <code>bool | None</code> <p>Whether the URL must have a host</p> <code>None</code> <code>default_host</code> <code>str | None</code> <p>The default host to use if the URL does not have a host</p> <code>None</code> <code>default_port</code> <code>int | None</code> <p>The default port to use if the URL does not have a port</p> <code>None</code> <code>default_path</code> <code>str | None</code> <p>The default path to use if the URL does not have a path</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to use strict URL parsing</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def url_schema(\n    *,\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; UrlSchema:\n    \"\"\"\n    Returns a schema that matches a URL value, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.url_schema()\n    v = SchemaValidator(schema)\n    print(v.validate_python('https://example.com'))\n    #&gt; https://example.com/\n    ```\n\n    Args:\n        max_length: The maximum length of the URL\n        allowed_schemes: The allowed URL schemes\n        host_required: Whether the URL must have a host\n        default_host: The default host to use if the URL does not have a host\n        default_port: The default port to use if the URL does not have a port\n        default_path: The default path to use if the URL does not have a path\n        strict: Whether to use strict URL parsing\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='url',\n        max_length=max_length,\n        allowed_schemes=allowed_schemes,\n        host_required=host_required,\n        default_host=default_host,\n        default_port=default_port,\n        default_path=default_path,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.multi_host_url_schema","title":"multi_host_url_schema","text":"<pre><code>multi_host_url_schema(\n    *,\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None\n) -&gt; MultiHostUrlSchema\n</code></pre> <p>Returns a schema that matches a URL value with possibly multiple hosts, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.multi_host_url_schema()\nv = SchemaValidator(schema)\nprint(v.validate_python('redis://localhost,0.0.0.0,127.0.0.1'))\n#&gt; redis://localhost,0.0.0.0,127.0.0.1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>max_length</code> <code>int | None</code> <p>The maximum length of the URL</p> <code>None</code> <code>allowed_schemes</code> <code>list[str] | None</code> <p>The allowed URL schemes</p> <code>None</code> <code>host_required</code> <code>bool | None</code> <p>Whether the URL must have a host</p> <code>None</code> <code>default_host</code> <code>str | None</code> <p>The default host to use if the URL does not have a host</p> <code>None</code> <code>default_port</code> <code>int | None</code> <p>The default port to use if the URL does not have a port</p> <code>None</code> <code>default_path</code> <code>str | None</code> <p>The default path to use if the URL does not have a path</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to use strict URL parsing</p> <code>None</code> <code>ref</code> <code>str | None</code> <p>optional unique identifier of the schema, used to reference the schema in other places</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def multi_host_url_schema(\n    *,\n    max_length: int | None = None,\n    allowed_schemes: list[str] | None = None,\n    host_required: bool | None = None,\n    default_host: str | None = None,\n    default_port: int | None = None,\n    default_path: str | None = None,\n    strict: bool | None = None,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; MultiHostUrlSchema:\n    \"\"\"\n    Returns a schema that matches a URL value with possibly multiple hosts, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.multi_host_url_schema()\n    v = SchemaValidator(schema)\n    print(v.validate_python('redis://localhost,0.0.0.0,127.0.0.1'))\n    #&gt; redis://localhost,0.0.0.0,127.0.0.1\n    ```\n\n    Args:\n        max_length: The maximum length of the URL\n        allowed_schemes: The allowed URL schemes\n        host_required: Whether the URL must have a host\n        default_host: The default host to use if the URL does not have a host\n        default_port: The default port to use if the URL does not have a port\n        default_path: The default path to use if the URL does not have a path\n        strict: Whether to use strict URL parsing\n        ref: optional unique identifier of the schema, used to reference the schema in other places\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='multi-host-url',\n        max_length=max_length,\n        allowed_schemes=allowed_schemes,\n        host_required=host_required,\n        default_host=default_host,\n        default_port=default_port,\n        default_path=default_path,\n        strict=strict,\n        ref=ref,\n        metadata=metadata,\n        serialization=serialization,\n    )\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.definitions_schema","title":"definitions_schema","text":"<pre><code>definitions_schema(\n    schema: CoreSchema, definitions: list[CoreSchema]\n) -&gt; DefinitionsSchema\n</code></pre> <p>Build a schema that contains both an inner schema and a list of definitions which can be used within the inner schema.</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema = core_schema.definitions_schema(\n    core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n    [core_schema.int_schema(ref='foobar')],\n)\nv = SchemaValidator(schema)\nassert v.validate_python([1, 2, '3']) == [1, 2, 3]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>CoreSchema</code> <p>The inner schema</p> required <code>definitions</code> <code>list[CoreSchema]</code> <p>List of definitions which can be referenced within inner schema</p> required Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def definitions_schema(schema: CoreSchema, definitions: list[CoreSchema]) -&gt; DefinitionsSchema:\n    \"\"\"\n    Build a schema that contains both an inner schema and a list of definitions which can be used\n    within the inner schema.\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema = core_schema.definitions_schema(\n        core_schema.list_schema(core_schema.definition_reference_schema('foobar')),\n        [core_schema.int_schema(ref='foobar')],\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python([1, 2, '3']) == [1, 2, 3]\n    ```\n\n    Args:\n        schema: The inner schema\n        definitions: List of definitions which can be referenced within inner schema\n    \"\"\"\n    return DefinitionsSchema(type='definitions', schema=schema, definitions=definitions)\n</code></pre>"},{"location":"api/pydantic_core_schema/#pydantic_core.core_schema.definition_reference_schema","title":"definition_reference_schema","text":"<pre><code>definition_reference_schema(\n    schema_ref: str,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; DefinitionReferenceSchema\n</code></pre> <p>Returns a schema that points to a schema stored in \"definitions\", this is useful for nested recursive models and also when you want to define validators separately from the main schema, e.g.:</p> <pre><code>from pydantic_core import SchemaValidator, core_schema\n\nschema_definition = core_schema.definition_reference_schema('list-schema')\nschema = core_schema.definitions_schema(\n    schema=schema_definition,\n    definitions=[\n        core_schema.list_schema(items_schema=schema_definition, ref='list-schema'),\n    ],\n)\nv = SchemaValidator(schema)\nassert v.validate_python([()]) == [[]]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>schema_ref</code> <code>str</code> <p>The schema ref to use for the definition reference schema</p> required <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Any other information you want to include with the schema, not used by pydantic-core</p> <code>None</code> <code>serialization</code> <code>SerSchema | None</code> <p>Custom serialization schema</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_core/core_schema.py</code> <pre><code>def definition_reference_schema(\n    schema_ref: str,\n    ref: str | None = None,\n    metadata: Dict[str, Any] | None = None,\n    serialization: SerSchema | None = None,\n) -&gt; DefinitionReferenceSchema:\n    \"\"\"\n    Returns a schema that points to a schema stored in \"definitions\", this is useful for nested recursive\n    models and also when you want to define validators separately from the main schema, e.g.:\n\n    ```py\n    from pydantic_core import SchemaValidator, core_schema\n\n    schema_definition = core_schema.definition_reference_schema('list-schema')\n    schema = core_schema.definitions_schema(\n        schema=schema_definition,\n        definitions=[\n            core_schema.list_schema(items_schema=schema_definition, ref='list-schema'),\n        ],\n    )\n    v = SchemaValidator(schema)\n    assert v.validate_python([()]) == [[]]\n    ```\n\n    Args:\n        schema_ref: The schema ref to use for the definition reference schema\n        metadata: Any other information you want to include with the schema, not used by pydantic-core\n        serialization: Custom serialization schema\n    \"\"\"\n    return _dict_not_none(\n        type='definition-ref', schema_ref=schema_ref, ref=ref, metadata=metadata, serialization=serialization\n    )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/","title":"Color","text":"<p>Color definitions are used as per the CSS3 CSS Color Module Level 3 specification.</p> <p>A few colors have multiple names referring to the sames colors, eg. <code>grey</code> and <code>gray</code> or <code>aqua</code> and <code>cyan</code>.</p> <p>In these cases the last color when sorted alphabetically takes preferences, eg. <code>Color((0, 255, 255)).as_named() == 'cyan'</code> because \"cyan\" comes after \"aqua\".</p>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.RGBA","title":"RGBA","text":"<pre><code>RGBA(r: float, g: float, b: float, alpha: float | None)\n</code></pre> <p>Internal use only as a representation of a color.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def __init__(self, r: float, g: float, b: float, alpha: float | None):\n    self.r = r\n    self.g = g\n    self.b = b\n    self.alpha = alpha\n\n    self._tuple: tuple[float, float, float, float | None] = (r, g, b, alpha)\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color","title":"Color","text":"<pre><code>Color(value: ColorType)\n</code></pre> <p>               Bases: <code>Representation</code></p> <p>Represents a color.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def __init__(self, value: ColorType) -&gt; None:\n    self._rgba: RGBA\n    self._original: ColorType\n    if isinstance(value, (tuple, list)):\n        self._rgba = parse_tuple(value)\n    elif isinstance(value, str):\n        self._rgba = parse_str(value)\n    elif isinstance(value, Color):\n        self._rgba = value._rgba\n        value = value._original\n    else:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: value must be a tuple, list or string',\n        )\n\n    # if we've got here value must be a valid color\n    self._original = value\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.original","title":"original","text":"<pre><code>original() -&gt; ColorType\n</code></pre> <p>Original value passed to <code>Color</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def original(self) -&gt; ColorType:\n    \"\"\"\n    Original value passed to `Color`.\n    \"\"\"\n    return self._original\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_named","title":"as_named","text":"<pre><code>as_named(*, fallback: bool = False) -&gt; str\n</code></pre> <p>Returns the name of the color if it can be found in <code>COLORS_BY_VALUE</code> dictionary, otherwise returns the hexadecimal representation of the color or raises <code>ValueError</code>.</p> <p>Parameters:</p> Name Type Description Default <code>fallback</code> <code>bool</code> <p>If True, falls back to returning the hexadecimal representation of the color instead of raising a ValueError when no named color is found.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The name of the color, or the hexadecimal representation of the color.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When no named color is found and fallback is <code>False</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_named(self, *, fallback: bool = False) -&gt; str:\n    \"\"\"\n    Returns the name of the color if it can be found in `COLORS_BY_VALUE` dictionary,\n    otherwise returns the hexadecimal representation of the color or raises `ValueError`.\n\n    Args:\n        fallback: If True, falls back to returning the hexadecimal representation of\n            the color instead of raising a ValueError when no named color is found.\n\n    Returns:\n        The name of the color, or the hexadecimal representation of the color.\n\n    Raises:\n        ValueError: When no named color is found and fallback is `False`.\n    \"\"\"\n    if self._rgba.alpha is not None:\n        return self.as_hex()\n    rgb = cast(Tuple[int, int, int], self.as_rgb_tuple())\n\n    if rgb in COLORS_BY_VALUE:\n        return COLORS_BY_VALUE[rgb]\n    else:\n        if fallback:\n            return self.as_hex()\n        else:\n            raise ValueError('no named color found, use fallback=True, as_hex() or as_rgb()')\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_hex","title":"as_hex","text":"<pre><code>as_hex(format: Literal['short', 'long'] = 'short') -&gt; str\n</code></pre> <p>Returns the hexadecimal representation of the color.</p> <p>Hex string representing the color can be 3, 4, 6, or 8 characters depending on whether the string a \"short\" representation of the color is possible and whether there's an alpha channel.</p> <p>Returns:</p> Type Description <code>str</code> <p>The hexadecimal representation of the color.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_hex(self, format: Literal['short', 'long'] = 'short') -&gt; str:\n    \"\"\"Returns the hexadecimal representation of the color.\n\n    Hex string representing the color can be 3, 4, 6, or 8 characters depending on whether the string\n    a \"short\" representation of the color is possible and whether there's an alpha channel.\n\n    Returns:\n        The hexadecimal representation of the color.\n    \"\"\"\n    values = [float_to_255(c) for c in self._rgba[:3]]\n    if self._rgba.alpha is not None:\n        values.append(float_to_255(self._rgba.alpha))\n\n    as_hex = ''.join(f'{v:02x}' for v in values)\n    if format == 'short' and all(c in repeat_colors for c in values):\n        as_hex = ''.join(as_hex[c] for c in range(0, len(as_hex), 2))\n    return f'#{as_hex}'\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_rgb","title":"as_rgb","text":"<pre><code>as_rgb() -&gt; str\n</code></pre> <p>Color as an <code>rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)</code> or <code>rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)</code> string.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_rgb(self) -&gt; str:\n    \"\"\"\n    Color as an `rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)` or `rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)` string.\n    \"\"\"\n    if self._rgba.alpha is None:\n        return f'rgb({float_to_255(self._rgba.r)}, {float_to_255(self._rgba.g)}, {float_to_255(self._rgba.b)})'\n    else:\n        return (\n            f'rgba({float_to_255(self._rgba.r)}, {float_to_255(self._rgba.g)}, {float_to_255(self._rgba.b)}, '\n            f'{round(self._alpha_float(), 2)})'\n        )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_rgb_tuple","title":"as_rgb_tuple","text":"<pre><code>as_rgb_tuple(*, alpha: bool | None = None) -&gt; ColorTuple\n</code></pre> <p>Returns the color as an RGB or RGBA tuple.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>bool | None</code> <p>Whether to include the alpha channel. There are three options for this input:</p> <ul> <li><code>None</code> (default): Include alpha only if it's set. (e.g. not <code>None</code>)</li> <li><code>True</code>: Always include alpha.</li> <li><code>False</code>: Always omit alpha.</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>ColorTuple</code> <p>A tuple that contains the values of the red, green, and blue channels in the range 0 to 255. If alpha is included, it is in the range 0 to 1.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_rgb_tuple(self, *, alpha: bool | None = None) -&gt; ColorTuple:\n    \"\"\"\n    Returns the color as an RGB or RGBA tuple.\n\n    Args:\n        alpha: Whether to include the alpha channel. There are three options for this input:\n\n            - `None` (default): Include alpha only if it's set. (e.g. not `None`)\n            - `True`: Always include alpha.\n            - `False`: Always omit alpha.\n\n    Returns:\n        A tuple that contains the values of the red, green, and blue channels in the range 0 to 255.\n            If alpha is included, it is in the range 0 to 1.\n    \"\"\"\n    r, g, b = (float_to_255(c) for c in self._rgba[:3])\n    if alpha is None and self._rgba.alpha is None or alpha is not None and not alpha:\n        return r, g, b\n    else:\n        return r, g, b, self._alpha_float()\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_hsl","title":"as_hsl","text":"<pre><code>as_hsl() -&gt; str\n</code></pre> <p>Color as an <code>hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;)</code> or <code>hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;, &lt;a&gt;)</code> string.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_hsl(self) -&gt; str:\n    \"\"\"\n    Color as an `hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;)` or `hsl(&lt;h&gt;, &lt;s&gt;, &lt;l&gt;, &lt;a&gt;)` string.\n    \"\"\"\n    if self._rgba.alpha is None:\n        h, s, li = self.as_hsl_tuple(alpha=False)  # type: ignore\n        return f'hsl({h * 360:0.0f}, {s:0.0%}, {li:0.0%})'\n    else:\n        h, s, li, a = self.as_hsl_tuple(alpha=True)  # type: ignore\n        return f'hsl({h * 360:0.0f}, {s:0.0%}, {li:0.0%}, {round(a, 2)})'\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.Color.as_hsl_tuple","title":"as_hsl_tuple","text":"<pre><code>as_hsl_tuple(*, alpha: bool | None = None) -&gt; HslColorTuple\n</code></pre> <p>Returns the color as an HSL or HSLA tuple.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>bool | None</code> <p>Whether to include the alpha channel.</p> <ul> <li><code>None</code> (default): Include the alpha channel only if it's set (e.g. not <code>None</code>).</li> <li><code>True</code>: Always include alpha.</li> <li><code>False</code>: Always omit alpha.</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>HslColorTuple</code> <p>The color as a tuple of hue, saturation, lightness, and alpha (if included). All elements are in the range 0 to 1.</p> Note <p>This is HSL as used in HTML and most other places, not HLS as used in Python's <code>colorsys</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def as_hsl_tuple(self, *, alpha: bool | None = None) -&gt; HslColorTuple:\n    \"\"\"\n    Returns the color as an HSL or HSLA tuple.\n\n    Args:\n        alpha: Whether to include the alpha channel.\n\n            - `None` (default): Include the alpha channel only if it's set (e.g. not `None`).\n            - `True`: Always include alpha.\n            - `False`: Always omit alpha.\n\n    Returns:\n        The color as a tuple of hue, saturation, lightness, and alpha (if included).\n            All elements are in the range 0 to 1.\n\n    Note:\n        This is HSL as used in HTML and most other places, not HLS as used in Python's `colorsys`.\n    \"\"\"\n    h, l, s = rgb_to_hls(self._rgba.r, self._rgba.g, self._rgba.b)\n    if alpha is None:\n        if self._rgba.alpha is None:\n            return h, s, l\n        else:\n            return h, s, l, self._alpha_float()\n    return (h, s, l, self._alpha_float()) if alpha else (h, s, l)\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_tuple","title":"parse_tuple","text":"<pre><code>parse_tuple(value: tuple[Any, ...]) -&gt; RGBA\n</code></pre> <p>Parse a tuple or list to get RGBA values.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>tuple[Any, ...]</code> <p>A tuple or list.</p> required <p>Returns:</p> Type Description <code>RGBA</code> <p>An <code>RGBA</code> tuple parsed from the input tuple.</p> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If tuple is not valid.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_tuple(value: tuple[Any, ...]) -&gt; RGBA:\n    \"\"\"Parse a tuple or list to get RGBA values.\n\n    Args:\n        value: A tuple or list.\n\n    Returns:\n        An `RGBA` tuple parsed from the input tuple.\n\n    Raises:\n        PydanticCustomError: If tuple is not valid.\n    \"\"\"\n    if len(value) == 3:\n        r, g, b = (parse_color_value(v) for v in value)\n        return RGBA(r, g, b, None)\n    elif len(value) == 4:\n        r, g, b = (parse_color_value(v) for v in value[:3])\n        return RGBA(r, g, b, parse_float_alpha(value[3]))\n    else:\n        raise PydanticCustomError('color_error', 'value is not a valid color: tuples must have length 3 or 4')\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_str","title":"parse_str","text":"<pre><code>parse_str(value: str) -&gt; RGBA\n</code></pre> <p>Parse a string representing a color to an RGBA tuple.</p> <p>Possible formats for the input string include:</p> <ul> <li>named color, see <code>COLORS_BY_NAME</code></li> <li>hex short eg. <code>&lt;prefix&gt;fff</code> (prefix can be <code>#</code>, <code>0x</code> or nothing)</li> <li>hex long eg. <code>&lt;prefix&gt;ffffff</code> (prefix can be <code>#</code>, <code>0x</code> or nothing)</li> <li><code>rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)</code></li> <li><code>rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)</code></li> <li><code>transparent</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>A string representing a color.</p> required <p>Returns:</p> Type Description <code>RGBA</code> <p>An <code>RGBA</code> tuple parsed from the input string.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input string cannot be parsed to an RGBA tuple.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_str(value: str) -&gt; RGBA:\n    \"\"\"\n    Parse a string representing a color to an RGBA tuple.\n\n    Possible formats for the input string include:\n\n    * named color, see `COLORS_BY_NAME`\n    * hex short eg. `&lt;prefix&gt;fff` (prefix can be `#`, `0x` or nothing)\n    * hex long eg. `&lt;prefix&gt;ffffff` (prefix can be `#`, `0x` or nothing)\n    * `rgb(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;)`\n    * `rgba(&lt;r&gt;, &lt;g&gt;, &lt;b&gt;, &lt;a&gt;)`\n    * `transparent`\n\n    Args:\n        value: A string representing a color.\n\n    Returns:\n        An `RGBA` tuple parsed from the input string.\n\n    Raises:\n        ValueError: If the input string cannot be parsed to an RGBA tuple.\n    \"\"\"\n\n    value_lower = value.lower()\n    if value_lower in COLORS_BY_NAME:\n        r, g, b = COLORS_BY_NAME[value_lower]\n        return ints_to_rgba(r, g, b, None)\n\n    m = re.fullmatch(r_hex_short, value_lower)\n    if m:\n        *rgb, a = m.groups()\n        r, g, b = (int(v * 2, 16) for v in rgb)\n        alpha = int(a * 2, 16) / 255 if a else None\n        return ints_to_rgba(r, g, b, alpha)\n\n    m = re.fullmatch(r_hex_long, value_lower)\n    if m:\n        *rgb, a = m.groups()\n        r, g, b = (int(v, 16) for v in rgb)\n        alpha = int(a, 16) / 255 if a else None\n        return ints_to_rgba(r, g, b, alpha)\n\n    m = re.fullmatch(r_rgb, value_lower) or re.fullmatch(r_rgb_v4_style, value_lower)\n    if m:\n        return ints_to_rgba(*m.groups())  # type: ignore\n\n    m = re.fullmatch(r_hsl, value_lower) or re.fullmatch(r_hsl_v4_style, value_lower)\n    if m:\n        return parse_hsl(*m.groups())  # type: ignore\n\n    if value_lower == 'transparent':\n        return RGBA(0, 0, 0, 0)\n\n    raise PydanticCustomError(\n        'color_error',\n        'value is not a valid color: string not recognised as a valid color',\n    )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.ints_to_rgba","title":"ints_to_rgba","text":"<pre><code>ints_to_rgba(\n    r: int | str,\n    g: int | str,\n    b: int | str,\n    alpha: float | None = None,\n) -&gt; RGBA\n</code></pre> <p>Converts integer or string values for RGB color and an optional alpha value to an <code>RGBA</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>int | str</code> <p>An integer or string representing the red color value.</p> required <code>g</code> <code>int | str</code> <p>An integer or string representing the green color value.</p> required <code>b</code> <code>int | str</code> <p>An integer or string representing the blue color value.</p> required <code>alpha</code> <code>float | None</code> <p>A float representing the alpha value. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>RGBA</code> <p>An instance of the <code>RGBA</code> class with the corresponding color and alpha values.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def ints_to_rgba(\n    r: int | str,\n    g: int | str,\n    b: int | str,\n    alpha: float | None = None,\n) -&gt; RGBA:\n    \"\"\"\n    Converts integer or string values for RGB color and an optional alpha value to an `RGBA` object.\n\n    Args:\n        r: An integer or string representing the red color value.\n        g: An integer or string representing the green color value.\n        b: An integer or string representing the blue color value.\n        alpha: A float representing the alpha value. Defaults to None.\n\n    Returns:\n        An instance of the `RGBA` class with the corresponding color and alpha values.\n    \"\"\"\n    return RGBA(\n        parse_color_value(r),\n        parse_color_value(g),\n        parse_color_value(b),\n        parse_float_alpha(alpha),\n    )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_color_value","title":"parse_color_value","text":"<pre><code>parse_color_value(\n    value: int | str, max_val: int = 255\n) -&gt; float\n</code></pre> <p>Parse the color value provided and return a number between 0 and 1.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int | str</code> <p>An integer or string color value.</p> required <code>max_val</code> <code>int</code> <p>Maximum range value. Defaults to 255.</p> <code>255</code> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the value is not a valid color.</p> <p>Returns:</p> Type Description <code>float</code> <p>A number between 0 and 1.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_color_value(value: int | str, max_val: int = 255) -&gt; float:\n    \"\"\"\n    Parse the color value provided and return a number between 0 and 1.\n\n    Args:\n        value: An integer or string color value.\n        max_val: Maximum range value. Defaults to 255.\n\n    Raises:\n        PydanticCustomError: If the value is not a valid color.\n\n    Returns:\n        A number between 0 and 1.\n    \"\"\"\n    try:\n        color = float(value)\n    except ValueError as e:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: color values must be a valid number',\n        ) from e\n    if 0 &lt;= color &lt;= max_val:\n        return color / max_val\n    else:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: color values must be in the range 0 to {max_val}',\n            {'max_val': max_val},\n        )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_float_alpha","title":"parse_float_alpha","text":"<pre><code>parse_float_alpha(\n    value: None | str | float | int,\n) -&gt; float | None\n</code></pre> <p>Parse an alpha value checking it's a valid float in the range 0 to 1.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>None | str | float | int</code> <p>The input value to parse.</p> required <p>Returns:</p> Type Description <code>float | None</code> <p>The parsed value as a float, or <code>None</code> if the value was None or equal 1.</p> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the input value cannot be successfully parsed as a float in the expected range.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_float_alpha(value: None | str | float | int) -&gt; float | None:\n    \"\"\"\n    Parse an alpha value checking it's a valid float in the range 0 to 1.\n\n    Args:\n        value: The input value to parse.\n\n    Returns:\n        The parsed value as a float, or `None` if the value was None or equal 1.\n\n    Raises:\n        PydanticCustomError: If the input value cannot be successfully parsed as a float in the expected range.\n    \"\"\"\n    if value is None:\n        return None\n    try:\n        if isinstance(value, str) and value.endswith('%'):\n            alpha = float(value[:-1]) / 100\n        else:\n            alpha = float(value)\n    except ValueError as e:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: alpha values must be a valid float',\n        ) from e\n\n    if math.isclose(alpha, 1):\n        return None\n    elif 0 &lt;= alpha &lt;= 1:\n        return alpha\n    else:\n        raise PydanticCustomError(\n            'color_error',\n            'value is not a valid color: alpha values must be in the range 0 to 1',\n        )\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.parse_hsl","title":"parse_hsl","text":"<pre><code>parse_hsl(\n    h: str,\n    h_units: str,\n    sat: str,\n    light: str,\n    alpha: float | None = None,\n) -&gt; RGBA\n</code></pre> <p>Parse raw hue, saturation, lightness, and alpha values and convert to RGBA.</p> <p>Parameters:</p> Name Type Description Default <code>h</code> <code>str</code> <p>The hue value.</p> required <code>h_units</code> <code>str</code> <p>The unit for hue value.</p> required <code>sat</code> <code>str</code> <p>The saturation value.</p> required <code>light</code> <code>str</code> <p>The lightness value.</p> required <code>alpha</code> <code>float | None</code> <p>Alpha value.</p> <code>None</code> <p>Returns:</p> Type Description <code>RGBA</code> <p>An instance of <code>RGBA</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def parse_hsl(h: str, h_units: str, sat: str, light: str, alpha: float | None = None) -&gt; RGBA:\n    \"\"\"\n    Parse raw hue, saturation, lightness, and alpha values and convert to RGBA.\n\n    Args:\n        h: The hue value.\n        h_units: The unit for hue value.\n        sat: The saturation value.\n        light: The lightness value.\n        alpha: Alpha value.\n\n    Returns:\n        An instance of `RGBA`.\n    \"\"\"\n    s_value, l_value = parse_color_value(sat, 100), parse_color_value(light, 100)\n\n    h_value = float(h)\n    if h_units in {None, 'deg'}:\n        h_value = h_value % 360 / 360\n    elif h_units == 'rad':\n        h_value = h_value % rads / rads\n    else:\n        # turns\n        h_value %= 1\n\n    r, g, b = hls_to_rgb(h_value, l_value, s_value)\n    return RGBA(r, g, b, parse_float_alpha(alpha))\n</code></pre>"},{"location":"api/pydantic_extra_types_color/#pydantic_extra_types.color.float_to_255","title":"float_to_255","text":"<pre><code>float_to_255(c: float) -&gt; int\n</code></pre> <p>Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive).</p> <p>Parameters:</p> Name Type Description Default <code>c</code> <code>float</code> <p>The float value to be converted. Must be between 0 and 1 (inclusive).</p> required <p>Returns:</p> Type Description <code>int</code> <p>The integer equivalent of the given float value rounded to the nearest whole number.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/color.py</code> <pre><code>def float_to_255(c: float) -&gt; int:\n    \"\"\"\n    Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive).\n\n    Args:\n        c: The float value to be converted. Must be between 0 and 1 (inclusive).\n\n    Returns:\n        The integer equivalent of the given float value rounded to the nearest whole number.\n    \"\"\"\n    return round(c * 255)\n</code></pre>"},{"location":"api/pydantic_extra_types_coordinate/","title":"Coordinate","text":"<p>The <code>pydantic_extra_types.coordinate</code> module provides the <code>Latitude</code>, <code>Longitude</code>, and <code>Coordinate</code> data types.</p>"},{"location":"api/pydantic_extra_types_coordinate/#pydantic_extra_types.coordinate.Latitude","title":"Latitude","text":"<p>               Bases: <code>float</code></p> <p>Latitude value should be between -90 and 90, inclusive.</p> <pre><code>from pydantic import BaseModel\nfrom pydantic_extra_types.coordinate import Latitude\n\nclass Location(BaseModel):\n    latitude: Latitude\n\nlocation = Location(latitude=41.40338)\nprint(location)\n#&gt; latitude=41.40338\n</code></pre>"},{"location":"api/pydantic_extra_types_coordinate/#pydantic_extra_types.coordinate.Longitude","title":"Longitude","text":"<p>               Bases: <code>float</code></p> <p>Longitude value should be between -180 and 180, inclusive.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.coordinate import Longitude\n\nclass Location(BaseModel):\n    longitude: Longitude\n\nlocation = Location(longitude=2.17403)\nprint(location)\n#&gt; longitude=2.17403\n</code></pre>"},{"location":"api/pydantic_extra_types_coordinate/#pydantic_extra_types.coordinate.Coordinate","title":"Coordinate  <code>dataclass</code>","text":"<pre><code>Coordinate(latitude: Latitude, longitude: Longitude)\n</code></pre> <p>               Bases: <code>Representation</code></p> <p>Coordinate parses Latitude and Longitude.</p> <p>You can use the <code>Coordinate</code> data type for storing coordinates. Coordinates can be defined using one of the following formats:</p> <ol> <li>Tuple: <code>(Latitude, Longitude)</code>. For example: <code>(41.40338, 2.17403)</code>.</li> <li><code>Coordinate</code> instance: <code>Coordinate(latitude=Latitude, longitude=Longitude)</code>.</li> </ol> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.coordinate import Coordinate\n\nclass Location(BaseModel):\n    coordinate: Coordinate\n\nlocation = Location(coordinate=(41.40338, 2.17403))\n#&gt; coordinate=Coordinate(latitude=41.40338, longitude=2.17403)\n</code></pre>"},{"location":"api/pydantic_extra_types_country/","title":"Country","text":"<p>Country definitions that are based on the ISO 3166.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryAlpha2","title":"CountryAlpha2","text":"<p>               Bases: <code>str</code></p> <p>CountryAlpha2 parses country codes in the ISO 3166-1 alpha-2 format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.country import CountryAlpha2\n\nclass Product(BaseModel):\n    made_in: CountryAlpha2\n\nproduct = Product(made_in='ES')\nprint(product)\n#&gt; made_in='ES'\n</code></pre>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryAlpha2.alpha3","title":"alpha3  <code>property</code>","text":"<pre><code>alpha3: str\n</code></pre> <p>The country code in the ISO 3166-1 alpha-3 format.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryAlpha2.numeric_code","title":"numeric_code  <code>property</code>","text":"<pre><code>numeric_code: str\n</code></pre> <p>The country code in the ISO 3166-1 numeric format.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryAlpha2.short_name","title":"short_name  <code>property</code>","text":"<pre><code>short_name: str\n</code></pre> <p>The country short name.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryAlpha3","title":"CountryAlpha3","text":"<p>               Bases: <code>str</code></p> <p>CountryAlpha3 parses country codes in the ISO 3166-1 alpha-3 format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.country import CountryAlpha3\n\nclass Product(BaseModel):\n    made_in: CountryAlpha3\n\nproduct = Product(made_in=\"USA\")\nprint(product)\n#&gt; made_in='USA'\n</code></pre>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryAlpha3.alpha2","title":"alpha2  <code>property</code>","text":"<pre><code>alpha2: str\n</code></pre> <p>The country code in the ISO 3166-1 alpha-2 format.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryAlpha3.numeric_code","title":"numeric_code  <code>property</code>","text":"<pre><code>numeric_code: str\n</code></pre> <p>The country code in the ISO 3166-1 numeric format.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryAlpha3.short_name","title":"short_name  <code>property</code>","text":"<pre><code>short_name: str\n</code></pre> <p>The country short name.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryNumericCode","title":"CountryNumericCode","text":"<p>               Bases: <code>str</code></p> <p>CountryNumericCode parses country codes in the ISO 3166-1 numeric format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.country import CountryNumericCode\n\nclass Product(BaseModel):\n    made_in: CountryNumericCode\n\nproduct = Product(made_in=\"840\")\nprint(product)\n#&gt; made_in='840'\n</code></pre>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryNumericCode.alpha2","title":"alpha2  <code>property</code>","text":"<pre><code>alpha2: str\n</code></pre> <p>The country code in the ISO 3166-1 alpha-2 format.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryNumericCode.alpha3","title":"alpha3  <code>property</code>","text":"<pre><code>alpha3: str\n</code></pre> <p>The country code in the ISO 3166-1 alpha-3 format.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryNumericCode.short_name","title":"short_name  <code>property</code>","text":"<pre><code>short_name: str\n</code></pre> <p>The country short name.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryShortName","title":"CountryShortName","text":"<p>               Bases: <code>str</code></p> <p>CountryShortName parses country codes in the short name format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.country import CountryShortName\n\nclass Product(BaseModel):\n    made_in: CountryShortName\n\nproduct = Product(made_in=\"United States\")\nprint(product)\n#&gt; made_in='United States'\n</code></pre>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryShortName.alpha2","title":"alpha2  <code>property</code>","text":"<pre><code>alpha2: str\n</code></pre> <p>The country code in the ISO 3166-1 alpha-2 format.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryShortName.alpha3","title":"alpha3  <code>property</code>","text":"<pre><code>alpha3: str\n</code></pre> <p>The country code in the ISO 3166-1 alpha-3 format.</p>"},{"location":"api/pydantic_extra_types_country/#pydantic_extra_types.country.CountryShortName.numeric_code","title":"numeric_code  <code>property</code>","text":"<pre><code>numeric_code: str\n</code></pre> <p>The country code in the ISO 3166-1 numeric format.</p>"},{"location":"api/pydantic_extra_types_currency_code/","title":"Currency","text":"<p>Currency definitions that are based on the ISO4217.</p>"},{"location":"api/pydantic_extra_types_currency_code/#pydantic_extra_types.currency_code.ISO4217","title":"ISO4217","text":"<p>               Bases: <code>str</code></p> <p>ISO4217 parses Currency in the ISO 4217 format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.currency_code import ISO4217\n\nclass Currency(BaseModel):\n    alpha_3: ISO4217\n\ncurrency = Currency(alpha_3='AED')\nprint(currency)\n# &gt; alpha_3='AED'\n</code></pre>"},{"location":"api/pydantic_extra_types_currency_code/#pydantic_extra_types.currency_code.Currency","title":"Currency","text":"<p>               Bases: <code>str</code></p> <p>Currency parses currency subset of the ISO 4217 format. It excludes bonds testing codes and precious metals.     <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.currency_code import Currency\n\nclass currency(BaseModel):\n    alpha_3: Currency\n\ncur = currency(alpha_3='AED')\nprint(cur)\n# &gt; alpha_3='AED'\n</code></pre></p>"},{"location":"api/pydantic_extra_types_isbn/","title":"ISBN","text":"<p>The <code>pydantic_extra_types.isbn</code> module provides functionality to recieve and validate ISBN.</p> <p>ISBN (International Standard Book Number) is a numeric commercial book identifier which is intended to be unique. This module provides a ISBN type for Pydantic models.</p>"},{"location":"api/pydantic_extra_types_isbn/#pydantic_extra_types.isbn.ISBN","title":"ISBN","text":"<p>               Bases: <code>str</code></p> <p>Represents a ISBN and provides methods for conversion, validation, and serialization.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.isbn import ISBN\n\n\nclass Book(BaseModel):\n    isbn: ISBN\n\nbook = Book(isbn=\"8537809667\")\nprint(book)\n#&gt; isbn='9788537809662'\n</code></pre>"},{"location":"api/pydantic_extra_types_isbn/#pydantic_extra_types.isbn.ISBN.validate_isbn_format","title":"validate_isbn_format  <code>staticmethod</code>","text":"<pre><code>validate_isbn_format(value: str) -&gt; None\n</code></pre> <p>Validate a ISBN format from the provided str value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The str value representing the ISBN in 10 or 13 digits.</p> required <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the ISBN is not valid.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/isbn.py</code> <pre><code>@staticmethod\ndef validate_isbn_format(value: str) -&gt; None:\n    \"\"\"Validate a ISBN format from the provided str value.\n\n    Args:\n        value: The str value representing the ISBN in 10 or 13 digits.\n\n    Raises:\n        PydanticCustomError: If the ISBN is not valid.\n    \"\"\"\n\n    isbn_length = len(value)\n\n    if isbn_length not in (10, 13):\n        raise PydanticCustomError('isbn_length', f'Length for ISBN must be 10 or 13 digits, not {isbn_length}')\n\n    if isbn_length == 10:\n        if not value[:-1].isdigit() or ((value[-1] != 'X') and (not value[-1].isdigit())):\n            raise PydanticCustomError('isbn10_invalid_characters', 'First 9 digits of ISBN-10 must be integers')\n        if isbn10_digit_calc(value) != value[-1]:\n            raise PydanticCustomError('isbn_invalid_digit_check_isbn10', 'Provided digit is invalid for given ISBN')\n\n    if isbn_length == 13:\n        if not value.isdigit():\n            raise PydanticCustomError('isbn13_invalid_characters', 'All digits of ISBN-13 must be integers')\n        if value[:3] not in ('978', '979'):\n            raise PydanticCustomError(\n                'isbn_invalid_early_characters', 'The first 3 digits of ISBN-13 must be 978 or 979'\n            )\n        if isbn13_digit_calc(value) != value[-1]:\n            raise PydanticCustomError('isbn_invalid_digit_check_isbn13', 'Provided digit is invalid for given ISBN')\n</code></pre>"},{"location":"api/pydantic_extra_types_isbn/#pydantic_extra_types.isbn.ISBN.convert_isbn10_to_isbn13","title":"convert_isbn10_to_isbn13  <code>staticmethod</code>","text":"<pre><code>convert_isbn10_to_isbn13(value: str) -&gt; str\n</code></pre> <p>Convert an ISBN-10 to ISBN-13.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>The ISBN-10 value to be converted.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The converted ISBN or the original value if no conversion is necessary.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/isbn.py</code> <pre><code>@staticmethod\ndef convert_isbn10_to_isbn13(value: str) -&gt; str:\n    \"\"\"Convert an ISBN-10 to ISBN-13.\n\n    Args:\n        value: The ISBN-10 value to be converted.\n\n    Returns:\n        The converted ISBN or the original value if no conversion is necessary.\n    \"\"\"\n\n    if len(value) == 10:\n        base_isbn = f'978{value[:-1]}'\n        isbn13_digit = isbn13_digit_calc(base_isbn)\n        return ISBN(f'{base_isbn}{isbn13_digit}')\n\n    return ISBN(value)\n</code></pre>"},{"location":"api/pydantic_extra_types_isbn/#pydantic_extra_types.isbn.isbn10_digit_calc","title":"isbn10_digit_calc","text":"<pre><code>isbn10_digit_calc(isbn: str) -&gt; str\n</code></pre> <p>Calc a ISBN-10 last digit from the provided str value. More information of validation algorithm on Wikipedia</p> <p>Parameters:</p> Name Type Description Default <code>isbn</code> <code>str</code> <p>The str value representing the ISBN in 10 digits.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The calculated last digit of the ISBN-10 value.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/isbn.py</code> <pre><code>def isbn10_digit_calc(isbn: str) -&gt; str:\n    \"\"\"Calc a ISBN-10 last digit from the provided str value. More information of validation algorithm on [Wikipedia](https://en.wikipedia.org/wiki/ISBN#Check_digits)\n\n    Args:\n        isbn: The str value representing the ISBN in 10 digits.\n\n    Returns:\n        The calculated last digit of the ISBN-10 value.\n    \"\"\"\n    total = sum(int(digit) * (10 - idx) for idx, digit in enumerate(isbn[:9]))\n\n    for check_digit in range(1, 11):\n        if (total + check_digit) % 11 == 0:\n            valid_check_digit = 'X' if check_digit == 10 else str(check_digit)\n\n    return valid_check_digit\n</code></pre>"},{"location":"api/pydantic_extra_types_isbn/#pydantic_extra_types.isbn.isbn13_digit_calc","title":"isbn13_digit_calc","text":"<pre><code>isbn13_digit_calc(isbn: str) -&gt; str\n</code></pre> <p>Calc a ISBN-13 last digit from the provided str value. More information of validation algorithm on Wikipedia</p> <p>Parameters:</p> Name Type Description Default <code>isbn</code> <code>str</code> <p>The str value representing the ISBN in 13 digits.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The calculated last digit of the ISBN-13 value.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/isbn.py</code> <pre><code>def isbn13_digit_calc(isbn: str) -&gt; str:\n    \"\"\"Calc a ISBN-13 last digit from the provided str value. More information of validation algorithm on [Wikipedia](https://en.wikipedia.org/wiki/ISBN#Check_digits)\n\n    Args:\n        isbn: The str value representing the ISBN in 13 digits.\n\n    Returns:\n        The calculated last digit of the ISBN-13 value.\n    \"\"\"\n    total = sum(int(digit) * (1 if idx % 2 == 0 else 3) for idx, digit in enumerate(isbn[:12]))\n\n    check_digit = (10 - (total % 10)) % 10\n\n    return str(check_digit)\n</code></pre>"},{"location":"api/pydantic_extra_types_language_code/","title":"Language","text":"<p>Language definitions that are based on the ISO 639-3 &amp; ISO 639-5.</p>"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.LanguageInfo","title":"LanguageInfo  <code>dataclass</code>","text":"<pre><code>LanguageInfo(\n    alpha2: Union[str, None], alpha3: str, name: str\n)\n</code></pre> <p>LanguageInfo is a dataclass that contains the language information.</p> <p>Parameters:</p> Name Type Description Default <code>alpha2</code> <code>Union[str, None]</code> <p>The language code in the ISO 639-1 alpha-2 format.</p> required <code>alpha3</code> <code>str</code> <p>The language code in the ISO 639-3 alpha-3 format.</p> required <code>name</code> <code>str</code> <p>The language name.</p> required"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.LanguageAlpha2","title":"LanguageAlpha2","text":"<p>               Bases: <code>str</code></p> <p>LanguageAlpha2 parses languages codes in the ISO 639-1 alpha-2 format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.language_code import LanguageAlpha2\n\nclass Movie(BaseModel):\n    audio_lang: LanguageAlpha2\n    subtitles_lang: LanguageAlpha2\n\nmovie = Movie(audio_lang='de', subtitles_lang='fr')\nprint(movie)\n#&gt; audio_lang='de' subtitles_lang='fr'\n</code></pre>"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.LanguageAlpha2.alpha3","title":"alpha3  <code>property</code>","text":"<pre><code>alpha3: str\n</code></pre> <p>The language code in the ISO 639-3 alpha-3 format.</p>"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.LanguageAlpha2.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>The language name.</p>"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.LanguageName","title":"LanguageName","text":"<p>               Bases: <code>str</code></p> <p>LanguageName parses languages names listed in the ISO 639-3 standard format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.language_code import LanguageName\n\nclass Movie(BaseModel):\n    audio_lang: LanguageName\n    subtitles_lang: LanguageName\n\nmovie = Movie(audio_lang='Dutch', subtitles_lang='Mandarin Chinese')\nprint(movie)\n#&gt; audio_lang='Dutch' subtitles_lang='Mandarin Chinese'\n</code></pre>"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.LanguageName.alpha2","title":"alpha2  <code>property</code>","text":"<pre><code>alpha2: Union[str, None]\n</code></pre> <p>The language code in the ISO 639-1 alpha-2 format. Does not exist for all languages.</p>"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.LanguageName.alpha3","title":"alpha3  <code>property</code>","text":"<pre><code>alpha3: str\n</code></pre> <p>The language code in the ISO 639-3 alpha-3 format.</p>"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.ISO639_3","title":"ISO639_3","text":"<p>               Bases: <code>str</code></p> <p>ISO639_3 parses Language in the ISO 639-3 alpha-3 format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.language_code import ISO639_3\n\nclass Language(BaseModel):\n    alpha_3: ISO639_3\n\nlang = Language(alpha_3='ssr')\nprint(lang)\n# &gt; alpha_3='ssr'\n</code></pre>"},{"location":"api/pydantic_extra_types_language_code/#pydantic_extra_types.language_code.ISO639_5","title":"ISO639_5","text":"<p>               Bases: <code>str</code></p> <p>ISO639_5 parses Language in the ISO 639-5 alpha-3 format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.language_code import ISO639_5\n\nclass Language(BaseModel):\n    alpha_3: ISO639_5\n\nlang = Language(alpha_3='gem')\nprint(lang)\n# &gt; alpha_3='gem'\n</code></pre>"},{"location":"api/pydantic_extra_types_mac_address/","title":"Mac Address","text":"<p>The MAC address module provides functionality to parse and validate MAC addresses in different formats, such as IEEE 802 MAC-48, EUI-48, EUI-64, or a 20-octet format.</p>"},{"location":"api/pydantic_extra_types_mac_address/#pydantic_extra_types.mac_address.MacAddress","title":"MacAddress","text":"<p>               Bases: <code>str</code></p> <p>Represents a MAC address and provides methods for conversion, validation, and serialization.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.mac_address import MacAddress\n\n\nclass Network(BaseModel):\n    mac_address: MacAddress\n\n\nnetwork = Network(mac_address=\"00:00:5e:00:53:01\")\nprint(network)\n#&gt; mac_address='00:00:5e:00:53:01'\n</code></pre>"},{"location":"api/pydantic_extra_types_mac_address/#pydantic_extra_types.mac_address.MacAddress.validate_mac_address","title":"validate_mac_address  <code>staticmethod</code>","text":"<pre><code>validate_mac_address(value: bytes) -&gt; str\n</code></pre> <p>Validate a MAC Address from the provided byte value.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/mac_address.py</code> <pre><code>@staticmethod\ndef validate_mac_address(value: bytes) -&gt; str:\n    \"\"\"\n    Validate a MAC Address from the provided byte value.\n    \"\"\"\n    if len(value) &lt; 14:\n        raise PydanticCustomError(\n            'mac_address_len',\n            'Length for a {mac_address} MAC address must be {required_length}',\n            {'mac_address': value.decode(), 'required_length': 14},\n        )\n\n    if value[2] in [ord(':'), ord('-')]:\n        if (len(value) + 1) % 3 != 0:\n            raise PydanticCustomError(\n                'mac_address_format', 'Must have the format xx:xx:xx:xx:xx:xx or xx-xx-xx-xx-xx-xx'\n            )\n        n = (len(value) + 1) // 3\n        if n not in (6, 8, 20):\n            raise PydanticCustomError(\n                'mac_address_format',\n                'Length for a {mac_address} MAC address must be {required_length}',\n                {'mac_address': value.decode(), 'required_length': (6, 8, 20)},\n            )\n        mac_address = bytearray(n)\n        x = 0\n        for i in range(n):\n            try:\n                byte_value = int(value[x : x + 2], 16)\n                mac_address[i] = byte_value\n                x += 3\n            except ValueError as e:\n                raise PydanticCustomError('mac_address_format', 'Unrecognized format') from e\n\n    elif value[4] == ord('.'):\n        if (len(value) + 1) % 5 != 0:\n            raise PydanticCustomError('mac_address_format', 'Must have the format xx.xx.xx.xx.xx.xx')\n        n = 2 * (len(value) + 1) // 5\n        if n not in (6, 8, 20):\n            raise PydanticCustomError(\n                'mac_address_format',\n                'Length for a {mac_address} MAC address must be {required_length}',\n                {'mac_address': value.decode(), 'required_length': (6, 8, 20)},\n            )\n        mac_address = bytearray(n)\n        x = 0\n        for i in range(0, n, 2):\n            try:\n                byte_value = int(value[x : x + 2], 16)\n                mac_address[i] = byte_value\n                byte_value = int(value[x + 2 : x + 4], 16)\n                mac_address[i + 1] = byte_value\n                x += 5\n            except ValueError as e:\n                raise PydanticCustomError('mac_address_format', 'Unrecognized format') from e\n\n    else:\n        raise PydanticCustomError('mac_address_format', 'Unrecognized format')\n\n    return ':'.join(f'{b:02x}' for b in mac_address)\n</code></pre>"},{"location":"api/pydantic_extra_types_payment/","title":"Payment","text":"<p>The <code>pydantic_extra_types.payment</code> module provides the <code>PaymentCardNumber</code> data type.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardBrand","title":"PaymentCardBrand","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Payment card brands supported by the <code>PaymentCardNumber</code>.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber","title":"PaymentCardNumber","text":"<pre><code>PaymentCardNumber(card_number: str)\n</code></pre> <p>               Bases: <code>str</code></p> <p>A payment card number.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/payment.py</code> <pre><code>def __init__(self, card_number: str):\n    self.validate_digits(card_number)\n\n    card_number = self.validate_luhn_check_digit(card_number)\n\n    self.bin = card_number[:6]\n    self.last4 = card_number[-4:]\n    self.brand = self.validate_brand(card_number)\n</code></pre>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.strip_whitespace","title":"strip_whitespace  <code>class-attribute</code>","text":"<pre><code>strip_whitespace: bool = True\n</code></pre> <p>Whether to strip whitespace from the input value.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.min_length","title":"min_length  <code>class-attribute</code>","text":"<pre><code>min_length: int = 12\n</code></pre> <p>The minimum length of the card number.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.max_length","title":"max_length  <code>class-attribute</code>","text":"<pre><code>max_length: int = 19\n</code></pre> <p>The maximum length of the card number.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.bin","title":"bin  <code>instance-attribute</code>","text":"<pre><code>bin: str = card_number[:6]\n</code></pre> <p>The first 6 digits of the card number.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.last4","title":"last4  <code>instance-attribute</code>","text":"<pre><code>last4: str = card_number[-4:]\n</code></pre> <p>The last 4 digits of the card number.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.brand","title":"brand  <code>instance-attribute</code>","text":"<pre><code>brand: PaymentCardBrand = validate_brand(card_number)\n</code></pre> <p>The brand of the card.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.masked","title":"masked  <code>property</code>","text":"<pre><code>masked: str\n</code></pre> <p>The masked card number.</p>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.validate","title":"validate  <code>classmethod</code>","text":"<pre><code>validate(\n    __input_value: str, _: ValidationInfo\n) -&gt; PaymentCardNumber\n</code></pre> <p>Validate the <code>PaymentCardNumber</code> instance.</p> <p>Parameters:</p> Name Type Description Default <code>__input_value</code> <code>str</code> <p>The input value to validate.</p> required <code>_</code> <code>ValidationInfo</code> <p>The validation info.</p> required <p>Returns:</p> Type Description <code>PaymentCardNumber</code> <p>The validated <code>PaymentCardNumber</code> instance.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/payment.py</code> <pre><code>@classmethod\ndef validate(cls, __input_value: str, _: core_schema.ValidationInfo) -&gt; PaymentCardNumber:\n    \"\"\"Validate the `PaymentCardNumber` instance.\n\n    Args:\n        __input_value: The input value to validate.\n        _: The validation info.\n\n    Returns:\n        The validated `PaymentCardNumber` instance.\n    \"\"\"\n    return cls(__input_value)\n</code></pre>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.validate_digits","title":"validate_digits  <code>classmethod</code>","text":"<pre><code>validate_digits(card_number: str) -&gt; None\n</code></pre> <p>Validate that the card number is all digits.</p> <p>Parameters:</p> Name Type Description Default <code>card_number</code> <code>str</code> <p>The card number to validate.</p> required <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the card number is not all digits.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/payment.py</code> <pre><code>@classmethod\ndef validate_digits(cls, card_number: str) -&gt; None:\n    \"\"\"Validate that the card number is all digits.\n\n    Args:\n        card_number: The card number to validate.\n\n    Raises:\n        PydanticCustomError: If the card number is not all digits.\n    \"\"\"\n    if not card_number or not all('0' &lt;= c &lt;= '9' for c in card_number):\n        raise PydanticCustomError('payment_card_number_digits', 'Card number is not all digits')\n</code></pre>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.validate_luhn_check_digit","title":"validate_luhn_check_digit  <code>classmethod</code>","text":"<pre><code>validate_luhn_check_digit(card_number: str) -&gt; str\n</code></pre> <p>Validate the payment card number. Based on the Luhn algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>card_number</code> <code>str</code> <p>The card number to validate.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The validated card number.</p> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the card number is not valid.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/payment.py</code> <pre><code>@classmethod\ndef validate_luhn_check_digit(cls, card_number: str) -&gt; str:\n    \"\"\"Validate the payment card number.\n    Based on the [Luhn algorithm](https://en.wikipedia.org/wiki/Luhn_algorithm).\n\n    Args:\n        card_number: The card number to validate.\n\n    Returns:\n        The validated card number.\n\n    Raises:\n        PydanticCustomError: If the card number is not valid.\n    \"\"\"\n    sum_ = int(card_number[-1])\n    length = len(card_number)\n    parity = length % 2\n    for i in range(length - 1):\n        digit = int(card_number[i])\n        if i % 2 == parity:\n            digit *= 2\n        if digit &gt; 9:\n            digit -= 9\n        sum_ += digit\n    valid = sum_ % 10 == 0\n    if not valid:\n        raise PydanticCustomError('payment_card_number_luhn', 'Card number is not luhn valid')\n    return card_number\n</code></pre>"},{"location":"api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.validate_brand","title":"validate_brand  <code>staticmethod</code>","text":"<pre><code>validate_brand(card_number: str) -&gt; PaymentCardBrand\n</code></pre> <p>Validate length based on BIN for major brands.</p> <p>Parameters:</p> Name Type Description Default <code>card_number</code> <code>str</code> <p>The card number to validate.</p> required <p>Returns:</p> Type Description <code>PaymentCardBrand</code> <p>The validated card brand.</p> <p>Raises:</p> Type Description <code>PydanticCustomError</code> <p>If the card number is not valid.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/payment.py</code> <pre><code>@staticmethod\ndef validate_brand(card_number: str) -&gt; PaymentCardBrand:\n    \"\"\"Validate length based on\n    [BIN](https://en.wikipedia.org/wiki/Payment_card_number#Issuer_identification_number_(IIN))\n    for major brands.\n\n    Args:\n        card_number: The card number to validate.\n\n    Returns:\n        The validated card brand.\n\n    Raises:\n        PydanticCustomError: If the card number is not valid.\n    \"\"\"\n    brand = PaymentCardBrand.other\n\n    if card_number[0] == '4':\n        brand = PaymentCardBrand.visa\n        required_length = [13, 16, 19]\n    elif 51 &lt;= int(card_number[:2]) &lt;= 55:\n        brand = PaymentCardBrand.mastercard\n        required_length = [16]\n    elif card_number[:2] in {'34', '37'}:\n        brand = PaymentCardBrand.amex\n        required_length = [15]\n    elif 2200 &lt;= int(card_number[:4]) &lt;= 2204:\n        brand = PaymentCardBrand.mir\n        required_length = list(range(16, 20))\n    elif card_number[:4] in {'5018', '5020', '5038', '5893', '6304', '6759', '6761', '6762', '6763'} or card_number[\n        :6\n    ] in (\n        '676770',\n        '676774',\n    ):\n        brand = PaymentCardBrand.maestro\n        required_length = list(range(12, 20))\n    elif card_number.startswith('65') or 644 &lt;= int(card_number[:3]) &lt;= 649 or card_number.startswith('6011'):\n        brand = PaymentCardBrand.discover\n        required_length = list(range(16, 20))\n    elif (\n        506099 &lt;= int(card_number[:6]) &lt;= 506198\n        or 650002 &lt;= int(card_number[:6]) &lt;= 650027\n        or 507865 &lt;= int(card_number[:6]) &lt;= 507964\n    ):\n        brand = PaymentCardBrand.verve\n        required_length = [16, 18, 19]\n    elif card_number[:4] in {'5019', '4571'}:\n        brand = PaymentCardBrand.dankort\n        required_length = [16]\n    elif card_number.startswith('9792'):\n        brand = PaymentCardBrand.troy\n        required_length = [16]\n    elif card_number[:2] in {'62', '81'}:\n        brand = PaymentCardBrand.unionpay\n        required_length = [16, 19]\n    elif 3528 &lt;= int(card_number[:4]) &lt;= 3589:\n        brand = PaymentCardBrand.jcb\n        required_length = [16, 19]\n\n    valid = len(card_number) in required_length if brand != PaymentCardBrand.other else True\n\n    if not valid:\n        raise PydanticCustomError(\n            'payment_card_number_brand',\n            f'Length for a {brand} card must be {\" or \".join(map(str, required_length))}',\n            {'brand': brand, 'required_length': required_length},\n        )\n\n    return brand\n</code></pre>"},{"location":"api/pydantic_extra_types_pendulum_dt/","title":"Pendulum","text":"<p>Native Pendulum DateTime object implementation. This is a copy of the Pendulum DateTime object, but with a Pydantic CoreSchema implementation. This allows Pydantic to validate the DateTime object.</p>"},{"location":"api/pydantic_extra_types_pendulum_dt/#pydantic_extra_types.pendulum_dt.DateTime","title":"DateTime","text":"<p>               Bases: <code>DateTime</code></p> <p>A <code>pendulum.DateTime</code> object. At runtime, this type decomposes into pendulum.DateTime automatically. This type exists because Pydantic throws a fit on unknown types.</p> <pre><code>from pydantic import BaseModel\nfrom pydantic_extra_types.pendulum_dt import DateTime\n\nclass test_model(BaseModel):\n    dt: DateTime\n\nprint(test_model(dt='2021-01-01T00:00:00+00:00'))\n\n#&gt; test_model(dt=DateTime(2021, 1, 1, 0, 0, 0, tzinfo=FixedTimezone(0, name=\"+00:00\")))\n</code></pre>"},{"location":"api/pydantic_extra_types_pendulum_dt/#pydantic_extra_types.pendulum_dt.Date","title":"Date","text":"<p>               Bases: <code>Date</code></p> <p>A <code>pendulum.Date</code> object. At runtime, this type decomposes into pendulum.Date automatically. This type exists because Pydantic throws a fit on unknown types.</p> <pre><code>from pydantic import BaseModel\nfrom pydantic_extra_types.pendulum_dt import Date\n\nclass test_model(BaseModel):\n    dt: Date\n\nprint(test_model(dt='2021-01-01'))\n\n#&gt; test_model(dt=Date(2021, 1, 1))\n</code></pre>"},{"location":"api/pydantic_extra_types_pendulum_dt/#pydantic_extra_types.pendulum_dt.Duration","title":"Duration","text":"<p>               Bases: <code>Duration</code></p> <p>A <code>pendulum.Duration</code> object. At runtime, this type decomposes into pendulum.Duration automatically. This type exists because Pydantic throws a fit on unknown types.</p> <pre><code>from pydantic import BaseModel\nfrom pydantic_extra_types.pendulum_dt import Duration\n\nclass test_model(BaseModel):\n    delta_t: Duration\n\nprint(test_model(delta_t='P1DT25H'))\n\n#&gt; test_model(delta_t=Duration(days=2, hours=1))\n</code></pre>"},{"location":"api/pydantic_extra_types_phone_numbers/","title":"Phone Numbers","text":"<p>The <code>pydantic_extra_types.phone_numbers</code> module provides the <code>PhoneNumber</code> data type.</p> <p>This class depends on the [phonenumbers] package, which is a Python port of Google's [libphonenumber].</p>"},{"location":"api/pydantic_extra_types_phone_numbers/#pydantic_extra_types.phone_numbers.PhoneNumber","title":"PhoneNumber","text":"<p>               Bases: <code>str</code></p> <p>A wrapper around phonenumbers package, which is a Python port of Google's libphonenumber.</p>"},{"location":"api/pydantic_extra_types_phone_numbers/#pydantic_extra_types.phone_numbers.PhoneNumber.supported_regions","title":"supported_regions  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>supported_regions: list[str] = []\n</code></pre> <p>The supported regions. If empty, all regions are supported.</p>"},{"location":"api/pydantic_extra_types_phone_numbers/#pydantic_extra_types.phone_numbers.PhoneNumber.default_region_code","title":"default_region_code  <code>class-attribute</code>","text":"<pre><code>default_region_code: str | None = None\n</code></pre> <p>The default region code to use when parsing phone numbers without an international prefix.</p>"},{"location":"api/pydantic_extra_types_phone_numbers/#pydantic_extra_types.phone_numbers.PhoneNumber.phone_format","title":"phone_format  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>phone_format: str = 'RFC3966'\n</code></pre> <p>The format of the phone number.</p>"},{"location":"api/pydantic_extra_types_phone_numbers/#pydantic_extra_types.phone_numbers.PhoneNumberValidator","title":"PhoneNumberValidator  <code>dataclass</code>","text":"<pre><code>PhoneNumberValidator(\n    default_region: Optional[str] = None,\n    number_format: str = \"RFC3966\",\n    supported_regions: Optional[Sequence[str]] = None,\n)\n</code></pre> <p>A pydantic before validator for phone numbers using the phonenumbers package, a Python port of Google's libphonenumber.</p> <p>Intended to be used to create custom pydantic data types using the <code>typing.Annotated</code> type construct.</p> <p>Parameters:</p> Name Type Description Default <code>default_region</code> <code>str | None</code> <p>The default region code to use when parsing phone numbers without an international prefix. If <code>None</code> (default), the region must be supplied in the phone number as an international prefix.</p> <code>None</code> <code>number_format</code> <code>str</code> <p>The format of the phone number to return. See <code>phonenumbers.PhoneNumberFormat</code> for valid values.</p> <code>'RFC3966'</code> <code>supported_regions</code> <code>list[str]</code> <p>The supported regions. If empty, all regions are supported (default).</p> <code>None</code> <p>Returns:     str: The formatted phone number.</p> Example <p>MyNumberType = Annotated[     Union[str, phonenumbers.PhoneNumber],     PhoneNumberValidator() ] USNumberType = Annotated[     Union[str, phonenumbers.PhoneNumber],     PhoneNumberValidator(supported_regions=['US'], default_region='US') ]</p> <p>class SomeModel(BaseModel):     phone_number: MyNumberType     us_number: USNumberType</p>"},{"location":"api/pydantic_extra_types_routing_numbers/","title":"Routing Numbers","text":"<p>The <code>pydantic_extra_types.routing_number</code> module provides the <code>ABARoutingNumber</code> data type.</p>"},{"location":"api/pydantic_extra_types_routing_numbers/#pydantic_extra_types.routing_number.ABARoutingNumber","title":"ABARoutingNumber","text":"<pre><code>ABARoutingNumber(routing_number: str)\n</code></pre> <p>               Bases: <code>str</code></p> <p>The <code>ABARoutingNumber</code> data type is a string of 9 digits representing an ABA routing transit number.</p> <p>The algorithm used to validate the routing number is described in the ABA routing transit number Wikipedia article.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.routing_number import ABARoutingNumber\n\nclass BankAccount(BaseModel):\n    routing_number: ABARoutingNumber\n\naccount = BankAccount(routing_number='122105155')\nprint(account)\n#&gt; routing_number='122105155'\n</code></pre> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/routing_number.py</code> <pre><code>def __init__(self, routing_number: str):\n    self._validate_digits(routing_number)\n    self._routing_number = self._validate_routing_number(routing_number)\n</code></pre>"},{"location":"api/pydantic_extra_types_script_code/","title":"Script Code","text":"<p>script definitions that are based on the ISO 15924</p>"},{"location":"api/pydantic_extra_types_script_code/#pydantic_extra_types.script_code.ISO_15924","title":"ISO_15924","text":"<p>               Bases: <code>str</code></p> <p>ISO_15924 parses script in the ISO 15924 format.</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_extra_types.language_code import ISO_15924\n\nclass Script(BaseModel):\n    alpha_4: ISO_15924\n\nscript = Script(alpha_4='Java')\nprint(lang)\n# &gt; script='Java'\n</code></pre>"},{"location":"api/pydantic_extra_types_semantic_version/","title":"Semantic Version","text":"<p>SemanticVersion definition that is based on the Semantiv Versioning Specification semver.</p>"},{"location":"api/pydantic_extra_types_semantic_version/#pydantic_extra_types.semantic_version.SemanticVersion","title":"SemanticVersion","text":"<p>Semantic version based on the official semver thread.</p>"},{"location":"api/pydantic_extra_types_timezone_name/","title":"Timezone Name","text":"<p>Time zone name validation and serialization module.</p>"},{"location":"api/pydantic_extra_types_timezone_name/#pydantic_extra_types.timezone_name.TimeZoneName","title":"TimeZoneName","text":"<p>               Bases: <code>str</code></p> <p>TimeZoneName is a custom string subclass for validating and serializing timezone names.</p> <p>The TimeZoneName class uses the IANA Time Zone Database for validation. It supports both strict and non-strict modes for timezone name validation.</p>"},{"location":"api/pydantic_extra_types_timezone_name/#pydantic_extra_types.timezone_name.TimeZoneName--examples","title":"Examples:","text":"<p>Some examples of using the TimeZoneName class:</p>"},{"location":"api/pydantic_extra_types_timezone_name/#pydantic_extra_types.timezone_name.TimeZoneName--normal-usage","title":"Normal usage:","text":"<pre><code>from pydantic_extra_types.timezone_name import TimeZoneName\nfrom pydantic import BaseModel\nclass Location(BaseModel):\n    city: str\n    timezone: TimeZoneName\n\nloc = Location(city=\"New York\", timezone=\"America/New_York\")\nprint(loc.timezone)\n\n&gt;&gt; America/New_York\n</code></pre>"},{"location":"api/pydantic_extra_types_timezone_name/#pydantic_extra_types.timezone_name.TimeZoneName--non-strict-mode","title":"Non-strict mode:","text":"<pre><code>from pydantic_extra_types.timezone_name import TimeZoneName, timezone_name_settings\n\n@timezone_name_settings(strict=False)\nclass TZNonStrict(TimeZoneName):\n    pass\n\ntz = TZNonStrict(\"america/new_york\")\n\nprint(tz)\n\n&gt;&gt; america/new_york\n</code></pre>"},{"location":"api/pydantic_extra_types_timezone_name/#pydantic_extra_types.timezone_name.get_timezones","title":"get_timezones","text":"<pre><code>get_timezones() -&gt; Set[str]\n</code></pre> <p>Determine the timezone provider and return available timezones.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_extra_types/timezone_name.py</code> <pre><code>def get_timezones() -&gt; Set[str]:\n    \"\"\"Determine the timezone provider and return available timezones.\"\"\"\n    if _is_available('zoneinfo') and _is_available('tzdata'):  # pragma: no cover\n        return _tz_provider_from_zone_info()\n    elif _is_available('pytz'):  # pragma: no cover\n        if sys.version_info[:2] &gt; (3, 8):\n            _warn_about_pytz_usage()\n        return _tz_provider_from_pytz()\n    else:  # pragma: no cover\n        if sys.version_info[:2] == (3, 8):\n            raise ImportError('No pytz module found. Please install it with \"pip install pytz\"')\n        raise ImportError('No timezone provider found. Please install tzdata with \"pip install tzdata\"')\n</code></pre>"},{"location":"api/pydantic_extra_types_ulid/","title":"ULID","text":"<p>The <code>pydantic_extra_types.ULID</code> module provides the [<code>ULID</code>] data type.</p> <p>This class depends on the [python-ulid] package, which is a validate by the ULID-spec.</p>"},{"location":"api/pydantic_extra_types_ulid/#pydantic_extra_types.ulid.ULID","title":"ULID  <code>dataclass</code>","text":"<pre><code>ULID(ulid: ULID)\n</code></pre> <p>               Bases: <code>Representation</code></p> <p>A wrapper around python-ulid package, which is a validate by the ULID-spec.</p>"},{"location":"api/pydantic_settings/","title":"Pydantic Settings","text":""},{"location":"api/pydantic_settings/#pydantic_settings.BaseSettings","title":"BaseSettings","text":"<pre><code>BaseSettings(\n    __pydantic_self__,\n    _case_sensitive: bool | None = None,\n    _env_prefix: str | None = None,\n    _env_file: DotenvType | None = ENV_FILE_SENTINEL,\n    _env_file_encoding: str | None = None,\n    _env_ignore_empty: bool | None = None,\n    _env_nested_delimiter: str | None = None,\n    _env_parse_none_str: str | None = None,\n    _env_parse_enums: bool | None = None,\n    _cli_prog_name: str | None = None,\n    _cli_parse_args: (\n        bool | list[str] | tuple[str, ...] | None\n    ) = None,\n    _cli_settings_source: (\n        CliSettingsSource[Any] | None\n    ) = None,\n    _cli_parse_none_str: str | None = None,\n    _cli_hide_none_type: bool | None = None,\n    _cli_avoid_json: bool | None = None,\n    _cli_enforce_required: bool | None = None,\n    _cli_use_class_docs_for_groups: bool | None = None,\n    _cli_exit_on_error: bool | None = None,\n    _cli_prefix: str | None = None,\n    _secrets_dir: str | Path | None = None,\n    **values: Any\n)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Base class for settings, allowing values to be overridden by environment variables.</p> <p>This is useful in production for secrets you do not wish to save in code, it plays nicely with docker(-compose), Heroku and any 12 factor app design.</p> <p>All the below attributes can be set via <code>model_config</code>.</p> <p>Parameters:</p> Name Type Description Default <code>_case_sensitive</code> <code>bool | None</code> <p>Whether environment variables names should be read with case-sensitivity. Defaults to <code>None</code>.</p> <code>None</code> <code>_env_prefix</code> <code>str | None</code> <p>Prefix for all environment variables. Defaults to <code>None</code>.</p> <code>None</code> <code>_env_file</code> <code>DotenvType | None</code> <p>The env file(s) to load settings values from. Defaults to <code>Path('')</code>, which means that the value from <code>model_config['env_file']</code> should be used. You can also pass <code>None</code> to indicate that environment variables should not be loaded from an env file.</p> <code>ENV_FILE_SENTINEL</code> <code>_env_file_encoding</code> <code>str | None</code> <p>The env file encoding, e.g. <code>'latin-1'</code>. Defaults to <code>None</code>.</p> <code>None</code> <code>_env_ignore_empty</code> <code>bool | None</code> <p>Ignore environment variables where the value is an empty string. Default to <code>False</code>.</p> <code>None</code> <code>_env_nested_delimiter</code> <code>str | None</code> <p>The nested env values delimiter. Defaults to <code>None</code>.</p> <code>None</code> <code>_env_parse_none_str</code> <code>str | None</code> <p>The env string value that should be parsed (e.g. \"null\", \"void\", \"None\", etc.) into <code>None</code> type(None). Defaults to <code>None</code> type(None), which means no parsing should occur.</p> <code>None</code> <code>_env_parse_enums</code> <code>bool | None</code> <p>Parse enum field names to values. Defaults to <code>None.</code>, which means no parsing should occur.</p> <code>None</code> <code>_cli_prog_name</code> <code>str | None</code> <p>The CLI program name to display in help text. Defaults to <code>None</code> if _cli_parse_args is <code>None</code>. Otherwse, defaults to sys.argv[0].</p> <code>None</code> <code>_cli_parse_args</code> <code>bool | list[str] | tuple[str, ...] | None</code> <p>The list of CLI arguments to parse. Defaults to None. If set to <code>True</code>, defaults to sys.argv[1:].</p> <code>None</code> <code>_cli_settings_source</code> <code>CliSettingsSource[Any] | None</code> <p>Override the default CLI settings source with a user defined instance. Defaults to None.</p> <code>None</code> <code>_cli_parse_none_str</code> <code>str | None</code> <p>The CLI string value that should be parsed (e.g. \"null\", \"void\", \"None\", etc.) into <code>None</code> type(None). Defaults to _env_parse_none_str value if set. Otherwise, defaults to \"null\" if _cli_avoid_json is <code>False</code>, and \"None\" if _cli_avoid_json is <code>True</code>.</p> <code>None</code> <code>_cli_hide_none_type</code> <code>bool | None</code> <p>Hide <code>None</code> values in CLI help text. Defaults to <code>False</code>.</p> <code>None</code> <code>_cli_avoid_json</code> <code>bool | None</code> <p>Avoid complex JSON objects in CLI help text. Defaults to <code>False</code>.</p> <code>None</code> <code>_cli_enforce_required</code> <code>bool | None</code> <p>Enforce required fields at the CLI. Defaults to <code>False</code>.</p> <code>None</code> <code>_cli_use_class_docs_for_groups</code> <code>bool | None</code> <p>Use class docstrings in CLI group help text instead of field descriptions. Defaults to <code>False</code>.</p> <code>None</code> <code>_cli_exit_on_error</code> <code>bool | None</code> <p>Determines whether or not the internal parser exits with error info when an error occurs. Defaults to <code>True</code>.</p> <code>None</code> <code>_cli_prefix</code> <code>str | None</code> <p>The root parser command line arguments prefix. Defaults to \"\".</p> <code>None</code> <code>_secrets_dir</code> <code>str | Path | None</code> <p>The secret files directory. Defaults to <code>None</code>.</p> <code>None</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/main.py</code> <pre><code>def __init__(\n    __pydantic_self__,\n    _case_sensitive: bool | None = None,\n    _env_prefix: str | None = None,\n    _env_file: DotenvType | None = ENV_FILE_SENTINEL,\n    _env_file_encoding: str | None = None,\n    _env_ignore_empty: bool | None = None,\n    _env_nested_delimiter: str | None = None,\n    _env_parse_none_str: str | None = None,\n    _env_parse_enums: bool | None = None,\n    _cli_prog_name: str | None = None,\n    _cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,\n    _cli_settings_source: CliSettingsSource[Any] | None = None,\n    _cli_parse_none_str: str | None = None,\n    _cli_hide_none_type: bool | None = None,\n    _cli_avoid_json: bool | None = None,\n    _cli_enforce_required: bool | None = None,\n    _cli_use_class_docs_for_groups: bool | None = None,\n    _cli_exit_on_error: bool | None = None,\n    _cli_prefix: str | None = None,\n    _secrets_dir: str | Path | None = None,\n    **values: Any,\n) -&gt; None:\n    # Uses something other than `self` the first arg to allow \"self\" as a settable attribute\n    super().__init__(\n        **__pydantic_self__._settings_build_values(\n            values,\n            _case_sensitive=_case_sensitive,\n            _env_prefix=_env_prefix,\n            _env_file=_env_file,\n            _env_file_encoding=_env_file_encoding,\n            _env_ignore_empty=_env_ignore_empty,\n            _env_nested_delimiter=_env_nested_delimiter,\n            _env_parse_none_str=_env_parse_none_str,\n            _env_parse_enums=_env_parse_enums,\n            _cli_prog_name=_cli_prog_name,\n            _cli_parse_args=_cli_parse_args,\n            _cli_settings_source=_cli_settings_source,\n            _cli_parse_none_str=_cli_parse_none_str,\n            _cli_hide_none_type=_cli_hide_none_type,\n            _cli_avoid_json=_cli_avoid_json,\n            _cli_enforce_required=_cli_enforce_required,\n            _cli_use_class_docs_for_groups=_cli_use_class_docs_for_groups,\n            _cli_exit_on_error=_cli_exit_on_error,\n            _cli_prefix=_cli_prefix,\n            _secrets_dir=_secrets_dir,\n        )\n    )\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.BaseSettings.settings_customise_sources","title":"settings_customise_sources  <code>classmethod</code>","text":"<pre><code>settings_customise_sources(\n    settings_cls: type[BaseSettings],\n    init_settings: PydanticBaseSettingsSource,\n    env_settings: PydanticBaseSettingsSource,\n    dotenv_settings: PydanticBaseSettingsSource,\n    file_secret_settings: PydanticBaseSettingsSource,\n) -&gt; tuple[PydanticBaseSettingsSource, ...]\n</code></pre> <p>Define the sources and their order for loading the settings values.</p> <p>Parameters:</p> Name Type Description Default <code>settings_cls</code> <code>type[BaseSettings]</code> <p>The Settings class.</p> required <code>init_settings</code> <code>PydanticBaseSettingsSource</code> <p>The <code>InitSettingsSource</code> instance.</p> required <code>env_settings</code> <code>PydanticBaseSettingsSource</code> <p>The <code>EnvSettingsSource</code> instance.</p> required <code>dotenv_settings</code> <code>PydanticBaseSettingsSource</code> <p>The <code>DotEnvSettingsSource</code> instance.</p> required <code>file_secret_settings</code> <code>PydanticBaseSettingsSource</code> <p>The <code>SecretsSettingsSource</code> instance.</p> required <p>Returns:</p> Type Description <code>tuple[PydanticBaseSettingsSource, ...]</code> <p>A tuple containing the sources and their order for loading the settings values.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/main.py</code> <pre><code>@classmethod\ndef settings_customise_sources(\n    cls,\n    settings_cls: type[BaseSettings],\n    init_settings: PydanticBaseSettingsSource,\n    env_settings: PydanticBaseSettingsSource,\n    dotenv_settings: PydanticBaseSettingsSource,\n    file_secret_settings: PydanticBaseSettingsSource,\n) -&gt; tuple[PydanticBaseSettingsSource, ...]:\n    \"\"\"\n    Define the sources and their order for loading the settings values.\n\n    Args:\n        settings_cls: The Settings class.\n        init_settings: The `InitSettingsSource` instance.\n        env_settings: The `EnvSettingsSource` instance.\n        dotenv_settings: The `DotEnvSettingsSource` instance.\n        file_secret_settings: The `SecretsSettingsSource` instance.\n\n    Returns:\n        A tuple containing the sources and their order for loading the settings values.\n    \"\"\"\n    return init_settings, env_settings, dotenv_settings, file_secret_settings\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.SettingsConfigDict","title":"SettingsConfigDict","text":"<p>               Bases: <code>ConfigDict</code></p>"},{"location":"api/pydantic_settings/#pydantic_settings.SettingsConfigDict.pyproject_toml_depth","title":"pyproject_toml_depth  <code>instance-attribute</code>","text":"<pre><code>pyproject_toml_depth: int\n</code></pre> <p>Number of levels up from the current working directory to attempt to find a pyproject.toml file.</p> <p>This is only used when a pyproject.toml file is not found in the current working directory.</p>"},{"location":"api/pydantic_settings/#pydantic_settings.SettingsConfigDict.pyproject_toml_table_header","title":"pyproject_toml_table_header  <code>instance-attribute</code>","text":"<pre><code>pyproject_toml_table_header: tuple[str, ...]\n</code></pre> <p>Header of the TOML table within a pyproject.toml file to use when filling variables. This is supplied as a <code>tuple[str, ...]</code> instead of a <code>str</code> to accommodate for headers containing a <code>.</code>.</p> <p>For example, <code>toml_table_header = (\"tool\", \"my.tool\", \"foo\")</code> can be used to fill variable values from a table with header <code>[tool.\"my.tool\".foo]</code>.</p> <p>To use the root table, exclude this config setting or provide an empty tuple.</p>"},{"location":"api/pydantic_settings/#pydantic_settings.CliSettingsSource","title":"CliSettingsSource","text":"<pre><code>CliSettingsSource(\n    settings_cls: type[BaseSettings],\n    cli_prog_name: str | None = None,\n    cli_parse_args: (\n        bool | list[str] | tuple[str, ...] | None\n    ) = None,\n    cli_parse_none_str: str | None = None,\n    cli_hide_none_type: bool | None = None,\n    cli_avoid_json: bool | None = None,\n    cli_enforce_required: bool | None = None,\n    cli_use_class_docs_for_groups: bool | None = None,\n    cli_exit_on_error: bool | None = None,\n    cli_prefix: str | None = None,\n    case_sensitive: bool | None = True,\n    root_parser: Any = None,\n    parse_args_method: (\n        Callable[..., Any] | None\n    ) = ArgumentParser.parse_args,\n    add_argument_method: (\n        Callable[..., Any] | None\n    ) = ArgumentParser.add_argument,\n    add_argument_group_method: (\n        Callable[..., Any] | None\n    ) = ArgumentParser.add_argument_group,\n    add_parser_method: (\n        Callable[..., Any] | None\n    ) = _SubParsersAction.add_parser,\n    add_subparsers_method: (\n        Callable[..., Any] | None\n    ) = ArgumentParser.add_subparsers,\n    formatter_class: Any = HelpFormatter,\n)\n</code></pre> <p>               Bases: <code>EnvSettingsSource</code>, <code>Generic[T]</code></p> <p>Source class for loading settings values from CLI.</p> Note <p>A <code>CliSettingsSource</code> connects with a <code>root_parser</code> object by using the parser methods to add <code>settings_cls</code> fields as command line arguments. The <code>CliSettingsSource</code> internal parser representation is based upon the <code>argparse</code> parsing library, and therefore, requires the parser methods to support the same attributes as their <code>argparse</code> library counterparts.</p> <p>Parameters:</p> Name Type Description Default <code>cli_prog_name</code> <code>str | None</code> <p>The CLI program name to display in help text. Defaults to <code>None</code> if cli_parse_args is <code>None</code>. Otherwse, defaults to sys.argv[0].</p> <code>None</code> <code>cli_parse_args</code> <code>bool | list[str] | tuple[str, ...] | None</code> <p>The list of CLI arguments to parse. Defaults to None. If set to <code>True</code>, defaults to sys.argv[1:].</p> <code>None</code> <code>cli_parse_none_str</code> <code>str | None</code> <p>The CLI string value that should be parsed (e.g. \"null\", \"void\", \"None\", etc.) into <code>None</code> type(None). Defaults to \"null\" if cli_avoid_json is <code>False</code>, and \"None\" if cli_avoid_json is <code>True</code>.</p> <code>None</code> <code>cli_hide_none_type</code> <code>bool | None</code> <p>Hide <code>None</code> values in CLI help text. Defaults to <code>False</code>.</p> <code>None</code> <code>cli_avoid_json</code> <code>bool | None</code> <p>Avoid complex JSON objects in CLI help text. Defaults to <code>False</code>.</p> <code>None</code> <code>cli_enforce_required</code> <code>bool | None</code> <p>Enforce required fields at the CLI. Defaults to <code>False</code>.</p> <code>None</code> <code>cli_use_class_docs_for_groups</code> <code>bool | None</code> <p>Use class docstrings in CLI group help text instead of field descriptions. Defaults to <code>False</code>.</p> <code>None</code> <code>cli_exit_on_error</code> <code>bool | None</code> <p>Determines whether or not the internal parser exits with error info when an error occurs. Defaults to <code>True</code>.</p> <code>None</code> <code>cli_prefix</code> <code>str | None</code> <p>Prefix for command line arguments added under the root parser. Defaults to \"\".</p> <code>None</code> <code>case_sensitive</code> <code>bool | None</code> <p>Whether CLI \"--arg\" names should be read with case-sensitivity. Defaults to <code>True</code>. Note: Case-insensitive matching is only supported on the internal root parser and does not apply to CLI subcommands.</p> <code>True</code> <code>root_parser</code> <code>Any</code> <p>The root parser object.</p> <code>None</code> <code>parse_args_method</code> <code>Callable[..., Any] | None</code> <p>The root parser parse args method. Defaults to <code>argparse.ArgumentParser.parse_args</code>.</p> <code>parse_args</code> <code>add_argument_method</code> <code>Callable[..., Any] | None</code> <p>The root parser add argument method. Defaults to <code>argparse.ArgumentParser.add_argument</code>.</p> <code>add_argument</code> <code>add_argument_group_method</code> <code>Callable[..., Any] | None</code> <p>The root parser add argument group method. Defaults to <code>argparse.ArgumentParser.add_argument_group</code>.</p> <code>add_argument_group</code> <code>add_parser_method</code> <code>Callable[..., Any] | None</code> <p>The root parser add new parser (sub-command) method. Defaults to <code>argparse._SubParsersAction.add_parser</code>.</p> <code>add_parser</code> <code>add_subparsers_method</code> <code>Callable[..., Any] | None</code> <p>The root parser add subparsers (sub-commands) method. Defaults to <code>argparse.ArgumentParser.add_subparsers</code>.</p> <code>add_subparsers</code> <code>formatter_class</code> <code>Any</code> <p>A class for customizing the root parser help text. Defaults to <code>argparse.HelpFormatter</code>.</p> <code>HelpFormatter</code> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    cli_prog_name: str | None = None,\n    cli_parse_args: bool | list[str] | tuple[str, ...] | None = None,\n    cli_parse_none_str: str | None = None,\n    cli_hide_none_type: bool | None = None,\n    cli_avoid_json: bool | None = None,\n    cli_enforce_required: bool | None = None,\n    cli_use_class_docs_for_groups: bool | None = None,\n    cli_exit_on_error: bool | None = None,\n    cli_prefix: str | None = None,\n    case_sensitive: bool | None = True,\n    root_parser: Any = None,\n    parse_args_method: Callable[..., Any] | None = ArgumentParser.parse_args,\n    add_argument_method: Callable[..., Any] | None = ArgumentParser.add_argument,\n    add_argument_group_method: Callable[..., Any] | None = ArgumentParser.add_argument_group,\n    add_parser_method: Callable[..., Any] | None = _SubParsersAction.add_parser,\n    add_subparsers_method: Callable[..., Any] | None = ArgumentParser.add_subparsers,\n    formatter_class: Any = HelpFormatter,\n) -&gt; None:\n    self.cli_prog_name = (\n        cli_prog_name if cli_prog_name is not None else settings_cls.model_config.get('cli_prog_name', sys.argv[0])\n    )\n    self.cli_hide_none_type = (\n        cli_hide_none_type\n        if cli_hide_none_type is not None\n        else settings_cls.model_config.get('cli_hide_none_type', False)\n    )\n    self.cli_avoid_json = (\n        cli_avoid_json if cli_avoid_json is not None else settings_cls.model_config.get('cli_avoid_json', False)\n    )\n    if not cli_parse_none_str:\n        cli_parse_none_str = 'None' if self.cli_avoid_json is True else 'null'\n    self.cli_parse_none_str = cli_parse_none_str\n    self.cli_enforce_required = (\n        cli_enforce_required\n        if cli_enforce_required is not None\n        else settings_cls.model_config.get('cli_enforce_required', False)\n    )\n    self.cli_use_class_docs_for_groups = (\n        cli_use_class_docs_for_groups\n        if cli_use_class_docs_for_groups is not None\n        else settings_cls.model_config.get('cli_use_class_docs_for_groups', False)\n    )\n    self.cli_exit_on_error = (\n        cli_exit_on_error\n        if cli_exit_on_error is not None\n        else settings_cls.model_config.get('cli_exit_on_error', True)\n    )\n    self.cli_prefix = cli_prefix if cli_prefix is not None else settings_cls.model_config.get('cli_prefix', '')\n    if self.cli_prefix:\n        if cli_prefix.startswith('.') or cli_prefix.endswith('.') or not cli_prefix.replace('.', '').isidentifier():  # type: ignore\n            raise SettingsError(f'CLI settings source prefix is invalid: {cli_prefix}')\n        self.cli_prefix += '.'\n\n    case_sensitive = case_sensitive if case_sensitive is not None else True\n    if not case_sensitive and root_parser is not None:\n        raise SettingsError('Case-insensitive matching is only supported on the internal root parser')\n\n    super().__init__(\n        settings_cls,\n        env_nested_delimiter='.',\n        env_parse_none_str=self.cli_parse_none_str,\n        env_parse_enums=True,\n        env_prefix=self.cli_prefix,\n        case_sensitive=case_sensitive,\n    )\n\n    root_parser = (\n        _CliInternalArgParser(\n            cli_exit_on_error=self.cli_exit_on_error, prog=self.cli_prog_name, description=settings_cls.__doc__\n        )\n        if root_parser is None\n        else root_parser\n    )\n    self._connect_root_parser(\n        root_parser=root_parser,\n        parse_args_method=parse_args_method,\n        add_argument_method=add_argument_method,\n        add_argument_group_method=add_argument_group_method,\n        add_parser_method=add_parser_method,\n        add_subparsers_method=add_subparsers_method,\n        formatter_class=formatter_class,\n    )\n\n    if cli_parse_args not in (None, False):\n        if cli_parse_args is True:\n            cli_parse_args = sys.argv[1:]\n        elif not isinstance(cli_parse_args, (list, tuple)):\n            raise SettingsError(\n                f'cli_parse_args must be List[str] or Tuple[str, ...], recieved {type(cli_parse_args)}'\n            )\n        self._load_env_vars(parsed_args=self._parse_args(self.root_parser, cli_parse_args))\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.CliSettingsSource.root_parser","title":"root_parser  <code>property</code>","text":"<pre><code>root_parser: T\n</code></pre> <p>The connected root parser instance.</p>"},{"location":"api/pydantic_settings/#pydantic_settings.DotEnvSettingsSource","title":"DotEnvSettingsSource","text":"<pre><code>DotEnvSettingsSource(\n    settings_cls: type[BaseSettings],\n    env_file: DotenvType | None = ENV_FILE_SENTINEL,\n    env_file_encoding: str | None = None,\n    case_sensitive: bool | None = None,\n    env_prefix: str | None = None,\n    env_nested_delimiter: str | None = None,\n    env_ignore_empty: bool | None = None,\n    env_parse_none_str: str | None = None,\n    env_parse_enums: bool | None = None,\n)\n</code></pre> <p>               Bases: <code>EnvSettingsSource</code></p> <p>Source class for loading settings values from env files.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    env_file: DotenvType | None = ENV_FILE_SENTINEL,\n    env_file_encoding: str | None = None,\n    case_sensitive: bool | None = None,\n    env_prefix: str | None = None,\n    env_nested_delimiter: str | None = None,\n    env_ignore_empty: bool | None = None,\n    env_parse_none_str: str | None = None,\n    env_parse_enums: bool | None = None,\n) -&gt; None:\n    self.env_file = env_file if env_file != ENV_FILE_SENTINEL else settings_cls.model_config.get('env_file')\n    self.env_file_encoding = (\n        env_file_encoding if env_file_encoding is not None else settings_cls.model_config.get('env_file_encoding')\n    )\n    super().__init__(\n        settings_cls,\n        case_sensitive,\n        env_prefix,\n        env_nested_delimiter,\n        env_ignore_empty,\n        env_parse_none_str,\n        env_parse_enums,\n    )\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.EnvSettingsSource","title":"EnvSettingsSource","text":"<pre><code>EnvSettingsSource(\n    settings_cls: type[BaseSettings],\n    case_sensitive: bool | None = None,\n    env_prefix: str | None = None,\n    env_nested_delimiter: str | None = None,\n    env_ignore_empty: bool | None = None,\n    env_parse_none_str: str | None = None,\n    env_parse_enums: bool | None = None,\n)\n</code></pre> <p>               Bases: <code>PydanticBaseEnvSettingsSource</code></p> <p>Source class for loading settings values from environment variables.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    case_sensitive: bool | None = None,\n    env_prefix: str | None = None,\n    env_nested_delimiter: str | None = None,\n    env_ignore_empty: bool | None = None,\n    env_parse_none_str: str | None = None,\n    env_parse_enums: bool | None = None,\n) -&gt; None:\n    super().__init__(\n        settings_cls, case_sensitive, env_prefix, env_ignore_empty, env_parse_none_str, env_parse_enums\n    )\n    self.env_nested_delimiter = (\n        env_nested_delimiter if env_nested_delimiter is not None else self.config.get('env_nested_delimiter')\n    )\n    self.env_prefix_len = len(self.env_prefix)\n\n    self.env_vars = self._load_env_vars()\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.EnvSettingsSource.get_field_value","title":"get_field_value","text":"<pre><code>get_field_value(\n    field: FieldInfo, field_name: str\n) -&gt; tuple[Any, str, bool]\n</code></pre> <p>Gets the value for field from environment variables and a flag to determine whether value is complex.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>field_name</code> <code>str</code> <p>The field name.</p> required <p>Returns:</p> Type Description <code>tuple[Any, str, bool]</code> <p>A tuple contains the key, value if the file exists otherwise <code>None</code>, and a flag to determine whether value is complex.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def get_field_value(self, field: FieldInfo, field_name: str) -&gt; tuple[Any, str, bool]:\n    \"\"\"\n    Gets the value for field from environment variables and a flag to determine whether value is complex.\n\n    Args:\n        field: The field.\n        field_name: The field name.\n\n    Returns:\n        A tuple contains the key, value if the file exists otherwise `None`, and\n            a flag to determine whether value is complex.\n    \"\"\"\n\n    env_val: str | None = None\n    for field_key, env_name, value_is_complex in self._extract_field_info(field, field_name):\n        env_val = self.env_vars.get(env_name)\n        if env_val is not None:\n            break\n\n    return env_val, field_key, value_is_complex\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.EnvSettingsSource.prepare_field_value","title":"prepare_field_value","text":"<pre><code>prepare_field_value(\n    field_name: str,\n    field: FieldInfo,\n    value: Any,\n    value_is_complex: bool,\n) -&gt; Any\n</code></pre> <p>Prepare value for the field.</p> <ul> <li>Extract value for nested field.</li> <li>Deserialize value to python object for complex field.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>field_name</code> <code>str</code> <p>The field name.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>A tuple contains prepared value for the field.</p> <p>Raises:</p> Type Description <code>ValuesError</code> <p>When There is an error in deserializing value for complex field.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:\n    \"\"\"\n    Prepare value for the field.\n\n    * Extract value for nested field.\n    * Deserialize value to python object for complex field.\n\n    Args:\n        field: The field.\n        field_name: The field name.\n\n    Returns:\n        A tuple contains prepared value for the field.\n\n    Raises:\n        ValuesError: When There is an error in deserializing value for complex field.\n    \"\"\"\n    is_complex, allow_parse_failure = self._field_is_complex(field)\n    if self.env_parse_enums and lenient_issubclass(field.annotation, Enum):\n        if value in tuple(val.name for val in field.annotation):  # type: ignore\n            value = field.annotation[value]  # type: ignore\n\n    if is_complex or value_is_complex:\n        if isinstance(value, EnvNoneType):\n            return value\n        elif value is None:\n            # field is complex but no value found so far, try explode_env_vars\n            env_val_built = self.explode_env_vars(field_name, field, self.env_vars)\n            if env_val_built:\n                return env_val_built\n        else:\n            # field is complex and there's a value, decode that as JSON, then add explode_env_vars\n            try:\n                value = self.decode_complex_value(field_name, field, value)\n            except ValueError as e:\n                if not allow_parse_failure:\n                    raise e\n\n            if isinstance(value, dict):\n                return deep_update(value, self.explode_env_vars(field_name, field, self.env_vars))\n            else:\n                return value\n    elif value is not None:\n        # simplest case, field is not complex, we only need to add the value if it was found\n        return value\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.EnvSettingsSource.next_field","title":"next_field  <code>staticmethod</code>","text":"<pre><code>next_field(\n    field: FieldInfo | Any | None,\n    key: str,\n    case_sensitive: bool | None = None,\n) -&gt; FieldInfo | None\n</code></pre> <p>Find the field in a sub model by key(env name)</p> <p>By having the following models:</p> <pre><code>```py\nclass SubSubModel(BaseSettings):\n    dvals: Dict\n\nclass SubModel(BaseSettings):\n    vals: list[str]\n    sub_sub_model: SubSubModel\n\nclass Cfg(BaseSettings):\n    sub_model: SubModel\n```\n</code></pre> Then <p>next_field(sub_model, 'vals') Returns the <code>vals</code> field of <code>SubModel</code> class next_field(sub_model, 'sub_sub_model') Returns <code>sub_sub_model</code> field of <code>SubModel</code> class</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>FieldInfo | Any | None</code> <p>The field.</p> required <code>key</code> <code>str</code> <p>The key (env name).</p> required <code>case_sensitive</code> <code>bool | None</code> <p>Whether to search for key case sensitively.</p> <code>None</code> <p>Returns:</p> Type Description <code>FieldInfo | None</code> <p>Field if it finds the next field otherwise <code>None</code>.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>@staticmethod\ndef next_field(field: FieldInfo | Any | None, key: str, case_sensitive: bool | None = None) -&gt; FieldInfo | None:\n    \"\"\"\n    Find the field in a sub model by key(env name)\n\n    By having the following models:\n\n        ```py\n        class SubSubModel(BaseSettings):\n            dvals: Dict\n\n        class SubModel(BaseSettings):\n            vals: list[str]\n            sub_sub_model: SubSubModel\n\n        class Cfg(BaseSettings):\n            sub_model: SubModel\n        ```\n\n    Then:\n        next_field(sub_model, 'vals') Returns the `vals` field of `SubModel` class\n        next_field(sub_model, 'sub_sub_model') Returns `sub_sub_model` field of `SubModel` class\n\n    Args:\n        field: The field.\n        key: The key (env name).\n        case_sensitive: Whether to search for key case sensitively.\n\n    Returns:\n        Field if it finds the next field otherwise `None`.\n    \"\"\"\n    if not field:\n        return None\n\n    annotation = field.annotation if isinstance(field, FieldInfo) else field\n    if origin_is_union(get_origin(annotation)) or isinstance(annotation, WithArgsTypes):\n        for type_ in get_args(annotation):\n            type_has_key = EnvSettingsSource.next_field(type_, key, case_sensitive)\n            if type_has_key:\n                return type_has_key\n    elif is_model_class(annotation) or is_pydantic_dataclass(annotation):\n        fields = (\n            annotation.__pydantic_fields__\n            if is_pydantic_dataclass(annotation)\n            else cast(BaseModel, annotation).model_fields\n        )\n        # `case_sensitive is None` is here to be compatible with the old behavior.\n        # Has to be removed in V3.\n        if (case_sensitive is None or case_sensitive) and fields.get(key):\n            return fields[key]\n        elif not case_sensitive:\n            for field_name, f in fields.items():\n                if field_name.lower() == key.lower():\n                    return f\n\n    return None\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.EnvSettingsSource.explode_env_vars","title":"explode_env_vars","text":"<pre><code>explode_env_vars(\n    field_name: str,\n    field: FieldInfo,\n    env_vars: Mapping[str, str | None],\n) -&gt; dict[str, Any]\n</code></pre> <p>Process env_vars and extract the values of keys containing env_nested_delimiter into nested dictionaries.</p> <p>This is applied to a single field, hence filtering by env_var prefix.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The field name.</p> required <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>env_vars</code> <code>Mapping[str, str | None]</code> <p>Environment variables.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dictionary contains extracted values from nested env values.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def explode_env_vars(self, field_name: str, field: FieldInfo, env_vars: Mapping[str, str | None]) -&gt; dict[str, Any]:\n    \"\"\"\n    Process env_vars and extract the values of keys containing env_nested_delimiter into nested dictionaries.\n\n    This is applied to a single field, hence filtering by env_var prefix.\n\n    Args:\n        field_name: The field name.\n        field: The field.\n        env_vars: Environment variables.\n\n    Returns:\n        A dictionary contains extracted values from nested env values.\n    \"\"\"\n    is_dict = lenient_issubclass(get_origin(field.annotation), dict)\n\n    prefixes = [\n        f'{env_name}{self.env_nested_delimiter}' for _, env_name, _ in self._extract_field_info(field, field_name)\n    ]\n    result: dict[str, Any] = {}\n    for env_name, env_val in env_vars.items():\n        if not any(env_name.startswith(prefix) for prefix in prefixes):\n            continue\n        # we remove the prefix before splitting in case the prefix has characters in common with the delimiter\n        env_name_without_prefix = env_name[self.env_prefix_len :]\n        _, *keys, last_key = env_name_without_prefix.split(self.env_nested_delimiter)\n        env_var = result\n        target_field: FieldInfo | None = field\n        for key in keys:\n            target_field = self.next_field(target_field, key, self.case_sensitive)\n            if isinstance(env_var, dict):\n                env_var = env_var.setdefault(key, {})\n\n        # get proper field with last_key\n        target_field = self.next_field(target_field, last_key, self.case_sensitive)\n\n        # check if env_val maps to a complex field and if so, parse the env_val\n        if (target_field or is_dict) and env_val:\n            if target_field:\n                is_complex, allow_json_failure = self._field_is_complex(target_field)\n            else:\n                # nested field type is dict\n                is_complex, allow_json_failure = True, True\n            if is_complex:\n                try:\n                    env_val = self.decode_complex_value(last_key, target_field, env_val)  # type: ignore\n                except ValueError as e:\n                    if not allow_json_failure:\n                        raise e\n        if isinstance(env_var, dict):\n            if last_key not in env_var or not isinstance(env_val, EnvNoneType) or env_var[last_key] is {}:\n                env_var[last_key] = env_val\n\n    return result\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.InitSettingsSource","title":"InitSettingsSource","text":"<pre><code>InitSettingsSource(\n    settings_cls: type[BaseSettings],\n    init_kwargs: dict[str, Any],\n)\n</code></pre> <p>               Bases: <code>PydanticBaseSettingsSource</code></p> <p>Source class for loading values provided during settings class initialization.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(self, settings_cls: type[BaseSettings], init_kwargs: dict[str, Any]):\n    self.init_kwargs = init_kwargs\n    super().__init__(settings_cls)\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.JsonConfigSettingsSource","title":"JsonConfigSettingsSource","text":"<pre><code>JsonConfigSettingsSource(\n    settings_cls: type[BaseSettings],\n    json_file: PathType | None = DEFAULT_PATH,\n    json_file_encoding: str | None = None,\n)\n</code></pre> <p>               Bases: <code>InitSettingsSource</code>, <code>ConfigFileSourceMixin</code></p> <p>A source class that loads variables from a JSON file</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    json_file: PathType | None = DEFAULT_PATH,\n    json_file_encoding: str | None = None,\n):\n    self.json_file_path = json_file if json_file != DEFAULT_PATH else settings_cls.model_config.get('json_file')\n    self.json_file_encoding = (\n        json_file_encoding\n        if json_file_encoding is not None\n        else settings_cls.model_config.get('json_file_encoding')\n    )\n    self.json_data = self._read_files(self.json_file_path)\n    super().__init__(settings_cls, self.json_data)\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.PydanticBaseSettingsSource","title":"PydanticBaseSettingsSource","text":"<pre><code>PydanticBaseSettingsSource(\n    settings_cls: type[BaseSettings],\n)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for settings sources, every settings source classes should inherit from it.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(self, settings_cls: type[BaseSettings]):\n    self.settings_cls = settings_cls\n    self.config = settings_cls.model_config\n    self._current_state: dict[str, Any] = {}\n    self._settings_sources_data: dict[str, dict[str, Any]] = {}\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.PydanticBaseSettingsSource.current_state","title":"current_state  <code>property</code>","text":"<pre><code>current_state: dict[str, Any]\n</code></pre> <p>The current state of the settings, populated by the previous settings sources.</p>"},{"location":"api/pydantic_settings/#pydantic_settings.PydanticBaseSettingsSource.settings_sources_data","title":"settings_sources_data  <code>property</code>","text":"<pre><code>settings_sources_data: dict[str, dict[str, Any]]\n</code></pre> <p>The state of all previous settings sources.</p>"},{"location":"api/pydantic_settings/#pydantic_settings.PydanticBaseSettingsSource.get_field_value","title":"get_field_value  <code>abstractmethod</code>","text":"<pre><code>get_field_value(\n    field: FieldInfo, field_name: str\n) -&gt; tuple[Any, str, bool]\n</code></pre> <p>Gets the value, the key for model creation, and a flag to determine whether value is complex.</p> <p>This is an abstract method that should be overridden in every settings source classes.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>field_name</code> <code>str</code> <p>The field name.</p> required <p>Returns:</p> Type Description <code>tuple[Any, str, bool]</code> <p>A tuple contains the key, value and a flag to determine whether value is complex.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>@abstractmethod\ndef get_field_value(self, field: FieldInfo, field_name: str) -&gt; tuple[Any, str, bool]:\n    \"\"\"\n    Gets the value, the key for model creation, and a flag to determine whether value is complex.\n\n    This is an abstract method that should be overridden in every settings source classes.\n\n    Args:\n        field: The field.\n        field_name: The field name.\n\n    Returns:\n        A tuple contains the key, value and a flag to determine whether value is complex.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.PydanticBaseSettingsSource.field_is_complex","title":"field_is_complex","text":"<pre><code>field_is_complex(field: FieldInfo) -&gt; bool\n</code></pre> <p>Checks whether a field is complex, in which case it will attempt to be parsed as JSON.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the field is complex.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def field_is_complex(self, field: FieldInfo) -&gt; bool:\n    \"\"\"\n    Checks whether a field is complex, in which case it will attempt to be parsed as JSON.\n\n    Args:\n        field: The field.\n\n    Returns:\n        Whether the field is complex.\n    \"\"\"\n    return _annotation_is_complex(field.annotation, field.metadata)\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.PydanticBaseSettingsSource.prepare_field_value","title":"prepare_field_value","text":"<pre><code>prepare_field_value(\n    field_name: str,\n    field: FieldInfo,\n    value: Any,\n    value_is_complex: bool,\n) -&gt; Any\n</code></pre> <p>Prepares the value of a field.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The field name.</p> required <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>value</code> <code>Any</code> <p>The value of the field that has to be prepared.</p> required <code>value_is_complex</code> <code>bool</code> <p>A flag to determine whether value is complex.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The prepared value.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def prepare_field_value(self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool) -&gt; Any:\n    \"\"\"\n    Prepares the value of a field.\n\n    Args:\n        field_name: The field name.\n        field: The field.\n        value: The value of the field that has to be prepared.\n        value_is_complex: A flag to determine whether value is complex.\n\n    Returns:\n        The prepared value.\n    \"\"\"\n    if value is not None and (self.field_is_complex(field) or value_is_complex):\n        return self.decode_complex_value(field_name, field, value)\n    return value\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.PydanticBaseSettingsSource.decode_complex_value","title":"decode_complex_value","text":"<pre><code>decode_complex_value(\n    field_name: str, field: FieldInfo, value: Any\n) -&gt; Any\n</code></pre> <p>Decode the value for a complex field</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The field name.</p> required <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>value</code> <code>Any</code> <p>The value of the field that has to be prepared.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The decoded value for further preparation</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def decode_complex_value(self, field_name: str, field: FieldInfo, value: Any) -&gt; Any:\n    \"\"\"\n    Decode the value for a complex field\n\n    Args:\n        field_name: The field name.\n        field: The field.\n        value: The value of the field that has to be prepared.\n\n    Returns:\n        The decoded value for further preparation\n    \"\"\"\n    return json.loads(value)\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.PyprojectTomlConfigSettingsSource","title":"PyprojectTomlConfigSettingsSource","text":"<pre><code>PyprojectTomlConfigSettingsSource(\n    settings_cls: type[BaseSettings],\n    toml_file: Path | None = None,\n)\n</code></pre> <p>               Bases: <code>TomlConfigSettingsSource</code></p> <p>A source class that loads variables from a <code>pyproject.toml</code> file.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    toml_file: Path | None = None,\n) -&gt; None:\n    self.toml_file_path = self._pick_pyproject_toml_file(\n        toml_file, settings_cls.model_config.get('pyproject_toml_depth', 0)\n    )\n    self.toml_table_header: tuple[str, ...] = settings_cls.model_config.get(\n        'pyproject_toml_table_header', ('tool', 'pydantic-settings')\n    )\n    self.toml_data = self._read_files(self.toml_file_path)\n    for key in self.toml_table_header:\n        self.toml_data = self.toml_data.get(key, {})\n    super(TomlConfigSettingsSource, self).__init__(settings_cls, self.toml_data)\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.SecretsSettingsSource","title":"SecretsSettingsSource","text":"<pre><code>SecretsSettingsSource(\n    settings_cls: type[BaseSettings],\n    secrets_dir: str | Path | None = None,\n    case_sensitive: bool | None = None,\n    env_prefix: str | None = None,\n    env_ignore_empty: bool | None = None,\n    env_parse_none_str: str | None = None,\n    env_parse_enums: bool | None = None,\n)\n</code></pre> <p>               Bases: <code>PydanticBaseEnvSettingsSource</code></p> <p>Source class for loading settings values from secret files.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    secrets_dir: str | Path | None = None,\n    case_sensitive: bool | None = None,\n    env_prefix: str | None = None,\n    env_ignore_empty: bool | None = None,\n    env_parse_none_str: str | None = None,\n    env_parse_enums: bool | None = None,\n) -&gt; None:\n    super().__init__(\n        settings_cls, case_sensitive, env_prefix, env_ignore_empty, env_parse_none_str, env_parse_enums\n    )\n    self.secrets_dir = secrets_dir if secrets_dir is not None else self.config.get('secrets_dir')\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.SecretsSettingsSource.find_case_path","title":"find_case_path  <code>classmethod</code>","text":"<pre><code>find_case_path(\n    dir_path: Path, file_name: str, case_sensitive: bool\n) -&gt; Path | None\n</code></pre> <p>Find a file within path's directory matching filename, optionally ignoring case.</p> <p>Parameters:</p> Name Type Description Default <code>dir_path</code> <code>Path</code> <p>Directory path.</p> required <code>file_name</code> <code>str</code> <p>File name.</p> required <code>case_sensitive</code> <code>bool</code> <p>Whether to search for file name case sensitively.</p> required <p>Returns:</p> Type Description <code>Path | None</code> <p>Whether file path or <code>None</code> if file does not exist in directory.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>@classmethod\ndef find_case_path(cls, dir_path: Path, file_name: str, case_sensitive: bool) -&gt; Path | None:\n    \"\"\"\n    Find a file within path's directory matching filename, optionally ignoring case.\n\n    Args:\n        dir_path: Directory path.\n        file_name: File name.\n        case_sensitive: Whether to search for file name case sensitively.\n\n    Returns:\n        Whether file path or `None` if file does not exist in directory.\n    \"\"\"\n    for f in dir_path.iterdir():\n        if f.name == file_name:\n            return f\n        elif not case_sensitive and f.name.lower() == file_name.lower():\n            return f\n    return None\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.SecretsSettingsSource.get_field_value","title":"get_field_value","text":"<pre><code>get_field_value(\n    field: FieldInfo, field_name: str\n) -&gt; tuple[Any, str, bool]\n</code></pre> <p>Gets the value for field from secret file and a flag to determine whether value is complex.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>FieldInfo</code> <p>The field.</p> required <code>field_name</code> <code>str</code> <p>The field name.</p> required <p>Returns:</p> Type Description <code>tuple[Any, str, bool]</code> <p>A tuple contains the key, value if the file exists otherwise <code>None</code>, and a flag to determine whether value is complex.</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def get_field_value(self, field: FieldInfo, field_name: str) -&gt; tuple[Any, str, bool]:\n    \"\"\"\n    Gets the value for field from secret file and a flag to determine whether value is complex.\n\n    Args:\n        field: The field.\n        field_name: The field name.\n\n    Returns:\n        A tuple contains the key, value if the file exists otherwise `None`, and\n            a flag to determine whether value is complex.\n    \"\"\"\n\n    for field_key, env_name, value_is_complex in self._extract_field_info(field, field_name):\n        path = self.find_case_path(self.secrets_path, env_name, self.case_sensitive)\n        if not path:\n            # path does not exist, we currently don't return a warning for this\n            continue\n\n        if path.is_file():\n            return path.read_text().strip(), field_key, value_is_complex\n        else:\n            warnings.warn(\n                f'attempted to load secret file \"{path}\" but found a {path_type_label(path)} instead.',\n                stacklevel=4,\n            )\n\n    return None, field_key, value_is_complex\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.TomlConfigSettingsSource","title":"TomlConfigSettingsSource","text":"<pre><code>TomlConfigSettingsSource(\n    settings_cls: type[BaseSettings],\n    toml_file: PathType | None = DEFAULT_PATH,\n)\n</code></pre> <p>               Bases: <code>InitSettingsSource</code>, <code>ConfigFileSourceMixin</code></p> <p>A source class that loads variables from a TOML file</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    toml_file: PathType | None = DEFAULT_PATH,\n):\n    self.toml_file_path = toml_file if toml_file != DEFAULT_PATH else settings_cls.model_config.get('toml_file')\n    self.toml_data = self._read_files(self.toml_file_path)\n    super().__init__(settings_cls, self.toml_data)\n</code></pre>"},{"location":"api/pydantic_settings/#pydantic_settings.YamlConfigSettingsSource","title":"YamlConfigSettingsSource","text":"<pre><code>YamlConfigSettingsSource(\n    settings_cls: type[BaseSettings],\n    yaml_file: PathType | None = DEFAULT_PATH,\n    yaml_file_encoding: str | None = None,\n)\n</code></pre> <p>               Bases: <code>InitSettingsSource</code>, <code>ConfigFileSourceMixin</code></p> <p>A source class that loads variables from a yaml file</p> Source code in <code>.venv/lib/python3.10/site-packages/pydantic_settings/sources.py</code> <pre><code>def __init__(\n    self,\n    settings_cls: type[BaseSettings],\n    yaml_file: PathType | None = DEFAULT_PATH,\n    yaml_file_encoding: str | None = None,\n):\n    self.yaml_file_path = yaml_file if yaml_file != DEFAULT_PATH else settings_cls.model_config.get('yaml_file')\n    self.yaml_file_encoding = (\n        yaml_file_encoding\n        if yaml_file_encoding is not None\n        else settings_cls.model_config.get('yaml_file_encoding')\n    )\n    self.yaml_data = self._read_files(self.yaml_file_path)\n    super().__init__(settings_cls, self.yaml_data)\n</code></pre>"},{"location":"api/root_model/","title":"RootModel","text":"<p>RootModel class and type definitions.</p>"},{"location":"api/root_model/#pydantic.root_model.RootModel","title":"RootModel","text":"<pre><code>RootModel(\n    root: RootModelRootType = PydanticUndefined, **data\n)\n</code></pre> <p>               Bases: <code>BaseModel</code>, <code>Generic[RootModelRootType]</code></p> <p>Usage Documentation</p> <p><code>RootModel</code> and custom root types</p> <p>A Pydantic <code>BaseModel</code> for the root object of the model.</p> <p>Attributes:</p> Name Type Description <code>root</code> <code>RootModelRootType</code> <p>The root object of the model.</p> <code>__pydantic_root_model__</code> <p>Whether the model is a RootModel.</p> <code>__pydantic_private__</code> <p>Private fields in the model.</p> <code>__pydantic_extra__</code> <p>Extra fields in the model.</p> Source code in <code>pydantic/root_model.py</code> <pre><code>def __init__(self, /, root: RootModelRootType = PydanticUndefined, **data) -&gt; None:  # type: ignore\n    __tracebackhide__ = True\n    if data:\n        if root is not PydanticUndefined:\n            raise ValueError(\n                '\"RootModel.__init__\" accepts either a single positional argument or arbitrary keyword arguments'\n            )\n        root = data  # type: ignore\n    self.__pydantic_validator__.validate_python(root, self_instance=self)\n</code></pre>"},{"location":"api/root_model/#pydantic.root_model.RootModel.model_construct","title":"model_construct  <code>classmethod</code>","text":"<pre><code>model_construct(\n    root: RootModelRootType,\n    _fields_set: set[str] | None = None,\n) -&gt; Self\n</code></pre> <p>Create a new model using the provided root object and update fields set.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>RootModelRootType</code> <p>The root object of the model.</p> required <code>_fields_set</code> <code>set[str] | None</code> <p>The set of fields to be updated.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The new model.</p> <p>Raises:</p> Type Description <code>NotImplemented</code> <p>If the model is not a subclass of <code>RootModel</code>.</p> Source code in <code>pydantic/root_model.py</code> <pre><code>@classmethod\ndef model_construct(cls, root: RootModelRootType, _fields_set: set[str] | None = None) -&gt; Self:  # type: ignore\n    \"\"\"Create a new model using the provided root object and update fields set.\n\n    Args:\n        root: The root object of the model.\n        _fields_set: The set of fields to be updated.\n\n    Returns:\n        The new model.\n\n    Raises:\n        NotImplemented: If the model is not a subclass of `RootModel`.\n    \"\"\"\n    return super().model_construct(root=root, _fields_set=_fields_set)\n</code></pre>"},{"location":"api/root_model/#pydantic.root_model.RootModel.model_dump","title":"model_dump","text":"<pre><code>model_dump(\n    *,\n    mode: Literal[\"json\", \"python\"] | str = \"python\",\n    include: Any = None,\n    exclude: Any = None,\n    context: dict[str, Any] | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: (\n        bool | Literal[\"none\", \"warn\", \"error\"]\n    ) = True,\n    serialize_as_any: bool = False\n) -&gt; Any\n</code></pre> <p>This method is included just to get a more accurate return type for type checkers. It is included in this <code>if TYPE_CHECKING:</code> block since no override is actually necessary.</p> <p>See the documentation of <code>BaseModel.model_dump</code> for more details about the arguments.</p> <p>Generally, this method will have a return type of <code>RootModelRootType</code>, assuming that <code>RootModelRootType</code> is not a <code>BaseModel</code> subclass. If <code>RootModelRootType</code> is a <code>BaseModel</code> subclass, then the return type will likely be <code>dict[str, Any]</code>, as <code>model_dump</code> calls are recursive. The return type could even be something different, in the case of a custom serializer. Thus, <code>Any</code> is used here to catch all of these cases.</p> Source code in <code>pydantic/root_model.py</code> <pre><code>def model_dump(  # type: ignore\n    self,\n    *,\n    mode: Literal['json', 'python'] | str = 'python',\n    include: Any = None,\n    exclude: Any = None,\n    context: dict[str, Any] | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool | Literal['none', 'warn', 'error'] = True,\n    serialize_as_any: bool = False,\n) -&gt; Any:\n    \"\"\"This method is included just to get a more accurate return type for type checkers.\n    It is included in this `if TYPE_CHECKING:` block since no override is actually necessary.\n\n    See the documentation of `BaseModel.model_dump` for more details about the arguments.\n\n    Generally, this method will have a return type of `RootModelRootType`, assuming that `RootModelRootType` is\n    not a `BaseModel` subclass. If `RootModelRootType` is a `BaseModel` subclass, then the return\n    type will likely be `dict[str, Any]`, as `model_dump` calls are recursive. The return type could\n    even be something different, in the case of a custom serializer.\n    Thus, `Any` is used here to catch all of these cases.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/standard_library_types/","title":"Standard Library Types","text":"<p>Pydantic supports many common types from the Python standard library. If you need stricter processing see Strict Types, including if you need to constrain the values allowed (e.g. to require a positive <code>int</code>).</p>"},{"location":"api/standard_library_types/#booleans","title":"Booleans","text":"<p>A standard <code>bool</code> field will raise a <code>ValidationError</code> if the value is not one of the following:</p> <ul> <li>A valid boolean (i.e. <code>True</code> or <code>False</code>),</li> <li>The integers <code>0</code> or <code>1</code>,</li> <li>a <code>str</code> which when converted to lower case is one of   <code>'0', 'off', 'f', 'false', 'n', 'no', '1', 'on', 't', 'true', 'y', 'yes'</code></li> <li>a <code>bytes</code> which is valid per the previous rule when decoded to <code>str</code></li> </ul> <p>Note</p> <p>If you want stricter boolean logic (e.g. a field which only permits <code>True</code> and <code>False</code>) you can use <code>StrictBool</code>.</p> <p>Here is a script demonstrating some of these behaviors:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass BooleanModel(BaseModel):\n    bool_value: bool\n\n\nprint(BooleanModel(bool_value=False))\n#&gt; bool_value=False\nprint(BooleanModel(bool_value='False'))\n#&gt; bool_value=False\nprint(BooleanModel(bool_value=1))\n#&gt; bool_value=True\ntry:\n    BooleanModel(bool_value=[])\nexcept ValidationError as e:\n    print(str(e))\n    \"\"\"\n    1 validation error for BooleanModel\n    bool_value\n      Input should be a valid boolean [type=bool_type, input_value=[], input_type=list]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#datetime-types","title":"Datetime Types","text":"<p>Pydantic supports the following datetime types:</p>"},{"location":"api/standard_library_types/#datetimedatetime","title":"<code>datetime.datetime</code>","text":"<ul> <li> <p><code>datetime</code> fields will accept values of type:</p> <ul> <li><code>datetime</code>; an existing <code>datetime</code> object</li> <li><code>int</code> or <code>float</code>; assumed as Unix time, i.e. seconds (if &gt;= <code>-2e10</code> and &lt;= <code>2e10</code>) or milliseconds   (if &lt; <code>-2e10</code>or &gt; <code>2e10</code>) since 1 January 1970</li> <li><code>str</code>; the following formats are accepted:<ul> <li><code>YYYY-MM-DD[T]HH:MM[:SS[.ffffff]][Z or [\u00b1]HH[:]MM]</code></li> <li><code>YYYY-MM-DD</code> is accepted in lax mode, but not in strict mode</li> <li><code>int</code> or <code>float</code> as a string (assumed as Unix time)</li> </ul> </li> <li><code>datetime.date</code> instances are accepted in lax mode, but not in strict mode</li> </ul> </li> </ul> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel\n\n\nclass Event(BaseModel):\n    dt: datetime = None\n\n\nevent = Event(dt='2032-04-23T10:20:30.400+02:30')\n\nprint(event.model_dump())\n\"\"\"\n{'dt': datetime.datetime(2032, 4, 23, 10, 20, 30, 400000, tzinfo=TzInfo(+02:30))}\n\"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#datetimedate","title":"<code>datetime.date</code>","text":"<ul> <li> <p><code>date</code> fields will accept values of type:</p> <ul> <li><code>date</code>; an existing <code>date</code> object</li> <li><code>int</code> or <code>float</code>; handled the same as described for <code>datetime</code> above</li> <li><code>str</code>; the following formats are accepted:<ul> <li><code>YYYY-MM-DD</code></li> <li><code>int</code> or <code>float</code> as a string (assumed as Unix time)</li> </ul> </li> </ul> </li> </ul> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel\n\n\nclass Birthday(BaseModel):\n    d: date = None\n\n\nmy_birthday = Birthday(d=1679616000.0)\n\nprint(my_birthday.model_dump())\n#&gt; {'d': datetime.date(2023, 3, 24)}\n</code></pre>"},{"location":"api/standard_library_types/#datetimetime","title":"<code>datetime.time</code>","text":"<ul> <li> <p><code>time</code> fields will accept values of type:</p> <ul> <li><code>time</code>; an existing <code>time</code> object</li> <li><code>str</code>; the following formats are accepted:<ul> <li><code>HH:MM[:SS[.ffffff]][Z or [\u00b1]HH[:]MM]</code></li> </ul> </li> </ul> </li> </ul> <pre><code>from datetime import time\n\nfrom pydantic import BaseModel\n\n\nclass Meeting(BaseModel):\n    t: time = None\n\n\nm = Meeting(t=time(4, 8, 16))\n\nprint(m.model_dump())\n#&gt; {'t': datetime.time(4, 8, 16)}\n</code></pre>"},{"location":"api/standard_library_types/#datetimetimedelta","title":"<code>datetime.timedelta</code>","text":"<ul> <li> <p><code>timedelta</code> fields will accept values of type:</p> <ul> <li><code>timedelta</code>; an existing <code>timedelta</code> object</li> <li><code>int</code> or <code>float</code>; assumed to be seconds</li> <li><code>str</code>; the following formats are accepted:<ul> <li><code>[-][DD]D[,][HH:MM:]SS[.ffffff]</code><ul> <li>Ex: <code>'1d,01:02:03.000004'</code> or <code>'1D01:02:03.000004'</code> or <code>'01:02:03'</code></li> </ul> </li> <li><code>[\u00b1]P[DD]DT[HH]H[MM]M[SS]S</code> (ISO 8601 format for timedelta)</li> </ul> </li> </ul> </li> </ul> <pre><code>from datetime import timedelta\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    td: timedelta = None\n\n\nm = Model(td='P3DT12H30M5S')\n\nprint(m.model_dump())\n#&gt; {'td': datetime.timedelta(days=3, seconds=45005)}\n</code></pre>"},{"location":"api/standard_library_types/#number-types","title":"Number Types","text":"<p>Pydantic supports the following numeric types from the Python standard library:</p>"},{"location":"api/standard_library_types/#int","title":"<code>int</code>","text":"<ul> <li>Pydantic uses <code>int(v)</code> to coerce types to an <code>int</code>;   see Data conversion for details on loss of information during data conversion.</li> </ul>"},{"location":"api/standard_library_types/#float","title":"<code>float</code>","text":"<ul> <li>Pydantic uses <code>float(v)</code> to coerce values to floats.</li> </ul>"},{"location":"api/standard_library_types/#enumintenum","title":"<code>enum.IntEnum</code>","text":"<ul> <li>Validation: Pydantic checks that the value is a valid <code>IntEnum</code> instance.</li> <li>Validation for subclass of <code>enum.IntEnum</code>: checks that the value is a valid member of the integer enum;   see Enums and Choices for more details.</li> </ul>"},{"location":"api/standard_library_types/#decimaldecimal","title":"<code>decimal.Decimal</code>","text":"<ul> <li>Validation: Pydantic attempts to convert the value to a string, then passes the string to <code>Decimal(v)</code>.</li> <li>Serialization: Pydantic serializes <code>Decimal</code> types as strings. You can use a custom serializer to override this behavior if desired. For example:</li> </ul> <pre><code>from decimal import Decimal\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, PlainSerializer\n\n\nclass Model(BaseModel):\n    x: Decimal\n    y: Annotated[\n        Decimal,\n        PlainSerializer(\n            lambda x: float(x), return_type=float, when_used='json'\n        ),\n    ]\n\n\nmy_model = Model(x=Decimal('1.1'), y=Decimal('2.1'))\n\nprint(my_model.model_dump())  # (1)!\n#&gt; {'x': Decimal('1.1'), 'y': Decimal('2.1')}\nprint(my_model.model_dump(mode='json'))  # (2)!\n#&gt; {'x': '1.1', 'y': 2.1}\nprint(my_model.model_dump_json())  # (3)!\n#&gt; {\"x\":\"1.1\",\"y\":2.1}\n</code></pre> <ol> <li>Using <code>model_dump</code>, both <code>x</code> and <code>y</code> remain instances of the <code>Decimal</code> type</li> <li>Using <code>model_dump</code> with <code>mode='json'</code>, <code>x</code> is serialized as a <code>string</code>, and <code>y</code> is serialized as a <code>float</code> because of the custom serializer applied.</li> <li>Using <code>model_dump_json</code>, <code>x</code> is serialized as a <code>string</code>, and <code>y</code> is serialized as a <code>float</code> because of the custom serializer applied.</li> </ol>"},{"location":"api/standard_library_types/#enum","title":"<code>Enum</code>","text":"<p>Pydantic uses Python's standard <code>enum</code> classes to define choices.</p> <p><code>enum.Enum</code> checks that the value is a valid <code>Enum</code> instance. Subclass of <code>enum.Enum</code> checks that the value is a valid member of the enum.</p> <pre><code>from enum import Enum, IntEnum\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass FruitEnum(str, Enum):\n    pear = 'pear'\n    banana = 'banana'\n\n\nclass ToolEnum(IntEnum):\n    spanner = 1\n    wrench = 2\n\n\nclass CookingModel(BaseModel):\n    fruit: FruitEnum = FruitEnum.pear\n    tool: ToolEnum = ToolEnum.spanner\n\n\nprint(CookingModel())\n#&gt; fruit=&lt;FruitEnum.pear: 'pear'&gt; tool=&lt;ToolEnum.spanner: 1&gt;\nprint(CookingModel(tool=2, fruit='banana'))\n#&gt; fruit=&lt;FruitEnum.banana: 'banana'&gt; tool=&lt;ToolEnum.wrench: 2&gt;\ntry:\n    CookingModel(fruit='other')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for CookingModel\n    fruit\n      Input should be 'pear' or 'banana' [type=enum, input_value='other', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#lists-and-tuples","title":"Lists and Tuples","text":""},{"location":"api/standard_library_types/#list","title":"<code>list</code>","text":"<p>Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a <code>list</code>. When a generic parameter is provided, the appropriate validation is applied to all items of the list.</p>"},{"location":"api/standard_library_types/#typinglist","title":"<code>typing.List</code>","text":"<p>Handled the same as <code>list</code> above.</p> <pre><code>from typing import List, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_list: Optional[list] = None\n    list_of_ints: Optional[List[int]] = None\n\n\nprint(Model(simple_list=['1', '2', '3']).simple_list)\n#&gt; ['1', '2', '3']\nprint(Model(list_of_ints=['1', '2', '3']).list_of_ints)\n#&gt; [1, 2, 3]\n</code></pre>"},{"location":"api/standard_library_types/#tuple","title":"<code>tuple</code>","text":"<p>Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a <code>tuple</code>. When generic parameters are provided, the appropriate validation is applied to the respective items of the tuple</p>"},{"location":"api/standard_library_types/#typingtuple","title":"<code>typing.Tuple</code>","text":"<p>Handled the same as <code>tuple</code> above.</p> <pre><code>from typing import Optional, Tuple\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_tuple: Optional[tuple] = None\n    tuple_of_different_types: Optional[Tuple[int, float, bool]] = None\n\n\nprint(Model(simple_tuple=[1, 2, 3, 4]).simple_tuple)\n#&gt; (1, 2, 3, 4)\nprint(Model(tuple_of_different_types=[3, 2, 1]).tuple_of_different_types)\n#&gt; (3, 2.0, True)\n</code></pre>"},{"location":"api/standard_library_types/#typingnamedtuple","title":"<code>typing.NamedTuple</code>","text":"<p>Subclasses of <code>typing.NamedTuple</code> are similar to <code>tuple</code>, but create instances of the given <code>namedtuple</code> class.</p> <p>Subclasses of <code>collections.namedtuple</code> are similar to subclass of <code>typing.NamedTuple</code>, but since field types are not specified, all fields are treated as having type <code>Any</code>.</p> <pre><code>from typing import NamedTuple\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Point(NamedTuple):\n    x: int\n    y: int\n\n\nclass Model(BaseModel):\n    p: Point\n\n\ntry:\n    Model(p=('1.3', '2'))\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    p.0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='1.3', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#deque","title":"Deque","text":""},{"location":"api/standard_library_types/#deque_1","title":"<code>deque</code>","text":"<p>Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a <code>deque</code>. When generic parameters are provided, the appropriate validation is applied to the respective items of the <code>deque</code>.</p>"},{"location":"api/standard_library_types/#typingdeque","title":"<code>typing.Deque</code>","text":"<p>Handled the same as <code>deque</code> above.</p> <pre><code>from typing import Deque, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    deque: Optional[Deque[int]] = None\n\n\nprint(Model(deque=[1, 2, 3]).deque)\n#&gt; deque([1, 2, 3])\n</code></pre>"},{"location":"api/standard_library_types/#sets","title":"Sets","text":""},{"location":"api/standard_library_types/#set","title":"<code>set</code>","text":"<p>Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a <code>set</code>. When a generic parameter is provided, the appropriate validation is applied to all items of the set.</p>"},{"location":"api/standard_library_types/#typingset","title":"<code>typing.Set</code>","text":"<p>Handled the same as <code>set</code> above.</p> <pre><code>from typing import Optional, Set\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_set: Optional[set] = None\n    set_of_ints: Optional[Set[int]] = None\n\n\nprint(Model(simple_set={'1', '2', '3'}).simple_set)\n#&gt; {'1', '2', '3'}\nprint(Model(simple_set=['1', '2', '3']).simple_set)\n#&gt; {'1', '2', '3'}\nprint(Model(set_of_ints=['1', '2', '3']).set_of_ints)\n#&gt; {1, 2, 3}\n</code></pre>"},{"location":"api/standard_library_types/#frozenset","title":"<code>frozenset</code>","text":"<p>Allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a <code>frozenset</code>. When a generic parameter is provided, the appropriate validation is applied to all items of the frozen set.</p>"},{"location":"api/standard_library_types/#typingfrozenset","title":"<code>typing.FrozenSet</code>","text":"<p>Handled the same as <code>frozenset</code> above.</p> <pre><code>from typing import FrozenSet, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    simple_frozenset: Optional[frozenset] = None\n    frozenset_of_ints: Optional[FrozenSet[int]] = None\n\n\nm1 = Model(simple_frozenset=['1', '2', '3'])\nprint(type(m1.simple_frozenset))\n#&gt; &lt;class 'frozenset'&gt;\nprint(sorted(m1.simple_frozenset))\n#&gt; ['1', '2', '3']\n\nm2 = Model(frozenset_of_ints=['1', '2', '3'])\nprint(type(m2.frozenset_of_ints))\n#&gt; &lt;class 'frozenset'&gt;\nprint(sorted(m2.frozenset_of_ints))\n#&gt; [1, 2, 3]\n</code></pre>"},{"location":"api/standard_library_types/#other-iterables","title":"Other Iterables","text":""},{"location":"api/standard_library_types/#typingsequence","title":"<code>typing.Sequence</code>","text":"<p>This is intended for use when the provided value should meet the requirements of the <code>Sequence</code> ABC, and it is desirable to do eager validation of the values in the container. Note that when validation must be performed on the values of the container, the type of the container may not be preserved since validation may end up replacing values. We guarantee that the validated value will be a valid <code>typing.Sequence</code>, but it may have a different type than was provided (generally, it will become a <code>list</code>).</p>"},{"location":"api/standard_library_types/#typingiterable","title":"<code>typing.Iterable</code>","text":"<p>This is intended for use when the provided value may be an iterable that shouldn't be consumed. See Infinite Generators below for more detail on parsing and validation. Similar to <code>typing.Sequence</code>, we guarantee that the validated result will be a valid <code>typing.Iterable</code>, but it may have a different type than was provided. In particular, even if a non-generator type such as a <code>list</code> is provided, the post-validation value of a field of type <code>typing.Iterable</code> will be a generator.</p> <p>Here is a simple example using <code>typing.Sequence</code>:</p> <pre><code>from typing import Sequence\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    sequence_of_ints: Sequence[int] = None\n\n\nprint(Model(sequence_of_ints=[1, 2, 3, 4]).sequence_of_ints)\n#&gt; [1, 2, 3, 4]\nprint(Model(sequence_of_ints=(1, 2, 3, 4)).sequence_of_ints)\n#&gt; (1, 2, 3, 4)\n</code></pre>"},{"location":"api/standard_library_types/#infinite-generators","title":"Infinite Generators","text":"<p>If you have a generator you want to validate, you can still use <code>Sequence</code> as described above. In that case, the generator will be consumed and stored on the model as a list and its values will be validated against the type parameter of the <code>Sequence</code> (e.g. <code>int</code> in <code>Sequence[int]</code>).</p> <p>However, if you have a generator that you don't want to be eagerly consumed (e.g. an infinite generator or a remote data loader), you can use a field of type <code>Iterable</code>:</p> <pre><code>from typing import Iterable\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    infinite: Iterable[int]\n\n\ndef infinite_ints():\n    i = 0\n    while True:\n        yield i\n        i += 1\n\n\nm = Model(infinite=infinite_ints())\nprint(m)\n\"\"\"\ninfinite=ValidatorIterator(index=0, schema=Some(Int(IntValidator { strict: false })))\n\"\"\"\n\nfor i in m.infinite:\n    print(i)\n    #&gt; 0\n    #&gt; 1\n    #&gt; 2\n    #&gt; 3\n    #&gt; 4\n    #&gt; 5\n    #&gt; 6\n    #&gt; 7\n    #&gt; 8\n    #&gt; 9\n    #&gt; 10\n    if i == 10:\n        break\n</code></pre> <p>Warning</p> <p>During initial validation, <code>Iterable</code> fields only perform a simple check that the provided argument is iterable. To prevent it from being consumed, no validation of the yielded values is performed eagerly.</p> <p>Though the yielded values are not validated eagerly, they are still validated when yielded, and will raise a <code>ValidationError</code> at yield time when appropriate:</p> <pre><code>from typing import Iterable\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    int_iterator: Iterable[int]\n\n\ndef my_iterator():\n    yield 13\n    yield '27'\n    yield 'a'\n\n\nm = Model(int_iterator=my_iterator())\nprint(next(m.int_iterator))\n#&gt; 13\nprint(next(m.int_iterator))\n#&gt; 27\ntry:\n    next(m.int_iterator)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for ValidatorIterator\n    2\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#mapping-types","title":"Mapping Types","text":""},{"location":"api/standard_library_types/#dict","title":"<code>dict</code>","text":"<p><code>dict(v)</code> is used to attempt to convert a dictionary. see <code>typing.Dict</code> below for sub-type constraints.</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: dict\n\n\nm = Model(x={'foo': 1})\nprint(m.model_dump())\n#&gt; {'x': {'foo': 1}}\n\ntry:\n    Model(x='test')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    x\n      Input should be a valid dictionary [type=dict_type, input_value='test', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#typingdict","title":"<code>typing.Dict</code>","text":"<pre><code>from typing import Dict\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: Dict[str, int]\n\n\nm = Model(x={'foo': 1})\nprint(m.model_dump())\n#&gt; {'x': {'foo': 1}}\n\ntry:\n    Model(x={'foo': '1'})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    x\n      Input should be a valid dictionary [type=dict_type, input_value='test', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#typeddict","title":"TypedDict","text":"<p>Note</p> <p>This is a new feature of the Python standard library as of Python 3.8. Because of limitations in typing.TypedDict before 3.12, the typing-extensions package is required for Python &lt;3.12. You'll need to import <code>TypedDict</code> from <code>typing_extensions</code> instead of <code>typing</code> and will get a build time error if you don't.</p> <p><code>TypedDict</code> declares a dictionary type that expects all of its instances to have a certain set of keys, where each key is associated with a value of a consistent type.</p> <p>It is same as <code>dict</code> but Pydantic will validate the dictionary since keys are annotated.</p> <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import TypeAdapter, ValidationError\n\n\nclass User(TypedDict):\n    name: str\n    id: int\n\n\nta = TypeAdapter(User)\n\nprint(ta.validate_python({'name': 'foo', 'id': 1}))\n#&gt; {'name': 'foo', 'id': 1}\n\ntry:\n    ta.validate_python({'name': 'foo'})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for typed-dict\n    id\n      Field required [type=missing, input_value={'name': 'foo'}, input_type=dict]\n    \"\"\"\n</code></pre> <p>You can define <code>__pydantic_config__</code> to change the model inherited from <code>TypedDict</code>. See the <code>ConfigDict</code> API reference for more details.</p> <pre><code>from typing import Optional\n\nfrom typing_extensions import TypedDict\n\nfrom pydantic import ConfigDict, TypeAdapter, ValidationError\n\n\n# `total=False` means keys are non-required\nclass UserIdentity(TypedDict, total=False):\n    name: Optional[str]\n    surname: str\n\n\nclass User(TypedDict):\n    __pydantic_config__ = ConfigDict(extra='forbid')\n\n    identity: UserIdentity\n    age: int\n\n\nta = TypeAdapter(User)\n\nprint(\n    ta.validate_python(\n        {'identity': {'name': 'Smith', 'surname': 'John'}, 'age': 37}\n    )\n)\n#&gt; {'identity': {'name': 'Smith', 'surname': 'John'}, 'age': 37}\n\nprint(\n    ta.validate_python(\n        {'identity': {'name': None, 'surname': 'John'}, 'age': 37}\n    )\n)\n#&gt; {'identity': {'name': None, 'surname': 'John'}, 'age': 37}\n\nprint(ta.validate_python({'identity': {}, 'age': 37}))\n#&gt; {'identity': {}, 'age': 37}\n\n\ntry:\n    ta.validate_python(\n        {'identity': {'name': ['Smith'], 'surname': 'John'}, 'age': 24}\n    )\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for typed-dict\n    identity.name\n      Input should be a valid string [type=string_type, input_value=['Smith'], input_type=list]\n    \"\"\"\n\ntry:\n    ta.validate_python(\n        {\n            'identity': {'name': 'Smith', 'surname': 'John'},\n            'age': '37',\n            'email': 'john.smith@me.com',\n        }\n    )\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for typed-dict\n    email\n      Extra inputs are not permitted [type=extra_forbidden, input_value='john.smith@me.com', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#callable","title":"Callable","text":"<p>See below for more detail on parsing and validation</p> <p>Fields can also be of type <code>Callable</code>:</p> <pre><code>from typing import Callable\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    callback: Callable[[int], int]\n\n\nm = Foo(callback=lambda x: x)\nprint(m)\n#&gt; callback=&lt;function &lt;lambda&gt; at 0x0123456789ab&gt;\n</code></pre> <p>Warning</p> <p>Callable fields only perform a simple check that the argument is callable; no validation of arguments, their types, or the return type is performed.</p>"},{"location":"api/standard_library_types/#ip-address-types","title":"IP Address Types","text":"<ul> <li><code>ipaddress.IPv4Address</code>: Uses the type itself for validation by passing the value to <code>IPv4Address(v)</code>.</li> <li><code>ipaddress.IPv4Interface</code>: Uses the type itself for validation by passing the value to <code>IPv4Address(v)</code>.</li> <li><code>ipaddress.IPv4Network</code>: Uses the type itself for validation by passing the value to <code>IPv4Network(v)</code>.</li> <li><code>ipaddress.IPv6Address</code>: Uses the type itself for validation by passing the value to <code>IPv6Address(v)</code>.</li> <li><code>ipaddress.IPv6Interface</code>: Uses the type itself for validation by passing the value to <code>IPv6Interface(v)</code>.</li> <li><code>ipaddress.IPv6Network</code>: Uses the type itself for validation by passing the value to <code>IPv6Network(v)</code>.</li> </ul> <p>See Network Types for other custom IP address types.</p>"},{"location":"api/standard_library_types/#uuid","title":"UUID","text":"<p>For UUID, Pydantic tries to use the type itself for validation by passing the value to <code>UUID(v)</code>. There's a fallback to <code>UUID(bytes=v)</code> for <code>bytes</code> and <code>bytearray</code>.</p> <p>In case you want to constrain the UUID version, you can check the following types:</p> <ul> <li><code>UUID1</code>: requires UUID version 1.</li> <li><code>UUID3</code>: requires UUID version 3.</li> <li><code>UUID4</code>: requires UUID version 4.</li> <li><code>UUID5</code>: requires UUID version 5.</li> </ul>"},{"location":"api/standard_library_types/#union","title":"Union","text":"<p>Pydantic has extensive support for union validation, both <code>typing.Union</code> and Python 3.10's pipe syntax (<code>A | B</code>) are supported. Read more in the <code>Unions</code> section of the concepts docs.</p>"},{"location":"api/standard_library_types/#type-and-typevar","title":"<code>Type</code> and <code>TypeVar</code>","text":""},{"location":"api/standard_library_types/#type","title":"<code>type</code>","text":"<p>Pydantic supports the use of <code>type[T]</code> to specify that a field may only accept classes (not instances) that are subclasses of <code>T</code>.</p>"},{"location":"api/standard_library_types/#typingtype","title":"<code>typing.Type</code>","text":"<p>Handled the same as <code>type</code> above.</p> <pre><code>from typing import Type\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Foo:\n    pass\n\n\nclass Bar(Foo):\n    pass\n\n\nclass Other:\n    pass\n\n\nclass SimpleModel(BaseModel):\n    just_subclasses: Type[Foo]\n\n\nSimpleModel(just_subclasses=Foo)\nSimpleModel(just_subclasses=Bar)\ntry:\n    SimpleModel(just_subclasses=Other)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for SimpleModel\n    just_subclasses\n      Input should be a subclass of Foo [type=is_subclass_of, input_value=&lt;class '__main__.Other'&gt;, input_type=type]\n    \"\"\"\n</code></pre> <p>You may also use <code>Type</code> to specify that any class is allowed.</p> <pre><code>from typing import Type\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Foo:\n    pass\n\n\nclass LenientSimpleModel(BaseModel):\n    any_class_goes: Type\n\n\nLenientSimpleModel(any_class_goes=int)\nLenientSimpleModel(any_class_goes=Foo)\ntry:\n    LenientSimpleModel(any_class_goes=Foo())\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for LenientSimpleModel\n    any_class_goes\n      Input should be a type [type=is_type, input_value=&lt;__main__.Foo object at 0x0123456789ab&gt;, input_type=Foo]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#typingtypevar","title":"<code>typing.TypeVar</code>","text":"<p><code>TypeVar</code> is supported either unconstrained, constrained or with a bound.</p> <pre><code>from typing import TypeVar\n\nfrom pydantic import BaseModel\n\nFoobar = TypeVar('Foobar')\nBoundFloat = TypeVar('BoundFloat', bound=float)\nIntStr = TypeVar('IntStr', int, str)\n\n\nclass Model(BaseModel):\n    a: Foobar  # equivalent of \": Any\"\n    b: BoundFloat  # equivalent of \": float\"\n    c: IntStr  # equivalent of \": Union[int, str]\"\n\n\nprint(Model(a=[1], b=4.2, c='x'))\n#&gt; a=[1] b=4.2 c='x'\n\n# a may be None\nprint(Model(a=None, b=1, c=1))\n#&gt; a=None b=1.0 c=1\n</code></pre>"},{"location":"api/standard_library_types/#none-types","title":"None Types","text":"<p><code>None</code>, <code>type(None)</code>, or <code>Literal[None]</code> are all equivalent according to the typing specification. Allows only <code>None</code> value.</p>"},{"location":"api/standard_library_types/#strings","title":"Strings","text":"<p><code>str</code>: Strings are accepted as-is. <code>bytes</code> and <code>bytearray</code> are converted using <code>v.decode()</code>. Enum<code>s inheriting from</code>str<code>are converted using</code>v.value`. All other types cause an error.</p> <p>Strings aren't Sequences</p> <p>While instances of <code>str</code> are technically valid instances of the <code>Sequence[str]</code> protocol from a type-checker's point of view, this is frequently not intended as is a common source of bugs.</p> <p>As a result, Pydantic raises a <code>ValidationError</code> if you attempt to pass a <code>str</code> or <code>bytes</code> instance into a field of type <code>Sequence[str]</code> or <code>Sequence[bytes]</code>:</p> <pre><code>from typing import Optional, Sequence\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    sequence_of_strs: Optional[Sequence[str]] = None\n    sequence_of_bytes: Optional[Sequence[bytes]] = None\n\n\nprint(Model(sequence_of_strs=['a', 'bc']).sequence_of_strs)\n#&gt; ['a', 'bc']\nprint(Model(sequence_of_strs=('a', 'bc')).sequence_of_strs)\n#&gt; ('a', 'bc')\nprint(Model(sequence_of_bytes=[b'a', b'bc']).sequence_of_bytes)\n#&gt; [b'a', b'bc']\nprint(Model(sequence_of_bytes=(b'a', b'bc')).sequence_of_bytes)\n#&gt; (b'a', b'bc')\n\n\ntry:\n    Model(sequence_of_strs='abc')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    sequence_of_strs\n      'str' instances are not allowed as a Sequence value [type=sequence_str, input_value='abc', input_type=str]\n    \"\"\"\ntry:\n    Model(sequence_of_bytes=b'abc')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    sequence_of_bytes\n      'bytes' instances are not allowed as a Sequence value [type=sequence_str, input_value=b'abc', input_type=bytes]\n    \"\"\"\n</code></pre>"},{"location":"api/standard_library_types/#bytes","title":"Bytes","text":"<p><code>bytes</code> are accepted as-is. <code>bytearray</code> is converted using <code>bytes(v)</code>. <code>str</code> are converted using <code>v.encode()</code>. <code>int</code>, <code>float</code>, and <code>Decimal</code> are coerced using <code>str(v).encode()</code>. See ByteSize for more details.</p>"},{"location":"api/standard_library_types/#typingliteral","title":"<code>typing.Literal</code>","text":"<p>Pydantic supports the use of <code>typing.Literal</code> as a lightweight way to specify that a field may accept only specific literal values:</p> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Pie(BaseModel):\n    flavor: Literal['apple', 'pumpkin']\n\n\nPie(flavor='apple')\nPie(flavor='pumpkin')\ntry:\n    Pie(flavor='cherry')\nexcept ValidationError as e:\n    print(str(e))\n    \"\"\"\n    1 validation error for Pie\n    flavor\n      Input should be 'apple' or 'pumpkin' [type=literal_error, input_value='cherry', input_type=str]\n    \"\"\"\n</code></pre> <p>One benefit of this field type is that it can be used to check for equality with one or more specific values without needing to declare custom validators:</p> <pre><code>from typing import ClassVar, List, Literal, Union\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Cake(BaseModel):\n    kind: Literal['cake']\n    required_utensils: ClassVar[List[str]] = ['fork', 'knife']\n\n\nclass IceCream(BaseModel):\n    kind: Literal['icecream']\n    required_utensils: ClassVar[List[str]] = ['spoon']\n\n\nclass Meal(BaseModel):\n    dessert: Union[Cake, IceCream]\n\n\nprint(type(Meal(dessert={'kind': 'cake'}).dessert).__name__)\n#&gt; Cake\nprint(type(Meal(dessert={'kind': 'icecream'}).dessert).__name__)\n#&gt; IceCream\ntry:\n    Meal(dessert={'kind': 'pie'})\nexcept ValidationError as e:\n    print(str(e))\n    \"\"\"\n    2 validation errors for Meal\n    dessert.Cake.kind\n      Input should be 'cake' [type=literal_error, input_value='pie', input_type=str]\n    dessert.IceCream.kind\n      Input should be 'icecream' [type=literal_error, input_value='pie', input_type=str]\n    \"\"\"\n</code></pre> <p>With proper ordering in an annotated <code>Union</code>, you can use this to parse types of decreasing specificity:</p> <pre><code>from typing import Literal, Optional, Union\n\nfrom pydantic import BaseModel\n\n\nclass Dessert(BaseModel):\n    kind: str\n\n\nclass Pie(Dessert):\n    kind: Literal['pie']\n    flavor: Optional[str]\n\n\nclass ApplePie(Pie):\n    flavor: Literal['apple']\n\n\nclass PumpkinPie(Pie):\n    flavor: Literal['pumpkin']\n\n\nclass Meal(BaseModel):\n    dessert: Union[ApplePie, PumpkinPie, Pie, Dessert]\n\n\nprint(type(Meal(dessert={'kind': 'pie', 'flavor': 'apple'}).dessert).__name__)\n#&gt; ApplePie\nprint(type(Meal(dessert={'kind': 'pie', 'flavor': 'pumpkin'}).dessert).__name__)\n#&gt; PumpkinPie\nprint(type(Meal(dessert={'kind': 'pie'}).dessert).__name__)\n#&gt; Dessert\nprint(type(Meal(dessert={'kind': 'cake'}).dessert).__name__)\n#&gt; Dessert\n</code></pre>"},{"location":"api/standard_library_types/#typingany","title":"<code>typing.Any</code>","text":"<p>Allows any value, including <code>None</code>.</p>"},{"location":"api/standard_library_types/#typingannotated","title":"<code>typing.Annotated</code>","text":"<p>Allows wrapping another type with arbitrary metadata, as per PEP-593. The <code>Annotated</code> hint may contain a single call to the <code>Field</code> function, but otherwise the additional metadata is ignored and the root type is used.</p>"},{"location":"api/standard_library_types/#typingpattern","title":"<code>typing.Pattern</code>","text":"<p>Will cause the input value to be passed to <code>re.compile(v)</code> to create a regular expression pattern.</p>"},{"location":"api/standard_library_types/#pathlibpath","title":"<code>pathlib.Path</code>","text":"<p>Simply uses the type itself for validation by passing the value to <code>Path(v)</code>.</p>"},{"location":"api/type_adapter/","title":"TypeAdapter","text":"<p>               Bases: <code>Generic[T]</code></p> <p>Usage Documentation</p> <p>Type Adapter</p> <p>Type adapters provide a flexible way to perform validation and serialization based on a Python type.</p> <p>A <code>TypeAdapter</code> instance exposes some of the functionality from <code>BaseModel</code> instance methods for types that do not have such methods (such as dataclasses, primitive types, and more).</p> <p>Note: <code>TypeAdapter</code> instances are not types, and cannot be used as type annotations for fields.</p> <p>Note: By default, <code>TypeAdapter</code> does not respect the <code>defer_build=True</code> setting in the <code>model_config</code> or in the <code>TypeAdapter</code> constructor <code>config</code>. You need to also explicitly set <code>experimental_defer_build_mode=('model', 'type_adapter')</code> of the config to defer the model validator and serializer construction. Thus, this feature is opt-in to ensure backwards compatibility.</p> <p>Attributes:</p> Name Type Description <code>core_schema</code> <code>CoreSchema</code> <p>The core schema for the type.</p> <code>validator</code> <code>SchemaValidator</code> <p>The schema validator for the type.</p> <code>serializer</code> <code>SchemaSerializer</code> <p>The schema serializer for the type.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Any</code> <p>The type associated with the <code>TypeAdapter</code>.</p> required <code>config</code> <code>ConfigDict | None</code> <p>Configuration for the <code>TypeAdapter</code>, should be a dictionary conforming to <code>ConfigDict</code>.</p> <code>None</code> <code>_parent_depth</code> <code>int</code> <p>depth at which to search the parent namespace to construct the local namespace.</p> <code>2</code> <code>module</code> <code>str | None</code> <p>The module that passes to plugin if provided.</p> <code>None</code> <p>Note</p> <p>You cannot use the <code>config</code> argument when instantiating a <code>TypeAdapter</code> if the type you're using has its own config that cannot be overridden (ex: <code>BaseModel</code>, <code>TypedDict</code>, and <code>dataclass</code>). A <code>type-adapter-config-unused</code> error will be raised in this case.</p> <p>Note</p> <p>The <code>_parent_depth</code> argument is named with an underscore to suggest its private nature and discourage use. It may be deprecated in a minor version, so we only recommend using it if you're comfortable with potential change in behavior / support.</p> Compatibility with <code>mypy</code> <p>Depending on the type used, <code>mypy</code> might raise an error when instantiating a <code>TypeAdapter</code>. As a workaround, you can explicitly annotate your variable:</p> <pre><code>from typing import Union\n\nfrom pydantic import TypeAdapter\n\nta: TypeAdapter[Union[str, int]] = TypeAdapter(Union[str, int])  # type: ignore[arg-type]\n</code></pre> <p>Returns:</p> Type Description <code>None</code> <p>A type adapter configured for the specified <code>type</code>.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>def __init__(\n    self,\n    type: Any,\n    *,\n    config: ConfigDict | None = None,\n    _parent_depth: int = 2,\n    module: str | None = None,\n) -&gt; None:\n    \"\"\"Initializes the TypeAdapter object.\n\n    Args:\n        type: The type associated with the `TypeAdapter`.\n        config: Configuration for the `TypeAdapter`, should be a dictionary conforming to [`ConfigDict`][pydantic.config.ConfigDict].\n        _parent_depth: depth at which to search the parent namespace to construct the local namespace.\n        module: The module that passes to plugin if provided.\n\n    !!! note\n        You cannot use the `config` argument when instantiating a `TypeAdapter` if the type you're using has its own\n        config that cannot be overridden (ex: `BaseModel`, `TypedDict`, and `dataclass`). A\n        [`type-adapter-config-unused`](../errors/usage_errors.md#type-adapter-config-unused) error will be raised in this case.\n\n    !!! note\n        The `_parent_depth` argument is named with an underscore to suggest its private nature and discourage use.\n        It may be deprecated in a minor version, so we only recommend using it if you're\n        comfortable with potential change in behavior / support.\n\n    ??? tip \"Compatibility with `mypy`\"\n        Depending on the type used, `mypy` might raise an error when instantiating a `TypeAdapter`. As a workaround, you can explicitly\n        annotate your variable:\n\n        ```py\n        from typing import Union\n\n        from pydantic import TypeAdapter\n\n        ta: TypeAdapter[Union[str, int]] = TypeAdapter(Union[str, int])  # type: ignore[arg-type]\n        ```\n\n    Returns:\n        A type adapter configured for the specified `type`.\n    \"\"\"\n    if _type_has_config(type) and config is not None:\n        raise PydanticUserError(\n            'Cannot use `config` when the type is a BaseModel, dataclass or TypedDict.'\n            ' These types can have their own config and setting the config via the `config`'\n            ' parameter to TypeAdapter will not override it, thus the `config` you passed to'\n            ' TypeAdapter becomes meaningless, which is probably not what you want.',\n            code='type-adapter-config-unused',\n        )\n\n    self._type = type\n    self._config = config\n    self._parent_depth = _parent_depth\n    if module is None:\n        f = sys._getframe(1)\n        self._module_name = cast(str, f.f_globals.get('__name__', ''))\n    else:\n        self._module_name = module\n\n    self._core_schema: CoreSchema | None = None\n    self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n    self._serializer: SchemaSerializer | None = None\n\n    if not self._defer_build():\n        # Immediately initialize the core schema, validator and serializer\n        with self._with_frame_depth(1):  # +1 frame depth for this __init__\n            # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n            # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n            self._init_core_attrs(rebuild_mocks=False)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.core_schema","title":"core_schema  <code>cached</code> <code>property</code>","text":"<pre><code>core_schema: CoreSchema\n</code></pre> <p>The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.</p>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.validator","title":"validator  <code>cached</code> <code>property</code>","text":"<pre><code>validator: SchemaValidator | PluggableSchemaValidator\n</code></pre> <p>The pydantic-core SchemaValidator used to validate instances of the model.</p>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.serializer","title":"serializer  <code>cached</code> <code>property</code>","text":"<pre><code>serializer: SchemaSerializer\n</code></pre> <p>The pydantic-core SchemaSerializer used to dump instances of the model.</p>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.validate_python","title":"validate_python","text":"<pre><code>validate_python(\n    object: Any,\n    /,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: dict[str, Any] | None = None,\n) -&gt; T\n</code></pre> <p>Validate a Python object against the model.</p> <p>Parameters:</p> Name Type Description Default <code>object</code> <code>Any</code> <p>The Python object to validate against the model.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to strictly check types.</p> <code>None</code> <code>from_attributes</code> <code>bool | None</code> <p>Whether to extract data from object attributes.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to pass to the validator.</p> <code>None</code> <p>Note</p> <p>When using <code>TypeAdapter</code> with a Pydantic <code>dataclass</code>, the use of the <code>from_attributes</code> argument is not supported.</p> <p>Returns:</p> Type Description <code>T</code> <p>The validated object.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@_frame_depth(1)\ndef validate_python(\n    self,\n    object: Any,\n    /,\n    *,\n    strict: bool | None = None,\n    from_attributes: bool | None = None,\n    context: dict[str, Any] | None = None,\n) -&gt; T:\n    \"\"\"Validate a Python object against the model.\n\n    Args:\n        object: The Python object to validate against the model.\n        strict: Whether to strictly check types.\n        from_attributes: Whether to extract data from object attributes.\n        context: Additional context to pass to the validator.\n\n    !!! note\n        When using `TypeAdapter` with a Pydantic `dataclass`, the use of the `from_attributes`\n        argument is not supported.\n\n    Returns:\n        The validated object.\n    \"\"\"\n    return self.validator.validate_python(object, strict=strict, from_attributes=from_attributes, context=context)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.validate_json","title":"validate_json","text":"<pre><code>validate_json(\n    data: str | bytes,\n    /,\n    *,\n    strict: bool | None = None,\n    context: dict[str, Any] | None = None,\n) -&gt; T\n</code></pre> <p>Usage Documentation</p> <p>Json Parsing</p> <p>Validate a JSON string or bytes against the model.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str | bytes</code> <p>The JSON data to validate against the model.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to strictly check types.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to use during validation.</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>The validated object.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@_frame_depth(1)\ndef validate_json(\n    self, data: str | bytes, /, *, strict: bool | None = None, context: dict[str, Any] | None = None\n) -&gt; T:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/json/#json-parsing\n\n    Validate a JSON string or bytes against the model.\n\n    Args:\n        data: The JSON data to validate against the model.\n        strict: Whether to strictly check types.\n        context: Additional context to use during validation.\n\n    Returns:\n        The validated object.\n    \"\"\"\n    return self.validator.validate_json(data, strict=strict, context=context)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.validate_strings","title":"validate_strings","text":"<pre><code>validate_strings(\n    obj: Any,\n    /,\n    *,\n    strict: bool | None = None,\n    context: dict[str, Any] | None = None,\n) -&gt; T\n</code></pre> <p>Validate object contains string data against the model.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>The object contains string data to validate.</p> required <code>strict</code> <code>bool | None</code> <p>Whether to strictly check types.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to use during validation.</p> <code>None</code> <p>Returns:</p> Type Description <code>T</code> <p>The validated object.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@_frame_depth(1)\ndef validate_strings(self, obj: Any, /, *, strict: bool | None = None, context: dict[str, Any] | None = None) -&gt; T:\n    \"\"\"Validate object contains string data against the model.\n\n    Args:\n        obj: The object contains string data to validate.\n        strict: Whether to strictly check types.\n        context: Additional context to use during validation.\n\n    Returns:\n        The validated object.\n    \"\"\"\n    return self.validator.validate_strings(obj, strict=strict, context=context)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.get_default_value","title":"get_default_value","text":"<pre><code>get_default_value(\n    *,\n    strict: bool | None = None,\n    context: dict[str, Any] | None = None\n) -&gt; Some[T] | None\n</code></pre> <p>Get the default value for the wrapped type.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to strictly check types.</p> <code>None</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to pass to the validator.</p> <code>None</code> <p>Returns:</p> Type Description <code>Some[T] | None</code> <p>The default value wrapped in a <code>Some</code> if there is one or None if not.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@_frame_depth(1)\ndef get_default_value(self, *, strict: bool | None = None, context: dict[str, Any] | None = None) -&gt; Some[T] | None:\n    \"\"\"Get the default value for the wrapped type.\n\n    Args:\n        strict: Whether to strictly check types.\n        context: Additional context to pass to the validator.\n\n    Returns:\n        The default value wrapped in a `Some` if there is one or None if not.\n    \"\"\"\n    return self.validator.get_default_value(strict=strict, context=context)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.dump_python","title":"dump_python","text":"<pre><code>dump_python(\n    instance: T,\n    /,\n    *,\n    mode: Literal[\"json\", \"python\"] = \"python\",\n    include: IncEx | None = None,\n    exclude: IncEx | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: (\n        bool | Literal[\"none\", \"warn\", \"error\"]\n    ) = True,\n    serialize_as_any: bool = False,\n    context: dict[str, Any] | None = None,\n) -&gt; Any\n</code></pre> <p>Dump an instance of the adapted type to a Python object.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>T</code> <p>The Python object to serialize.</p> required <code>mode</code> <code>Literal['json', 'python']</code> <p>The output format.</p> <code>'python'</code> <code>include</code> <code>IncEx | None</code> <p>Fields to include in the output.</p> <code>None</code> <code>exclude</code> <code>IncEx | None</code> <p>Fields to exclude from the output.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use alias names for field names.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude unset fields.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields with default values.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields with None values.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to output the serialized data in a way that is compatible with deserialization.</p> <code>False</code> <code>warnings</code> <code>bool | Literal['none', 'warn', 'error']</code> <p>How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors, \"error\" raises a <code>PydanticSerializationError</code>.</p> <code>True</code> <code>serialize_as_any</code> <code>bool</code> <p>Whether to serialize fields with duck-typing serialization behavior.</p> <code>False</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to pass to the serializer.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The serialized object.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@_frame_depth(1)\ndef dump_python(\n    self,\n    instance: T,\n    /,\n    *,\n    mode: Literal['json', 'python'] = 'python',\n    include: IncEx | None = None,\n    exclude: IncEx | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool | Literal['none', 'warn', 'error'] = True,\n    serialize_as_any: bool = False,\n    context: dict[str, Any] | None = None,\n) -&gt; Any:\n    \"\"\"Dump an instance of the adapted type to a Python object.\n\n    Args:\n        instance: The Python object to serialize.\n        mode: The output format.\n        include: Fields to include in the output.\n        exclude: Fields to exclude from the output.\n        by_alias: Whether to use alias names for field names.\n        exclude_unset: Whether to exclude unset fields.\n        exclude_defaults: Whether to exclude fields with default values.\n        exclude_none: Whether to exclude fields with None values.\n        round_trip: Whether to output the serialized data in a way that is compatible with deserialization.\n        warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n            \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n        serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n        context: Additional context to pass to the serializer.\n\n    Returns:\n        The serialized object.\n    \"\"\"\n    return self.serializer.to_python(\n        instance,\n        mode=mode,\n        by_alias=by_alias,\n        include=include,\n        exclude=exclude,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        round_trip=round_trip,\n        warnings=warnings,\n        serialize_as_any=serialize_as_any,\n        context=context,\n    )\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.dump_json","title":"dump_json","text":"<pre><code>dump_json(\n    instance: T,\n    /,\n    *,\n    indent: int | None = None,\n    include: IncEx | None = None,\n    exclude: IncEx | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: (\n        bool | Literal[\"none\", \"warn\", \"error\"]\n    ) = True,\n    serialize_as_any: bool = False,\n    context: dict[str, Any] | None = None,\n) -&gt; bytes\n</code></pre> <p>Usage Documentation</p> <p>JSON Serialization</p> <p>Serialize an instance of the adapted type to JSON.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>T</code> <p>The instance to be serialized.</p> required <code>indent</code> <code>int | None</code> <p>Number of spaces for JSON indentation.</p> <code>None</code> <code>include</code> <code>IncEx | None</code> <p>Fields to include.</p> <code>None</code> <code>exclude</code> <code>IncEx | None</code> <p>Fields to exclude.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use alias names for field names.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude unset fields.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields with default values.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields with a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to serialize and deserialize the instance to ensure round-tripping.</p> <code>False</code> <code>warnings</code> <code>bool | Literal['none', 'warn', 'error']</code> <p>How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors, \"error\" raises a <code>PydanticSerializationError</code>.</p> <code>True</code> <code>serialize_as_any</code> <code>bool</code> <p>Whether to serialize fields with duck-typing serialization behavior.</p> <code>False</code> <code>context</code> <code>dict[str, Any] | None</code> <p>Additional context to pass to the serializer.</p> <code>None</code> <p>Returns:</p> Type Description <code>bytes</code> <p>The JSON representation of the given instance as bytes.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@_frame_depth(1)\ndef dump_json(\n    self,\n    instance: T,\n    /,\n    *,\n    indent: int | None = None,\n    include: IncEx | None = None,\n    exclude: IncEx | None = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool | Literal['none', 'warn', 'error'] = True,\n    serialize_as_any: bool = False,\n    context: dict[str, Any] | None = None,\n) -&gt; bytes:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/json/#json-serialization\n\n    Serialize an instance of the adapted type to JSON.\n\n    Args:\n        instance: The instance to be serialized.\n        indent: Number of spaces for JSON indentation.\n        include: Fields to include.\n        exclude: Fields to exclude.\n        by_alias: Whether to use alias names for field names.\n        exclude_unset: Whether to exclude unset fields.\n        exclude_defaults: Whether to exclude fields with default values.\n        exclude_none: Whether to exclude fields with a value of `None`.\n        round_trip: Whether to serialize and deserialize the instance to ensure round-tripping.\n        warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n            \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n        serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n        context: Additional context to pass to the serializer.\n\n    Returns:\n        The JSON representation of the given instance as bytes.\n    \"\"\"\n    return self.serializer.to_json(\n        instance,\n        indent=indent,\n        include=include,\n        exclude=exclude,\n        by_alias=by_alias,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        round_trip=round_trip,\n        warnings=warnings,\n        serialize_as_any=serialize_as_any,\n        context=context,\n    )\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.json_schema","title":"json_schema","text":"<pre><code>json_schema(\n    *,\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[\n        GenerateJsonSchema\n    ] = GenerateJsonSchema,\n    mode: JsonSchemaMode = \"validation\"\n) -&gt; dict[str, Any]\n</code></pre> <p>Generate a JSON schema for the adapted type.</p> <p>Parameters:</p> Name Type Description Default <code>by_alias</code> <code>bool</code> <p>Whether to use alias names for field names.</p> <code>True</code> <code>ref_template</code> <code>str</code> <p>The format string used for generating $ref strings.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>The generator class used for creating the schema.</p> <code>GenerateJsonSchema</code> <code>mode</code> <code>JsonSchemaMode</code> <p>The mode to use for schema generation.</p> <code>'validation'</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The JSON schema for the model as a dictionary.</p> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@_frame_depth(1)\ndef json_schema(\n    self,\n    *,\n    by_alias: bool = True,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n    mode: JsonSchemaMode = 'validation',\n) -&gt; dict[str, Any]:\n    \"\"\"Generate a JSON schema for the adapted type.\n\n    Args:\n        by_alias: Whether to use alias names for field names.\n        ref_template: The format string used for generating $ref strings.\n        schema_generator: The generator class used for creating the schema.\n        mode: The mode to use for schema generation.\n\n    Returns:\n        The JSON schema for the model as a dictionary.\n    \"\"\"\n    schema_generator_instance = schema_generator(by_alias=by_alias, ref_template=ref_template)\n    return schema_generator_instance.generate(self.core_schema, mode=mode)\n</code></pre>"},{"location":"api/type_adapter/#pydantic.type_adapter.TypeAdapter.json_schemas","title":"json_schemas  <code>staticmethod</code>","text":"<pre><code>json_schemas(\n    inputs: Iterable[\n        tuple[\n            JsonSchemaKeyT, JsonSchemaMode, TypeAdapter[Any]\n        ]\n    ],\n    /,\n    *,\n    by_alias: bool = True,\n    title: str | None = None,\n    description: str | None = None,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[\n        GenerateJsonSchema\n    ] = GenerateJsonSchema,\n) -&gt; tuple[\n    dict[\n        tuple[JsonSchemaKeyT, JsonSchemaMode],\n        JsonSchemaValue,\n    ],\n    JsonSchemaValue,\n]\n</code></pre> <p>Generate a JSON schema including definitions from multiple type adapters.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>Iterable[tuple[JsonSchemaKeyT, JsonSchemaMode, TypeAdapter[Any]]]</code> <p>Inputs to schema generation. The first two items will form the keys of the (first) output mapping; the type adapters will provide the core schemas that get converted into definitions in the output JSON schema.</p> required <code>by_alias</code> <code>bool</code> <p>Whether to use alias names.</p> <code>True</code> <code>title</code> <code>str | None</code> <p>The title for the schema.</p> <code>None</code> <code>description</code> <code>str | None</code> <p>The description for the schema.</p> <code>None</code> <code>ref_template</code> <code>str</code> <p>The format string used for generating $ref strings.</p> <code>DEFAULT_REF_TEMPLATE</code> <code>schema_generator</code> <code>type[GenerateJsonSchema]</code> <p>The generator class used for creating the schema.</p> <code>GenerateJsonSchema</code> <p>Returns:</p> Type Description <code>tuple[dict[tuple[JsonSchemaKeyT, JsonSchemaMode], JsonSchemaValue], JsonSchemaValue]</code> <p>A tuple where:</p> <ul> <li>The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and     whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have     JsonRef references to definitions that are defined in the second returned element.)</li> <li>The second element is a JSON schema containing all definitions referenced in the first returned     element, along with the optional title and description keys.</li> </ul> Source code in <code>pydantic/type_adapter.py</code> <pre><code>@staticmethod\ndef json_schemas(\n    inputs: Iterable[tuple[JsonSchemaKeyT, JsonSchemaMode, TypeAdapter[Any]]],\n    /,\n    *,\n    by_alias: bool = True,\n    title: str | None = None,\n    description: str | None = None,\n    ref_template: str = DEFAULT_REF_TEMPLATE,\n    schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema,\n) -&gt; tuple[dict[tuple[JsonSchemaKeyT, JsonSchemaMode], JsonSchemaValue], JsonSchemaValue]:\n    \"\"\"Generate a JSON schema including definitions from multiple type adapters.\n\n    Args:\n        inputs: Inputs to schema generation. The first two items will form the keys of the (first)\n            output mapping; the type adapters will provide the core schemas that get converted into\n            definitions in the output JSON schema.\n        by_alias: Whether to use alias names.\n        title: The title for the schema.\n        description: The description for the schema.\n        ref_template: The format string used for generating $ref strings.\n        schema_generator: The generator class used for creating the schema.\n\n    Returns:\n        A tuple where:\n\n            - The first element is a dictionary whose keys are tuples of JSON schema key type and JSON mode, and\n                whose values are the JSON schema corresponding to that pair of inputs. (These schemas may have\n                JsonRef references to definitions that are defined in the second returned element.)\n            - The second element is a JSON schema containing all definitions referenced in the first returned\n                element, along with the optional title and description keys.\n\n    \"\"\"\n    schema_generator_instance = schema_generator(by_alias=by_alias, ref_template=ref_template)\n\n    inputs_ = []\n    for key, mode, adapter in inputs:\n        with adapter._with_frame_depth(1):  # +1 for json_schemas staticmethod\n            inputs_.append((key, mode, adapter.core_schema))\n\n    json_schemas_map, definitions = schema_generator_instance.generate_definitions(inputs_)\n\n    json_schema: dict[str, Any] = {}\n    if definitions:\n        json_schema['$defs'] = definitions\n    if title:\n        json_schema['title'] = title\n    if description:\n        json_schema['description'] = description\n\n    return json_schemas_map, json_schema\n</code></pre>"},{"location":"api/types/","title":"Pydantic Types","text":""},{"location":"api/types/#pydantic.types","title":"pydantic.types","text":"<p>The types module contains custom types used by pydantic.</p>"},{"location":"api/types/#pydantic.types.StrictBool","title":"StrictBool  <code>module-attribute</code>","text":"<pre><code>StrictBool = Annotated[bool, Strict()]\n</code></pre> <p>A boolean that must be either <code>True</code> or <code>False</code>.</p>"},{"location":"api/types/#pydantic.types.PositiveInt","title":"PositiveInt  <code>module-attribute</code>","text":"<pre><code>PositiveInt = Annotated[int, Gt(0)]\n</code></pre> <p>An integer that must be greater than zero.</p> <pre><code>from pydantic import BaseModel, PositiveInt, ValidationError\n\nclass Model(BaseModel):\n    positive_int: PositiveInt\n\nm = Model(positive_int=1)\nprint(repr(m))\n#&gt; Model(positive_int=1)\n\ntry:\n    Model(positive_int=-1)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'greater_than',\n            'loc': ('positive_int',),\n            'msg': 'Input should be greater than 0',\n            'input': -1,\n            'ctx': {'gt': 0},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.NegativeInt","title":"NegativeInt  <code>module-attribute</code>","text":"<pre><code>NegativeInt = Annotated[int, Lt(0)]\n</code></pre> <p>An integer that must be less than zero.</p> <pre><code>from pydantic import BaseModel, NegativeInt, ValidationError\n\nclass Model(BaseModel):\n    negative_int: NegativeInt\n\nm = Model(negative_int=-1)\nprint(repr(m))\n#&gt; Model(negative_int=-1)\n\ntry:\n    Model(negative_int=1)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'less_than',\n            'loc': ('negative_int',),\n            'msg': 'Input should be less than 0',\n            'input': 1,\n            'ctx': {'lt': 0},\n            'url': 'https://errors.pydantic.dev/2/v/less_than',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.NonPositiveInt","title":"NonPositiveInt  <code>module-attribute</code>","text":"<pre><code>NonPositiveInt = Annotated[int, Le(0)]\n</code></pre> <p>An integer that must be less than or equal to zero.</p> <pre><code>from pydantic import BaseModel, NonPositiveInt, ValidationError\n\nclass Model(BaseModel):\n    non_positive_int: NonPositiveInt\n\nm = Model(non_positive_int=0)\nprint(repr(m))\n#&gt; Model(non_positive_int=0)\n\ntry:\n    Model(non_positive_int=1)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'less_than_equal',\n            'loc': ('non_positive_int',),\n            'msg': 'Input should be less than or equal to 0',\n            'input': 1,\n            'ctx': {'le': 0},\n            'url': 'https://errors.pydantic.dev/2/v/less_than_equal',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.NonNegativeInt","title":"NonNegativeInt  <code>module-attribute</code>","text":"<pre><code>NonNegativeInt = Annotated[int, Ge(0)]\n</code></pre> <p>An integer that must be greater than or equal to zero.</p> <pre><code>from pydantic import BaseModel, NonNegativeInt, ValidationError\n\nclass Model(BaseModel):\n    non_negative_int: NonNegativeInt\n\nm = Model(non_negative_int=0)\nprint(repr(m))\n#&gt; Model(non_negative_int=0)\n\ntry:\n    Model(non_negative_int=-1)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'greater_than_equal',\n            'loc': ('non_negative_int',),\n            'msg': 'Input should be greater than or equal to 0',\n            'input': -1,\n            'ctx': {'ge': 0},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than_equal',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.StrictInt","title":"StrictInt  <code>module-attribute</code>","text":"<pre><code>StrictInt = Annotated[int, Strict()]\n</code></pre> <p>An integer that must be validated in strict mode.</p> <pre><code>from pydantic import BaseModel, StrictInt, ValidationError\n\nclass StrictIntModel(BaseModel):\n    strict_int: StrictInt\n\ntry:\n    StrictIntModel(strict_int=3.14159)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for StrictIntModel\n    strict_int\n      Input should be a valid integer [type=int_type, input_value=3.14159, input_type=float]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.PositiveFloat","title":"PositiveFloat  <code>module-attribute</code>","text":"<pre><code>PositiveFloat = Annotated[float, Gt(0)]\n</code></pre> <p>A float that must be greater than zero.</p> <pre><code>from pydantic import BaseModel, PositiveFloat, ValidationError\n\nclass Model(BaseModel):\n    positive_float: PositiveFloat\n\nm = Model(positive_float=1.0)\nprint(repr(m))\n#&gt; Model(positive_float=1.0)\n\ntry:\n    Model(positive_float=-1.0)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'greater_than',\n            'loc': ('positive_float',),\n            'msg': 'Input should be greater than 0',\n            'input': -1.0,\n            'ctx': {'gt': 0.0},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.NegativeFloat","title":"NegativeFloat  <code>module-attribute</code>","text":"<pre><code>NegativeFloat = Annotated[float, Lt(0)]\n</code></pre> <p>A float that must be less than zero.</p> <pre><code>from pydantic import BaseModel, NegativeFloat, ValidationError\n\nclass Model(BaseModel):\n    negative_float: NegativeFloat\n\nm = Model(negative_float=-1.0)\nprint(repr(m))\n#&gt; Model(negative_float=-1.0)\n\ntry:\n    Model(negative_float=1.0)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'less_than',\n            'loc': ('negative_float',),\n            'msg': 'Input should be less than 0',\n            'input': 1.0,\n            'ctx': {'lt': 0.0},\n            'url': 'https://errors.pydantic.dev/2/v/less_than',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.NonPositiveFloat","title":"NonPositiveFloat  <code>module-attribute</code>","text":"<pre><code>NonPositiveFloat = Annotated[float, Le(0)]\n</code></pre> <p>A float that must be less than or equal to zero.</p> <pre><code>from pydantic import BaseModel, NonPositiveFloat, ValidationError\n\nclass Model(BaseModel):\n    non_positive_float: NonPositiveFloat\n\nm = Model(non_positive_float=0.0)\nprint(repr(m))\n#&gt; Model(non_positive_float=0.0)\n\ntry:\n    Model(non_positive_float=1.0)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'less_than_equal',\n            'loc': ('non_positive_float',),\n            'msg': 'Input should be less than or equal to 0',\n            'input': 1.0,\n            'ctx': {'le': 0.0},\n            'url': 'https://errors.pydantic.dev/2/v/less_than_equal',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.NonNegativeFloat","title":"NonNegativeFloat  <code>module-attribute</code>","text":"<pre><code>NonNegativeFloat = Annotated[float, Ge(0)]\n</code></pre> <p>A float that must be greater than or equal to zero.</p> <pre><code>from pydantic import BaseModel, NonNegativeFloat, ValidationError\n\nclass Model(BaseModel):\n    non_negative_float: NonNegativeFloat\n\nm = Model(non_negative_float=0.0)\nprint(repr(m))\n#&gt; Model(non_negative_float=0.0)\n\ntry:\n    Model(non_negative_float=-1.0)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'greater_than_equal',\n            'loc': ('non_negative_float',),\n            'msg': 'Input should be greater than or equal to 0',\n            'input': -1.0,\n            'ctx': {'ge': 0.0},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than_equal',\n        }\n    ]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.StrictFloat","title":"StrictFloat  <code>module-attribute</code>","text":"<pre><code>StrictFloat = Annotated[float, Strict(True)]\n</code></pre> <p>A float that must be validated in strict mode.</p> <pre><code>from pydantic import BaseModel, StrictFloat, ValidationError\n\nclass StrictFloatModel(BaseModel):\n    strict_float: StrictFloat\n\ntry:\n    StrictFloatModel(strict_float='1.0')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for StrictFloatModel\n    strict_float\n      Input should be a valid number [type=float_type, input_value='1.0', input_type=str]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.FiniteFloat","title":"FiniteFloat  <code>module-attribute</code>","text":"<pre><code>FiniteFloat = Annotated[float, AllowInfNan(False)]\n</code></pre> <p>A float that must be finite (not <code>-inf</code>, <code>inf</code>, or <code>nan</code>).</p> <pre><code>from pydantic import BaseModel, FiniteFloat\n\nclass Model(BaseModel):\n    finite: FiniteFloat\n\nm = Model(finite=1.0)\nprint(m)\n#&gt; finite=1.0\n</code></pre>"},{"location":"api/types/#pydantic.types.StrictBytes","title":"StrictBytes  <code>module-attribute</code>","text":"<pre><code>StrictBytes = Annotated[bytes, Strict()]\n</code></pre> <p>A bytes that must be validated in strict mode.</p>"},{"location":"api/types/#pydantic.types.StrictStr","title":"StrictStr  <code>module-attribute</code>","text":"<pre><code>StrictStr = Annotated[str, Strict()]\n</code></pre> <p>A string that must be validated in strict mode.</p>"},{"location":"api/types/#pydantic.types.UUID1","title":"UUID1  <code>module-attribute</code>","text":"<pre><code>UUID1 = Annotated[UUID, UuidVersion(1)]\n</code></pre> <p>A UUID that must be version 1.</p> <pre><code>import uuid\n\nfrom pydantic import UUID1, BaseModel\n\nclass Model(BaseModel):\n    uuid1: UUID1\n\nModel(uuid1=uuid.uuid1())\n</code></pre>"},{"location":"api/types/#pydantic.types.UUID3","title":"UUID3  <code>module-attribute</code>","text":"<pre><code>UUID3 = Annotated[UUID, UuidVersion(3)]\n</code></pre> <p>A UUID that must be version 3.</p> <pre><code>import uuid\n\nfrom pydantic import UUID3, BaseModel\n\nclass Model(BaseModel):\n    uuid3: UUID3\n\nModel(uuid3=uuid.uuid3(uuid.NAMESPACE_DNS, 'pydantic.org'))\n</code></pre>"},{"location":"api/types/#pydantic.types.UUID4","title":"UUID4  <code>module-attribute</code>","text":"<pre><code>UUID4 = Annotated[UUID, UuidVersion(4)]\n</code></pre> <p>A UUID that must be version 4.</p> <pre><code>import uuid\n\nfrom pydantic import UUID4, BaseModel\n\nclass Model(BaseModel):\n    uuid4: UUID4\n\nModel(uuid4=uuid.uuid4())\n</code></pre>"},{"location":"api/types/#pydantic.types.UUID5","title":"UUID5  <code>module-attribute</code>","text":"<pre><code>UUID5 = Annotated[UUID, UuidVersion(5)]\n</code></pre> <p>A UUID that must be version 5.</p> <pre><code>import uuid\n\nfrom pydantic import UUID5, BaseModel\n\nclass Model(BaseModel):\n    uuid5: UUID5\n\nModel(uuid5=uuid.uuid5(uuid.NAMESPACE_DNS, 'pydantic.org'))\n</code></pre>"},{"location":"api/types/#pydantic.types.FilePath","title":"FilePath  <code>module-attribute</code>","text":"<pre><code>FilePath = Annotated[Path, PathType('file')]\n</code></pre> <p>A path that must point to a file.</p> <pre><code>from pathlib import Path\n\nfrom pydantic import BaseModel, FilePath, ValidationError\n\nclass Model(BaseModel):\n    f: FilePath\n\npath = Path('text.txt')\npath.touch()\nm = Model(f='text.txt')\nprint(m.model_dump())\n#&gt; {'f': PosixPath('text.txt')}\npath.unlink()\n\npath = Path('directory')\npath.mkdir(exist_ok=True)\ntry:\n    Model(f='directory')  # directory\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    f\n      Path does not point to a file [type=path_not_file, input_value='directory', input_type=str]\n    '''\npath.rmdir()\n\ntry:\n    Model(f='not-exists-file')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    f\n      Path does not point to a file [type=path_not_file, input_value='not-exists-file', input_type=str]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.DirectoryPath","title":"DirectoryPath  <code>module-attribute</code>","text":"<pre><code>DirectoryPath = Annotated[Path, PathType('dir')]\n</code></pre> <p>A path that must point to a directory.</p> <pre><code>from pathlib import Path\n\nfrom pydantic import BaseModel, DirectoryPath, ValidationError\n\nclass Model(BaseModel):\n    f: DirectoryPath\n\npath = Path('directory/')\npath.mkdir()\nm = Model(f='directory/')\nprint(m.model_dump())\n#&gt; {'f': PosixPath('directory')}\npath.rmdir()\n\npath = Path('file.txt')\npath.touch()\ntry:\n    Model(f='file.txt')  # file\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    f\n      Path does not point to a directory [type=path_not_directory, input_value='file.txt', input_type=str]\n    '''\npath.unlink()\n\ntry:\n    Model(f='not-exists-directory')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    f\n      Path does not point to a directory [type=path_not_directory, input_value='not-exists-directory', input_type=str]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.NewPath","title":"NewPath  <code>module-attribute</code>","text":"<pre><code>NewPath = Annotated[Path, PathType('new')]\n</code></pre> <p>A path for a new file or directory that must not already exist. The parent directory must already exist.</p>"},{"location":"api/types/#pydantic.types.Base64Bytes","title":"Base64Bytes  <code>module-attribute</code>","text":"<pre><code>Base64Bytes = Annotated[\n    bytes, EncodedBytes(encoder=Base64Encoder)\n]\n</code></pre> <p>A bytes type that is encoded and decoded using the standard (non-URL-safe) base64 encoder.</p> Note <p>Under the hood, <code>Base64Bytes</code> use standard library <code>base64.encodebytes</code> and <code>base64.decodebytes</code> functions.</p> <p>As a result, attempting to decode url-safe base64 data using the <code>Base64Bytes</code> type may fail or produce an incorrect decoding.</p> <pre><code>from pydantic import Base64Bytes, BaseModel, ValidationError\n\nclass Model(BaseModel):\n    base64_bytes: Base64Bytes\n\n# Initialize the model with base64 data\nm = Model(base64_bytes=b'VGhpcyBpcyB0aGUgd2F5')\n\n# Access decoded value\nprint(m.base64_bytes)\n#&gt; b'This is the way'\n\n# Serialize into the base64 form\nprint(m.model_dump())\n#&gt; {'base64_bytes': b'VGhpcyBpcyB0aGUgd2F5\n'}\n\n# Validate base64 data\ntry:\n    print(Model(base64_bytes=b'undecodable').base64_bytes)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    base64_bytes\n      Base64 decoding error: 'Incorrect padding' [type=base64_decode, input_value=b'undecodable', input_type=bytes]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.Base64Str","title":"Base64Str  <code>module-attribute</code>","text":"<pre><code>Base64Str = Annotated[\n    str, EncodedStr(encoder=Base64Encoder)\n]\n</code></pre> <p>A str type that is encoded and decoded using the standard (non-URL-safe) base64 encoder.</p> Note <p>Under the hood, <code>Base64Bytes</code> use standard library <code>base64.encodebytes</code> and <code>base64.decodebytes</code> functions.</p> <p>As a result, attempting to decode url-safe base64 data using the <code>Base64Str</code> type may fail or produce an incorrect decoding.</p> <pre><code>from pydantic import Base64Str, BaseModel, ValidationError\n\nclass Model(BaseModel):\n    base64_str: Base64Str\n\n# Initialize the model with base64 data\nm = Model(base64_str='VGhlc2UgYXJlbid0IHRoZSBkcm9pZHMgeW91J3JlIGxvb2tpbmcgZm9y')\n\n# Access decoded value\nprint(m.base64_str)\n#&gt; These aren't the droids you're looking for\n\n# Serialize into the base64 form\nprint(m.model_dump())\n#&gt; {'base64_str': 'VGhlc2UgYXJlbid0IHRoZSBkcm9pZHMgeW91J3JlIGxvb2tpbmcgZm9y\n'}\n\n# Validate base64 data\ntry:\n    print(Model(base64_str='undecodable').base64_str)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    base64_str\n      Base64 decoding error: 'Incorrect padding' [type=base64_decode, input_value='undecodable', input_type=str]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.Base64UrlBytes","title":"Base64UrlBytes  <code>module-attribute</code>","text":"<pre><code>Base64UrlBytes = Annotated[\n    bytes, EncodedBytes(encoder=Base64UrlEncoder)\n]\n</code></pre> <p>A bytes type that is encoded and decoded using the URL-safe base64 encoder.</p> Note <p>Under the hood, <code>Base64UrlBytes</code> use standard library <code>base64.urlsafe_b64encode</code> and <code>base64.urlsafe_b64decode</code> functions.</p> <p>As a result, the <code>Base64UrlBytes</code> type can be used to faithfully decode \"vanilla\" base64 data (using <code>'+'</code> and <code>'/'</code>).</p> <pre><code>from pydantic import Base64UrlBytes, BaseModel\n\nclass Model(BaseModel):\n    base64url_bytes: Base64UrlBytes\n\n# Initialize the model with base64 data\nm = Model(base64url_bytes=b'SHc_dHc-TXc==')\nprint(m)\n#&gt; base64url_bytes=b'Hw?tw&gt;Mw'\n</code></pre>"},{"location":"api/types/#pydantic.types.Base64UrlStr","title":"Base64UrlStr  <code>module-attribute</code>","text":"<pre><code>Base64UrlStr = Annotated[\n    str, EncodedStr(encoder=Base64UrlEncoder)\n]\n</code></pre> <p>A str type that is encoded and decoded using the URL-safe base64 encoder.</p> Note <p>Under the hood, <code>Base64UrlStr</code> use standard library <code>base64.urlsafe_b64encode</code> and <code>base64.urlsafe_b64decode</code> functions.</p> <p>As a result, the <code>Base64UrlStr</code> type can be used to faithfully decode \"vanilla\" base64 data (using <code>'+'</code> and <code>'/'</code>).</p> <pre><code>from pydantic import Base64UrlStr, BaseModel\n\nclass Model(BaseModel):\n    base64url_str: Base64UrlStr\n\n# Initialize the model with base64 data\nm = Model(base64url_str='SHc_dHc-TXc==')\nprint(m)\n#&gt; base64url_str='Hw?tw&gt;Mw'\n</code></pre>"},{"location":"api/types/#pydantic.types.JsonValue","title":"JsonValue  <code>module-attribute</code>","text":"<pre><code>JsonValue: TypeAlias = Union[\n    List[\"JsonValue\"],\n    Dict[str, \"JsonValue\"],\n    str,\n    bool,\n    int,\n    float,\n    None,\n]\n</code></pre> <p>A <code>JsonValue</code> is used to represent a value that can be serialized to JSON.</p> <p>It may be one of:</p> <ul> <li><code>List['JsonValue']</code></li> <li><code>Dict[str, 'JsonValue']</code></li> <li><code>str</code></li> <li><code>bool</code></li> <li><code>int</code></li> <li><code>float</code></li> <li><code>None</code></li> </ul> <p>The following example demonstrates how to use <code>JsonValue</code> to validate JSON data, and what kind of errors to expect when input data is not json serializable.</p> <pre><code>import json\n\nfrom pydantic import BaseModel, JsonValue, ValidationError\n\nclass Model(BaseModel):\n    j: JsonValue\n\nvalid_json_data = {'j': {'a': {'b': {'c': 1, 'd': [2, None]}}}}\ninvalid_json_data = {'j': {'a': {'b': ...}}}\n\nprint(repr(Model.model_validate(valid_json_data)))\n#&gt; Model(j={'a': {'b': {'c': 1, 'd': [2, None]}}})\nprint(repr(Model.model_validate_json(json.dumps(valid_json_data))))\n#&gt; Model(j={'a': {'b': {'c': 1, 'd': [2, None]}}})\n\ntry:\n    Model.model_validate(invalid_json_data)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    j.dict.a.dict.b\n      input was not a valid JSON value [type=invalid-json-value, input_value=Ellipsis, input_type=ellipsis]\n    '''\n</code></pre>"},{"location":"api/types/#pydantic.types.OnErrorOmit","title":"OnErrorOmit  <code>module-attribute</code>","text":"<pre><code>OnErrorOmit = Annotated[T, _OnErrorOmit]\n</code></pre> <p>When used as an item in a list, the key type in a dict, optional values of a TypedDict, etc. this annotation omits the item from the iteration if there is any error validating it. That is, instead of a <code>ValidationError</code> being propagated up and the entire iterable being discarded any invalid items are discarded and the valid ones are returned.</p>"},{"location":"api/types/#pydantic.types.Strict","title":"Strict  <code>dataclass</code>","text":"<p>               Bases: <code>PydanticMetadata</code>, <code>BaseMetadata</code></p> <p>Usage Documentation</p> <p>Strict mode with <code>Annotated[..., Strict()]</code></p> <p>A field metadata class to indicate that a field should be validated in strict mode. Use this class as an annotation via <code>Annotated</code>, as seen below.</p> <p>Attributes:</p> Name Type Description <code>strict</code> <code>bool</code> <p>Whether to validate the field in strict mode.</p> Example <pre><code>from typing_extensions import Annotated\n\nfrom pydantic.types import Strict\n\nStrictBool = Annotated[bool, Strict()]\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass\nclass Strict(_fields.PydanticMetadata, BaseMetadata):\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/strict_mode/#strict-mode-with-annotated-strict\n\n    A field metadata class to indicate that a field should be validated in strict mode.\n    Use this class as an annotation via [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated), as seen below.\n\n    Attributes:\n        strict: Whether to validate the field in strict mode.\n\n    Example:\n        ```python\n        from typing_extensions import Annotated\n\n        from pydantic.types import Strict\n\n        StrictBool = Annotated[bool, Strict()]\n        ```\n    \"\"\"\n\n    strict: bool = True\n\n    def __hash__(self) -&gt; int:\n        return hash(self.strict)\n</code></pre>"},{"location":"api/types/#pydantic.types.AllowInfNan","title":"AllowInfNan  <code>dataclass</code>","text":"<p>               Bases: <code>PydanticMetadata</code></p> <p>A field metadata class to indicate that a field should allow <code>-inf</code>, <code>inf</code>, and <code>nan</code>.</p> <p>Use this class as an annotation via <code>Annotated</code>, as seen below.</p> <p>Attributes:</p> Name Type Description <code>allow_inf_nan</code> <code>bool</code> <p>Whether to allow <code>-inf</code>, <code>inf</code>, and <code>nan</code>. Defaults to <code>True</code>.</p> Example <p>```python from typing_extensions import Annotated</p> <p>from pydantic.types import AllowInfNan</p> <p>LaxFloat = Annotated[float, AllowInfNan()]</p> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass\nclass AllowInfNan(_fields.PydanticMetadata):\n    \"\"\"A field metadata class to indicate that a field should allow `-inf`, `inf`, and `nan`.\n\n    Use this class as an annotation via [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated), as seen below.\n\n    Attributes:\n        allow_inf_nan: Whether to allow `-inf`, `inf`, and `nan`. Defaults to `True`.\n\n    Example:\n        ```python\n        from typing_extensions import Annotated\n\n        from pydantic.types import AllowInfNan\n\n        LaxFloat = Annotated[float, AllowInfNan()]\n    \"\"\"\n\n    allow_inf_nan: bool = True\n\n    def __hash__(self) -&gt; int:\n        return hash(self.allow_inf_nan)\n</code></pre>"},{"location":"api/types/#pydantic.types.StringConstraints","title":"StringConstraints  <code>dataclass</code>","text":"<p>               Bases: <code>GroupedMetadata</code></p> <p>Usage Documentation</p> <p>String Constraints</p> <p>A field metadata class to apply constraints to <code>str</code> types. Use this class as an annotation via <code>Annotated</code>, as seen below.</p> <p>Attributes:</p> Name Type Description <code>strip_whitespace</code> <code>bool | None</code> <p>Whether to remove leading and trailing whitespace.</p> <code>to_upper</code> <code>bool | None</code> <p>Whether to convert the string to uppercase.</p> <code>to_lower</code> <code>bool | None</code> <p>Whether to convert the string to lowercase.</p> <code>strict</code> <code>bool | None</code> <p>Whether to validate the string in strict mode.</p> <code>min_length</code> <code>int | None</code> <p>The minimum length of the string.</p> <code>max_length</code> <code>int | None</code> <p>The maximum length of the string.</p> <code>pattern</code> <code>str | Pattern[str] | None</code> <p>A regex pattern that the string must match.</p> Example <p>```python from typing_extensions import Annotated</p> <p>from pydantic.types import StringConstraints</p> <p>ConstrainedStr = Annotated[str, StringConstraints(min_length=1, max_length=10)]</p> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass(frozen=True)\nclass StringConstraints(annotated_types.GroupedMetadata):\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/fields/#string-constraints\n\n    A field metadata class to apply constraints to `str` types.\n    Use this class as an annotation via [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated), as seen below.\n\n    Attributes:\n        strip_whitespace: Whether to remove leading and trailing whitespace.\n        to_upper: Whether to convert the string to uppercase.\n        to_lower: Whether to convert the string to lowercase.\n        strict: Whether to validate the string in strict mode.\n        min_length: The minimum length of the string.\n        max_length: The maximum length of the string.\n        pattern: A regex pattern that the string must match.\n\n    Example:\n        ```python\n        from typing_extensions import Annotated\n\n        from pydantic.types import StringConstraints\n\n        ConstrainedStr = Annotated[str, StringConstraints(min_length=1, max_length=10)]\n    \"\"\"\n\n    strip_whitespace: bool | None = None\n    to_upper: bool | None = None\n    to_lower: bool | None = None\n    strict: bool | None = None\n    min_length: int | None = None\n    max_length: int | None = None\n    pattern: str | Pattern[str] | None = None\n\n    def __iter__(self) -&gt; Iterator[BaseMetadata]:\n        if self.min_length is not None:\n            yield MinLen(self.min_length)\n        if self.max_length is not None:\n            yield MaxLen(self.max_length)\n        if self.strict is not None:\n            yield Strict(self.strict)\n        if (\n            self.strip_whitespace is not None\n            or self.pattern is not None\n            or self.to_lower is not None\n            or self.to_upper is not None\n        ):\n            yield _fields.pydantic_general_metadata(\n                strip_whitespace=self.strip_whitespace,\n                to_upper=self.to_upper,\n                to_lower=self.to_lower,\n                pattern=self.pattern,\n            )\n</code></pre>"},{"location":"api/types/#pydantic.types.ImportString","title":"ImportString","text":"<p>A type that can be used to import a type from a string.</p> <p><code>ImportString</code> expects a string and loads the Python object importable at that dotted path. Attributes of modules may be separated from the module by <code>:</code> or <code>.</code>, e.g. if <code>'math:cos'</code> was provided, the resulting field value would be the function<code>cos</code>. If a <code>.</code> is used and both an attribute and submodule are present at the same path, the module will be preferred.</p> <p>On model instantiation, pointers will be evaluated and imported. There is some nuance to this behavior, demonstrated in the examples below.</p> <p>Good behavior: <pre><code>import math\n\nfrom pydantic import BaseModel, Field, ImportString, ValidationError\n\nclass ImportThings(BaseModel):\n    obj: ImportString\n\n# A string value will cause an automatic import\nmy_cos = ImportThings(obj='math.cos')\n\n# You can use the imported function as you would expect\ncos_of_0 = my_cos.obj(0)\nassert cos_of_0 == 1\n\n# A string whose value cannot be imported will raise an error\ntry:\n    ImportThings(obj='foo.bar')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for ImportThings\n    obj\n      Invalid python path: No module named 'foo.bar' [type=import_error, input_value='foo.bar', input_type=str]\n    '''\n\n# Actual python objects can be assigned as well\nmy_cos = ImportThings(obj=math.cos)\nmy_cos_2 = ImportThings(obj='math.cos')\nmy_cos_3 = ImportThings(obj='math:cos')\nassert my_cos == my_cos_2 == my_cos_3\n\n# You can set default field value either as Python object:\nclass ImportThingsDefaultPyObj(BaseModel):\n    obj: ImportString = math.cos\n\n# or as a string value (but only if used with `validate_default=True`)\nclass ImportThingsDefaultString(BaseModel):\n    obj: ImportString = Field(default='math.cos', validate_default=True)\n\nmy_cos_default1 = ImportThingsDefaultPyObj()\nmy_cos_default2 = ImportThingsDefaultString()\nassert my_cos_default1.obj == my_cos_default2.obj == math.cos\n\n# note: this will not work!\nclass ImportThingsMissingValidateDefault(BaseModel):\n    obj: ImportString = 'math.cos'\n\nmy_cos_default3 = ImportThingsMissingValidateDefault()\nassert my_cos_default3.obj == 'math.cos'  # just string, not evaluated\n</code></pre></p> <p>Serializing an <code>ImportString</code> type to json is also possible.</p> <p>```py lint=\"skip\" from pydantic import BaseModel, ImportString</p> <p>class ImportThings(BaseModel):     obj: ImportString</p>"},{"location":"api/types/#pydantic.types.ImportString--create-an-instance","title":"Create an instance","text":"<p>m = ImportThings(obj='math.cos') print(m)</p>"},{"location":"api/types/#pydantic.types.ImportString--obj","title":"&gt; obj= <p>print(m.model_dump_json())</p>","text":""},{"location":"api/types/#pydantic.types.ImportString--_1","title":"&gt; <p>```</p>  Source code in <code>pydantic/types.py</code> <pre><code>class ImportString:\n    \"\"\"A type that can be used to import a type from a string.\n\n    `ImportString` expects a string and loads the Python object importable at that dotted path.\n    Attributes of modules may be separated from the module by `:` or `.`, e.g. if `'math:cos'` was provided,\n    the resulting field value would be the function`cos`. If a `.` is used and both an attribute and submodule\n    are present at the same path, the module will be preferred.\n\n    On model instantiation, pointers will be evaluated and imported. There is\n    some nuance to this behavior, demonstrated in the examples below.\n\n    **Good behavior:**\n    ```py\n    import math\n\n    from pydantic import BaseModel, Field, ImportString, ValidationError\n\n    class ImportThings(BaseModel):\n        obj: ImportString\n\n    # A string value will cause an automatic import\n    my_cos = ImportThings(obj='math.cos')\n\n    # You can use the imported function as you would expect\n    cos_of_0 = my_cos.obj(0)\n    assert cos_of_0 == 1\n\n    # A string whose value cannot be imported will raise an error\n    try:\n        ImportThings(obj='foo.bar')\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for ImportThings\n        obj\n          Invalid python path: No module named 'foo.bar' [type=import_error, input_value='foo.bar', input_type=str]\n        '''\n\n    # Actual python objects can be assigned as well\n    my_cos = ImportThings(obj=math.cos)\n    my_cos_2 = ImportThings(obj='math.cos')\n    my_cos_3 = ImportThings(obj='math:cos')\n    assert my_cos == my_cos_2 == my_cos_3\n\n    # You can set default field value either as Python object:\n    class ImportThingsDefaultPyObj(BaseModel):\n        obj: ImportString = math.cos\n\n    # or as a string value (but only if used with `validate_default=True`)\n    class ImportThingsDefaultString(BaseModel):\n        obj: ImportString = Field(default='math.cos', validate_default=True)\n\n    my_cos_default1 = ImportThingsDefaultPyObj()\n    my_cos_default2 = ImportThingsDefaultString()\n    assert my_cos_default1.obj == my_cos_default2.obj == math.cos\n\n    # note: this will not work!\n    class ImportThingsMissingValidateDefault(BaseModel):\n        obj: ImportString = 'math.cos'\n\n    my_cos_default3 = ImportThingsMissingValidateDefault()\n    assert my_cos_default3.obj == 'math.cos'  # just string, not evaluated\n    ```\n\n    Serializing an `ImportString` type to json is also possible.\n\n    ```py lint=\"skip\"\n    from pydantic import BaseModel, ImportString\n\n    class ImportThings(BaseModel):\n        obj: ImportString\n\n    # Create an instance\n    m = ImportThings(obj='math.cos')\n    print(m)\n    #&gt; obj=&lt;built-in function cos&gt;\n    print(m.model_dump_json())\n    #&gt; {\"obj\":\"math.cos\"}\n    ```\n    \"\"\"\n\n    @classmethod\n    def __class_getitem__(cls, item: AnyType) -&gt; AnyType:\n        return Annotated[item, cls()]\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        serializer = core_schema.plain_serializer_function_ser_schema(cls._serialize, when_used='json')\n        if cls is source:\n            # Treat bare usage of ImportString (`schema is None`) as the same as ImportString[Any]\n            return core_schema.no_info_plain_validator_function(\n                function=_validators.import_string, serialization=serializer\n            )\n        else:\n            return core_schema.no_info_before_validator_function(\n                function=_validators.import_string, schema=handler(source), serialization=serializer\n            )\n\n    @classmethod\n    def __get_pydantic_json_schema__(cls, cs: CoreSchema, handler: GetJsonSchemaHandler) -&gt; JsonSchemaValue:\n        return handler(core_schema.str_schema())\n\n    @staticmethod\n    def _serialize(v: Any) -&gt; str:\n        if isinstance(v, ModuleType):\n            return v.__name__\n        elif hasattr(v, '__module__') and hasattr(v, '__name__'):\n            return f'{v.__module__}.{v.__name__}'\n        # Handle special cases for sys.XXX streams\n        # if we see more of these, we should consider a more general solution\n        elif hasattr(v, 'name'):\n            if v.name == '&lt;stdout&gt;':\n                return 'sys.stdout'\n            elif v.name == '&lt;stdin&gt;':\n                return 'sys.stdin'\n            elif v.name == '&lt;stderr&gt;':\n                return 'sys.stderr'\n        else:\n            return v\n\n    def __repr__(self) -&gt; str:\n        return 'ImportString'\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.UuidVersion","title":"UuidVersion  <code>dataclass</code>","text":"<p>A field metadata class to indicate a UUID version.</p> <p>Use this class as an annotation via <code>Annotated</code>, as seen below.</p> <p>Attributes:</p> Name Type Description <code>uuid_version</code> <code>Literal[1, 3, 4, 5]</code> <p>The version of the UUID. Must be one of 1, 3, 4, or 5.</p> Example <pre><code>from typing_extensions import Annotated\nfrom uuid import UUID\n\nfrom pydantic.types import UuidVersion\n\nUUID1 = Annotated[UUID, UuidVersion(1)]\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass(**_internal_dataclass.slots_true)\nclass UuidVersion:\n    \"\"\"A field metadata class to indicate a [UUID](https://docs.python.org/3/library/uuid.html) version.\n\n    Use this class as an annotation via [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated), as seen below.\n\n    Attributes:\n        uuid_version: The version of the UUID. Must be one of 1, 3, 4, or 5.\n\n    Example:\n        ```python\n        from typing_extensions import Annotated\n        from uuid import UUID\n\n        from pydantic.types import UuidVersion\n\n        UUID1 = Annotated[UUID, UuidVersion(1)]\n        ```\n    \"\"\"\n\n    uuid_version: Literal[1, 3, 4, 5]\n\n    def __get_pydantic_json_schema__(\n        self, core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; JsonSchemaValue:\n        field_schema = handler(core_schema)\n        field_schema.pop('anyOf', None)  # remove the bytes/str union\n        field_schema.update(type='string', format=f'uuid{self.uuid_version}')\n        return field_schema\n\n    def __get_pydantic_core_schema__(self, source: Any, handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema:\n        if isinstance(self, source):\n            # used directly as a type\n            return core_schema.uuid_schema(version=self.uuid_version)\n        else:\n            # update existing schema with self.uuid_version\n            schema = handler(source)\n            _check_annotated_type(schema['type'], 'uuid', self.__class__.__name__)\n            schema['version'] = self.uuid_version  # type: ignore\n            return schema\n\n    def __hash__(self) -&gt; int:\n        return hash(type(self.uuid_version))\n</code></pre>"},{"location":"api/types/#pydantic.types.Json","title":"Json","text":"<p>A special type wrapper which loads JSON before parsing.</p> <p>You can use the <code>Json</code> data type to make Pydantic first load a raw JSON string before validating the loaded data into the parametrized type:</p> <pre><code>from typing import Any, List\n\nfrom pydantic import BaseModel, Json, ValidationError\n\nclass AnyJsonModel(BaseModel):\n    json_obj: Json[Any]\n\nclass ConstrainedJsonModel(BaseModel):\n    json_obj: Json[List[int]]\n\nprint(AnyJsonModel(json_obj='{\"b\": 1}'))\n#&gt; json_obj={'b': 1}\nprint(ConstrainedJsonModel(json_obj='[1, 2, 3]'))\n#&gt; json_obj=[1, 2, 3]\n\ntry:\n    ConstrainedJsonModel(json_obj=12)\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for ConstrainedJsonModel\n    json_obj\n      JSON input should be string, bytes or bytearray [type=json_type, input_value=12, input_type=int]\n    '''\n\ntry:\n    ConstrainedJsonModel(json_obj='[a, b]')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for ConstrainedJsonModel\n    json_obj\n      Invalid JSON: expected value at line 1 column 2 [type=json_invalid, input_value='[a, b]', input_type=str]\n    '''\n\ntry:\n    ConstrainedJsonModel(json_obj='[\"a\", \"b\"]')\nexcept ValidationError as e:\n    print(e)\n    '''\n    2 validation errors for ConstrainedJsonModel\n    json_obj.0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    json_obj.1\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='b', input_type=str]\n    '''\n</code></pre> <p>When you dump the model using <code>model_dump</code> or <code>model_dump_json</code>, the dumped value will be the result of validation, not the original JSON string. However, you can use the argument <code>round_trip=True</code> to get the original JSON string back:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, Json\n\nclass ConstrainedJsonModel(BaseModel):\n    json_obj: Json[List[int]]\n\nprint(ConstrainedJsonModel(json_obj='[1, 2, 3]').model_dump_json())\n#&gt; {\"json_obj\":[1,2,3]}\nprint(\n    ConstrainedJsonModel(json_obj='[1, 2, 3]').model_dump_json(round_trip=True)\n)\n#&gt; {\"json_obj\":\"[1,2,3]\"}\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>class Json:\n    \"\"\"A special type wrapper which loads JSON before parsing.\n\n    You can use the `Json` data type to make Pydantic first load a raw JSON string before\n    validating the loaded data into the parametrized type:\n\n    ```py\n    from typing import Any, List\n\n    from pydantic import BaseModel, Json, ValidationError\n\n    class AnyJsonModel(BaseModel):\n        json_obj: Json[Any]\n\n    class ConstrainedJsonModel(BaseModel):\n        json_obj: Json[List[int]]\n\n    print(AnyJsonModel(json_obj='{\"b\": 1}'))\n    #&gt; json_obj={'b': 1}\n    print(ConstrainedJsonModel(json_obj='[1, 2, 3]'))\n    #&gt; json_obj=[1, 2, 3]\n\n    try:\n        ConstrainedJsonModel(json_obj=12)\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for ConstrainedJsonModel\n        json_obj\n          JSON input should be string, bytes or bytearray [type=json_type, input_value=12, input_type=int]\n        '''\n\n    try:\n        ConstrainedJsonModel(json_obj='[a, b]')\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for ConstrainedJsonModel\n        json_obj\n          Invalid JSON: expected value at line 1 column 2 [type=json_invalid, input_value='[a, b]', input_type=str]\n        '''\n\n    try:\n        ConstrainedJsonModel(json_obj='[\"a\", \"b\"]')\n    except ValidationError as e:\n        print(e)\n        '''\n        2 validation errors for ConstrainedJsonModel\n        json_obj.0\n          Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n        json_obj.1\n          Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='b', input_type=str]\n        '''\n    ```\n\n    When you dump the model using `model_dump` or `model_dump_json`, the dumped value will be the result of validation,\n    not the original JSON string. However, you can use the argument `round_trip=True` to get the original JSON string back:\n\n    ```py\n    from typing import List\n\n    from pydantic import BaseModel, Json\n\n    class ConstrainedJsonModel(BaseModel):\n        json_obj: Json[List[int]]\n\n    print(ConstrainedJsonModel(json_obj='[1, 2, 3]').model_dump_json())\n    #&gt; {\"json_obj\":[1,2,3]}\n    print(\n        ConstrainedJsonModel(json_obj='[1, 2, 3]').model_dump_json(round_trip=True)\n    )\n    #&gt; {\"json_obj\":\"[1,2,3]\"}\n    ```\n    \"\"\"\n\n    @classmethod\n    def __class_getitem__(cls, item: AnyType) -&gt; AnyType:\n        return Annotated[item, cls()]\n\n    @classmethod\n    def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema:\n        if cls is source:\n            return core_schema.json_schema(None)\n        else:\n            return core_schema.json_schema(handler(source))\n\n    def __repr__(self) -&gt; str:\n        return 'Json'\n\n    def __hash__(self) -&gt; int:\n        return hash(type(self))\n\n    def __eq__(self, other: Any) -&gt; bool:\n        return type(other) is type(self)\n</code></pre>"},{"location":"api/types/#pydantic.types.Secret","title":"Secret","text":"<p>               Bases: <code>_SecretBase[SecretType]</code></p> <p>A generic base class used for defining a field with sensitive information that you do not want to be visible in logging or tracebacks.</p> <p>You may either directly parametrize <code>Secret</code> with a type, or subclass from <code>Secret</code> with a parametrized type. The benefit of subclassing is that you can define a custom <code>_display</code> method, which will be used for <code>repr()</code> and <code>str()</code> methods. The examples below demonstrate both ways of using <code>Secret</code> to create a new secret type.</p> <ol> <li>Directly parametrizing <code>Secret</code> with a type:</li> </ol> <pre><code>from pydantic import BaseModel, Secret\n\nSecretBool = Secret[bool]\n\nclass Model(BaseModel):\n    secret_bool: SecretBool\n\nm = Model(secret_bool=True)\nprint(m.model_dump())\n#&gt; {'secret_bool': Secret('**********')}\n\nprint(m.model_dump_json())\n#&gt; {\"secret_bool\":\"**********\"}\n\nprint(m.secret_bool.get_secret_value())\n#&gt; True\n</code></pre> <ol> <li>Subclassing from parametrized <code>Secret</code>:</li> </ol> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, Secret\n\nclass SecretDate(Secret[date]):\n    def _display(self) -&gt; str:\n        return '****/**/**'\n\nclass Model(BaseModel):\n    secret_date: SecretDate\n\nm = Model(secret_date=date(2022, 1, 1))\nprint(m.model_dump())\n#&gt; {'secret_date': SecretDate('****/**/**')}\n\nprint(m.model_dump_json())\n#&gt; {\"secret_date\":\"****/**/**\"}\n\nprint(m.secret_date.get_secret_value())\n#&gt; 2022-01-01\n</code></pre> <p>The value returned by the <code>_display</code> method will be used for <code>repr()</code> and <code>str()</code>.</p> Source code in <code>pydantic/types.py</code> <pre><code>class Secret(_SecretBase[SecretType]):\n    \"\"\"A generic base class used for defining a field with sensitive information that you do not want to be visible in logging or tracebacks.\n\n    You may either directly parametrize `Secret` with a type, or subclass from `Secret` with a parametrized type. The benefit of subclassing\n    is that you can define a custom `_display` method, which will be used for `repr()` and `str()` methods. The examples below demonstrate both\n    ways of using `Secret` to create a new secret type.\n\n    1. Directly parametrizing `Secret` with a type:\n\n    ```py\n    from pydantic import BaseModel, Secret\n\n    SecretBool = Secret[bool]\n\n    class Model(BaseModel):\n        secret_bool: SecretBool\n\n    m = Model(secret_bool=True)\n    print(m.model_dump())\n    #&gt; {'secret_bool': Secret('**********')}\n\n    print(m.model_dump_json())\n    #&gt; {\"secret_bool\":\"**********\"}\n\n    print(m.secret_bool.get_secret_value())\n    #&gt; True\n    ```\n\n    2. Subclassing from parametrized `Secret`:\n\n    ```py\n    from datetime import date\n\n    from pydantic import BaseModel, Secret\n\n    class SecretDate(Secret[date]):\n        def _display(self) -&gt; str:\n            return '****/**/**'\n\n    class Model(BaseModel):\n        secret_date: SecretDate\n\n    m = Model(secret_date=date(2022, 1, 1))\n    print(m.model_dump())\n    #&gt; {'secret_date': SecretDate('****/**/**')}\n\n    print(m.model_dump_json())\n    #&gt; {\"secret_date\":\"****/**/**\"}\n\n    print(m.secret_date.get_secret_value())\n    #&gt; 2022-01-01\n    ```\n\n    The value returned by the `_display` method will be used for `repr()` and `str()`.\n    \"\"\"\n\n    def _display(self) -&gt; str | bytes:\n        return '**********' if self.get_secret_value() else ''\n\n    @classmethod\n    def __get_pydantic_core_schema__(cls, source: type[Any], handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema:\n        inner_type = None\n        # if origin_type is Secret, then cls is a GenericAlias, and we can extract the inner type directly\n        origin_type = get_origin(source)\n        if origin_type is not None:\n            inner_type = get_args(source)[0]\n        # otherwise, we need to get the inner type from the base class\n        else:\n            bases = getattr(cls, '__orig_bases__', getattr(cls, '__bases__', []))\n            for base in bases:\n                if get_origin(base) is Secret:\n                    inner_type = get_args(base)[0]\n            if bases == [] or inner_type is None:\n                raise TypeError(\n                    f\"Can't get secret type from {cls.__name__}. \"\n                    'Please use Secret[&lt;type&gt;], or subclass from Secret[&lt;type&gt;] instead.'\n                )\n\n        inner_schema = handler.generate_schema(inner_type)  # type: ignore\n\n        def validate_secret_value(value, handler) -&gt; Secret[SecretType]:\n            if isinstance(value, Secret):\n                value = value.get_secret_value()\n            validated_inner = handler(value)\n            return cls(validated_inner)\n\n        def serialize(value: Secret[SecretType], info: core_schema.SerializationInfo) -&gt; str | Secret[SecretType]:\n            if info.mode == 'json':\n                return str(value)\n            else:\n                return value\n\n        return core_schema.json_or_python_schema(\n            python_schema=core_schema.no_info_wrap_validator_function(\n                validate_secret_value,\n                inner_schema,\n            ),\n            json_schema=core_schema.no_info_after_validator_function(lambda x: cls(x), inner_schema),\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                serialize,\n                info_arg=True,\n                when_used='always',\n            ),\n        )\n</code></pre>"},{"location":"api/types/#pydantic.types.SecretStr","title":"SecretStr","text":"<p>               Bases: <code>_SecretField[str]</code></p> <p>A string used for storing sensitive information that you do not want to be visible in logging or tracebacks.</p> <p>When the secret value is nonempty, it is displayed as <code>'**********'</code> instead of the underlying value in calls to <code>repr()</code> and <code>str()</code>. If the value is empty, it is displayed as <code>''</code>.</p> <pre><code>from pydantic import BaseModel, SecretStr\n\nclass User(BaseModel):\n    username: str\n    password: SecretStr\n\nuser = User(username='scolvin', password='password1')\n\nprint(user)\n#&gt; username='scolvin' password=SecretStr('**********')\nprint(user.password.get_secret_value())\n#&gt; password1\nprint((SecretStr('password'), SecretStr('')))\n#&gt; (SecretStr('**********'), SecretStr(''))\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>class SecretStr(_SecretField[str]):\n    \"\"\"A string used for storing sensitive information that you do not want to be visible in logging or tracebacks.\n\n    When the secret value is nonempty, it is displayed as `'**********'` instead of the underlying value in\n    calls to `repr()` and `str()`. If the value _is_ empty, it is displayed as `''`.\n\n    ```py\n    from pydantic import BaseModel, SecretStr\n\n    class User(BaseModel):\n        username: str\n        password: SecretStr\n\n    user = User(username='scolvin', password='password1')\n\n    print(user)\n    #&gt; username='scolvin' password=SecretStr('**********')\n    print(user.password.get_secret_value())\n    #&gt; password1\n    print((SecretStr('password'), SecretStr('')))\n    #&gt; (SecretStr('**********'), SecretStr(''))\n    ```\n    \"\"\"\n\n    _inner_schema: ClassVar[CoreSchema] = core_schema.str_schema()\n    _error_kind: ClassVar[str] = 'string_type'\n\n    def __len__(self) -&gt; int:\n        return len(self._secret_value)\n\n    def _display(self) -&gt; str:\n        return _secret_display(self._secret_value)\n</code></pre>"},{"location":"api/types/#pydantic.types.SecretBytes","title":"SecretBytes","text":"<p>               Bases: <code>_SecretField[bytes]</code></p> <p>A bytes used for storing sensitive information that you do not want to be visible in logging or tracebacks.</p> <p>It displays <code>b'**********'</code> instead of the string value on <code>repr()</code> and <code>str()</code> calls. When the secret value is nonempty, it is displayed as <code>b'**********'</code> instead of the underlying value in calls to <code>repr()</code> and <code>str()</code>. If the value is empty, it is displayed as <code>b''</code>.</p> <pre><code>from pydantic import BaseModel, SecretBytes\n\nclass User(BaseModel):\n    username: str\n    password: SecretBytes\n\nuser = User(username='scolvin', password=b'password1')\n#&gt; username='scolvin' password=SecretBytes(b'**********')\nprint(user.password.get_secret_value())\n#&gt; b'password1'\nprint((SecretBytes(b'password'), SecretBytes(b'')))\n#&gt; (SecretBytes(b'**********'), SecretBytes(b''))\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>class SecretBytes(_SecretField[bytes]):\n    \"\"\"A bytes used for storing sensitive information that you do not want to be visible in logging or tracebacks.\n\n    It displays `b'**********'` instead of the string value on `repr()` and `str()` calls.\n    When the secret value is nonempty, it is displayed as `b'**********'` instead of the underlying value in\n    calls to `repr()` and `str()`. If the value _is_ empty, it is displayed as `b''`.\n\n    ```py\n    from pydantic import BaseModel, SecretBytes\n\n    class User(BaseModel):\n        username: str\n        password: SecretBytes\n\n    user = User(username='scolvin', password=b'password1')\n    #&gt; username='scolvin' password=SecretBytes(b'**********')\n    print(user.password.get_secret_value())\n    #&gt; b'password1'\n    print((SecretBytes(b'password'), SecretBytes(b'')))\n    #&gt; (SecretBytes(b'**********'), SecretBytes(b''))\n    ```\n    \"\"\"\n\n    _inner_schema: ClassVar[CoreSchema] = core_schema.bytes_schema()\n    _error_kind: ClassVar[str] = 'bytes_type'\n\n    def __len__(self) -&gt; int:\n        return len(self._secret_value)\n\n    def _display(self) -&gt; bytes:\n        return _secret_display(self._secret_value).encode()\n</code></pre>"},{"location":"api/types/#pydantic.types.PaymentCardNumber","title":"PaymentCardNumber","text":"<p>               Bases: <code>str</code></p> <p>Based on: https://en.wikipedia.org/wiki/Payment_card_number.</p> Source code in <code>pydantic/types.py</code> <pre><code>@deprecated(\n    'The `PaymentCardNumber` class is deprecated, use `pydantic_extra_types` instead. '\n    'See https://docs.pydantic.dev/latest/api/pydantic_extra_types_payment/#pydantic_extra_types.payment.PaymentCardNumber.',\n    category=PydanticDeprecatedSince20,\n)\nclass PaymentCardNumber(str):\n    \"\"\"Based on: https://en.wikipedia.org/wiki/Payment_card_number.\"\"\"\n\n    strip_whitespace: ClassVar[bool] = True\n    min_length: ClassVar[int] = 12\n    max_length: ClassVar[int] = 19\n    bin: str\n    last4: str\n    brand: PaymentCardBrand\n\n    def __init__(self, card_number: str):\n        self.validate_digits(card_number)\n\n        card_number = self.validate_luhn_check_digit(card_number)\n\n        self.bin = card_number[:6]\n        self.last4 = card_number[-4:]\n        self.brand = self.validate_brand(card_number)\n\n    @classmethod\n    def __get_pydantic_core_schema__(cls, source: type[Any], handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema:\n        return core_schema.with_info_after_validator_function(\n            cls.validate,\n            core_schema.str_schema(\n                min_length=cls.min_length, max_length=cls.max_length, strip_whitespace=cls.strip_whitespace\n            ),\n        )\n\n    @classmethod\n    def validate(cls, input_value: str, /, _: core_schema.ValidationInfo) -&gt; PaymentCardNumber:\n        \"\"\"Validate the card number and return a `PaymentCardNumber` instance.\"\"\"\n        return cls(input_value)\n\n    @property\n    def masked(self) -&gt; str:\n        \"\"\"Mask all but the last 4 digits of the card number.\n\n        Returns:\n            A masked card number string.\n        \"\"\"\n        num_masked = len(self) - 10  # len(bin) + len(last4) == 10\n        return f'{self.bin}{\"*\" * num_masked}{self.last4}'\n\n    @classmethod\n    def validate_digits(cls, card_number: str) -&gt; None:\n        \"\"\"Validate that the card number is all digits.\"\"\"\n        if not card_number.isdigit():\n            raise PydanticCustomError('payment_card_number_digits', 'Card number is not all digits')\n\n    @classmethod\n    def validate_luhn_check_digit(cls, card_number: str) -&gt; str:\n        \"\"\"Based on: https://en.wikipedia.org/wiki/Luhn_algorithm.\"\"\"\n        sum_ = int(card_number[-1])\n        length = len(card_number)\n        parity = length % 2\n        for i in range(length - 1):\n            digit = int(card_number[i])\n            if i % 2 == parity:\n                digit *= 2\n            if digit &gt; 9:\n                digit -= 9\n            sum_ += digit\n        valid = sum_ % 10 == 0\n        if not valid:\n            raise PydanticCustomError('payment_card_number_luhn', 'Card number is not luhn valid')\n        return card_number\n\n    @staticmethod\n    def validate_brand(card_number: str) -&gt; PaymentCardBrand:\n        \"\"\"Validate length based on BIN for major brands:\n        https://en.wikipedia.org/wiki/Payment_card_number#Issuer_identification_number_(IIN).\n        \"\"\"\n        if card_number[0] == '4':\n            brand = PaymentCardBrand.visa\n        elif 51 &lt;= int(card_number[:2]) &lt;= 55:\n            brand = PaymentCardBrand.mastercard\n        elif card_number[:2] in {'34', '37'}:\n            brand = PaymentCardBrand.amex\n        else:\n            brand = PaymentCardBrand.other\n\n        required_length: None | int | str = None\n        if brand in PaymentCardBrand.mastercard:\n            required_length = 16\n            valid = len(card_number) == required_length\n        elif brand == PaymentCardBrand.visa:\n            required_length = '13, 16 or 19'\n            valid = len(card_number) in {13, 16, 19}\n        elif brand == PaymentCardBrand.amex:\n            required_length = 15\n            valid = len(card_number) == required_length\n        else:\n            valid = True\n\n        if not valid:\n            raise PydanticCustomError(\n                'payment_card_number_brand',\n                'Length for a {brand} card must be {required_length}',\n                {'brand': brand, 'required_length': required_length},\n            )\n        return brand\n</code></pre>"},{"location":"api/types/#pydantic.types.PaymentCardNumber.masked","title":"masked  <code>property</code>   <pre><code>masked: str\n</code></pre>  <p>Mask all but the last 4 digits of the card number.</p> <p>Returns:</p>    Type Description      <code>str</code>    <p>A masked card number string.</p>","text":""},{"location":"api/types/#pydantic.types.PaymentCardNumber.validate","title":"validate  <code>classmethod</code>   <pre><code>validate(\n    input_value: str, /, _: ValidationInfo\n) -&gt; PaymentCardNumber\n</code></pre>  <p>Validate the card number and return a <code>PaymentCardNumber</code> instance.</p>  Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef validate(cls, input_value: str, /, _: core_schema.ValidationInfo) -&gt; PaymentCardNumber:\n    \"\"\"Validate the card number and return a `PaymentCardNumber` instance.\"\"\"\n    return cls(input_value)\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.PaymentCardNumber.validate_digits","title":"validate_digits  <code>classmethod</code>   <pre><code>validate_digits(card_number: str) -&gt; None\n</code></pre>  <p>Validate that the card number is all digits.</p>  Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef validate_digits(cls, card_number: str) -&gt; None:\n    \"\"\"Validate that the card number is all digits.\"\"\"\n    if not card_number.isdigit():\n        raise PydanticCustomError('payment_card_number_digits', 'Card number is not all digits')\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.PaymentCardNumber.validate_luhn_check_digit","title":"validate_luhn_check_digit  <code>classmethod</code>   <pre><code>validate_luhn_check_digit(card_number: str) -&gt; str\n</code></pre>  <p>Based on: https://en.wikipedia.org/wiki/Luhn_algorithm.</p>  Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef validate_luhn_check_digit(cls, card_number: str) -&gt; str:\n    \"\"\"Based on: https://en.wikipedia.org/wiki/Luhn_algorithm.\"\"\"\n    sum_ = int(card_number[-1])\n    length = len(card_number)\n    parity = length % 2\n    for i in range(length - 1):\n        digit = int(card_number[i])\n        if i % 2 == parity:\n            digit *= 2\n        if digit &gt; 9:\n            digit -= 9\n        sum_ += digit\n    valid = sum_ % 10 == 0\n    if not valid:\n        raise PydanticCustomError('payment_card_number_luhn', 'Card number is not luhn valid')\n    return card_number\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.PaymentCardNumber.validate_brand","title":"validate_brand  <code>staticmethod</code>   <pre><code>validate_brand(card_number: str) -&gt; PaymentCardBrand\n</code></pre>  <p>Validate length based on BIN for major brands: https://en.wikipedia.org/wiki/Payment_card_number#Issuer_identification_number_(IIN).</p>  Source code in <code>pydantic/types.py</code> <pre><code>@staticmethod\ndef validate_brand(card_number: str) -&gt; PaymentCardBrand:\n    \"\"\"Validate length based on BIN for major brands:\n    https://en.wikipedia.org/wiki/Payment_card_number#Issuer_identification_number_(IIN).\n    \"\"\"\n    if card_number[0] == '4':\n        brand = PaymentCardBrand.visa\n    elif 51 &lt;= int(card_number[:2]) &lt;= 55:\n        brand = PaymentCardBrand.mastercard\n    elif card_number[:2] in {'34', '37'}:\n        brand = PaymentCardBrand.amex\n    else:\n        brand = PaymentCardBrand.other\n\n    required_length: None | int | str = None\n    if brand in PaymentCardBrand.mastercard:\n        required_length = 16\n        valid = len(card_number) == required_length\n    elif brand == PaymentCardBrand.visa:\n        required_length = '13, 16 or 19'\n        valid = len(card_number) in {13, 16, 19}\n    elif brand == PaymentCardBrand.amex:\n        required_length = 15\n        valid = len(card_number) == required_length\n    else:\n        valid = True\n\n    if not valid:\n        raise PydanticCustomError(\n            'payment_card_number_brand',\n            'Length for a {brand} card must be {required_length}',\n            {'brand': brand, 'required_length': required_length},\n        )\n    return brand\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.ByteSize","title":"ByteSize","text":"<p>               Bases: <code>int</code></p> <p>Converts a string representing a number of bytes with units (such as <code>'1KB'</code> or <code>'11.5MiB'</code>) into an integer.</p> <p>You can use the <code>ByteSize</code> data type to (case-insensitively) convert a string representation of a number of bytes into an integer, and also to print out human-readable strings representing a number of bytes.</p> <p>In conformance with IEC 80000-13 Standard we interpret <code>'1KB'</code> to mean 1000 bytes, and <code>'1KiB'</code> to mean 1024 bytes. In general, including a middle <code>'i'</code> will cause the unit to be interpreted as a power of 2, rather than a power of 10 (so, for example, <code>'1 MB'</code> is treated as <code>1_000_000</code> bytes, whereas <code>'1 MiB'</code> is treated as <code>1_048_576</code> bytes).</p> <p>Info</p> <p>Note that <code>1b</code> will be parsed as \"1 byte\" and not \"1 bit\".</p> <pre><code>from pydantic import BaseModel, ByteSize\n\nclass MyModel(BaseModel):\n    size: ByteSize\n\nprint(MyModel(size=52000).size)\n#&gt; 52000\nprint(MyModel(size='3000 KiB').size)\n#&gt; 3072000\n\nm = MyModel(size='50 PB')\nprint(m.size.human_readable())\n#&gt; 44.4PiB\nprint(m.size.human_readable(decimal=True))\n#&gt; 50.0PB\nprint(m.size.human_readable(separator=' '))\n#&gt; 44.4 PiB\n\nprint(m.size.to('TiB'))\n#&gt; 45474.73508864641\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>class ByteSize(int):\n    \"\"\"Converts a string representing a number of bytes with units (such as `'1KB'` or `'11.5MiB'`) into an integer.\n\n    You can use the `ByteSize` data type to (case-insensitively) convert a string representation of a number of bytes into\n    an integer, and also to print out human-readable strings representing a number of bytes.\n\n    In conformance with [IEC 80000-13 Standard](https://en.wikipedia.org/wiki/ISO/IEC_80000) we interpret `'1KB'` to mean 1000 bytes,\n    and `'1KiB'` to mean 1024 bytes. In general, including a middle `'i'` will cause the unit to be interpreted as a power of 2,\n    rather than a power of 10 (so, for example, `'1 MB'` is treated as `1_000_000` bytes, whereas `'1 MiB'` is treated as `1_048_576` bytes).\n\n    !!! info\n        Note that `1b` will be parsed as \"1 byte\" and not \"1 bit\".\n\n    ```py\n    from pydantic import BaseModel, ByteSize\n\n    class MyModel(BaseModel):\n        size: ByteSize\n\n    print(MyModel(size=52000).size)\n    #&gt; 52000\n    print(MyModel(size='3000 KiB').size)\n    #&gt; 3072000\n\n    m = MyModel(size='50 PB')\n    print(m.size.human_readable())\n    #&gt; 44.4PiB\n    print(m.size.human_readable(decimal=True))\n    #&gt; 50.0PB\n    print(m.size.human_readable(separator=' '))\n    #&gt; 44.4 PiB\n\n    print(m.size.to('TiB'))\n    #&gt; 45474.73508864641\n    ```\n    \"\"\"\n\n    byte_sizes = {\n        'b': 1,\n        'kb': 10**3,\n        'mb': 10**6,\n        'gb': 10**9,\n        'tb': 10**12,\n        'pb': 10**15,\n        'eb': 10**18,\n        'kib': 2**10,\n        'mib': 2**20,\n        'gib': 2**30,\n        'tib': 2**40,\n        'pib': 2**50,\n        'eib': 2**60,\n        'bit': 1 / 8,\n        'kbit': 10**3 / 8,\n        'mbit': 10**6 / 8,\n        'gbit': 10**9 / 8,\n        'tbit': 10**12 / 8,\n        'pbit': 10**15 / 8,\n        'ebit': 10**18 / 8,\n        'kibit': 2**10 / 8,\n        'mibit': 2**20 / 8,\n        'gibit': 2**30 / 8,\n        'tibit': 2**40 / 8,\n        'pibit': 2**50 / 8,\n        'eibit': 2**60 / 8,\n    }\n    byte_sizes.update({k.lower()[0]: v for k, v in byte_sizes.items() if 'i' not in k})\n\n    byte_string_pattern = r'^\\s*(\\d*\\.?\\d+)\\s*(\\w+)?'\n    byte_string_re = re.compile(byte_string_pattern, re.IGNORECASE)\n\n    @classmethod\n    def __get_pydantic_core_schema__(cls, source: type[Any], handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema:\n        return core_schema.with_info_after_validator_function(\n            function=cls._validate,\n            schema=core_schema.union_schema(\n                [\n                    core_schema.str_schema(pattern=cls.byte_string_pattern),\n                    core_schema.int_schema(ge=0),\n                ],\n                custom_error_type='byte_size',\n                custom_error_message='could not parse value and unit from byte string',\n            ),\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                int, return_schema=core_schema.int_schema(ge=0)\n            ),\n        )\n\n    @classmethod\n    def _validate(cls, input_value: Any, /, _: core_schema.ValidationInfo) -&gt; ByteSize:\n        try:\n            return cls(int(input_value))\n        except ValueError:\n            pass\n\n        str_match = cls.byte_string_re.match(str(input_value))\n        if str_match is None:\n            raise PydanticCustomError('byte_size', 'could not parse value and unit from byte string')\n\n        scalar, unit = str_match.groups()\n        if unit is None:\n            unit = 'b'\n\n        try:\n            unit_mult = cls.byte_sizes[unit.lower()]\n        except KeyError:\n            raise PydanticCustomError('byte_size_unit', 'could not interpret byte unit: {unit}', {'unit': unit})\n\n        return cls(int(float(scalar) * unit_mult))\n\n    def human_readable(self, decimal: bool = False, separator: str = '') -&gt; str:\n        \"\"\"Converts a byte size to a human readable string.\n\n        Args:\n            decimal: If True, use decimal units (e.g. 1000 bytes per KB). If False, use binary units\n                (e.g. 1024 bytes per KiB).\n            separator: A string used to split the value and unit. Defaults to an empty string ('').\n\n        Returns:\n            A human readable string representation of the byte size.\n        \"\"\"\n        if decimal:\n            divisor = 1000\n            units = 'B', 'KB', 'MB', 'GB', 'TB', 'PB'\n            final_unit = 'EB'\n        else:\n            divisor = 1024\n            units = 'B', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB'\n            final_unit = 'EiB'\n\n        num = float(self)\n        for unit in units:\n            if abs(num) &lt; divisor:\n                if unit == 'B':\n                    return f'{num:0.0f}{separator}{unit}'\n                else:\n                    return f'{num:0.1f}{separator}{unit}'\n            num /= divisor\n\n        return f'{num:0.1f}{separator}{final_unit}'\n\n    def to(self, unit: str) -&gt; float:\n        \"\"\"Converts a byte size to another unit, including both byte and bit units.\n\n        Args:\n            unit: The unit to convert to. Must be one of the following: B, KB, MB, GB, TB, PB, EB,\n                KiB, MiB, GiB, TiB, PiB, EiB (byte units) and\n                bit, kbit, mbit, gbit, tbit, pbit, ebit,\n                kibit, mibit, gibit, tibit, pibit, eibit (bit units).\n\n        Returns:\n            The byte size in the new unit.\n        \"\"\"\n        try:\n            unit_div = self.byte_sizes[unit.lower()]\n        except KeyError:\n            raise PydanticCustomError('byte_size_unit', 'Could not interpret byte unit: {unit}', {'unit': unit})\n\n        return self / unit_div\n</code></pre>"},{"location":"api/types/#pydantic.types.ByteSize.human_readable","title":"human_readable  <pre><code>human_readable(\n    decimal: bool = False, separator: str = \"\"\n) -&gt; str\n</code></pre>  <p>Converts a byte size to a human readable string.</p> <p>Parameters:</p>    Name Type Description Default     <code>decimal</code>  <code>bool</code>    <p>If True, use decimal units (e.g. 1000 bytes per KB). If False, use binary units (e.g. 1024 bytes per KiB).</p>    <code>False</code>    <code>separator</code>  <code>str</code>    <p>A string used to split the value and unit. Defaults to an empty string ('').</p>    <code>''</code>     <p>Returns:</p>    Type Description      <code>str</code>    <p>A human readable string representation of the byte size.</p>       Source code in <code>pydantic/types.py</code> <pre><code>def human_readable(self, decimal: bool = False, separator: str = '') -&gt; str:\n    \"\"\"Converts a byte size to a human readable string.\n\n    Args:\n        decimal: If True, use decimal units (e.g. 1000 bytes per KB). If False, use binary units\n            (e.g. 1024 bytes per KiB).\n        separator: A string used to split the value and unit. Defaults to an empty string ('').\n\n    Returns:\n        A human readable string representation of the byte size.\n    \"\"\"\n    if decimal:\n        divisor = 1000\n        units = 'B', 'KB', 'MB', 'GB', 'TB', 'PB'\n        final_unit = 'EB'\n    else:\n        divisor = 1024\n        units = 'B', 'KiB', 'MiB', 'GiB', 'TiB', 'PiB'\n        final_unit = 'EiB'\n\n    num = float(self)\n    for unit in units:\n        if abs(num) &lt; divisor:\n            if unit == 'B':\n                return f'{num:0.0f}{separator}{unit}'\n            else:\n                return f'{num:0.1f}{separator}{unit}'\n        num /= divisor\n\n    return f'{num:0.1f}{separator}{final_unit}'\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.ByteSize.to","title":"to  <pre><code>to(unit: str) -&gt; float\n</code></pre>  <p>Converts a byte size to another unit, including both byte and bit units.</p> <p>Parameters:</p>    Name Type Description Default     <code>unit</code>  <code>str</code>    <p>The unit to convert to. Must be one of the following: B, KB, MB, GB, TB, PB, EB, KiB, MiB, GiB, TiB, PiB, EiB (byte units) and bit, kbit, mbit, gbit, tbit, pbit, ebit, kibit, mibit, gibit, tibit, pibit, eibit (bit units).</p>    required     <p>Returns:</p>    Type Description      <code>float</code>    <p>The byte size in the new unit.</p>       Source code in <code>pydantic/types.py</code> <pre><code>def to(self, unit: str) -&gt; float:\n    \"\"\"Converts a byte size to another unit, including both byte and bit units.\n\n    Args:\n        unit: The unit to convert to. Must be one of the following: B, KB, MB, GB, TB, PB, EB,\n            KiB, MiB, GiB, TiB, PiB, EiB (byte units) and\n            bit, kbit, mbit, gbit, tbit, pbit, ebit,\n            kibit, mibit, gibit, tibit, pibit, eibit (bit units).\n\n    Returns:\n        The byte size in the new unit.\n    \"\"\"\n    try:\n        unit_div = self.byte_sizes[unit.lower()]\n    except KeyError:\n        raise PydanticCustomError('byte_size_unit', 'Could not interpret byte unit: {unit}', {'unit': unit})\n\n    return self / unit_div\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.PastDate","title":"PastDate","text":"<p>A date in the past.</p> Source code in <code>pydantic/types.py</code> <pre><code>class PastDate:\n    \"\"\"A date in the past.\"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if cls is source:\n            # used directly as a type\n            return core_schema.date_schema(now_op='past')\n        else:\n            schema = handler(source)\n            _check_annotated_type(schema['type'], 'date', cls.__name__)\n            schema['now_op'] = 'past'\n            return schema\n\n    def __repr__(self) -&gt; str:\n        return 'PastDate'\n</code></pre>"},{"location":"api/types/#pydantic.types.FutureDate","title":"FutureDate","text":"<p>A date in the future.</p> Source code in <code>pydantic/types.py</code> <pre><code>class FutureDate:\n    \"\"\"A date in the future.\"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if cls is source:\n            # used directly as a type\n            return core_schema.date_schema(now_op='future')\n        else:\n            schema = handler(source)\n            _check_annotated_type(schema['type'], 'date', cls.__name__)\n            schema['now_op'] = 'future'\n            return schema\n\n    def __repr__(self) -&gt; str:\n        return 'FutureDate'\n</code></pre>"},{"location":"api/types/#pydantic.types.AwareDatetime","title":"AwareDatetime","text":"<p>A datetime that requires timezone info.</p> Source code in <code>pydantic/types.py</code> <pre><code>class AwareDatetime:\n    \"\"\"A datetime that requires timezone info.\"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if cls is source:\n            # used directly as a type\n            return core_schema.datetime_schema(tz_constraint='aware')\n        else:\n            schema = handler(source)\n            _check_annotated_type(schema['type'], 'datetime', cls.__name__)\n            schema['tz_constraint'] = 'aware'\n            return schema\n\n    def __repr__(self) -&gt; str:\n        return 'AwareDatetime'\n</code></pre>"},{"location":"api/types/#pydantic.types.NaiveDatetime","title":"NaiveDatetime","text":"<p>A datetime that doesn't require timezone info.</p> Source code in <code>pydantic/types.py</code> <pre><code>class NaiveDatetime:\n    \"\"\"A datetime that doesn't require timezone info.\"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if cls is source:\n            # used directly as a type\n            return core_schema.datetime_schema(tz_constraint='naive')\n        else:\n            schema = handler(source)\n            _check_annotated_type(schema['type'], 'datetime', cls.__name__)\n            schema['tz_constraint'] = 'naive'\n            return schema\n\n    def __repr__(self) -&gt; str:\n        return 'NaiveDatetime'\n</code></pre>"},{"location":"api/types/#pydantic.types.PastDatetime","title":"PastDatetime","text":"<p>A datetime that must be in the past.</p> Source code in <code>pydantic/types.py</code> <pre><code>class PastDatetime:\n    \"\"\"A datetime that must be in the past.\"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if cls is source:\n            # used directly as a type\n            return core_schema.datetime_schema(now_op='past')\n        else:\n            schema = handler(source)\n            _check_annotated_type(schema['type'], 'datetime', cls.__name__)\n            schema['now_op'] = 'past'\n            return schema\n\n    def __repr__(self) -&gt; str:\n        return 'PastDatetime'\n</code></pre>"},{"location":"api/types/#pydantic.types.FutureDatetime","title":"FutureDatetime","text":"<p>A datetime that must be in the future.</p> Source code in <code>pydantic/types.py</code> <pre><code>class FutureDatetime:\n    \"\"\"A datetime that must be in the future.\"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if cls is source:\n            # used directly as a type\n            return core_schema.datetime_schema(now_op='future')\n        else:\n            schema = handler(source)\n            _check_annotated_type(schema['type'], 'datetime', cls.__name__)\n            schema['now_op'] = 'future'\n            return schema\n\n    def __repr__(self) -&gt; str:\n        return 'FutureDatetime'\n</code></pre>"},{"location":"api/types/#pydantic.types.EncoderProtocol","title":"EncoderProtocol","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for encoding and decoding data to and from bytes.</p> Source code in <code>pydantic/types.py</code> <pre><code>class EncoderProtocol(Protocol):\n    \"\"\"Protocol for encoding and decoding data to and from bytes.\"\"\"\n\n    @classmethod\n    def decode(cls, data: bytes) -&gt; bytes:\n        \"\"\"Decode the data using the encoder.\n\n        Args:\n            data: The data to decode.\n\n        Returns:\n            The decoded data.\n        \"\"\"\n        ...\n\n    @classmethod\n    def encode(cls, value: bytes) -&gt; bytes:\n        \"\"\"Encode the data using the encoder.\n\n        Args:\n            value: The data to encode.\n\n        Returns:\n            The encoded data.\n        \"\"\"\n        ...\n\n    @classmethod\n    def get_json_format(cls) -&gt; str:\n        \"\"\"Get the JSON format for the encoded data.\n\n        Returns:\n            The JSON format for the encoded data.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/types/#pydantic.types.EncoderProtocol.decode","title":"decode  <code>classmethod</code>   <pre><code>decode(data: bytes) -&gt; bytes\n</code></pre>  <p>Decode the data using the encoder.</p> <p>Parameters:</p>    Name Type Description Default     <code>data</code>  <code>bytes</code>    <p>The data to decode.</p>    required     <p>Returns:</p>    Type Description      <code>bytes</code>    <p>The decoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef decode(cls, data: bytes) -&gt; bytes:\n    \"\"\"Decode the data using the encoder.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    ...\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.EncoderProtocol.encode","title":"encode  <code>classmethod</code>   <pre><code>encode(value: bytes) -&gt; bytes\n</code></pre>  <p>Encode the data using the encoder.</p> <p>Parameters:</p>    Name Type Description Default     <code>value</code>  <code>bytes</code>    <p>The data to encode.</p>    required     <p>Returns:</p>    Type Description      <code>bytes</code>    <p>The encoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef encode(cls, value: bytes) -&gt; bytes:\n    \"\"\"Encode the data using the encoder.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    ...\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.EncoderProtocol.get_json_format","title":"get_json_format  <code>classmethod</code>   <pre><code>get_json_format() -&gt; str\n</code></pre>  <p>Get the JSON format for the encoded data.</p> <p>Returns:</p>    Type Description      <code>str</code>    <p>The JSON format for the encoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef get_json_format(cls) -&gt; str:\n    \"\"\"Get the JSON format for the encoded data.\n\n    Returns:\n        The JSON format for the encoded data.\n    \"\"\"\n    ...\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.Base64Encoder","title":"Base64Encoder","text":"<p>               Bases: <code>EncoderProtocol</code></p> <p>Standard (non-URL-safe) Base64 encoder.</p> Source code in <code>pydantic/types.py</code> <pre><code>class Base64Encoder(EncoderProtocol):\n    \"\"\"Standard (non-URL-safe) Base64 encoder.\"\"\"\n\n    @classmethod\n    def decode(cls, data: bytes) -&gt; bytes:\n        \"\"\"Decode the data from base64 encoded bytes to original bytes data.\n\n        Args:\n            data: The data to decode.\n\n        Returns:\n            The decoded data.\n        \"\"\"\n        try:\n            return base64.decodebytes(data)\n        except ValueError as e:\n            raise PydanticCustomError('base64_decode', \"Base64 decoding error: '{error}'\", {'error': str(e)})\n\n    @classmethod\n    def encode(cls, value: bytes) -&gt; bytes:\n        \"\"\"Encode the data from bytes to a base64 encoded bytes.\n\n        Args:\n            value: The data to encode.\n\n        Returns:\n            The encoded data.\n        \"\"\"\n        return base64.encodebytes(value)\n\n    @classmethod\n    def get_json_format(cls) -&gt; Literal['base64']:\n        \"\"\"Get the JSON format for the encoded data.\n\n        Returns:\n            The JSON format for the encoded data.\n        \"\"\"\n        return 'base64'\n</code></pre>"},{"location":"api/types/#pydantic.types.Base64Encoder.decode","title":"decode  <code>classmethod</code>   <pre><code>decode(data: bytes) -&gt; bytes\n</code></pre>  <p>Decode the data from base64 encoded bytes to original bytes data.</p> <p>Parameters:</p>    Name Type Description Default     <code>data</code>  <code>bytes</code>    <p>The data to decode.</p>    required     <p>Returns:</p>    Type Description      <code>bytes</code>    <p>The decoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef decode(cls, data: bytes) -&gt; bytes:\n    \"\"\"Decode the data from base64 encoded bytes to original bytes data.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    try:\n        return base64.decodebytes(data)\n    except ValueError as e:\n        raise PydanticCustomError('base64_decode', \"Base64 decoding error: '{error}'\", {'error': str(e)})\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.Base64Encoder.encode","title":"encode  <code>classmethod</code>   <pre><code>encode(value: bytes) -&gt; bytes\n</code></pre>  <p>Encode the data from bytes to a base64 encoded bytes.</p> <p>Parameters:</p>    Name Type Description Default     <code>value</code>  <code>bytes</code>    <p>The data to encode.</p>    required     <p>Returns:</p>    Type Description      <code>bytes</code>    <p>The encoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef encode(cls, value: bytes) -&gt; bytes:\n    \"\"\"Encode the data from bytes to a base64 encoded bytes.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    return base64.encodebytes(value)\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.Base64Encoder.get_json_format","title":"get_json_format  <code>classmethod</code>   <pre><code>get_json_format() -&gt; Literal['base64']\n</code></pre>  <p>Get the JSON format for the encoded data.</p> <p>Returns:</p>    Type Description      <code>Literal['base64']</code>    <p>The JSON format for the encoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef get_json_format(cls) -&gt; Literal['base64']:\n    \"\"\"Get the JSON format for the encoded data.\n\n    Returns:\n        The JSON format for the encoded data.\n    \"\"\"\n    return 'base64'\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.Base64UrlEncoder","title":"Base64UrlEncoder","text":"<p>               Bases: <code>EncoderProtocol</code></p> <p>URL-safe Base64 encoder.</p> Source code in <code>pydantic/types.py</code> <pre><code>class Base64UrlEncoder(EncoderProtocol):\n    \"\"\"URL-safe Base64 encoder.\"\"\"\n\n    @classmethod\n    def decode(cls, data: bytes) -&gt; bytes:\n        \"\"\"Decode the data from base64 encoded bytes to original bytes data.\n\n        Args:\n            data: The data to decode.\n\n        Returns:\n            The decoded data.\n        \"\"\"\n        try:\n            return base64.urlsafe_b64decode(data)\n        except ValueError as e:\n            raise PydanticCustomError('base64_decode', \"Base64 decoding error: '{error}'\", {'error': str(e)})\n\n    @classmethod\n    def encode(cls, value: bytes) -&gt; bytes:\n        \"\"\"Encode the data from bytes to a base64 encoded bytes.\n\n        Args:\n            value: The data to encode.\n\n        Returns:\n            The encoded data.\n        \"\"\"\n        return base64.urlsafe_b64encode(value)\n\n    @classmethod\n    def get_json_format(cls) -&gt; Literal['base64url']:\n        \"\"\"Get the JSON format for the encoded data.\n\n        Returns:\n            The JSON format for the encoded data.\n        \"\"\"\n        return 'base64url'\n</code></pre>"},{"location":"api/types/#pydantic.types.Base64UrlEncoder.decode","title":"decode  <code>classmethod</code>   <pre><code>decode(data: bytes) -&gt; bytes\n</code></pre>  <p>Decode the data from base64 encoded bytes to original bytes data.</p> <p>Parameters:</p>    Name Type Description Default     <code>data</code>  <code>bytes</code>    <p>The data to decode.</p>    required     <p>Returns:</p>    Type Description      <code>bytes</code>    <p>The decoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef decode(cls, data: bytes) -&gt; bytes:\n    \"\"\"Decode the data from base64 encoded bytes to original bytes data.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    try:\n        return base64.urlsafe_b64decode(data)\n    except ValueError as e:\n        raise PydanticCustomError('base64_decode', \"Base64 decoding error: '{error}'\", {'error': str(e)})\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.Base64UrlEncoder.encode","title":"encode  <code>classmethod</code>   <pre><code>encode(value: bytes) -&gt; bytes\n</code></pre>  <p>Encode the data from bytes to a base64 encoded bytes.</p> <p>Parameters:</p>    Name Type Description Default     <code>value</code>  <code>bytes</code>    <p>The data to encode.</p>    required     <p>Returns:</p>    Type Description      <code>bytes</code>    <p>The encoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef encode(cls, value: bytes) -&gt; bytes:\n    \"\"\"Encode the data from bytes to a base64 encoded bytes.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    return base64.urlsafe_b64encode(value)\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.Base64UrlEncoder.get_json_format","title":"get_json_format  <code>classmethod</code>   <pre><code>get_json_format() -&gt; Literal['base64url']\n</code></pre>  <p>Get the JSON format for the encoded data.</p> <p>Returns:</p>    Type Description      <code>Literal['base64url']</code>    <p>The JSON format for the encoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>@classmethod\ndef get_json_format(cls) -&gt; Literal['base64url']:\n    \"\"\"Get the JSON format for the encoded data.\n\n    Returns:\n        The JSON format for the encoded data.\n    \"\"\"\n    return 'base64url'\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.EncodedBytes","title":"EncodedBytes  <code>dataclass</code>","text":"<p>A bytes type that is encoded and decoded using the specified encoder.</p> <p><code>EncodedBytes</code> needs an encoder that implements <code>EncoderProtocol</code> to operate.</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, EncodedBytes, EncoderProtocol, ValidationError\n\nclass MyEncoder(EncoderProtocol):\n    @classmethod\n    def decode(cls, data: bytes) -&gt; bytes:\n        if data == b'**undecodable**':\n            raise ValueError('Cannot decode data')\n        return data[13:]\n\n    @classmethod\n    def encode(cls, value: bytes) -&gt; bytes:\n        return b'**encoded**: ' + value\n\n    @classmethod\n    def get_json_format(cls) -&gt; str:\n        return 'my-encoder'\n\nMyEncodedBytes = Annotated[bytes, EncodedBytes(encoder=MyEncoder)]\n\nclass Model(BaseModel):\n    my_encoded_bytes: MyEncodedBytes\n\n# Initialize the model with encoded data\nm = Model(my_encoded_bytes=b'**encoded**: some bytes')\n\n# Access decoded value\nprint(m.my_encoded_bytes)\n#&gt; b'some bytes'\n\n# Serialize into the encoded form\nprint(m.model_dump())\n#&gt; {'my_encoded_bytes': b'**encoded**: some bytes'}\n\n# Validate encoded data\ntry:\n    Model(my_encoded_bytes=b'**undecodable**')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    my_encoded_bytes\n      Value error, Cannot decode data [type=value_error, input_value=b'**undecodable**', input_type=bytes]\n    '''\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass(**_internal_dataclass.slots_true)\nclass EncodedBytes:\n    \"\"\"A bytes type that is encoded and decoded using the specified encoder.\n\n    `EncodedBytes` needs an encoder that implements `EncoderProtocol` to operate.\n\n    ```py\n    from typing_extensions import Annotated\n\n    from pydantic import BaseModel, EncodedBytes, EncoderProtocol, ValidationError\n\n    class MyEncoder(EncoderProtocol):\n        @classmethod\n        def decode(cls, data: bytes) -&gt; bytes:\n            if data == b'**undecodable**':\n                raise ValueError('Cannot decode data')\n            return data[13:]\n\n        @classmethod\n        def encode(cls, value: bytes) -&gt; bytes:\n            return b'**encoded**: ' + value\n\n        @classmethod\n        def get_json_format(cls) -&gt; str:\n            return 'my-encoder'\n\n    MyEncodedBytes = Annotated[bytes, EncodedBytes(encoder=MyEncoder)]\n\n    class Model(BaseModel):\n        my_encoded_bytes: MyEncodedBytes\n\n    # Initialize the model with encoded data\n    m = Model(my_encoded_bytes=b'**encoded**: some bytes')\n\n    # Access decoded value\n    print(m.my_encoded_bytes)\n    #&gt; b'some bytes'\n\n    # Serialize into the encoded form\n    print(m.model_dump())\n    #&gt; {'my_encoded_bytes': b'**encoded**: some bytes'}\n\n    # Validate encoded data\n    try:\n        Model(my_encoded_bytes=b'**undecodable**')\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Model\n        my_encoded_bytes\n          Value error, Cannot decode data [type=value_error, input_value=b'**undecodable**', input_type=bytes]\n        '''\n    ```\n    \"\"\"\n\n    encoder: type[EncoderProtocol]\n\n    def __get_pydantic_json_schema__(\n        self, core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; JsonSchemaValue:\n        field_schema = handler(core_schema)\n        field_schema.update(type='string', format=self.encoder.get_json_format())\n        return field_schema\n\n    def __get_pydantic_core_schema__(self, source: type[Any], handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema:\n        return core_schema.with_info_after_validator_function(\n            function=self.decode,\n            schema=core_schema.bytes_schema(),\n            serialization=core_schema.plain_serializer_function_ser_schema(function=self.encode),\n        )\n\n    def decode(self, data: bytes, _: core_schema.ValidationInfo) -&gt; bytes:\n        \"\"\"Decode the data using the specified encoder.\n\n        Args:\n            data: The data to decode.\n\n        Returns:\n            The decoded data.\n        \"\"\"\n        return self.encoder.decode(data)\n\n    def encode(self, value: bytes) -&gt; bytes:\n        \"\"\"Encode the data using the specified encoder.\n\n        Args:\n            value: The data to encode.\n\n        Returns:\n            The encoded data.\n        \"\"\"\n        return self.encoder.encode(value)\n\n    def __hash__(self) -&gt; int:\n        return hash(self.encoder)\n</code></pre>"},{"location":"api/types/#pydantic.types.EncodedBytes.decode","title":"decode  <pre><code>decode(data: bytes, _: ValidationInfo) -&gt; bytes\n</code></pre>  <p>Decode the data using the specified encoder.</p> <p>Parameters:</p>    Name Type Description Default     <code>data</code>  <code>bytes</code>    <p>The data to decode.</p>    required     <p>Returns:</p>    Type Description      <code>bytes</code>    <p>The decoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>def decode(self, data: bytes, _: core_schema.ValidationInfo) -&gt; bytes:\n    \"\"\"Decode the data using the specified encoder.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    return self.encoder.decode(data)\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.EncodedBytes.encode","title":"encode  <pre><code>encode(value: bytes) -&gt; bytes\n</code></pre>  <p>Encode the data using the specified encoder.</p> <p>Parameters:</p>    Name Type Description Default     <code>value</code>  <code>bytes</code>    <p>The data to encode.</p>    required     <p>Returns:</p>    Type Description      <code>bytes</code>    <p>The encoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>def encode(self, value: bytes) -&gt; bytes:\n    \"\"\"Encode the data using the specified encoder.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    return self.encoder.encode(value)\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.EncodedStr","title":"EncodedStr  <code>dataclass</code>","text":"<p>               Bases: <code>EncodedBytes</code></p> <p>A str type that is encoded and decoded using the specified encoder.</p> <p><code>EncodedStr</code> needs an encoder that implements <code>EncoderProtocol</code> to operate.</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, EncodedStr, EncoderProtocol, ValidationError\n\nclass MyEncoder(EncoderProtocol):\n    @classmethod\n    def decode(cls, data: bytes) -&gt; bytes:\n        if data == b'**undecodable**':\n            raise ValueError('Cannot decode data')\n        return data[13:]\n\n    @classmethod\n    def encode(cls, value: bytes) -&gt; bytes:\n        return b'**encoded**: ' + value\n\n    @classmethod\n    def get_json_format(cls) -&gt; str:\n        return 'my-encoder'\n\nMyEncodedStr = Annotated[str, EncodedStr(encoder=MyEncoder)]\n\nclass Model(BaseModel):\n    my_encoded_str: MyEncodedStr\n\n# Initialize the model with encoded data\nm = Model(my_encoded_str='**encoded**: some str')\n\n# Access decoded value\nprint(m.my_encoded_str)\n#&gt; some str\n\n# Serialize into the encoded form\nprint(m.model_dump())\n#&gt; {'my_encoded_str': '**encoded**: some str'}\n\n# Validate encoded data\ntry:\n    Model(my_encoded_str='**undecodable**')\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    my_encoded_str\n      Value error, Cannot decode data [type=value_error, input_value='**undecodable**', input_type=str]\n    '''\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass(**_internal_dataclass.slots_true)\nclass EncodedStr(EncodedBytes):\n    \"\"\"A str type that is encoded and decoded using the specified encoder.\n\n    `EncodedStr` needs an encoder that implements `EncoderProtocol` to operate.\n\n    ```py\n    from typing_extensions import Annotated\n\n    from pydantic import BaseModel, EncodedStr, EncoderProtocol, ValidationError\n\n    class MyEncoder(EncoderProtocol):\n        @classmethod\n        def decode(cls, data: bytes) -&gt; bytes:\n            if data == b'**undecodable**':\n                raise ValueError('Cannot decode data')\n            return data[13:]\n\n        @classmethod\n        def encode(cls, value: bytes) -&gt; bytes:\n            return b'**encoded**: ' + value\n\n        @classmethod\n        def get_json_format(cls) -&gt; str:\n            return 'my-encoder'\n\n    MyEncodedStr = Annotated[str, EncodedStr(encoder=MyEncoder)]\n\n    class Model(BaseModel):\n        my_encoded_str: MyEncodedStr\n\n    # Initialize the model with encoded data\n    m = Model(my_encoded_str='**encoded**: some str')\n\n    # Access decoded value\n    print(m.my_encoded_str)\n    #&gt; some str\n\n    # Serialize into the encoded form\n    print(m.model_dump())\n    #&gt; {'my_encoded_str': '**encoded**: some str'}\n\n    # Validate encoded data\n    try:\n        Model(my_encoded_str='**undecodable**')\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Model\n        my_encoded_str\n          Value error, Cannot decode data [type=value_error, input_value='**undecodable**', input_type=str]\n        '''\n    ```\n    \"\"\"\n\n    def __get_pydantic_core_schema__(self, source: type[Any], handler: GetCoreSchemaHandler) -&gt; core_schema.CoreSchema:\n        return core_schema.with_info_after_validator_function(\n            function=self.decode_str,\n            schema=super(EncodedStr, self).__get_pydantic_core_schema__(source=source, handler=handler),  # noqa: UP008\n            serialization=core_schema.plain_serializer_function_ser_schema(function=self.encode_str),\n        )\n\n    def decode_str(self, data: bytes, _: core_schema.ValidationInfo) -&gt; str:\n        \"\"\"Decode the data using the specified encoder.\n\n        Args:\n            data: The data to decode.\n\n        Returns:\n            The decoded data.\n        \"\"\"\n        return data.decode()\n\n    def encode_str(self, value: str) -&gt; str:\n        \"\"\"Encode the data using the specified encoder.\n\n        Args:\n            value: The data to encode.\n\n        Returns:\n            The encoded data.\n        \"\"\"\n        return super(EncodedStr, self).encode(value=value.encode()).decode()  # noqa: UP008\n\n    def __hash__(self) -&gt; int:\n        return hash(self.encoder)\n</code></pre>"},{"location":"api/types/#pydantic.types.EncodedStr.decode_str","title":"decode_str  <pre><code>decode_str(data: bytes, _: ValidationInfo) -&gt; str\n</code></pre>  <p>Decode the data using the specified encoder.</p> <p>Parameters:</p>    Name Type Description Default     <code>data</code>  <code>bytes</code>    <p>The data to decode.</p>    required     <p>Returns:</p>    Type Description      <code>str</code>    <p>The decoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>def decode_str(self, data: bytes, _: core_schema.ValidationInfo) -&gt; str:\n    \"\"\"Decode the data using the specified encoder.\n\n    Args:\n        data: The data to decode.\n\n    Returns:\n        The decoded data.\n    \"\"\"\n    return data.decode()\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.EncodedStr.encode_str","title":"encode_str  <pre><code>encode_str(value: str) -&gt; str\n</code></pre>  <p>Encode the data using the specified encoder.</p> <p>Parameters:</p>    Name Type Description Default     <code>value</code>  <code>str</code>    <p>The data to encode.</p>    required     <p>Returns:</p>    Type Description      <code>str</code>    <p>The encoded data.</p>       Source code in <code>pydantic/types.py</code> <pre><code>def encode_str(self, value: str) -&gt; str:\n    \"\"\"Encode the data using the specified encoder.\n\n    Args:\n        value: The data to encode.\n\n    Returns:\n        The encoded data.\n    \"\"\"\n    return super(EncodedStr, self).encode(value=value.encode()).decode()  # noqa: UP008\n</code></pre>","text":""},{"location":"api/types/#pydantic.types.GetPydanticSchema","title":"GetPydanticSchema  <code>dataclass</code>","text":"<p>Usage Documentation</p> <p>Using <code>GetPydanticSchema</code> to reduce boilerplate</p> <p>A convenience class for creating an annotation that provides pydantic custom type hooks.</p> <p>This class is intended to eliminate the need to create a custom \"marker\" which defines the  <code>__get_pydantic_core_schema__</code> and <code>__get_pydantic_json_schema__</code> custom hook methods.</p> <p>For example, to have a field treated by type checkers as <code>int</code>, but by pydantic as <code>Any</code>, you can do: <pre><code>from typing import Any\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetPydanticSchema\n\nHandleAsAny = GetPydanticSchema(lambda _s, h: h(Any))\n\nclass Model(BaseModel):\n    x: Annotated[int, HandleAsAny]  # pydantic sees `x: Any`\n\nprint(repr(Model(x='abc').x))\n#&gt; 'abc'\n</code></pre></p> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass(**_internal_dataclass.slots_true)\nclass GetPydanticSchema:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/types/#using-getpydanticschema-to-reduce-boilerplate\n\n    A convenience class for creating an annotation that provides pydantic custom type hooks.\n\n    This class is intended to eliminate the need to create a custom \"marker\" which defines the\n     `__get_pydantic_core_schema__` and `__get_pydantic_json_schema__` custom hook methods.\n\n    For example, to have a field treated by type checkers as `int`, but by pydantic as `Any`, you can do:\n    ```python\n    from typing import Any\n\n    from typing_extensions import Annotated\n\n    from pydantic import BaseModel, GetPydanticSchema\n\n    HandleAsAny = GetPydanticSchema(lambda _s, h: h(Any))\n\n    class Model(BaseModel):\n        x: Annotated[int, HandleAsAny]  # pydantic sees `x: Any`\n\n    print(repr(Model(x='abc').x))\n    #&gt; 'abc'\n    ```\n    \"\"\"\n\n    get_pydantic_core_schema: Callable[[Any, GetCoreSchemaHandler], CoreSchema] | None = None\n    get_pydantic_json_schema: Callable[[Any, GetJsonSchemaHandler], JsonSchemaValue] | None = None\n\n    # Note: we may want to consider adding a convenience staticmethod `def for_type(type_: Any) -&gt; GetPydanticSchema:`\n    #   which returns `GetPydanticSchema(lambda _s, h: h(type_))`\n\n    if not TYPE_CHECKING:\n        # We put `__getattr__` in a non-TYPE_CHECKING block because otherwise, mypy allows arbitrary attribute access\n\n        def __getattr__(self, item: str) -&gt; Any:\n            \"\"\"Use this rather than defining `__get_pydantic_core_schema__` etc. to reduce the number of nested calls.\"\"\"\n            if item == '__get_pydantic_core_schema__' and self.get_pydantic_core_schema:\n                return self.get_pydantic_core_schema\n            elif item == '__get_pydantic_json_schema__' and self.get_pydantic_json_schema:\n                return self.get_pydantic_json_schema\n            else:\n                return object.__getattribute__(self, item)\n\n    __hash__ = object.__hash__\n</code></pre>"},{"location":"api/types/#pydantic.types.Tag","title":"Tag  <code>dataclass</code>","text":"<p>Provides a way to specify the expected tag to use for a case of a (callable) discriminated union.</p> <p>Also provides a way to label a union case in error messages.</p> <p>When using a callable <code>Discriminator</code>, attach a <code>Tag</code> to each case in the <code>Union</code> to specify the tag that should be used to identify that case. For example, in the below example, the <code>Tag</code> is used to specify that if <code>get_discriminator_value</code> returns <code>'apple'</code>, the input should be validated as an <code>ApplePie</code>, and if it returns <code>'pumpkin'</code>, the input should be validated as a <code>PumpkinPie</code>.</p> <p>The primary role of the <code>Tag</code> here is to map the return value from the callable <code>Discriminator</code> function to the appropriate member of the <code>Union</code> in question.</p> <pre><code>from typing import Any, Union\n\nfrom typing_extensions import Annotated, Literal\n\nfrom pydantic import BaseModel, Discriminator, Tag\n\nclass Pie(BaseModel):\n    time_to_cook: int\n    num_ingredients: int\n\nclass ApplePie(Pie):\n    fruit: Literal['apple'] = 'apple'\n\nclass PumpkinPie(Pie):\n    filling: Literal['pumpkin'] = 'pumpkin'\n\ndef get_discriminator_value(v: Any) -&gt; str:\n    if isinstance(v, dict):\n        return v.get('fruit', v.get('filling'))\n    return getattr(v, 'fruit', getattr(v, 'filling', None))\n\nclass ThanksgivingDinner(BaseModel):\n    dessert: Annotated[\n        Union[\n            Annotated[ApplePie, Tag('apple')],\n            Annotated[PumpkinPie, Tag('pumpkin')],\n        ],\n        Discriminator(get_discriminator_value),\n    ]\n\napple_variation = ThanksgivingDinner.model_validate(\n    {'dessert': {'fruit': 'apple', 'time_to_cook': 60, 'num_ingredients': 8}}\n)\nprint(repr(apple_variation))\n'''\nThanksgivingDinner(dessert=ApplePie(time_to_cook=60, num_ingredients=8, fruit='apple'))\n'''\n\npumpkin_variation = ThanksgivingDinner.model_validate(\n    {\n        'dessert': {\n            'filling': 'pumpkin',\n            'time_to_cook': 40,\n            'num_ingredients': 6,\n        }\n    }\n)\nprint(repr(pumpkin_variation))\n'''\nThanksgivingDinner(dessert=PumpkinPie(time_to_cook=40, num_ingredients=6, filling='pumpkin'))\n'''\n</code></pre> <p>Note</p> <p>You must specify a <code>Tag</code> for every case in a <code>Tag</code> that is associated with a callable <code>Discriminator</code>. Failing to do so will result in a <code>PydanticUserError</code> with code <code>callable-discriminator-no-tag</code>.</p> <p>See the Discriminated Unions concepts docs for more details on how to use <code>Tag</code>s.</p> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass(**_internal_dataclass.slots_true, frozen=True)\nclass Tag:\n    \"\"\"Provides a way to specify the expected tag to use for a case of a (callable) discriminated union.\n\n    Also provides a way to label a union case in error messages.\n\n    When using a callable `Discriminator`, attach a `Tag` to each case in the `Union` to specify the tag that\n    should be used to identify that case. For example, in the below example, the `Tag` is used to specify that\n    if `get_discriminator_value` returns `'apple'`, the input should be validated as an `ApplePie`, and if it\n    returns `'pumpkin'`, the input should be validated as a `PumpkinPie`.\n\n    The primary role of the `Tag` here is to map the return value from the callable `Discriminator` function to\n    the appropriate member of the `Union` in question.\n\n    ```py\n    from typing import Any, Union\n\n    from typing_extensions import Annotated, Literal\n\n    from pydantic import BaseModel, Discriminator, Tag\n\n    class Pie(BaseModel):\n        time_to_cook: int\n        num_ingredients: int\n\n    class ApplePie(Pie):\n        fruit: Literal['apple'] = 'apple'\n\n    class PumpkinPie(Pie):\n        filling: Literal['pumpkin'] = 'pumpkin'\n\n    def get_discriminator_value(v: Any) -&gt; str:\n        if isinstance(v, dict):\n            return v.get('fruit', v.get('filling'))\n        return getattr(v, 'fruit', getattr(v, 'filling', None))\n\n    class ThanksgivingDinner(BaseModel):\n        dessert: Annotated[\n            Union[\n                Annotated[ApplePie, Tag('apple')],\n                Annotated[PumpkinPie, Tag('pumpkin')],\n            ],\n            Discriminator(get_discriminator_value),\n        ]\n\n    apple_variation = ThanksgivingDinner.model_validate(\n        {'dessert': {'fruit': 'apple', 'time_to_cook': 60, 'num_ingredients': 8}}\n    )\n    print(repr(apple_variation))\n    '''\n    ThanksgivingDinner(dessert=ApplePie(time_to_cook=60, num_ingredients=8, fruit='apple'))\n    '''\n\n    pumpkin_variation = ThanksgivingDinner.model_validate(\n        {\n            'dessert': {\n                'filling': 'pumpkin',\n                'time_to_cook': 40,\n                'num_ingredients': 6,\n            }\n        }\n    )\n    print(repr(pumpkin_variation))\n    '''\n    ThanksgivingDinner(dessert=PumpkinPie(time_to_cook=40, num_ingredients=6, filling='pumpkin'))\n    '''\n    ```\n\n    !!! note\n        You must specify a `Tag` for every case in a `Tag` that is associated with a\n        callable `Discriminator`. Failing to do so will result in a `PydanticUserError` with code\n        [`callable-discriminator-no-tag`](../errors/usage_errors.md#callable-discriminator-no-tag).\n\n    See the [Discriminated Unions] concepts docs for more details on how to use `Tag`s.\n\n    [Discriminated Unions]: ../concepts/unions.md#discriminated-unions\n    \"\"\"\n\n    tag: str\n\n    def __get_pydantic_core_schema__(self, source_type: Any, handler: GetCoreSchemaHandler) -&gt; CoreSchema:\n        schema = handler(source_type)\n        metadata = schema.setdefault('metadata', {})\n        assert isinstance(metadata, dict)\n        metadata[_core_utils.TAGGED_UNION_TAG_KEY] = self.tag\n        return schema\n</code></pre>"},{"location":"api/types/#pydantic.types.Discriminator","title":"Discriminator  <code>dataclass</code>","text":"<p>Usage Documentation</p> <p>Discriminated Unions with callable <code>Discriminator</code></p> <p>Provides a way to use a custom callable as the way to extract the value of a union discriminator.</p> <p>This allows you to get validation behavior like you'd get from <code>Field(discriminator=&lt;field_name&gt;)</code>, but without needing to have a single shared field across all the union choices. This also makes it possible to handle unions of models and primitive types with discriminated-union-style validation errors. Finally, this allows you to use a custom callable as the way to identify which member of a union a value belongs to, while still seeing all the performance benefits of a discriminated union.</p> <p>Consider this example, which is much more performant with the use of <code>Discriminator</code> and thus a <code>TaggedUnion</code> than it would be as a normal <code>Union</code>.</p> <pre><code>from typing import Any, Union\n\nfrom typing_extensions import Annotated, Literal\n\nfrom pydantic import BaseModel, Discriminator, Tag\n\nclass Pie(BaseModel):\n    time_to_cook: int\n    num_ingredients: int\n\nclass ApplePie(Pie):\n    fruit: Literal['apple'] = 'apple'\n\nclass PumpkinPie(Pie):\n    filling: Literal['pumpkin'] = 'pumpkin'\n\ndef get_discriminator_value(v: Any) -&gt; str:\n    if isinstance(v, dict):\n        return v.get('fruit', v.get('filling'))\n    return getattr(v, 'fruit', getattr(v, 'filling', None))\n\nclass ThanksgivingDinner(BaseModel):\n    dessert: Annotated[\n        Union[\n            Annotated[ApplePie, Tag('apple')],\n            Annotated[PumpkinPie, Tag('pumpkin')],\n        ],\n        Discriminator(get_discriminator_value),\n    ]\n\napple_variation = ThanksgivingDinner.model_validate(\n    {'dessert': {'fruit': 'apple', 'time_to_cook': 60, 'num_ingredients': 8}}\n)\nprint(repr(apple_variation))\n'''\nThanksgivingDinner(dessert=ApplePie(time_to_cook=60, num_ingredients=8, fruit='apple'))\n'''\n\npumpkin_variation = ThanksgivingDinner.model_validate(\n    {\n        'dessert': {\n            'filling': 'pumpkin',\n            'time_to_cook': 40,\n            'num_ingredients': 6,\n        }\n    }\n)\nprint(repr(pumpkin_variation))\n'''\nThanksgivingDinner(dessert=PumpkinPie(time_to_cook=40, num_ingredients=6, filling='pumpkin'))\n'''\n</code></pre> <p>See the Discriminated Unions concepts docs for more details on how to use <code>Discriminator</code>s.</p> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass(**_internal_dataclass.slots_true, frozen=True)\nclass Discriminator:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/unions/#discriminated-unions-with-callable-discriminator\n\n    Provides a way to use a custom callable as the way to extract the value of a union discriminator.\n\n    This allows you to get validation behavior like you'd get from `Field(discriminator=&lt;field_name&gt;)`,\n    but without needing to have a single shared field across all the union choices. This also makes it\n    possible to handle unions of models and primitive types with discriminated-union-style validation errors.\n    Finally, this allows you to use a custom callable as the way to identify which member of a union a value\n    belongs to, while still seeing all the performance benefits of a discriminated union.\n\n    Consider this example, which is much more performant with the use of `Discriminator` and thus a `TaggedUnion`\n    than it would be as a normal `Union`.\n\n    ```py\n    from typing import Any, Union\n\n    from typing_extensions import Annotated, Literal\n\n    from pydantic import BaseModel, Discriminator, Tag\n\n    class Pie(BaseModel):\n        time_to_cook: int\n        num_ingredients: int\n\n    class ApplePie(Pie):\n        fruit: Literal['apple'] = 'apple'\n\n    class PumpkinPie(Pie):\n        filling: Literal['pumpkin'] = 'pumpkin'\n\n    def get_discriminator_value(v: Any) -&gt; str:\n        if isinstance(v, dict):\n            return v.get('fruit', v.get('filling'))\n        return getattr(v, 'fruit', getattr(v, 'filling', None))\n\n    class ThanksgivingDinner(BaseModel):\n        dessert: Annotated[\n            Union[\n                Annotated[ApplePie, Tag('apple')],\n                Annotated[PumpkinPie, Tag('pumpkin')],\n            ],\n            Discriminator(get_discriminator_value),\n        ]\n\n    apple_variation = ThanksgivingDinner.model_validate(\n        {'dessert': {'fruit': 'apple', 'time_to_cook': 60, 'num_ingredients': 8}}\n    )\n    print(repr(apple_variation))\n    '''\n    ThanksgivingDinner(dessert=ApplePie(time_to_cook=60, num_ingredients=8, fruit='apple'))\n    '''\n\n    pumpkin_variation = ThanksgivingDinner.model_validate(\n        {\n            'dessert': {\n                'filling': 'pumpkin',\n                'time_to_cook': 40,\n                'num_ingredients': 6,\n            }\n        }\n    )\n    print(repr(pumpkin_variation))\n    '''\n    ThanksgivingDinner(dessert=PumpkinPie(time_to_cook=40, num_ingredients=6, filling='pumpkin'))\n    '''\n    ```\n\n    See the [Discriminated Unions] concepts docs for more details on how to use `Discriminator`s.\n\n    [Discriminated Unions]: ../concepts/unions.md#discriminated-unions\n    \"\"\"\n\n    discriminator: str | Callable[[Any], Hashable]\n    \"\"\"The callable or field name for discriminating the type in a tagged union.\n\n    A `Callable` discriminator must extract the value of the discriminator from the input.\n    A `str` discriminator must be the name of a field to discriminate against.\n    \"\"\"\n    custom_error_type: str | None = None\n    \"\"\"Type to use in [custom errors](../errors/errors.md#custom-errors) replacing the standard discriminated union\n    validation errors.\n    \"\"\"\n    custom_error_message: str | None = None\n    \"\"\"Message to use in custom errors.\"\"\"\n    custom_error_context: dict[str, int | str | float] | None = None\n    \"\"\"Context to use in custom errors.\"\"\"\n\n    def __get_pydantic_core_schema__(self, source_type: Any, handler: GetCoreSchemaHandler) -&gt; CoreSchema:\n        origin = _typing_extra.get_origin(source_type)\n        if not origin or not _typing_extra.origin_is_union(origin):\n            raise TypeError(f'{type(self).__name__} must be used with a Union type, not {source_type}')\n\n        if isinstance(self.discriminator, str):\n            from pydantic import Field\n\n            return handler(Annotated[source_type, Field(discriminator=self.discriminator)])\n        else:\n            original_schema = handler(source_type)\n            return self._convert_schema(original_schema)\n\n    def _convert_schema(self, original_schema: core_schema.CoreSchema) -&gt; core_schema.TaggedUnionSchema:\n        if original_schema['type'] != 'union':\n            # This likely indicates that the schema was a single-item union that was simplified.\n            # In this case, we do the same thing we do in\n            # `pydantic._internal._discriminated_union._ApplyInferredDiscriminator._apply_to_root`, namely,\n            # package the generated schema back into a single-item union.\n            original_schema = core_schema.union_schema([original_schema])\n\n        tagged_union_choices = {}\n        for choice in original_schema['choices']:\n            tag = None\n            if isinstance(choice, tuple):\n                choice, tag = choice\n            metadata = choice.get('metadata')\n            if metadata is not None:\n                metadata_tag = metadata.get(_core_utils.TAGGED_UNION_TAG_KEY)\n                if metadata_tag is not None:\n                    tag = metadata_tag\n            if tag is None:\n                raise PydanticUserError(\n                    f'`Tag` not provided for choice {choice} used with `Discriminator`',\n                    code='callable-discriminator-no-tag',\n                )\n            tagged_union_choices[tag] = choice\n\n        # Have to do these verbose checks to ensure falsy values ('' and {}) don't get ignored\n        custom_error_type = self.custom_error_type\n        if custom_error_type is None:\n            custom_error_type = original_schema.get('custom_error_type')\n\n        custom_error_message = self.custom_error_message\n        if custom_error_message is None:\n            custom_error_message = original_schema.get('custom_error_message')\n\n        custom_error_context = self.custom_error_context\n        if custom_error_context is None:\n            custom_error_context = original_schema.get('custom_error_context')\n\n        custom_error_type = original_schema.get('custom_error_type') if custom_error_type is None else custom_error_type\n        return core_schema.tagged_union_schema(\n            tagged_union_choices,\n            self.discriminator,\n            custom_error_type=custom_error_type,\n            custom_error_message=custom_error_message,\n            custom_error_context=custom_error_context,\n            strict=original_schema.get('strict'),\n            ref=original_schema.get('ref'),\n            metadata=original_schema.get('metadata'),\n            serialization=original_schema.get('serialization'),\n        )\n</code></pre>"},{"location":"api/types/#pydantic.types.Discriminator.discriminator","title":"discriminator  <code>instance-attribute</code>   <pre><code>discriminator: str | Callable[[Any], Hashable]\n</code></pre>  <p>The callable or field name for discriminating the type in a tagged union.</p> <p>A <code>Callable</code> discriminator must extract the value of the discriminator from the input. A <code>str</code> discriminator must be the name of a field to discriminate against.</p>","text":""},{"location":"api/types/#pydantic.types.Discriminator.custom_error_type","title":"custom_error_type  <code>class-attribute</code> <code>instance-attribute</code>   <pre><code>custom_error_type: str | None = None\n</code></pre>  <p>Type to use in custom errors replacing the standard discriminated union validation errors.</p>","text":""},{"location":"api/types/#pydantic.types.Discriminator.custom_error_message","title":"custom_error_message  <code>class-attribute</code> <code>instance-attribute</code>   <pre><code>custom_error_message: str | None = None\n</code></pre>  <p>Message to use in custom errors.</p>","text":""},{"location":"api/types/#pydantic.types.Discriminator.custom_error_context","title":"custom_error_context  <code>class-attribute</code> <code>instance-attribute</code>   <pre><code>custom_error_context: (\n    dict[str, int | str | float] | None\n) = None\n</code></pre>  <p>Context to use in custom errors.</p>","text":""},{"location":"api/types/#pydantic.types.FailFast","title":"FailFast  <code>dataclass</code>","text":"<p>               Bases: <code>PydanticMetadata</code>, <code>BaseMetadata</code></p> <p>A <code>FailFast</code> annotation can be used to specify that validation should stop at the first error.</p> <p>This can be useful when you want to validate a large amount of data and you only need to know if it's valid or not.</p> <p>You might want to enable this setting if you want to validate your data faster (basically, if you use this, validation will be more performant with the caveat that you get less information).</p> <pre><code>from typing import List\nfrom typing_extensions import Annotated\nfrom pydantic import BaseModel, FailFast, ValidationError\n\nclass Model(BaseModel):\n    x: Annotated[List[int], FailFast()]\n\n# This will raise a single error for the first invalid value and stop validation\ntry:\n    obj = Model(x=[1, 2, 'a', 4, 5, 'b', 7, 8, 9, 'c'])\nexcept ValidationError as e:\n    print(e)\n    '''\n    1 validation error for Model\n    x.2\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    '''\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>@_dataclasses.dataclass\nclass FailFast(_fields.PydanticMetadata, BaseMetadata):\n    \"\"\"A `FailFast` annotation can be used to specify that validation should stop at the first error.\n\n    This can be useful when you want to validate a large amount of data and you only need to know if it's valid or not.\n\n    You might want to enable this setting if you want to validate your data faster (basically, if you use this,\n    validation will be more performant with the caveat that you get less information).\n\n    ```py\n    from typing import List\n    from typing_extensions import Annotated\n    from pydantic import BaseModel, FailFast, ValidationError\n\n    class Model(BaseModel):\n        x: Annotated[List[int], FailFast()]\n\n    # This will raise a single error for the first invalid value and stop validation\n    try:\n        obj = Model(x=[1, 2, 'a', 4, 5, 'b', 7, 8, 9, 'c'])\n    except ValidationError as e:\n        print(e)\n        '''\n        1 validation error for Model\n        x.2\n          Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n        '''\n    ```\n    \"\"\"\n\n    fail_fast: bool = True\n</code></pre>"},{"location":"api/types/#pydantic.types.conint","title":"conint","text":"<pre><code>conint(\n    *,\n    strict: bool | None = None,\n    gt: int | None = None,\n    ge: int | None = None,\n    lt: int | None = None,\n    le: int | None = None,\n    multiple_of: int | None = None\n) -&gt; type[int]\n</code></pre> <p>Discouraged</p> <p>This function is discouraged in favor of using <code>Annotated</code> with <code>Field</code> instead.</p> <p>This function will be deprecated in Pydantic 3.0.</p> <p>The reason is that <code>conint</code> returns a type, which doesn't play well with static analysis tools.</p>  Don't do this Do this <pre><code>from pydantic import BaseModel, conint\n\nclass Foo(BaseModel):\n    bar: conint(strict=True, gt=0)\n</code></pre> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\nclass Foo(BaseModel):\n    bar: Annotated[int, Field(strict=True, gt=0)]\n</code></pre> <p>A wrapper around <code>int</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the integer in strict mode. Defaults to <code>None</code>.</p> <code>None</code> <code>gt</code> <code>int | None</code> <p>The value must be greater than this.</p> <code>None</code> <code>ge</code> <code>int | None</code> <p>The value must be greater than or equal to this.</p> <code>None</code> <code>lt</code> <code>int | None</code> <p>The value must be less than this.</p> <code>None</code> <code>le</code> <code>int | None</code> <p>The value must be less than or equal to this.</p> <code>None</code> <code>multiple_of</code> <code>int | None</code> <p>The value must be a multiple of this.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[int]</code> <p>The wrapped integer type.</p> <pre><code>from pydantic import BaseModel, ValidationError, conint\n\nclass ConstrainedExample(BaseModel):\n    constrained_int: conint(gt=1)\n\nm = ConstrainedExample(constrained_int=2)\nprint(repr(m))\n#&gt; ConstrainedExample(constrained_int=2)\n\ntry:\n    ConstrainedExample(constrained_int=0)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'greater_than',\n            'loc': ('constrained_int',),\n            'msg': 'Input should be greater than 1',\n            'input': 0,\n            'ctx': {'gt': 1},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than',\n        }\n    ]\n    '''\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>def conint(\n    *,\n    strict: bool | None = None,\n    gt: int | None = None,\n    ge: int | None = None,\n    lt: int | None = None,\n    le: int | None = None,\n    multiple_of: int | None = None,\n) -&gt; type[int]:\n    \"\"\"\n    !!! warning \"Discouraged\"\n        This function is **discouraged** in favor of using\n        [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated) with\n        [`Field`][pydantic.fields.Field] instead.\n\n        This function will be **deprecated** in Pydantic 3.0.\n\n        The reason is that `conint` returns a type, which doesn't play well with static analysis tools.\n\n        === \":x: Don't do this\"\n            ```py\n            from pydantic import BaseModel, conint\n\n            class Foo(BaseModel):\n                bar: conint(strict=True, gt=0)\n            ```\n\n        === \":white_check_mark: Do this\"\n            ```py\n            from typing_extensions import Annotated\n\n            from pydantic import BaseModel, Field\n\n            class Foo(BaseModel):\n                bar: Annotated[int, Field(strict=True, gt=0)]\n            ```\n\n    A wrapper around `int` that allows for additional constraints.\n\n    Args:\n        strict: Whether to validate the integer in strict mode. Defaults to `None`.\n        gt: The value must be greater than this.\n        ge: The value must be greater than or equal to this.\n        lt: The value must be less than this.\n        le: The value must be less than or equal to this.\n        multiple_of: The value must be a multiple of this.\n\n    Returns:\n        The wrapped integer type.\n\n    ```py\n    from pydantic import BaseModel, ValidationError, conint\n\n    class ConstrainedExample(BaseModel):\n        constrained_int: conint(gt=1)\n\n    m = ConstrainedExample(constrained_int=2)\n    print(repr(m))\n    #&gt; ConstrainedExample(constrained_int=2)\n\n    try:\n        ConstrainedExample(constrained_int=0)\n    except ValidationError as e:\n        print(e.errors())\n        '''\n        [\n            {\n                'type': 'greater_than',\n                'loc': ('constrained_int',),\n                'msg': 'Input should be greater than 1',\n                'input': 0,\n                'ctx': {'gt': 1},\n                'url': 'https://errors.pydantic.dev/2/v/greater_than',\n            }\n        ]\n        '''\n    ```\n\n    \"\"\"  # noqa: D212\n    return Annotated[  # pyright: ignore[reportReturnType]\n        int,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Interval(gt=gt, ge=ge, lt=lt, le=le),\n        annotated_types.MultipleOf(multiple_of) if multiple_of is not None else None,\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.confloat","title":"confloat","text":"<pre><code>confloat(\n    *,\n    strict: bool | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    multiple_of: float | None = None,\n    allow_inf_nan: bool | None = None\n) -&gt; type[float]\n</code></pre> <p>Discouraged</p> <p>This function is discouraged in favor of using <code>Annotated</code> with <code>Field</code> instead.</p> <p>This function will be deprecated in Pydantic 3.0.</p> <p>The reason is that <code>confloat</code> returns a type, which doesn't play well with static analysis tools.</p>  Don't do this Do this <pre><code>from pydantic import BaseModel, confloat\n\nclass Foo(BaseModel):\n    bar: confloat(strict=True, gt=0)\n</code></pre> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\nclass Foo(BaseModel):\n    bar: Annotated[float, Field(strict=True, gt=0)]\n</code></pre> <p>A wrapper around <code>float</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the float in strict mode.</p> <code>None</code> <code>gt</code> <code>float | None</code> <p>The value must be greater than this.</p> <code>None</code> <code>ge</code> <code>float | None</code> <p>The value must be greater than or equal to this.</p> <code>None</code> <code>lt</code> <code>float | None</code> <p>The value must be less than this.</p> <code>None</code> <code>le</code> <code>float | None</code> <p>The value must be less than or equal to this.</p> <code>None</code> <code>multiple_of</code> <code>float | None</code> <p>The value must be a multiple of this.</p> <code>None</code> <code>allow_inf_nan</code> <code>bool | None</code> <p>Whether to allow <code>-inf</code>, <code>inf</code>, and <code>nan</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[float]</code> <p>The wrapped float type.</p> <pre><code>from pydantic import BaseModel, ValidationError, confloat\n\nclass ConstrainedExample(BaseModel):\n    constrained_float: confloat(gt=1.0)\n\nm = ConstrainedExample(constrained_float=1.1)\nprint(repr(m))\n#&gt; ConstrainedExample(constrained_float=1.1)\n\ntry:\n    ConstrainedExample(constrained_float=0.9)\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'greater_than',\n            'loc': ('constrained_float',),\n            'msg': 'Input should be greater than 1',\n            'input': 0.9,\n            'ctx': {'gt': 1.0},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than',\n        }\n    ]\n    '''\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>def confloat(\n    *,\n    strict: bool | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    multiple_of: float | None = None,\n    allow_inf_nan: bool | None = None,\n) -&gt; type[float]:\n    \"\"\"\n    !!! warning \"Discouraged\"\n        This function is **discouraged** in favor of using\n        [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated) with\n        [`Field`][pydantic.fields.Field] instead.\n\n        This function will be **deprecated** in Pydantic 3.0.\n\n        The reason is that `confloat` returns a type, which doesn't play well with static analysis tools.\n\n        === \":x: Don't do this\"\n            ```py\n            from pydantic import BaseModel, confloat\n\n            class Foo(BaseModel):\n                bar: confloat(strict=True, gt=0)\n            ```\n\n        === \":white_check_mark: Do this\"\n            ```py\n            from typing_extensions import Annotated\n\n            from pydantic import BaseModel, Field\n\n            class Foo(BaseModel):\n                bar: Annotated[float, Field(strict=True, gt=0)]\n            ```\n\n    A wrapper around `float` that allows for additional constraints.\n\n    Args:\n        strict: Whether to validate the float in strict mode.\n        gt: The value must be greater than this.\n        ge: The value must be greater than or equal to this.\n        lt: The value must be less than this.\n        le: The value must be less than or equal to this.\n        multiple_of: The value must be a multiple of this.\n        allow_inf_nan: Whether to allow `-inf`, `inf`, and `nan`.\n\n    Returns:\n        The wrapped float type.\n\n    ```py\n    from pydantic import BaseModel, ValidationError, confloat\n\n    class ConstrainedExample(BaseModel):\n        constrained_float: confloat(gt=1.0)\n\n    m = ConstrainedExample(constrained_float=1.1)\n    print(repr(m))\n    #&gt; ConstrainedExample(constrained_float=1.1)\n\n    try:\n        ConstrainedExample(constrained_float=0.9)\n    except ValidationError as e:\n        print(e.errors())\n        '''\n        [\n            {\n                'type': 'greater_than',\n                'loc': ('constrained_float',),\n                'msg': 'Input should be greater than 1',\n                'input': 0.9,\n                'ctx': {'gt': 1.0},\n                'url': 'https://errors.pydantic.dev/2/v/greater_than',\n            }\n        ]\n        '''\n    ```\n    \"\"\"  # noqa: D212\n    return Annotated[  # pyright: ignore[reportReturnType]\n        float,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Interval(gt=gt, ge=ge, lt=lt, le=le),\n        annotated_types.MultipleOf(multiple_of) if multiple_of is not None else None,\n        AllowInfNan(allow_inf_nan) if allow_inf_nan is not None else None,\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.conbytes","title":"conbytes","text":"<pre><code>conbytes(\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None\n) -&gt; type[bytes]\n</code></pre> <p>A wrapper around <code>bytes</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>min_length</code> <code>int | None</code> <p>The minimum length of the bytes.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the bytes.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to validate the bytes in strict mode.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[bytes]</code> <p>The wrapped bytes type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def conbytes(\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    strict: bool | None = None,\n) -&gt; type[bytes]:\n    \"\"\"A wrapper around `bytes` that allows for additional constraints.\n\n    Args:\n        min_length: The minimum length of the bytes.\n        max_length: The maximum length of the bytes.\n        strict: Whether to validate the bytes in strict mode.\n\n    Returns:\n        The wrapped bytes type.\n    \"\"\"\n    return Annotated[  # pyright: ignore[reportReturnType]\n        bytes,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Len(min_length or 0, max_length),\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.constr","title":"constr","text":"<pre><code>constr(\n    *,\n    strip_whitespace: bool | None = None,\n    to_upper: bool | None = None,\n    to_lower: bool | None = None,\n    strict: bool | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | Pattern[str] | None = None\n) -&gt; type[str]\n</code></pre> <p>Discouraged</p> <p>This function is discouraged in favor of using <code>Annotated</code> with <code>StringConstraints</code> instead.</p> <p>This function will be deprecated in Pydantic 3.0.</p> <p>The reason is that <code>constr</code> returns a type, which doesn't play well with static analysis tools.</p>  Don't do this Do this <pre><code>from pydantic import BaseModel, constr\n\nclass Foo(BaseModel):\n    bar: constr(strip_whitespace=True, to_upper=True, pattern=r'^[A-Z]+$')\n</code></pre> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, StringConstraints\n\nclass Foo(BaseModel):\n    bar: Annotated[\n        str,\n        StringConstraints(\n            strip_whitespace=True, to_upper=True, pattern=r'^[A-Z]+$'\n        ),\n    ]\n</code></pre> <p>A wrapper around <code>str</code> that allows for additional constraints.</p> <pre><code>from pydantic import BaseModel, constr\n\nclass Foo(BaseModel):\n    bar: constr(strip_whitespace=True, to_upper=True)\n\nfoo = Foo(bar='  hello  ')\nprint(foo)\n#&gt; bar='HELLO'\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>strip_whitespace</code> <code>bool | None</code> <p>Whether to remove leading and trailing whitespace.</p> <code>None</code> <code>to_upper</code> <code>bool | None</code> <p>Whether to turn all characters to uppercase.</p> <code>None</code> <code>to_lower</code> <code>bool | None</code> <p>Whether to turn all characters to lowercase.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Whether to validate the string in strict mode.</p> <code>None</code> <code>min_length</code> <code>int | None</code> <p>The minimum length of the string.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the string.</p> <code>None</code> <code>pattern</code> <code>str | Pattern[str] | None</code> <p>A regex pattern to validate the string against.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[str]</code> <p>The wrapped string type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def constr(\n    *,\n    strip_whitespace: bool | None = None,\n    to_upper: bool | None = None,\n    to_lower: bool | None = None,\n    strict: bool | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | Pattern[str] | None = None,\n) -&gt; type[str]:\n    \"\"\"\n    !!! warning \"Discouraged\"\n        This function is **discouraged** in favor of using\n        [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated) with\n        [`StringConstraints`][pydantic.types.StringConstraints] instead.\n\n        This function will be **deprecated** in Pydantic 3.0.\n\n        The reason is that `constr` returns a type, which doesn't play well with static analysis tools.\n\n        === \":x: Don't do this\"\n            ```py\n            from pydantic import BaseModel, constr\n\n            class Foo(BaseModel):\n                bar: constr(strip_whitespace=True, to_upper=True, pattern=r'^[A-Z]+$')\n            ```\n\n        === \":white_check_mark: Do this\"\n            ```py\n            from typing_extensions import Annotated\n\n            from pydantic import BaseModel, StringConstraints\n\n            class Foo(BaseModel):\n                bar: Annotated[\n                    str,\n                    StringConstraints(\n                        strip_whitespace=True, to_upper=True, pattern=r'^[A-Z]+$'\n                    ),\n                ]\n            ```\n\n    A wrapper around `str` that allows for additional constraints.\n\n    ```py\n    from pydantic import BaseModel, constr\n\n    class Foo(BaseModel):\n        bar: constr(strip_whitespace=True, to_upper=True)\n\n    foo = Foo(bar='  hello  ')\n    print(foo)\n    #&gt; bar='HELLO'\n    ```\n\n    Args:\n        strip_whitespace: Whether to remove leading and trailing whitespace.\n        to_upper: Whether to turn all characters to uppercase.\n        to_lower: Whether to turn all characters to lowercase.\n        strict: Whether to validate the string in strict mode.\n        min_length: The minimum length of the string.\n        max_length: The maximum length of the string.\n        pattern: A regex pattern to validate the string against.\n\n    Returns:\n        The wrapped string type.\n    \"\"\"  # noqa: D212\n    return Annotated[  # pyright: ignore[reportReturnType]\n        str,\n        StringConstraints(\n            strip_whitespace=strip_whitespace,\n            to_upper=to_upper,\n            to_lower=to_lower,\n            strict=strict,\n            min_length=min_length,\n            max_length=max_length,\n            pattern=pattern,\n        ),\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.conset","title":"conset","text":"<pre><code>conset(\n    item_type: type[HashableItemType],\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None\n) -&gt; type[set[HashableItemType]]\n</code></pre> <p>A wrapper around <code>typing.Set</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>item_type</code> <code>type[HashableItemType]</code> <p>The type of the items in the set.</p> required <code>min_length</code> <code>int | None</code> <p>The minimum length of the set.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the set.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[set[HashableItemType]]</code> <p>The wrapped set type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def conset(\n    item_type: type[HashableItemType], *, min_length: int | None = None, max_length: int | None = None\n) -&gt; type[set[HashableItemType]]:\n    \"\"\"A wrapper around `typing.Set` that allows for additional constraints.\n\n    Args:\n        item_type: The type of the items in the set.\n        min_length: The minimum length of the set.\n        max_length: The maximum length of the set.\n\n    Returns:\n        The wrapped set type.\n    \"\"\"\n    return Annotated[Set[item_type], annotated_types.Len(min_length or 0, max_length)]  # pyright: ignore[reportReturnType]\n</code></pre>"},{"location":"api/types/#pydantic.types.confrozenset","title":"confrozenset","text":"<pre><code>confrozenset(\n    item_type: type[HashableItemType],\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None\n) -&gt; type[frozenset[HashableItemType]]\n</code></pre> <p>A wrapper around <code>typing.FrozenSet</code> that allows for additional constraints.</p> <p>Parameters:</p> Name Type Description Default <code>item_type</code> <code>type[HashableItemType]</code> <p>The type of the items in the frozenset.</p> required <code>min_length</code> <code>int | None</code> <p>The minimum length of the frozenset.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the frozenset.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[frozenset[HashableItemType]]</code> <p>The wrapped frozenset type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def confrozenset(\n    item_type: type[HashableItemType], *, min_length: int | None = None, max_length: int | None = None\n) -&gt; type[frozenset[HashableItemType]]:\n    \"\"\"A wrapper around `typing.FrozenSet` that allows for additional constraints.\n\n    Args:\n        item_type: The type of the items in the frozenset.\n        min_length: The minimum length of the frozenset.\n        max_length: The maximum length of the frozenset.\n\n    Returns:\n        The wrapped frozenset type.\n    \"\"\"\n    return Annotated[FrozenSet[item_type], annotated_types.Len(min_length or 0, max_length)]  # pyright: ignore[reportReturnType]\n</code></pre>"},{"location":"api/types/#pydantic.types.conlist","title":"conlist","text":"<pre><code>conlist(\n    item_type: type[AnyItemType],\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    unique_items: bool | None = None\n) -&gt; type[list[AnyItemType]]\n</code></pre> <p>A wrapper around typing.List that adds validation.</p> <p>Parameters:</p> Name Type Description Default <code>item_type</code> <code>type[AnyItemType]</code> <p>The type of the items in the list.</p> required <code>min_length</code> <code>int | None</code> <p>The minimum length of the list. Defaults to None.</p> <code>None</code> <code>max_length</code> <code>int | None</code> <p>The maximum length of the list. Defaults to None.</p> <code>None</code> <code>unique_items</code> <code>bool | None</code> <p>Whether the items in the list must be unique. Defaults to None.</p> <p>Warning</p> <p>The <code>unique_items</code> parameter is deprecated, use <code>Set</code> instead. See this issue for more details.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[list[AnyItemType]]</code> <p>The wrapped list type.</p> Source code in <code>pydantic/types.py</code> <pre><code>def conlist(\n    item_type: type[AnyItemType],\n    *,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    unique_items: bool | None = None,\n) -&gt; type[list[AnyItemType]]:\n    \"\"\"A wrapper around typing.List that adds validation.\n\n    Args:\n        item_type: The type of the items in the list.\n        min_length: The minimum length of the list. Defaults to None.\n        max_length: The maximum length of the list. Defaults to None.\n        unique_items: Whether the items in the list must be unique. Defaults to None.\n            !!! warning Deprecated\n                The `unique_items` parameter is deprecated, use `Set` instead.\n                See [this issue](https://github.com/pydantic/pydantic-core/issues/296) for more details.\n\n    Returns:\n        The wrapped list type.\n    \"\"\"\n    if unique_items is not None:\n        raise PydanticUserError(\n            (\n                '`unique_items` is removed, use `Set` instead'\n                '(this feature is discussed in https://github.com/pydantic/pydantic-core/issues/296)'\n            ),\n            code='removed-kwargs',\n        )\n    return Annotated[List[item_type], annotated_types.Len(min_length or 0, max_length)]  # pyright: ignore[reportReturnType]\n</code></pre>"},{"location":"api/types/#pydantic.types.condecimal","title":"condecimal","text":"<pre><code>condecimal(\n    *,\n    strict: bool | None = None,\n    gt: int | Decimal | None = None,\n    ge: int | Decimal | None = None,\n    lt: int | Decimal | None = None,\n    le: int | Decimal | None = None,\n    multiple_of: int | Decimal | None = None,\n    max_digits: int | None = None,\n    decimal_places: int | None = None,\n    allow_inf_nan: bool | None = None\n) -&gt; type[Decimal]\n</code></pre> <p>Discouraged</p> <p>This function is discouraged in favor of using <code>Annotated</code> with <code>Field</code> instead.</p> <p>This function will be deprecated in Pydantic 3.0.</p> <p>The reason is that <code>condecimal</code> returns a type, which doesn't play well with static analysis tools.</p>  Don't do this Do this <pre><code>from pydantic import BaseModel, condecimal\n\nclass Foo(BaseModel):\n    bar: condecimal(strict=True, allow_inf_nan=True)\n</code></pre> <pre><code>from decimal import Decimal\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\nclass Foo(BaseModel):\n    bar: Annotated[Decimal, Field(strict=True, allow_inf_nan=True)]\n</code></pre> <p>A wrapper around Decimal that adds validation.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the value in strict mode. Defaults to <code>None</code>.</p> <code>None</code> <code>gt</code> <code>int | Decimal | None</code> <p>The value must be greater than this. Defaults to <code>None</code>.</p> <code>None</code> <code>ge</code> <code>int | Decimal | None</code> <p>The value must be greater than or equal to this. Defaults to <code>None</code>.</p> <code>None</code> <code>lt</code> <code>int | Decimal | None</code> <p>The value must be less than this. Defaults to <code>None</code>.</p> <code>None</code> <code>le</code> <code>int | Decimal | None</code> <p>The value must be less than or equal to this. Defaults to <code>None</code>.</p> <code>None</code> <code>multiple_of</code> <code>int | Decimal | None</code> <p>The value must be a multiple of this. Defaults to <code>None</code>.</p> <code>None</code> <code>max_digits</code> <code>int | None</code> <p>The maximum number of digits. Defaults to <code>None</code>.</p> <code>None</code> <code>decimal_places</code> <code>int | None</code> <p>The number of decimal places. Defaults to <code>None</code>.</p> <code>None</code> <code>allow_inf_nan</code> <code>bool | None</code> <p>Whether to allow infinity and NaN. Defaults to <code>None</code>.</p> <code>None</code> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, ValidationError, condecimal\n\nclass ConstrainedExample(BaseModel):\n    constrained_decimal: condecimal(gt=Decimal('1.0'))\n\nm = ConstrainedExample(constrained_decimal=Decimal('1.1'))\nprint(repr(m))\n#&gt; ConstrainedExample(constrained_decimal=Decimal('1.1'))\n\ntry:\n    ConstrainedExample(constrained_decimal=Decimal('0.9'))\nexcept ValidationError as e:\n    print(e.errors())\n    '''\n    [\n        {\n            'type': 'greater_than',\n            'loc': ('constrained_decimal',),\n            'msg': 'Input should be greater than 1.0',\n            'input': Decimal('0.9'),\n            'ctx': {'gt': Decimal('1.0')},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than',\n        }\n    ]\n    '''\n</code></pre> Source code in <code>pydantic/types.py</code> <pre><code>def condecimal(\n    *,\n    strict: bool | None = None,\n    gt: int | Decimal | None = None,\n    ge: int | Decimal | None = None,\n    lt: int | Decimal | None = None,\n    le: int | Decimal | None = None,\n    multiple_of: int | Decimal | None = None,\n    max_digits: int | None = None,\n    decimal_places: int | None = None,\n    allow_inf_nan: bool | None = None,\n) -&gt; type[Decimal]:\n    \"\"\"\n    !!! warning \"Discouraged\"\n        This function is **discouraged** in favor of using\n        [`Annotated`](https://docs.python.org/3/library/typing.html#typing.Annotated) with\n        [`Field`][pydantic.fields.Field] instead.\n\n        This function will be **deprecated** in Pydantic 3.0.\n\n        The reason is that `condecimal` returns a type, which doesn't play well with static analysis tools.\n\n        === \":x: Don't do this\"\n            ```py\n            from pydantic import BaseModel, condecimal\n\n            class Foo(BaseModel):\n                bar: condecimal(strict=True, allow_inf_nan=True)\n            ```\n\n        === \":white_check_mark: Do this\"\n            ```py\n            from decimal import Decimal\n\n            from typing_extensions import Annotated\n\n            from pydantic import BaseModel, Field\n\n            class Foo(BaseModel):\n                bar: Annotated[Decimal, Field(strict=True, allow_inf_nan=True)]\n            ```\n\n    A wrapper around Decimal that adds validation.\n\n    Args:\n        strict: Whether to validate the value in strict mode. Defaults to `None`.\n        gt: The value must be greater than this. Defaults to `None`.\n        ge: The value must be greater than or equal to this. Defaults to `None`.\n        lt: The value must be less than this. Defaults to `None`.\n        le: The value must be less than or equal to this. Defaults to `None`.\n        multiple_of: The value must be a multiple of this. Defaults to `None`.\n        max_digits: The maximum number of digits. Defaults to `None`.\n        decimal_places: The number of decimal places. Defaults to `None`.\n        allow_inf_nan: Whether to allow infinity and NaN. Defaults to `None`.\n\n    ```py\n    from decimal import Decimal\n\n    from pydantic import BaseModel, ValidationError, condecimal\n\n    class ConstrainedExample(BaseModel):\n        constrained_decimal: condecimal(gt=Decimal('1.0'))\n\n    m = ConstrainedExample(constrained_decimal=Decimal('1.1'))\n    print(repr(m))\n    #&gt; ConstrainedExample(constrained_decimal=Decimal('1.1'))\n\n    try:\n        ConstrainedExample(constrained_decimal=Decimal('0.9'))\n    except ValidationError as e:\n        print(e.errors())\n        '''\n        [\n            {\n                'type': 'greater_than',\n                'loc': ('constrained_decimal',),\n                'msg': 'Input should be greater than 1.0',\n                'input': Decimal('0.9'),\n                'ctx': {'gt': Decimal('1.0')},\n                'url': 'https://errors.pydantic.dev/2/v/greater_than',\n            }\n        ]\n        '''\n    ```\n    \"\"\"  # noqa: D212\n    return Annotated[  # pyright: ignore[reportReturnType]\n        Decimal,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Interval(gt=gt, ge=ge, lt=lt, le=le),\n        annotated_types.MultipleOf(multiple_of) if multiple_of is not None else None,\n        _fields.pydantic_general_metadata(max_digits=max_digits, decimal_places=decimal_places),\n        AllowInfNan(allow_inf_nan) if allow_inf_nan is not None else None,\n    ]\n</code></pre>"},{"location":"api/types/#pydantic.types.condate","title":"condate","text":"<pre><code>condate(\n    *,\n    strict: bool | None = None,\n    gt: date | None = None,\n    ge: date | None = None,\n    lt: date | None = None,\n    le: date | None = None\n) -&gt; type[date]\n</code></pre> <p>A wrapper for date that adds constraints.</p> <p>Parameters:</p> Name Type Description Default <code>strict</code> <code>bool | None</code> <p>Whether to validate the date value in strict mode. Defaults to <code>None</code>.</p> <code>None</code> <code>gt</code> <code>date | None</code> <p>The value must be greater than this. Defaults to <code>None</code>.</p> <code>None</code> <code>ge</code> <code>date | None</code> <p>The value must be greater than or equal to this. Defaults to <code>None</code>.</p> <code>None</code> <code>lt</code> <code>date | None</code> <p>The value must be less than this. Defaults to <code>None</code>.</p> <code>None</code> <code>le</code> <code>date | None</code> <p>The value must be less than or equal to this. Defaults to <code>None</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>type[date]</code> <p>A date type with the specified constraints.</p> Source code in <code>pydantic/types.py</code> <pre><code>def condate(\n    *,\n    strict: bool | None = None,\n    gt: date | None = None,\n    ge: date | None = None,\n    lt: date | None = None,\n    le: date | None = None,\n) -&gt; type[date]:\n    \"\"\"A wrapper for date that adds constraints.\n\n    Args:\n        strict: Whether to validate the date value in strict mode. Defaults to `None`.\n        gt: The value must be greater than this. Defaults to `None`.\n        ge: The value must be greater than or equal to this. Defaults to `None`.\n        lt: The value must be less than this. Defaults to `None`.\n        le: The value must be less than or equal to this. Defaults to `None`.\n\n    Returns:\n        A date type with the specified constraints.\n    \"\"\"\n    return Annotated[  # pyright: ignore[reportReturnType]\n        date,\n        Strict(strict) if strict is not None else None,\n        annotated_types.Interval(gt=gt, ge=ge, lt=lt, le=le),\n    ]\n</code></pre>"},{"location":"api/validate_call/","title":"Validate Call","text":"<p>Decorator for validating function calls.</p>"},{"location":"api/validate_call/#pydantic.validate_call_decorator.validate_call","title":"validate_call","text":"<pre><code>validate_call(\n    func: AnyCallableT | None = None,\n    /,\n    *,\n    config: ConfigDict | None = None,\n    validate_return: bool = False,\n) -&gt; AnyCallableT | Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <p>Usage Documentation</p> <p>Validation Decorator</p> <p>Returns a decorated wrapper around the function that validates the arguments and, optionally, the return value.</p> <p>Usage may be either as a plain decorator <code>@validate_call</code> or with arguments <code>@validate_call(...)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>AnyCallableT | None</code> <p>The function to be decorated.</p> <code>None</code> <code>config</code> <code>ConfigDict | None</code> <p>The configuration dictionary.</p> <code>None</code> <code>validate_return</code> <code>bool</code> <p>Whether to validate the return value.</p> <code>False</code> <p>Returns:</p> Type Description <code>AnyCallableT | Callable[[AnyCallableT], AnyCallableT]</code> <p>The decorated function.</p> Source code in <code>pydantic/validate_call_decorator.py</code> <pre><code>def validate_call(\n    func: AnyCallableT | None = None,\n    /,\n    *,\n    config: ConfigDict | None = None,\n    validate_return: bool = False,\n) -&gt; AnyCallableT | Callable[[AnyCallableT], AnyCallableT]:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.9/concepts/validation_decorator/\n\n    Returns a decorated wrapper around the function that validates the arguments and, optionally, the return value.\n\n    Usage may be either as a plain decorator `@validate_call` or with arguments `@validate_call(...)`.\n\n    Args:\n        func: The function to be decorated.\n        config: The configuration dictionary.\n        validate_return: Whether to validate the return value.\n\n    Returns:\n        The decorated function.\n    \"\"\"\n    local_ns = _typing_extra.parent_frame_namespace()\n\n    def validate(function: AnyCallableT) -&gt; AnyCallableT:\n        if isinstance(function, (classmethod, staticmethod)):\n            name = type(function).__name__\n            raise TypeError(f'The `@{name}` decorator should be applied after `@validate_call` (put `@{name}` on top)')\n\n        validate_call_wrapper = _validate_call.ValidateCallWrapper(function, config, validate_return, local_ns)\n\n        @functools.wraps(function)\n        def wrapper_function(*args, **kwargs):\n            return validate_call_wrapper(*args, **kwargs)\n\n        wrapper_function.raw_function = function  # type: ignore\n\n        return wrapper_function  # type: ignore\n\n    if func:\n        return validate(func)\n    else:\n        return validate\n</code></pre>"},{"location":"api/version/","title":"Version Information","text":""},{"location":"api/version/#pydantic.__version__","title":"pydantic.__version__  <code>module-attribute</code>","text":"<pre><code>__version__ = VERSION\n</code></pre>"},{"location":"api/version/#pydantic.version.version_info","title":"pydantic.version.version_info","text":"<pre><code>version_info() -&gt; str\n</code></pre> <p>Return complete version information for Pydantic and its dependencies.</p> Source code in <code>pydantic/version.py</code> <pre><code>def version_info() -&gt; str:\n    \"\"\"Return complete version information for Pydantic and its dependencies.\"\"\"\n    import importlib.metadata as importlib_metadata\n    import os\n    import platform\n    import sys\n    from pathlib import Path\n\n    import pydantic_core._pydantic_core as pdc\n\n    from ._internal import _git as git\n\n    # get data about packages that are closely related to pydantic, use pydantic or often conflict with pydantic\n    package_names = {\n        'email-validator',\n        'fastapi',\n        'mypy',\n        'pydantic-extra-types',\n        'pydantic-settings',\n        'pyright',\n        'typing_extensions',\n    }\n    related_packages = []\n\n    for dist in importlib_metadata.distributions():\n        name = dist.metadata['Name']\n        if name in package_names:\n            related_packages.append(f'{name}-{dist.version}')\n\n    pydantic_dir = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n    most_recent_commit = (\n        git.git_revision(pydantic_dir) if git.is_git_repo(pydantic_dir) and git.have_git() else 'unknown'\n    )\n\n    info = {\n        'pydantic version': VERSION,\n        'pydantic-core version': pdc.__version__,\n        'pydantic-core build': getattr(pdc, 'build_info', None) or pdc.build_profile,\n        'install path': Path(__file__).resolve().parent,\n        'python version': sys.version,\n        'platform': platform.platform(),\n        'related packages': ' '.join(related_packages),\n        'commit': most_recent_commit,\n    }\n    return '\\n'.join('{:&gt;30} {}'.format(k + ':', str(v).replace('\\n', ' ')) for k, v in info.items())\n</code></pre>"},{"location":"concepts/alias/","title":"Alias","text":"<p>An alias is an alternative name for a field, used when serializing and deserializing data.</p> <p>You can specify an alias in the following ways:</p> <ul> <li><code>alias</code> on the <code>Field</code><ul> <li>must be a <code>str</code></li> </ul> </li> <li><code>validation_alias</code> on the <code>Field</code><ul> <li>can be an instance of <code>str</code>, <code>AliasPath</code>, or <code>AliasChoices</code></li> </ul> </li> <li><code>serialization_alias</code> on the <code>Field</code><ul> <li>must be a <code>str</code></li> </ul> </li> <li><code>alias_generator</code> on the <code>Config</code><ul> <li>can be a callable or an instance of <code>AliasGenerator</code></li> </ul> </li> </ul> <p>For examples of how to use <code>alias</code>, <code>validation_alias</code>, and <code>serialization_alias</code>, see Field aliases.</p>"},{"location":"concepts/alias/#aliaspath-and-aliaschoices","title":"<code>AliasPath</code> and <code>AliasChoices</code>","text":"API Documentation <p><code>pydantic.aliases.AliasPath</code> <code>pydantic.aliases.AliasChoices</code></p> <p>Pydantic provides two special types for convenience when using <code>validation_alias</code>: <code>AliasPath</code> and <code>AliasChoices</code>.</p> <p>The <code>AliasPath</code> is used to specify a path to a field using aliases. For example:</p> <pre><code>from pydantic import BaseModel, Field, AliasPath\n\n\nclass User(BaseModel):\n    first_name: str = Field(validation_alias=AliasPath('names', 0))\n    last_name: str = Field(validation_alias=AliasPath('names', 1))\n\nuser = User.model_validate({'names': ['John', 'Doe']})  # (1)!\nprint(user)\n#&gt; first_name='John' last_name='Doe'\n</code></pre> <ol> <li> <p>We are using <code>model_validate</code> to validate a dictionary using the field aliases.</p> <p>You can see more details about <code>model_validate</code> in the API reference.</p> </li> </ol> <p>In the <code>'first_name'</code> field, we are using the alias <code>'names'</code> and the index <code>0</code> to specify the path to the first name. In the <code>'last_name'</code> field, we are using the alias <code>'names'</code> and the index <code>1</code> to specify the path to the last name.</p> <p><code>AliasChoices</code> is used to specify a choice of aliases. For example:</p> <pre><code>from pydantic import BaseModel, Field, AliasChoices\n\n\nclass User(BaseModel):\n    first_name: str = Field(validation_alias=AliasChoices('first_name', 'fname'))\n    last_name: str = Field(validation_alias=AliasChoices('last_name', 'lname'))\n\nuser = User.model_validate({'fname': 'John', 'lname': 'Doe'})  # (1)!\nprint(user)\n#&gt; first_name='John' last_name='Doe'\nuser = User.model_validate({'first_name': 'John', 'lname': 'Doe'})  # (2)!\nprint(user)\n#&gt; first_name='John' last_name='Doe'\n</code></pre> <ol> <li>We are using the second alias choice for both fields.</li> <li>We are using the first alias choice for the field <code>'first_name'</code> and the second alias choice    for the field <code>'last_name'</code>.</li> </ol> <p>You can also use <code>AliasChoices</code> with <code>AliasPath</code>:</p> <pre><code>from pydantic import BaseModel, Field, AliasPath, AliasChoices\n\n\nclass User(BaseModel):\n    first_name: str = Field(validation_alias=AliasChoices('first_name', AliasPath('names', 0)))\n    last_name: str = Field(validation_alias=AliasChoices('last_name', AliasPath('names', 1)))\n\n\nuser = User.model_validate({'first_name': 'John', 'last_name': 'Doe'})\nprint(user)\n#&gt; first_name='John' last_name='Doe'\nuser = User.model_validate({'names': ['John', 'Doe']})\nprint(user)\n#&gt; first_name='John' last_name='Doe'\nuser = User.model_validate({'names': ['John'], 'last_name': 'Doe'})\nprint(user)\n#&gt; first_name='John' last_name='Doe'\n</code></pre>"},{"location":"concepts/alias/#using-alias-generators","title":"Using alias generators","text":"<p>You can use the <code>alias_generator</code> parameter of <code>Config</code> to specify a callable (or group of callables, via <code>AliasGenerator</code>) that will generate aliases for all fields in a model. This is useful if you want to use a consistent naming convention for all fields in a model, but do not want to specify the alias for each field individually.</p> <p>Note</p> <p>Pydantic offers three built-in alias generators that you can use out of the box:</p> <p><code>to_pascal</code> <code>to_camel</code> <code>to_snake</code></p>"},{"location":"concepts/alias/#using-a-callable","title":"Using a callable","text":"<p>Here's a basic example using a callable:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass Tree(BaseModel):\n    model_config = ConfigDict(\n        alias_generator=lambda field_name: field_name.upper()\n    )\n\n    age: int\n    height: float\n    kind: str\n\n\nt = Tree.model_validate({'AGE': 12, 'HEIGHT': 1.2, 'KIND': 'oak'})\nprint(t.model_dump(by_alias=True))\n#&gt; {'AGE': 12, 'HEIGHT': 1.2, 'KIND': 'oak'}\n</code></pre>"},{"location":"concepts/alias/#using-an-aliasgenerator","title":"Using an <code>AliasGenerator</code>","text":"API Documentation <p><code>pydantic.aliases.AliasGenerator</code></p> <p><code>AliasGenerator</code> is a class that allows you to specify multiple alias generators for a model. You can use an <code>AliasGenerator</code> to specify different alias generators for validation and serialization.</p> <p>This is particularly useful if you need to use different naming conventions for loading and saving data, but you don't want to specify the validation and serialization aliases for each field individually.</p> <p>For example:</p> <pre><code>from pydantic import AliasGenerator, BaseModel, ConfigDict\n\n\nclass Tree(BaseModel):\n    model_config = ConfigDict(\n        alias_generator=AliasGenerator(\n            validation_alias=lambda field_name: field_name.upper(),\n            serialization_alias=lambda field_name: field_name.title(),\n        )\n    )\n\n    age: int\n    height: float\n    kind: str\n\n\nt = Tree.model_validate({'AGE': 12, 'HEIGHT': 1.2, 'KIND': 'oak'})\nprint(t.model_dump(by_alias=True))\n#&gt; {'Age': 12, 'Height': 1.2, 'Kind': 'oak'}\n</code></pre>"},{"location":"concepts/alias/#alias-precedence","title":"Alias Precedence","text":"<p>If you specify an <code>alias</code> on the <code>Field</code>, it will take precedence over the generated alias by default:</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\ndef to_camel(string: str) -&gt; str:\n    return ''.join(word.capitalize() for word in string.split('_'))\n\n\nclass Voice(BaseModel):\n    model_config = ConfigDict(alias_generator=to_camel)\n\n    name: str\n    language_code: str = Field(alias='lang')\n\n\nvoice = Voice(Name='Filiz', lang='tr-TR')\nprint(voice.language_code)\n#&gt; tr-TR\nprint(voice.model_dump(by_alias=True))\n#&gt; {'Name': 'Filiz', 'lang': 'tr-TR'}\n</code></pre>"},{"location":"concepts/alias/#alias-priority","title":"Alias Priority","text":"<p>You may set <code>alias_priority</code> on a field to change this behavior:</p> <ul> <li><code>alias_priority=2</code> the alias will not be overridden by the alias generator.</li> <li><code>alias_priority=1</code> the alias will be overridden by the alias generator.</li> <li><code>alias_priority</code> not set:<ul> <li>alias is set: the alias will not be overridden by the alias generator.</li> <li>alias is not set: the alias will be overridden by the alias generator.</li> </ul> </li> </ul> <p>The same precedence applies to <code>validation_alias</code> and <code>serialization_alias</code>. See more about the different field aliases under field aliases.</p>"},{"location":"concepts/config/","title":"Configuration","text":"<p>Behaviour of Pydantic can be controlled via the <code>BaseModel.model_config</code>, and as an argument to <code>TypeAdapter</code>.</p> <p>Note</p> <p>Before v2.0, the <code>Config</code> class was used. This is still supported, but deprecated.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    model_config = ConfigDict(str_max_length=10)\n\n    v: str\n\n\ntry:\n    m = Model(v='x' * 20)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    v\n      String should have at most 10 characters [type=string_too_long, input_value='xxxxxxxxxxxxxxxxxxxx', input_type=str]\n    \"\"\"\n</code></pre> <p>Also, you can specify config options as model class kwargs: <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel, extra='forbid'):  # (1)!\n    a: str\n\n\ntry:\n    Model(a='spam', b='oh no')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    b\n      Extra inputs are not permitted [type=extra_forbidden, input_value='oh no', input_type=str]\n    \"\"\"\n</code></pre></p> <ol> <li>See the Extra Attributes section for more details.</li> </ol> <p>Similarly, if using the <code>@dataclass</code> decorator from Pydantic: <pre><code>from datetime import datetime\n\nfrom pydantic import ConfigDict, ValidationError\nfrom pydantic.dataclasses import dataclass\n\nconfig = ConfigDict(str_max_length=10, validate_assignment=True)\n\n\n@dataclass(config=config)\nclass User:\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime = None\n\n\nuser = User(id='42', signup_ts='2032-06-21T12:00')\ntry:\n    user.name = 'x' * 20\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for User\n    name\n      String should have at most 10 characters [type=string_too_long, input_value='xxxxxxxxxxxxxxxxxxxx', input_type=str]\n    \"\"\"\n</code></pre></p>"},{"location":"concepts/config/#configuration-with-dataclass-from-the-standard-library-or-typeddict","title":"Configuration with <code>dataclass</code> from the standard library or <code>TypedDict</code>","text":"<p>If using the <code>dataclass</code> from the standard library or <code>TypedDict</code>, you should use <code>__pydantic_config__</code> instead.</p> <pre><code>from dataclasses import dataclass\nfrom datetime import datetime\n\nfrom pydantic import ConfigDict\n\n\n@dataclass\nclass User:\n    __pydantic_config__ = ConfigDict(strict=True)\n\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime = None\n</code></pre> <p>Alternatively, the <code>with_config</code> decorator can be used to comply with type checkers.</p> <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import ConfigDict, with_config\n\n\n@with_config(ConfigDict(str_to_lower=True))\nclass Model(TypedDict):\n    x: str\n</code></pre>"},{"location":"concepts/config/#change-behaviour-globally","title":"Change behaviour globally","text":"<p>If you wish to change the behaviour of Pydantic globally, you can create your own custom <code>BaseModel</code> with custom <code>model_config</code> since the config is inherited:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass Parent(BaseModel):\n    model_config = ConfigDict(extra='allow')\n\n\nclass Model(Parent):\n    x: str\n\n\nm = Model(x='foo', y='bar')\nprint(m.model_dump())\n#&gt; {'x': 'foo', 'y': 'bar'}\n</code></pre> <p>If you add a <code>model_config</code> to the <code>Model</code> class, it will merge with the <code>model_config</code> from <code>Parent</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass Parent(BaseModel):\n    model_config = ConfigDict(extra='allow')\n\n\nclass Model(Parent):\n    model_config = ConfigDict(str_to_lower=True)  # (1)!\n\n    x: str\n\n\nm = Model(x='FOO', y='bar')\nprint(m.model_dump())\n#&gt; {'x': 'foo', 'y': 'bar'}\nprint(m.model_config)\n#&gt; {'extra': 'allow', 'str_to_lower': True}\n</code></pre>"},{"location":"concepts/conversion_table/","title":"Conversion Table","text":"<p>The following table provides details on how Pydantic converts data during validation in both strict and lax modes.</p> <p>The \"Strict\" column contains checkmarks for type conversions that are allowed when validating in Strict Mode.</p> AllJSONJSON - StrictPythonPython - Strict Field Type Input Strict Input Source Conditions <code>bool</code> <code>bool</code> \u2713 Python &amp; JSON <code>bool</code> <code>float</code> Python &amp; JSON Allowed values: <code>0.0, 1.0</code>. <code>bool</code> <code>int</code> Python &amp; JSON Allowed values: <code>0, 1</code>. <code>bool</code> <code>str</code> Python &amp; JSON Allowed values: <code>'f'</code>, <code>'n'</code>, <code>'no'</code>, <code>'off'</code>, <code>'false'</code>, <code>'False'</code>, <code>'t'</code>, <code>'y'</code>, <code>'on'</code>, <code>'yes'</code>, <code>'true'</code>, <code>'True'</code>. <code>bool</code> <code>Decimal</code> Python Allowed values: <code>Decimal(0), Decimal(1)</code>. <code>bytes</code> <code>bytearray</code> Python <code>bytes</code> <code>bytes</code> \u2713 Python <code>bytes</code> <code>str</code> \u2713 JSON <code>bytes</code> <code>str</code> Python <code>callable</code> <code>-</code> JSON Never valid. <code>callable</code> <code>Any</code> \u2713 Python <code>callable()</code> check must return <code>True</code>. <code>date</code> <code>bytes</code> Python Format: <code>YYYY-MM-DD</code> (UTF-8). <code>date</code> <code>date</code> \u2713 Python <code>date</code> <code>datetime</code> Python Must be exact date, eg. no <code>H</code>, <code>M</code>, <code>S</code>, <code>f</code>. <code>date</code> <code>float</code> Python &amp; JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>date</code> <code>int</code> Python &amp; JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>date</code> <code>str</code> Python &amp; JSON Format: <code>YYYY-MM-DD</code>. <code>date</code> <code>Decimal</code> Python Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>datetime</code> <code>bytes</code> Python Format: <code>YYYY-MM-DDTHH:MM:SS.f</code> or <code>YYYY-MM-DD</code>. See speedate, (UTF-8). <code>datetime</code> <code>date</code> Python <code>datetime</code> <code>datetime</code> \u2713 Python <code>datetime</code> <code>float</code> Python &amp; JSON Interpreted as seconds or ms from epoch, see speedate. <code>datetime</code> <code>int</code> Python &amp; JSON Interpreted as seconds or ms from epoch, see speedate. <code>datetime</code> <code>str</code> Python &amp; JSON Format: <code>YYYY-MM-DDTHH:MM:SS.f</code> or <code>YYYY-MM-DD</code>. See speedate. <code>datetime</code> <code>Decimal</code> Python Interpreted as seconds or ms from epoch, see speedate. <code>deque</code> <code>deque</code> \u2713 Python <code>deque</code> <code>frozenset</code> Python <code>deque</code> <code>list</code> Python <code>deque</code> <code>set</code> Python <code>deque</code> <code>tuple</code> Python <code>deque</code> <code>Array</code> \u2713 JSON <code>dict</code> <code>dict</code> \u2713 Python <code>dict</code> <code>Mapping</code> Python Must implement the mapping interface and have an <code>items()</code> method. <code>dict</code> <code>Object</code> \u2713 JSON <code>float</code> <code>bool</code> Python &amp; JSON <code>float</code> <code>bytes</code> Python Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>float</code> <code>float</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>float</code> <code>int</code> \u2713 Python &amp; JSON <code>float</code> <code>str</code> Python &amp; JSON Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>float</code> <code>Decimal</code> Python <code>frozenset</code> <code>deque</code> Python <code>frozenset</code> <code>dict_keys</code> Python <code>frozenset</code> <code>dict_values</code> Python <code>frozenset</code> <code>frozenset</code> \u2713 Python <code>frozenset</code> <code>list</code> Python <code>frozenset</code> <code>set</code> Python <code>frozenset</code> <code>tuple</code> Python <code>frozenset</code> <code>Array</code> \u2713 JSON <code>int</code> <code>bool</code> Python &amp; JSON <code>int</code> <code>bytes</code> Python Must be numeric only, e.g. <code>[0-9]+</code>. <code>int</code> <code>float</code> Python &amp; JSON Must be exact int, e.g. <code>val % 1 == 0</code>, raises error for <code>nan</code>, <code>inf</code>. <code>int</code> <code>int</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>int</code> <code>int</code> Python &amp; JSON <code>int</code> <code>str</code> Python &amp; JSON Must be numeric only, e.g. <code>[0-9]+</code>. <code>int</code> <code>Decimal</code> Python Must be exact int, e.g. <code>val % 1 == 0</code>. <code>list</code> <code>deque</code> Python <code>list</code> <code>dict_keys</code> Python <code>list</code> <code>dict_values</code> Python <code>list</code> <code>frozenset</code> Python <code>list</code> <code>list</code> \u2713 Python <code>list</code> <code>set</code> Python <code>list</code> <code>tuple</code> Python <code>list</code> <code>Array</code> \u2713 JSON <code>namedtuple</code> <code>dict</code> \u2713 Python <code>namedtuple</code> <code>list</code> \u2713 Python <code>namedtuple</code> <code>namedtuple</code> \u2713 Python <code>namedtuple</code> <code>tuple</code> \u2713 Python <code>namedtuple</code> <code>Array</code> \u2713 JSON <code>namedtuple</code> <code>NamedTuple</code> \u2713 Python <code>set</code> <code>deque</code> Python <code>set</code> <code>dict_keys</code> Python <code>set</code> <code>dict_values</code> Python <code>set</code> <code>frozenset</code> Python <code>set</code> <code>list</code> Python <code>set</code> <code>set</code> \u2713 Python <code>set</code> <code>tuple</code> Python <code>set</code> <code>Array</code> \u2713 JSON <code>str</code> <code>bytearray</code> Python Assumes UTF-8, error on unicode decoding error. <code>str</code> <code>bytes</code> Python Assumes UTF-8, error on unicode decoding error. <code>str</code> <code>str</code> \u2713 Python &amp; JSON <code>time</code> <code>bytes</code> Python Format: <code>HH:MM:SS.FFFFFF</code>. See speedate. <code>time</code> <code>float</code> Python &amp; JSON Interpreted as seconds, range <code>0 - 86399.9*</code>. <code>time</code> <code>int</code> Python &amp; JSON Interpreted as seconds, range <code>0 - 86399</code>. <code>time</code> <code>str</code> Python &amp; JSON Format: <code>HH:MM:SS.FFFFFF</code>. See speedate. <code>time</code> <code>time</code> \u2713 Python <code>time</code> <code>Decimal</code> Python Interpreted as seconds, range <code>0 - 86399.9*</code>. <code>timedelta</code> <code>bytes</code> Python Format: <code>ISO8601</code>. See speedate, (UTF-8). <code>timedelta</code> <code>float</code> Python &amp; JSON Interpreted as seconds. <code>timedelta</code> <code>int</code> Python &amp; JSON Interpreted as seconds. <code>timedelta</code> <code>str</code> Python &amp; JSON Format: <code>ISO8601</code>. See speedate. <code>timedelta</code> <code>timedelta</code> \u2713 Python <code>timedelta</code> <code>Decimal</code> Python Interpreted as seconds. <code>tuple</code> <code>deque</code> Python <code>tuple</code> <code>dict_keys</code> Python <code>tuple</code> <code>dict_values</code> Python <code>tuple</code> <code>frozenset</code> Python <code>tuple</code> <code>list</code> Python <code>tuple</code> <code>set</code> Python <code>tuple</code> <code>tuple</code> \u2713 Python <code>tuple</code> <code>Array</code> \u2713 JSON <code>Any</code> <code>Any</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>float</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>int</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>str</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>Decimal</code> \u2713 Python <code>Decimal</code> <code>float</code> \u2713 JSON <code>Decimal</code> <code>float</code> Python &amp; JSON <code>Decimal</code> <code>int</code> \u2713 JSON <code>Decimal</code> <code>int</code> Python &amp; JSON <code>Decimal</code> <code>str</code> \u2713 JSON <code>Decimal</code> <code>str</code> Python &amp; JSON Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>Decimal</code> <code>Decimal</code> \u2713 Python <code>Enum</code> <code>Any</code> \u2713 JSON Input value must be convertible to enum values. <code>Enum</code> <code>Any</code> Python Input value must be convertible to enum values. <code>Enum</code> <code>Enum</code> \u2713 Python <code>IPv4Address</code> <code>bytes</code> Python <code>IPv4Address</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**32</code> <code>IPv4Address</code> <code>str</code> \u2713 JSON <code>IPv4Address</code> <code>str</code> Python &amp; JSON <code>IPv4Address</code> <code>IPv4Address</code> \u2713 Python <code>IPv4Address</code> <code>IPv4Interface</code> \u2713 Python <code>IPv4Interface</code> <code>bytes</code> Python <code>IPv4Interface</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**32</code> <code>IPv4Interface</code> <code>str</code> \u2713 JSON <code>IPv4Interface</code> <code>str</code> Python &amp; JSON <code>IPv4Interface</code> <code>tuple</code> Python <code>IPv4Interface</code> <code>IPv4Address</code> Python <code>IPv4Interface</code> <code>IPv4Interface</code> \u2713 Python <code>IPv4Network</code> <code>bytes</code> Python <code>IPv4Network</code> <code>int</code> Python integer representing the IP network, must be less than <code>2**32</code> <code>IPv4Network</code> <code>str</code> \u2713 JSON <code>IPv4Network</code> <code>str</code> Python &amp; JSON <code>IPv4Network</code> <code>IPv4Address</code> Python <code>IPv4Network</code> <code>IPv4Interface</code> Python <code>IPv4Network</code> <code>IPv4Network</code> \u2713 Python <code>IPv6Address</code> <code>bytes</code> Python <code>IPv6Address</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**128</code> <code>IPv6Address</code> <code>str</code> \u2713 JSON <code>IPv6Address</code> <code>str</code> Python &amp; JSON <code>IPv6Address</code> <code>IPv6Address</code> \u2713 Python <code>IPv6Address</code> <code>IPv6Interface</code> \u2713 Python <code>IPv6Interface</code> <code>bytes</code> Python <code>IPv6Interface</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**128</code> <code>IPv6Interface</code> <code>str</code> \u2713 JSON <code>IPv6Interface</code> <code>str</code> Python &amp; JSON <code>IPv6Interface</code> <code>tuple</code> Python <code>IPv6Interface</code> <code>IPv6Address</code> Python <code>IPv6Interface</code> <code>IPv6Interface</code> \u2713 Python <code>IPv6Network</code> <code>bytes</code> Python <code>IPv6Network</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**128</code> <code>IPv6Network</code> <code>str</code> \u2713 JSON <code>IPv6Network</code> <code>str</code> Python &amp; JSON <code>IPv6Network</code> <code>IPv6Address</code> Python <code>IPv6Network</code> <code>IPv6Interface</code> Python <code>IPv6Network</code> <code>IPv6Network</code> \u2713 Python <code>InstanceOf</code> <code>-</code> JSON Never valid. <code>InstanceOf</code> <code>Any</code> \u2713 Python <code>isinstance()</code> check must return <code>True</code>. <code>IntEnum</code> <code>Any</code> \u2713 JSON Input value must be convertible to enum values. <code>IntEnum</code> <code>Any</code> Python Input value must be convertible to enum values. <code>IntEnum</code> <code>IntEnum</code> \u2713 Python <code>Iterable</code> <code>deque</code> \u2713 Python <code>Iterable</code> <code>frozenset</code> \u2713 Python <code>Iterable</code> <code>list</code> \u2713 Python <code>Iterable</code> <code>set</code> \u2713 Python <code>Iterable</code> <code>tuple</code> \u2713 Python <code>Iterable</code> <code>Array</code> \u2713 JSON <code>NamedTuple</code> <code>dict</code> \u2713 Python <code>NamedTuple</code> <code>list</code> \u2713 Python <code>NamedTuple</code> <code>namedtuple</code> \u2713 Python <code>NamedTuple</code> <code>tuple</code> \u2713 Python <code>NamedTuple</code> <code>Array</code> \u2713 JSON <code>NamedTuple</code> <code>NamedTuple</code> \u2713 Python <code>None</code> <code>None</code> \u2713 Python &amp; JSON <code>Path</code> <code>str</code> \u2713 JSON <code>Path</code> <code>str</code> Python <code>Path</code> <code>Path</code> \u2713 Python <code>Pattern</code> <code>bytes</code> \u2713 Python Input must be a valid pattern. <code>Pattern</code> <code>str</code> \u2713 Python &amp; JSON Input must be a valid pattern. <code>Sequence</code> <code>deque</code> Python <code>Sequence</code> <code>list</code> \u2713 Python <code>Sequence</code> <code>tuple</code> Python <code>Sequence</code> <code>Array</code> \u2713 JSON <code>Type</code> <code>Type</code> \u2713 Python <code>TypedDict</code> <code>dict</code> \u2713 Python <code>TypedDict</code> <code>Any</code> \u2713 Python <code>TypedDict</code> <code>Mapping</code> Python Must implement the mapping interface and have an <code>items()</code> method. <code>TypedDict</code> <code>Object</code> \u2713 JSON <code>UUID</code> <code>str</code> \u2713 JSON <code>UUID</code> <code>str</code> Python <code>UUID</code> <code>UUID</code> \u2713 Python Field Type Input Strict Input Source Conditions <code>bool</code> <code>bool</code> \u2713 Python &amp; JSON <code>bool</code> <code>float</code> Python &amp; JSON Allowed values: <code>0.0, 1.0</code>. <code>bool</code> <code>int</code> Python &amp; JSON Allowed values: <code>0, 1</code>. <code>bool</code> <code>str</code> Python &amp; JSON Allowed values: <code>'f'</code>, <code>'n'</code>, <code>'no'</code>, <code>'off'</code>, <code>'false'</code>, <code>'False'</code>, <code>'t'</code>, <code>'y'</code>, <code>'on'</code>, <code>'yes'</code>, <code>'true'</code>, <code>'True'</code>. <code>bytes</code> <code>str</code> \u2713 JSON <code>callable</code> <code>-</code> JSON Never valid. <code>date</code> <code>float</code> Python &amp; JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>date</code> <code>int</code> Python &amp; JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>date</code> <code>str</code> Python &amp; JSON Format: <code>YYYY-MM-DD</code>. <code>datetime</code> <code>float</code> Python &amp; JSON Interpreted as seconds or ms from epoch, see speedate. <code>datetime</code> <code>int</code> Python &amp; JSON Interpreted as seconds or ms from epoch, see speedate. <code>datetime</code> <code>str</code> Python &amp; JSON Format: <code>YYYY-MM-DDTHH:MM:SS.f</code> or <code>YYYY-MM-DD</code>. See speedate. <code>deque</code> <code>Array</code> \u2713 JSON <code>dict</code> <code>Object</code> \u2713 JSON <code>float</code> <code>bool</code> Python &amp; JSON <code>float</code> <code>float</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>float</code> <code>int</code> \u2713 Python &amp; JSON <code>float</code> <code>str</code> Python &amp; JSON Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>frozenset</code> <code>Array</code> \u2713 JSON <code>int</code> <code>bool</code> Python &amp; JSON <code>int</code> <code>float</code> Python &amp; JSON Must be exact int, e.g. <code>val % 1 == 0</code>, raises error for <code>nan</code>, <code>inf</code>. <code>int</code> <code>int</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>int</code> <code>int</code> Python &amp; JSON <code>int</code> <code>str</code> Python &amp; JSON Must be numeric only, e.g. <code>[0-9]+</code>. <code>list</code> <code>Array</code> \u2713 JSON <code>namedtuple</code> <code>Array</code> \u2713 JSON <code>set</code> <code>Array</code> \u2713 JSON <code>str</code> <code>str</code> \u2713 Python &amp; JSON <code>time</code> <code>float</code> Python &amp; JSON Interpreted as seconds, range <code>0 - 86399.9*</code>. <code>time</code> <code>int</code> Python &amp; JSON Interpreted as seconds, range <code>0 - 86399</code>. <code>time</code> <code>str</code> Python &amp; JSON Format: <code>HH:MM:SS.FFFFFF</code>. See speedate. <code>timedelta</code> <code>float</code> Python &amp; JSON Interpreted as seconds. <code>timedelta</code> <code>int</code> Python &amp; JSON Interpreted as seconds. <code>timedelta</code> <code>str</code> Python &amp; JSON Format: <code>ISO8601</code>. See speedate. <code>tuple</code> <code>Array</code> \u2713 JSON <code>Any</code> <code>Any</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>float</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>int</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>str</code> \u2713 Python &amp; JSON <code>Decimal</code> <code>float</code> \u2713 JSON <code>Decimal</code> <code>float</code> Python &amp; JSON <code>Decimal</code> <code>int</code> \u2713 JSON <code>Decimal</code> <code>int</code> Python &amp; JSON <code>Decimal</code> <code>str</code> \u2713 JSON <code>Decimal</code> <code>str</code> Python &amp; JSON Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>Enum</code> <code>Any</code> \u2713 JSON Input value must be convertible to enum values. <code>IPv4Address</code> <code>str</code> \u2713 JSON <code>IPv4Address</code> <code>str</code> Python &amp; JSON <code>IPv4Interface</code> <code>str</code> \u2713 JSON <code>IPv4Interface</code> <code>str</code> Python &amp; JSON <code>IPv4Network</code> <code>str</code> \u2713 JSON <code>IPv4Network</code> <code>str</code> Python &amp; JSON <code>IPv6Address</code> <code>str</code> \u2713 JSON <code>IPv6Address</code> <code>str</code> Python &amp; JSON <code>IPv6Interface</code> <code>str</code> \u2713 JSON <code>IPv6Interface</code> <code>str</code> Python &amp; JSON <code>IPv6Network</code> <code>str</code> \u2713 JSON <code>IPv6Network</code> <code>str</code> Python &amp; JSON <code>InstanceOf</code> <code>-</code> JSON Never valid. <code>IntEnum</code> <code>Any</code> \u2713 JSON Input value must be convertible to enum values. <code>Iterable</code> <code>Array</code> \u2713 JSON <code>NamedTuple</code> <code>Array</code> \u2713 JSON <code>None</code> <code>None</code> \u2713 Python &amp; JSON <code>Path</code> <code>str</code> \u2713 JSON <code>Pattern</code> <code>str</code> \u2713 Python &amp; JSON Input must be a valid pattern. <code>Sequence</code> <code>Array</code> \u2713 JSON <code>TypedDict</code> <code>Object</code> \u2713 JSON <code>UUID</code> <code>str</code> \u2713 JSON Field Type Input Strict Input Source Conditions <code>bool</code> <code>bool</code> \u2713 Python &amp; JSON <code>bytes</code> <code>str</code> \u2713 JSON <code>deque</code> <code>Array</code> \u2713 JSON <code>dict</code> <code>Object</code> \u2713 JSON <code>float</code> <code>float</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>float</code> <code>int</code> \u2713 Python &amp; JSON <code>frozenset</code> <code>Array</code> \u2713 JSON <code>int</code> <code>int</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>list</code> <code>Array</code> \u2713 JSON <code>namedtuple</code> <code>Array</code> \u2713 JSON <code>set</code> <code>Array</code> \u2713 JSON <code>str</code> <code>str</code> \u2713 Python &amp; JSON <code>tuple</code> <code>Array</code> \u2713 JSON <code>Any</code> <code>Any</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>float</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>int</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>str</code> \u2713 Python &amp; JSON <code>Decimal</code> <code>float</code> \u2713 JSON <code>Decimal</code> <code>int</code> \u2713 JSON <code>Decimal</code> <code>str</code> \u2713 JSON <code>Enum</code> <code>Any</code> \u2713 JSON Input value must be convertible to enum values. <code>IPv4Address</code> <code>str</code> \u2713 JSON <code>IPv4Interface</code> <code>str</code> \u2713 JSON <code>IPv4Network</code> <code>str</code> \u2713 JSON <code>IPv6Address</code> <code>str</code> \u2713 JSON <code>IPv6Interface</code> <code>str</code> \u2713 JSON <code>IPv6Network</code> <code>str</code> \u2713 JSON <code>IntEnum</code> <code>Any</code> \u2713 JSON Input value must be convertible to enum values. <code>Iterable</code> <code>Array</code> \u2713 JSON <code>NamedTuple</code> <code>Array</code> \u2713 JSON <code>None</code> <code>None</code> \u2713 Python &amp; JSON <code>Path</code> <code>str</code> \u2713 JSON <code>Pattern</code> <code>str</code> \u2713 Python &amp; JSON Input must be a valid pattern. <code>Sequence</code> <code>Array</code> \u2713 JSON <code>TypedDict</code> <code>Object</code> \u2713 JSON <code>UUID</code> <code>str</code> \u2713 JSON Field Type Input Strict Input Source Conditions <code>bool</code> <code>bool</code> \u2713 Python &amp; JSON <code>bool</code> <code>float</code> Python &amp; JSON Allowed values: <code>0.0, 1.0</code>. <code>bool</code> <code>int</code> Python &amp; JSON Allowed values: <code>0, 1</code>. <code>bool</code> <code>str</code> Python &amp; JSON Allowed values: <code>'f'</code>, <code>'n'</code>, <code>'no'</code>, <code>'off'</code>, <code>'false'</code>, <code>'False'</code>, <code>'t'</code>, <code>'y'</code>, <code>'on'</code>, <code>'yes'</code>, <code>'true'</code>, <code>'True'</code>. <code>bool</code> <code>Decimal</code> Python Allowed values: <code>Decimal(0), Decimal(1)</code>. <code>bytes</code> <code>bytearray</code> Python <code>bytes</code> <code>bytes</code> \u2713 Python <code>bytes</code> <code>str</code> Python <code>callable</code> <code>Any</code> \u2713 Python <code>callable()</code> check must return <code>True</code>. <code>date</code> <code>bytes</code> Python Format: <code>YYYY-MM-DD</code> (UTF-8). <code>date</code> <code>date</code> \u2713 Python <code>date</code> <code>datetime</code> Python Must be exact date, eg. no <code>H</code>, <code>M</code>, <code>S</code>, <code>f</code>. <code>date</code> <code>float</code> Python &amp; JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>date</code> <code>int</code> Python &amp; JSON Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>date</code> <code>str</code> Python &amp; JSON Format: <code>YYYY-MM-DD</code>. <code>date</code> <code>Decimal</code> Python Interpreted as seconds or ms from epoch. See speedate. Must be exact date. <code>datetime</code> <code>bytes</code> Python Format: <code>YYYY-MM-DDTHH:MM:SS.f</code> or <code>YYYY-MM-DD</code>. See speedate, (UTF-8). <code>datetime</code> <code>date</code> Python <code>datetime</code> <code>datetime</code> \u2713 Python <code>datetime</code> <code>float</code> Python &amp; JSON Interpreted as seconds or ms from epoch, see speedate. <code>datetime</code> <code>int</code> Python &amp; JSON Interpreted as seconds or ms from epoch, see speedate. <code>datetime</code> <code>str</code> Python &amp; JSON Format: <code>YYYY-MM-DDTHH:MM:SS.f</code> or <code>YYYY-MM-DD</code>. See speedate. <code>datetime</code> <code>Decimal</code> Python Interpreted as seconds or ms from epoch, see speedate. <code>deque</code> <code>deque</code> \u2713 Python <code>deque</code> <code>frozenset</code> Python <code>deque</code> <code>list</code> Python <code>deque</code> <code>set</code> Python <code>deque</code> <code>tuple</code> Python <code>dict</code> <code>dict</code> \u2713 Python <code>dict</code> <code>Mapping</code> Python Must implement the mapping interface and have an <code>items()</code> method. <code>float</code> <code>bool</code> Python &amp; JSON <code>float</code> <code>bytes</code> Python Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>float</code> <code>float</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>float</code> <code>int</code> \u2713 Python &amp; JSON <code>float</code> <code>str</code> Python &amp; JSON Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>float</code> <code>Decimal</code> Python <code>frozenset</code> <code>deque</code> Python <code>frozenset</code> <code>dict_keys</code> Python <code>frozenset</code> <code>dict_values</code> Python <code>frozenset</code> <code>frozenset</code> \u2713 Python <code>frozenset</code> <code>list</code> Python <code>frozenset</code> <code>set</code> Python <code>frozenset</code> <code>tuple</code> Python <code>int</code> <code>bool</code> Python &amp; JSON <code>int</code> <code>bytes</code> Python Must be numeric only, e.g. <code>[0-9]+</code>. <code>int</code> <code>float</code> Python &amp; JSON Must be exact int, e.g. <code>val % 1 == 0</code>, raises error for <code>nan</code>, <code>inf</code>. <code>int</code> <code>int</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>int</code> <code>int</code> Python &amp; JSON <code>int</code> <code>str</code> Python &amp; JSON Must be numeric only, e.g. <code>[0-9]+</code>. <code>int</code> <code>Decimal</code> Python Must be exact int, e.g. <code>val % 1 == 0</code>. <code>list</code> <code>deque</code> Python <code>list</code> <code>dict_keys</code> Python <code>list</code> <code>dict_values</code> Python <code>list</code> <code>frozenset</code> Python <code>list</code> <code>list</code> \u2713 Python <code>list</code> <code>set</code> Python <code>list</code> <code>tuple</code> Python <code>namedtuple</code> <code>dict</code> \u2713 Python <code>namedtuple</code> <code>list</code> \u2713 Python <code>namedtuple</code> <code>namedtuple</code> \u2713 Python <code>namedtuple</code> <code>tuple</code> \u2713 Python <code>namedtuple</code> <code>NamedTuple</code> \u2713 Python <code>set</code> <code>deque</code> Python <code>set</code> <code>dict_keys</code> Python <code>set</code> <code>dict_values</code> Python <code>set</code> <code>frozenset</code> Python <code>set</code> <code>list</code> Python <code>set</code> <code>set</code> \u2713 Python <code>set</code> <code>tuple</code> Python <code>str</code> <code>bytearray</code> Python Assumes UTF-8, error on unicode decoding error. <code>str</code> <code>bytes</code> Python Assumes UTF-8, error on unicode decoding error. <code>str</code> <code>str</code> \u2713 Python &amp; JSON <code>time</code> <code>bytes</code> Python Format: <code>HH:MM:SS.FFFFFF</code>. See speedate. <code>time</code> <code>float</code> Python &amp; JSON Interpreted as seconds, range <code>0 - 86399.9*</code>. <code>time</code> <code>int</code> Python &amp; JSON Interpreted as seconds, range <code>0 - 86399</code>. <code>time</code> <code>str</code> Python &amp; JSON Format: <code>HH:MM:SS.FFFFFF</code>. See speedate. <code>time</code> <code>time</code> \u2713 Python <code>time</code> <code>Decimal</code> Python Interpreted as seconds, range <code>0 - 86399.9*</code>. <code>timedelta</code> <code>bytes</code> Python Format: <code>ISO8601</code>. See speedate, (UTF-8). <code>timedelta</code> <code>float</code> Python &amp; JSON Interpreted as seconds. <code>timedelta</code> <code>int</code> Python &amp; JSON Interpreted as seconds. <code>timedelta</code> <code>str</code> Python &amp; JSON Format: <code>ISO8601</code>. See speedate. <code>timedelta</code> <code>timedelta</code> \u2713 Python <code>timedelta</code> <code>Decimal</code> Python Interpreted as seconds. <code>tuple</code> <code>deque</code> Python <code>tuple</code> <code>dict_keys</code> Python <code>tuple</code> <code>dict_values</code> Python <code>tuple</code> <code>frozenset</code> Python <code>tuple</code> <code>list</code> Python <code>tuple</code> <code>set</code> Python <code>tuple</code> <code>tuple</code> \u2713 Python <code>Any</code> <code>Any</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>float</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>int</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>str</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>Decimal</code> \u2713 Python <code>Decimal</code> <code>float</code> Python &amp; JSON <code>Decimal</code> <code>int</code> Python &amp; JSON <code>Decimal</code> <code>str</code> Python &amp; JSON Must match <code>[0-9]+(\\.[0-9]+)?</code>. <code>Decimal</code> <code>Decimal</code> \u2713 Python <code>Enum</code> <code>Any</code> Python Input value must be convertible to enum values. <code>Enum</code> <code>Enum</code> \u2713 Python <code>IPv4Address</code> <code>bytes</code> Python <code>IPv4Address</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**32</code> <code>IPv4Address</code> <code>str</code> Python &amp; JSON <code>IPv4Address</code> <code>IPv4Address</code> \u2713 Python <code>IPv4Address</code> <code>IPv4Interface</code> \u2713 Python <code>IPv4Interface</code> <code>bytes</code> Python <code>IPv4Interface</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**32</code> <code>IPv4Interface</code> <code>str</code> Python &amp; JSON <code>IPv4Interface</code> <code>tuple</code> Python <code>IPv4Interface</code> <code>IPv4Address</code> Python <code>IPv4Interface</code> <code>IPv4Interface</code> \u2713 Python <code>IPv4Network</code> <code>bytes</code> Python <code>IPv4Network</code> <code>int</code> Python integer representing the IP network, must be less than <code>2**32</code> <code>IPv4Network</code> <code>str</code> Python &amp; JSON <code>IPv4Network</code> <code>IPv4Address</code> Python <code>IPv4Network</code> <code>IPv4Interface</code> Python <code>IPv4Network</code> <code>IPv4Network</code> \u2713 Python <code>IPv6Address</code> <code>bytes</code> Python <code>IPv6Address</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**128</code> <code>IPv6Address</code> <code>str</code> Python &amp; JSON <code>IPv6Address</code> <code>IPv6Address</code> \u2713 Python <code>IPv6Address</code> <code>IPv6Interface</code> \u2713 Python <code>IPv6Interface</code> <code>bytes</code> Python <code>IPv6Interface</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**128</code> <code>IPv6Interface</code> <code>str</code> Python &amp; JSON <code>IPv6Interface</code> <code>tuple</code> Python <code>IPv6Interface</code> <code>IPv6Address</code> Python <code>IPv6Interface</code> <code>IPv6Interface</code> \u2713 Python <code>IPv6Network</code> <code>bytes</code> Python <code>IPv6Network</code> <code>int</code> Python integer representing the IP address, must be less than <code>2**128</code> <code>IPv6Network</code> <code>str</code> Python &amp; JSON <code>IPv6Network</code> <code>IPv6Address</code> Python <code>IPv6Network</code> <code>IPv6Interface</code> Python <code>IPv6Network</code> <code>IPv6Network</code> \u2713 Python <code>InstanceOf</code> <code>Any</code> \u2713 Python <code>isinstance()</code> check must return <code>True</code>. <code>IntEnum</code> <code>Any</code> Python Input value must be convertible to enum values. <code>IntEnum</code> <code>IntEnum</code> \u2713 Python <code>Iterable</code> <code>deque</code> \u2713 Python <code>Iterable</code> <code>frozenset</code> \u2713 Python <code>Iterable</code> <code>list</code> \u2713 Python <code>Iterable</code> <code>set</code> \u2713 Python <code>Iterable</code> <code>tuple</code> \u2713 Python <code>NamedTuple</code> <code>dict</code> \u2713 Python <code>NamedTuple</code> <code>list</code> \u2713 Python <code>NamedTuple</code> <code>namedtuple</code> \u2713 Python <code>NamedTuple</code> <code>tuple</code> \u2713 Python <code>NamedTuple</code> <code>NamedTuple</code> \u2713 Python <code>None</code> <code>None</code> \u2713 Python &amp; JSON <code>Path</code> <code>str</code> Python <code>Path</code> <code>Path</code> \u2713 Python <code>Pattern</code> <code>bytes</code> \u2713 Python Input must be a valid pattern. <code>Pattern</code> <code>str</code> \u2713 Python &amp; JSON Input must be a valid pattern. <code>Sequence</code> <code>deque</code> Python <code>Sequence</code> <code>list</code> \u2713 Python <code>Sequence</code> <code>tuple</code> Python <code>Type</code> <code>Type</code> \u2713 Python <code>TypedDict</code> <code>dict</code> \u2713 Python <code>TypedDict</code> <code>Any</code> \u2713 Python <code>TypedDict</code> <code>Mapping</code> Python Must implement the mapping interface and have an <code>items()</code> method. <code>UUID</code> <code>str</code> Python <code>UUID</code> <code>UUID</code> \u2713 Python Field Type Input Strict Input Source Conditions <code>bool</code> <code>bool</code> \u2713 Python &amp; JSON <code>bytes</code> <code>bytes</code> \u2713 Python <code>callable</code> <code>Any</code> \u2713 Python <code>callable()</code> check must return <code>True</code>. <code>date</code> <code>date</code> \u2713 Python <code>datetime</code> <code>datetime</code> \u2713 Python <code>deque</code> <code>deque</code> \u2713 Python <code>dict</code> <code>dict</code> \u2713 Python <code>float</code> <code>float</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>float</code> <code>int</code> \u2713 Python &amp; JSON <code>frozenset</code> <code>frozenset</code> \u2713 Python <code>int</code> <code>int</code> \u2713 Python &amp; JSON <code>bool</code> is explicitly forbidden. <code>list</code> <code>list</code> \u2713 Python <code>namedtuple</code> <code>dict</code> \u2713 Python <code>namedtuple</code> <code>list</code> \u2713 Python <code>namedtuple</code> <code>namedtuple</code> \u2713 Python <code>namedtuple</code> <code>tuple</code> \u2713 Python <code>namedtuple</code> <code>NamedTuple</code> \u2713 Python <code>set</code> <code>set</code> \u2713 Python <code>str</code> <code>str</code> \u2713 Python &amp; JSON <code>time</code> <code>time</code> \u2713 Python <code>timedelta</code> <code>timedelta</code> \u2713 Python <code>tuple</code> <code>tuple</code> \u2713 Python <code>Any</code> <code>Any</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>float</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>int</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>str</code> \u2713 Python &amp; JSON <code>ByteSize</code> <code>Decimal</code> \u2713 Python <code>Decimal</code> <code>Decimal</code> \u2713 Python <code>Enum</code> <code>Enum</code> \u2713 Python <code>IPv4Address</code> <code>IPv4Address</code> \u2713 Python <code>IPv4Address</code> <code>IPv4Interface</code> \u2713 Python <code>IPv4Interface</code> <code>IPv4Interface</code> \u2713 Python <code>IPv4Network</code> <code>IPv4Network</code> \u2713 Python <code>IPv6Address</code> <code>IPv6Address</code> \u2713 Python <code>IPv6Address</code> <code>IPv6Interface</code> \u2713 Python <code>IPv6Interface</code> <code>IPv6Interface</code> \u2713 Python <code>IPv6Network</code> <code>IPv6Network</code> \u2713 Python <code>InstanceOf</code> <code>Any</code> \u2713 Python <code>isinstance()</code> check must return <code>True</code>. <code>IntEnum</code> <code>IntEnum</code> \u2713 Python <code>Iterable</code> <code>deque</code> \u2713 Python <code>Iterable</code> <code>frozenset</code> \u2713 Python <code>Iterable</code> <code>list</code> \u2713 Python <code>Iterable</code> <code>set</code> \u2713 Python <code>Iterable</code> <code>tuple</code> \u2713 Python <code>NamedTuple</code> <code>dict</code> \u2713 Python <code>NamedTuple</code> <code>list</code> \u2713 Python <code>NamedTuple</code> <code>namedtuple</code> \u2713 Python <code>NamedTuple</code> <code>tuple</code> \u2713 Python <code>NamedTuple</code> <code>NamedTuple</code> \u2713 Python <code>None</code> <code>None</code> \u2713 Python &amp; JSON <code>Path</code> <code>Path</code> \u2713 Python <code>Pattern</code> <code>bytes</code> \u2713 Python Input must be a valid pattern. <code>Pattern</code> <code>str</code> \u2713 Python &amp; JSON Input must be a valid pattern. <code>Sequence</code> <code>list</code> \u2713 Python <code>Type</code> <code>Type</code> \u2713 Python <code>TypedDict</code> <code>dict</code> \u2713 Python <code>TypedDict</code> <code>Any</code> \u2713 Python <code>UUID</code> <code>UUID</code> \u2713 Python"},{"location":"concepts/dataclasses/","title":"Dataclasses","text":"API Documentation <p><code>pydantic.dataclasses.dataclass</code></p> <p>If you don't want to use Pydantic's <code>BaseModel</code> you can instead get the same data validation on standard dataclasses (introduced in Python 3.7).</p> <pre><code>from datetime import datetime\n\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    signup_ts: datetime = None\n\n\nuser = User(id='42', signup_ts='2032-06-21T12:00')\nprint(user)\n\"\"\"\nUser(id=42, name='John Doe', signup_ts=datetime.datetime(2032, 6, 21, 12, 0))\n\"\"\"\n</code></pre> <p>Note</p> <p>Keep in mind that <code>pydantic.dataclasses.dataclass</code> is not a replacement for <code>pydantic.BaseModel</code>. <code>pydantic.dataclasses.dataclass</code> provides a similar functionality to <code>dataclasses.dataclass</code> with the addition of Pydantic validation. There are cases where subclassing <code>pydantic.BaseModel</code> is the better choice.</p> <p>For more information and discussion see pydantic/pydantic#710.</p> <p>Some differences between Pydantic dataclasses and <code>BaseModel</code> include:</p> <ul> <li>How initialization hooks work</li> <li>JSON dumping</li> </ul> <p>You can use all the standard Pydantic field types. Note, however, that arguments passed to constructor will be copied in order to perform validation and, where necessary coercion.</p> <p>To perform validation or generate a JSON schema on a Pydantic dataclass, you should now wrap the dataclass with a <code>TypeAdapter</code> and make use of its methods.</p> <p>Fields that require a <code>default_factory</code> can be specified by either a <code>pydantic.Field</code> or a <code>dataclasses.field</code>.</p> <pre><code>import dataclasses\nfrom typing import List, Optional\n\nfrom pydantic import Field, TypeAdapter\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    friends: List[int] = dataclasses.field(default_factory=lambda: [0])\n    age: Optional[int] = dataclasses.field(\n        default=None,\n        metadata=dict(title='The age of the user', description='do not lie!'),\n    )\n    height: Optional[int] = Field(None, title='The height in cm', ge=50, le=300)\n\n\nuser = User(id='42')\nprint(TypeAdapter(User).json_schema())\n\"\"\"\n{\n    'properties': {\n        'id': {'title': 'Id', 'type': 'integer'},\n        'name': {'default': 'John Doe', 'title': 'Name', 'type': 'string'},\n        'friends': {\n            'items': {'type': 'integer'},\n            'title': 'Friends',\n            'type': 'array',\n        },\n        'age': {\n            'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n            'default': None,\n            'description': 'do not lie!',\n            'title': 'The age of the user',\n        },\n        'height': {\n            'anyOf': [\n                {'maximum': 300, 'minimum': 50, 'type': 'integer'},\n                {'type': 'null'},\n            ],\n            'default': None,\n            'title': 'The height in cm',\n        },\n    },\n    'required': ['id'],\n    'title': 'User',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <p><code>pydantic.dataclasses.dataclass</code>'s arguments are the same as the standard decorator, except one extra keyword argument <code>config</code> which has the same meaning as model_config.</p> <p>Warning</p> <p>After v1.2, The Mypy plugin must be installed to type check pydantic dataclasses.</p> <p>For more information about combining validators with dataclasses, see dataclass validators.</p>"},{"location":"concepts/dataclasses/#dataclass-config","title":"Dataclass config","text":"<p>If you want to modify the <code>config</code> like you would with a <code>BaseModel</code>, you have two options:</p> <ul> <li>Apply config to the dataclass decorator as a dict</li> <li>Use <code>ConfigDict</code> as the config</li> </ul> <pre><code>from pydantic import ConfigDict\nfrom pydantic.dataclasses import dataclass\n\n\n# Option 1 - use directly a dict\n# Note: `mypy` will still raise typo error\n@dataclass(config=dict(validate_assignment=True))  # (1)!\nclass MyDataclass1:\n    a: int\n\n\n# Option 2 - use `ConfigDict`\n# (same as before at runtime since it's a `TypedDict` but with intellisense)\n@dataclass(config=ConfigDict(validate_assignment=True))\nclass MyDataclass2:\n    a: int\n</code></pre> <ol> <li>You can read more about <code>validate_assignment</code> in API reference.</li> </ol> <p>Note</p> <p>Pydantic dataclasses support <code>extra</code> configuration to <code>ignore</code>, <code>forbid</code>, or <code>allow</code> extra fields passed to the initializer. However, some default behavior of stdlib dataclasses may prevail. For example, any extra fields present on a Pydantic dataclass using <code>extra='allow'</code> are omitted when the dataclass is <code>print</code>ed.</p>"},{"location":"concepts/dataclasses/#nested-dataclasses","title":"Nested dataclasses","text":"<p>Nested dataclasses are supported both in dataclasses and normal models.</p> <pre><code>from pydantic import AnyUrl\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass NavbarButton:\n    href: AnyUrl\n\n\n@dataclass\nclass Navbar:\n    button: NavbarButton\n\n\nnavbar = Navbar(button={'href': 'https://example.com'})\nprint(navbar)\n#&gt; Navbar(button=NavbarButton(href=Url('https://example.com/')))\n</code></pre> <p>When used as fields, dataclasses (Pydantic or vanilla) should use dicts as validation inputs.</p>"},{"location":"concepts/dataclasses/#generic-dataclasses","title":"Generic dataclasses","text":"<p>Pydantic supports generic dataclasses, including those with type variables.</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import TypeAdapter\nfrom pydantic.dataclasses import dataclass\n\nT = TypeVar('T')\n\n\n@dataclass\nclass GenericDataclass(Generic[T]):\n    x: T\n\n\nvalidator = TypeAdapter(GenericDataclass)\n\nassert validator.validate_python({'x': None}).x is None\nassert validator.validate_python({'x': 1}).x == 1\nassert validator.validate_python({'x': 'a'}).x == 'a'\n</code></pre> <p>Note that, if you use the dataclass as a field of a <code>BaseModel</code> or via FastAPI you don't need a <code>TypeAdapter</code>.</p>"},{"location":"concepts/dataclasses/#stdlib-dataclasses-and-pydantic-dataclasses","title":"Stdlib dataclasses and Pydantic dataclasses","text":""},{"location":"concepts/dataclasses/#inherit-from-stdlib-dataclasses","title":"Inherit from stdlib dataclasses","text":"<p>Stdlib dataclasses (nested or not) can also be inherited and Pydantic will automatically validate all the inherited fields.</p> <pre><code>import dataclasses\n\nimport pydantic\n\n\n@dataclasses.dataclass\nclass Z:\n    z: int\n\n\n@dataclasses.dataclass\nclass Y(Z):\n    y: int = 0\n\n\n@pydantic.dataclasses.dataclass\nclass X(Y):\n    x: int = 0\n\n\nfoo = X(x=b'1', y='2', z='3')\nprint(foo)\n#&gt; X(z=3, y=2, x=1)\n\ntry:\n    X(z='pika')\nexcept pydantic.ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for X\n    z\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='pika', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/dataclasses/#use-of-stdlib-dataclasses-with-basemodel","title":"Use of stdlib dataclasses with <code>BaseModel</code>","text":"<p>Bear in mind that stdlib dataclasses (nested or not) are automatically converted into Pydantic dataclasses when mixed with <code>BaseModel</code>! Furthermore the generated Pydantic dataclass will have the exact same configuration (<code>order</code>, <code>frozen</code>, ...) as the original one.</p> <pre><code>import dataclasses\nfrom datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel, ConfigDict, ValidationError\n\n\n@dataclasses.dataclass(frozen=True)\nclass User:\n    name: str\n\n\n@dataclasses.dataclass\nclass File:\n    filename: str\n    last_modification_time: Optional[datetime] = None\n\n\nclass Foo(BaseModel):\n    # Required so that pydantic revalidates the model attributes\n    model_config = ConfigDict(revalidate_instances='always')\n\n    file: File\n    user: Optional[User] = None\n\n\nfile = File(\n    filename=['not', 'a', 'string'],\n    last_modification_time='2020-01-01T00:00',\n)  # nothing is validated as expected\nprint(file)\n\"\"\"\nFile(filename=['not', 'a', 'string'], last_modification_time='2020-01-01T00:00')\n\"\"\"\n\ntry:\n    Foo(file=file)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Foo\n    file.filename\n      Input should be a valid string [type=string_type, input_value=['not', 'a', 'string'], input_type=list]\n    \"\"\"\n\nfoo = Foo(file=File(filename='myfile'), user=User(name='pika'))\ntry:\n    foo.user.name = 'bulbi'\nexcept dataclasses.FrozenInstanceError as e:\n    print(e)\n    #&gt; cannot assign to field 'name'\n</code></pre>"},{"location":"concepts/dataclasses/#use-custom-types","title":"Use custom types","text":"<p>Since stdlib dataclasses are automatically converted to add validation, using custom types may cause some unexpected behavior. In this case you can simply add <code>arbitrary_types_allowed</code> in the config!</p> <pre><code>import dataclasses\n\nfrom pydantic import BaseModel, ConfigDict\nfrom pydantic.errors import PydanticSchemaGenerationError\n\n\nclass ArbitraryType:\n    def __init__(self, value):\n        self.value = value\n\n    def __repr__(self):\n        return f'ArbitraryType(value={self.value!r})'\n\n\n@dataclasses.dataclass\nclass DC:\n    a: ArbitraryType\n    b: str\n\n\n# valid as it is a builtin dataclass without validation\nmy_dc = DC(a=ArbitraryType(value=3), b='qwe')\n\ntry:\n\n    class Model(BaseModel):\n        dc: DC\n        other: str\n\n    # invalid as it is now a pydantic dataclass\n    Model(dc=my_dc, other='other')\nexcept PydanticSchemaGenerationError as e:\n    print(e.message)\n    \"\"\"\n    Unable to generate pydantic-core schema for &lt;class '__main__.ArbitraryType'&gt;. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n\n    If you got this error by calling handler(&lt;some type&gt;) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(&lt;some type&gt;)` since we do not call `__get_pydantic_core_schema__` on `&lt;some type&gt;` otherwise to avoid infinite recursion.\n    \"\"\"\n\n\nclass Model(BaseModel):\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n    dc: DC\n    other: str\n\n\nm = Model(dc=my_dc, other='other')\nprint(repr(m))\n#&gt; Model(dc=DC(a=ArbitraryType(value=3), b='qwe'), other='other')\n</code></pre>"},{"location":"concepts/dataclasses/#checking-if-a-dataclass-is-a-pydantic-dataclass","title":"Checking if a dataclass is a pydantic dataclass","text":"<p>Pydantic dataclasses are still considered dataclasses, so using <code>dataclasses.is_dataclass</code> will return <code>True</code>. To check if a type is specifically a pydantic dataclass you can use <code>pydantic.dataclasses.is_pydantic_dataclass</code>.</p> <pre><code>import dataclasses\n\nimport pydantic\n\n\n@dataclasses.dataclass\nclass StdLibDataclass:\n    id: int\n\n\nPydanticDataclass = pydantic.dataclasses.dataclass(StdLibDataclass)\n\nprint(dataclasses.is_dataclass(StdLibDataclass))\n#&gt; True\nprint(pydantic.dataclasses.is_pydantic_dataclass(StdLibDataclass))\n#&gt; False\n\nprint(dataclasses.is_dataclass(PydanticDataclass))\n#&gt; True\nprint(pydantic.dataclasses.is_pydantic_dataclass(PydanticDataclass))\n#&gt; True\n</code></pre>"},{"location":"concepts/dataclasses/#initialization-hooks","title":"Initialization hooks","text":"<p>When you initialize a dataclass, it is possible to execute code before or after validation with the help of the <code>@model_validator</code> decorator <code>mode</code> parameter.</p> <pre><code>from typing import Any, Dict\n\nfrom typing_extensions import Self\n\nfrom pydantic import model_validator\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass Birth:\n    year: int\n    month: int\n    day: int\n\n\n@dataclass\nclass User:\n    birth: Birth\n\n    @model_validator(mode='before')\n    @classmethod\n    def pre_root(cls, values: Dict[str, Any]) -&gt; Dict[str, Any]:\n        print(f'First: {values}')\n        \"\"\"\n        First: ArgsKwargs((), {'birth': {'year': 1995, 'month': 3, 'day': 2}})\n        \"\"\"\n        return values\n\n    @model_validator(mode='after')\n    def post_root(self) -&gt; Self:\n        print(f'Third: {self}')\n        #&gt; Third: User(birth=Birth(year=1995, month=3, day=2))\n        return self\n\n    def __post_init__(self):\n        print(f'Second: {self.birth}')\n        #&gt; Second: Birth(year=1995, month=3, day=2)\n\n\nuser = User(**{'birth': {'year': 1995, 'month': 3, 'day': 2}})\n</code></pre> <p>The <code>__post_init__</code> in Pydantic dataclasses is called in the middle of validators. Here is the order:</p> <ul> <li><code>model_validator(mode='before')</code></li> <li><code>field_validator(mode='before')</code></li> <li><code>field_validator(mode='after')</code></li> <li>Inner validators. e.g. validation for types like <code>int</code>, <code>str</code>, ...</li> <li><code>__post_init__</code>.</li> <li><code>model_validator(mode='after')</code></li> </ul> <pre><code>from dataclasses import InitVar\nfrom pathlib import Path\nfrom typing import Optional\n\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass PathData:\n    path: Path\n    base_path: InitVar[Optional[Path]]\n\n    def __post_init__(self, base_path):\n        print(f'Received path={self.path!r}, base_path={base_path!r}')\n        #&gt; Received path=PosixPath('world'), base_path=PosixPath('/hello')\n        if base_path is not None:\n            self.path = base_path / self.path\n\n\npath_data = PathData('world', base_path='/hello')\n# Received path='world', base_path='/hello'\nassert path_data.path == Path('/hello/world')\n</code></pre>"},{"location":"concepts/dataclasses/#difference-with-stdlib-dataclasses","title":"Difference with stdlib dataclasses","text":"<p>Note that the <code>dataclasses.dataclass</code> from Python stdlib implements only the <code>__post_init__</code> method since it doesn't run a validation step.</p>"},{"location":"concepts/dataclasses/#json-dumping","title":"JSON dumping","text":"<p>Pydantic dataclasses do not feature a <code>.model_dump_json()</code> function. To dump them as JSON, you will need to make use of the RootModel as follows:</p> <pre><code>import dataclasses\nfrom typing import List\n\nfrom pydantic import RootModel\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass User:\n    id: int\n    name: str = 'John Doe'\n    friends: List[int] = dataclasses.field(default_factory=lambda: [0])\n\n\nuser = User(id='42')\nprint(RootModel[User](User(id='42')).model_dump_json(indent=4))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"id\": 42,\n  \"name\": \"John Doe\",\n  \"friends\": [\n    0\n  ]\n}\n</code></pre>"},{"location":"concepts/experimental/","title":"Experimental Features","text":"<p>In this section you will find documentation for new, experimental features in Pydantic. These features are subject to change or removal, and we are looking for feedback and suggestions before making them a permanent part of Pydantic.</p> <p>See our Version Policy for more information on experimental features.</p>"},{"location":"concepts/experimental/#feedback","title":"Feedback","text":"<p>We welcome feedback on experimental features! Please open an issue on the Pydantic GitHub repository to share your thoughts, requests, or suggestions.</p> <p>We also encourage you to read through existing feedback and add your thoughts to existing issues.</p>"},{"location":"concepts/experimental/#warnings-on-import","title":"Warnings on Import","text":"<p>When you import an experimental feature from the <code>experimental</code> module, you'll see a warning message that the feature is experimental. You can disable this warning with the following:</p> <pre><code>import warnings\n\nfrom pydantic import PydanticExperimentalWarning\n\nwarnings.filterwarnings('ignore', category=PydanticExperimentalWarning)\n</code></pre>"},{"location":"concepts/experimental/#pipeline-api","title":"Pipeline API","text":"<p>Pydantic v2.8.0 introduced an experimental \"pipeline\" API that allows composing of parsing (validation), constraints and transformations in a more type-safe manner than existing APIs. This API is subject to change or removal, we are looking for feedback and suggestions before making it a permanent part of Pydantic.</p> API Documentation <p><code>pydantic.experimental.pipeline</code></p> <p>Generally, the pipeline API is used to define a sequence of steps to apply to incoming data during validation. The pipeline API is designed to be more type-safe and composable than the existing Pydantic API.</p> <p>Each step in the pipeline can be:</p> <ul> <li>A validation step that runs pydantic validation on the provided type</li> <li>A transformation step that modifies the data</li> <li>A constraint step that checks the data against a condition</li> <li>A predicate step that checks the data against a condition and raises an error if it returns <code>False</code></li> </ul> <p>Note that the following example attempts to be exhaustive at the cost of complexity: if you find yourself writing this many transformations in type annotations you may want to consider having a <code>UserIn</code> and <code>UserOut</code> model (example below) or similar where you make the transformations via idomatic plain Python code. These APIs are meant for situations where the code savings are significant and the added complexity is relatively small.</p> <pre><code>from __future__ import annotations\n\nfrom datetime import datetime\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel\nfrom pydantic.experimental.pipeline import validate_as, validate_as_deferred\n\n\nclass User(BaseModel):\n    name: Annotated[str, validate_as(str).str_lower()]  # (1)!\n    age: Annotated[int, validate_as(int).gt(0)]  # (2)!\n    username: Annotated[str, validate_as(str).str_pattern(r'[a-z]+')]  # (3)!\n    password: Annotated[\n        str,\n        validate_as(str)\n        .transform(str.lower)\n        .predicate(lambda x: x != 'password'),  # (4)!\n    ]\n    favorite_number: Annotated[  # (5)!\n        int,\n        (validate_as(int) | validate_as(str).str_strip().validate_as(int)).gt(\n            0\n        ),\n    ]\n    friends: Annotated[list[User], validate_as(...).len(0, 100)]  # (6)!\n    family: Annotated[  # (7)!\n        list[User],\n        validate_as_deferred(lambda: list[User]).transform(lambda x: x[1:]),\n    ]\n    bio: Annotated[\n        datetime,\n        validate_as(int)\n        .transform(lambda x: x / 1_000_000)\n        .validate_as(...),  # (8)!\n    ]\n</code></pre> <ol> <li>Lowercase a string.</li> <li>Constrain an integer to be greater than zero.</li> <li>Constrain a string to match a regex pattern.</li> <li>You can also use the lower level transform, constrain and predicate methods.</li> <li>Use the <code>|</code> or <code>&amp;</code> operators to combine steps (like a logical OR or AND).</li> <li>Calling <code>validate_as(...)</code> with <code>Ellipsis</code>, <code>...</code> as the first positional argument implies <code>validate_as(&lt;field type&gt;)</code>. Use <code>validate_as(Any)</code> to accept any type.</li> <li>For recursive types you can use <code>validate_as_deferred</code> to reference the type itself before it's defined.</li> <li>You can call <code>validate_as()</code> before or after other steps to do pre or post processing.</li> </ol>"},{"location":"concepts/experimental/#mapping-from-beforevalidator-aftervalidator-and-wrapvalidator","title":"Mapping from <code>BeforeValidator</code>, <code>AfterValidator</code> and <code>WrapValidator</code>","text":"<p>The <code>validate_as</code> method is a more type-safe way to define <code>BeforeValidator</code>, <code>AfterValidator</code> and <code>WrapValidator</code>:</p> Python 3.8 and abovePython 3.9 and above <pre><code>from typing_extensions import Annotated\n\nfrom pydantic.experimental.pipeline import transform, validate_as\n\n# BeforeValidator\nAnnotated[int, validate_as(str).str_strip().validate_as(...)]  # (1)!\n# AfterValidator\nAnnotated[int, transform(lambda x: x * 2)]  # (2)!\n# WrapValidator\nAnnotated[\n    int,\n    validate_as(str)\n    .str_strip()\n    .validate_as(...)\n    .transform(lambda x: x * 2),  # (3)!\n]\n</code></pre> <ol> <li>Strip whitespace from a string before parsing it as an integer.</li> <li>Multiply an integer by 2 after parsing it.</li> <li>Strip whitespace from a string, validate it as an integer, then multiply it by 2.</li> </ol> <pre><code>from typing import Annotated\n\nfrom pydantic.experimental.pipeline import transform, validate_as\n\n# BeforeValidator\nAnnotated[int, validate_as(str).str_strip().validate_as(...)]  # (1)!\n# AfterValidator\nAnnotated[int, transform(lambda x: x * 2)]  # (2)!\n# WrapValidator\nAnnotated[\n    int,\n    validate_as(str)\n    .str_strip()\n    .validate_as(...)\n    .transform(lambda x: x * 2),  # (3)!\n]\n</code></pre> <ol> <li>Strip whitespace from a string before parsing it as an integer.</li> <li>Multiply an integer by 2 after parsing it.</li> <li>Strip whitespace from a string, validate it as an integer, then multiply it by 2.</li> </ol>"},{"location":"concepts/experimental/#alternative-patterns","title":"Alternative patterns","text":"<p>There are many alternative patterns to use depending on the scenario. Just as an example, consider the <code>UserIn</code> and <code>UserOut</code> pattern mentioned above:</p> <pre><code>from __future__ import annotations\n\nfrom pydantic import BaseModel\n\n\nclass UserIn(BaseModel):\n    favorite_number: int | str\n\n\nclass UserOut(BaseModel):\n    favorite_number: int\n\n\ndef my_api(user: UserIn) -&gt; UserOut:\n    favorite_number = user.favorite_number\n    if isinstance(favorite_number, str):\n        favorite_number = int(user.favorite_number.strip())\n\n    return UserOut(favorite_number=favorite_number)\n\n\nassert my_api(UserIn(favorite_number=' 1 ')).favorite_number == 1\n</code></pre> <p>This example uses plain idiomatic Python code that may be easier to understand, type-check, etc. than the examples above. The approach you choose should really depend on your use case. You will have to compare verbosity, performance, ease of returning meaningful errors to your users, etc. to choose the right pattern. Just be mindful of abusing advanced patterns like the pipeline API just because you can.</p>"},{"location":"concepts/fields/","title":"Fields","text":"API Documentation <p><code>pydantic.fields.Field</code></p> <p>The <code>Field</code> function is used to customize and add metadata to fields of models.</p>"},{"location":"concepts/fields/#default-values","title":"Default values","text":"<p>The <code>default</code> parameter is used to define a default value for a field.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(default='John Doe')\n\n\nuser = User()\nprint(user)\n#&gt; name='John Doe'\n</code></pre> <p>You can also use <code>default_factory</code> to define a callable that will be called to generate a default value.</p> <pre><code>from uuid import uuid4\n\nfrom pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    id: str = Field(default_factory=lambda: uuid4().hex)\n</code></pre> <p>Info</p> <p>The <code>default</code> and <code>default_factory</code> parameters are mutually exclusive.</p> <p>Note</p> <p>If you use <code>typing.Optional</code>, it doesn't mean that the field has a default value of <code>None</code>!</p>"},{"location":"concepts/fields/#using-annotated","title":"Using <code>Annotated</code>","text":"<p>The <code>Field</code> function can also be used together with <code>Annotated</code>.</p> <pre><code>from uuid import uuid4\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    id: Annotated[str, Field(default_factory=lambda: uuid4().hex)]\n</code></pre> <p>Note</p> <p>Defaults can be set outside <code>Annotated</code> as the assigned value or with <code>Field.default_factory</code> inside <code>Annotated</code>. The <code>Field.default</code> argument is not supported inside <code>Annotated</code>.</p>"},{"location":"concepts/fields/#field-aliases","title":"Field aliases","text":"<p>For validation and serialization, you can define an alias for a field.</p> <p>There are three ways to define an alias:</p> <ul> <li><code>Field(..., alias='foo')</code></li> <li><code>Field(..., validation_alias='foo')</code></li> <li><code>Field(..., serialization_alias='foo')</code></li> </ul> <p>The <code>alias</code> parameter is used for both validation and serialization. If you want to use different aliases for validation and serialization respectively, you can use the<code>validation_alias</code> and <code>serialization_alias</code> parameters, which will apply only in their respective use cases.</p> <p>Here is an example of using the <code>alias</code> parameter:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(..., alias='username')\n\n\nuser = User(username='johndoe')  # (1)!\nprint(user)\n#&gt; name='johndoe'\nprint(user.model_dump(by_alias=True))  # (2)!\n#&gt; {'username': 'johndoe'}\n</code></pre> <ol> <li>The alias <code>'username'</code> is used for instance creation and validation.</li> <li> <p>We are using <code>model_dump</code> to convert the model into a serializable format.</p> <p>You can see more details about <code>model_dump</code> in the API reference.</p> <p>Note that the <code>by_alias</code> keyword argument defaults to <code>False</code>, and must be specified explicitly to dump models using the field (serialization) aliases.</p> <p>When <code>by_alias=True</code>, the alias <code>'username'</code> is also used during serialization.</p> </li> </ol> <p>If you want to use an alias only for validation, you can use the <code>validation_alias</code> parameter:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(..., validation_alias='username')\n\n\nuser = User(username='johndoe')  # (1)!\nprint(user)\n#&gt; name='johndoe'\nprint(user.model_dump(by_alias=True))  # (2)!\n#&gt; {'name': 'johndoe'}\n</code></pre> <ol> <li>The validation alias <code>'username'</code> is used during validation.</li> <li>The field name <code>'name'</code> is used during serialization.</li> </ol> <p>If you only want to define an alias for serialization, you can use the <code>serialization_alias</code> parameter:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(..., serialization_alias='username')\n\n\nuser = User(name='johndoe')  # (1)!\nprint(user)\n#&gt; name='johndoe'\nprint(user.model_dump(by_alias=True))  # (2)!\n#&gt; {'username': 'johndoe'}\n</code></pre> <ol> <li>The field name <code>'name'</code> is used for validation.</li> <li>The serialization alias <code>'username'</code> is used for serialization.</li> </ol> <p>Alias precedence and priority</p> <p>In case you use <code>alias</code> together with <code>validation_alias</code> or <code>serialization_alias</code> at the same time, the <code>validation_alias</code> will have priority over <code>alias</code> for validation, and <code>serialization_alias</code> will have priority over <code>alias</code> for serialization.</p> <p>If you use an <code>alias_generator</code> in the Model Config, you can control the order of precedence for specified field vs generated aliases via the <code>alias_priority</code> setting. You can read more about alias precedence here.</p> VSCode and Pyright users <p>In VSCode, if you use the Pylance extension, you won't see a warning when instantiating a model using a field's alias:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(..., alias='username')\n\n\nuser = User(username='johndoe')  # (1)!\n</code></pre> <ol> <li>VSCode will NOT show a warning here.</li> </ol> <p>When the <code>'alias'</code> keyword argument is specified, even if you set <code>populate_by_name</code> to <code>True</code> in the Model Config, VSCode will show a warning when instantiating a model using the field name (though it will work at runtime) \u2014 in this case, <code>'name'</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(populate_by_name=True)\n\n    name: str = Field(..., alias='username')\n\n\nuser = User(name='johndoe')  # (1)!\n</code></pre> <ol> <li>VSCode will show a warning here.</li> </ol> <p>To \"trick\" VSCode into preferring the field name, you can use the <code>str</code> function to wrap the alias value. With this approach, though, a warning is shown when instantiating a model using the alias for the field:</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(populate_by_name=True)\n\n    name: str = Field(..., alias=str('username'))  # noqa: UP018\n\n\nuser = User(name='johndoe')  # (1)!\nuser = User(username='johndoe')  # (2)!\n</code></pre> <ol> <li>Now VSCode will NOT show a warning</li> <li>VSCode will show a warning here, though</li> </ol> <p>This is discussed in more detail in this issue.</p> <p>For more information on alias usage, see the Alias concepts page.</p>"},{"location":"concepts/fields/#validation-alias","title":"Validation Alias","text":"<p>Even though Pydantic treats <code>alias</code> and <code>validation_alias</code> the same when creating model instances, VSCode will not use the <code>validation_alias</code> in the class initializer signature. If you want VSCode to use the <code>validation_alias</code> in the class initializer, you can instead specify both an <code>alias</code> and <code>serialization_alias</code>, as the <code>serialization_alias</code> will override the <code>alias</code> during serialization:</p> <p><pre><code>from pydantic import BaseModel, Field\n\n\nclass MyModel(BaseModel):\n    my_field: int = Field(..., validation_alias='myValidationAlias')\n</code></pre> with: <pre><code>from pydantic import BaseModel, Field\n\n\nclass MyModel(BaseModel):\n    my_field: int = Field(\n        ...,\n        alias='myValidationAlias',\n        serialization_alias='my_serialization_alias',\n    )\n\n\nm = MyModel(myValidationAlias=1)\nprint(m.model_dump(by_alias=True))\n#&gt; {'my_serialization_alias': 1}\n</code></pre></p> <p>All of the above will likely also apply to other tools that respect the <code>@typing.dataclass_transform</code> decorator, such as Pyright.</p>"},{"location":"concepts/fields/#numeric-constraints","title":"Numeric Constraints","text":"<p>There are some keyword arguments that can be used to constrain numeric values:</p> <ul> <li><code>gt</code> - greater than</li> <li><code>lt</code> - less than</li> <li><code>ge</code> - greater than or equal to</li> <li><code>le</code> - less than or equal to</li> <li><code>multiple_of</code> - a multiple of the given number</li> <li><code>allow_inf_nan</code> - allow <code>'inf'</code>, <code>'-inf'</code>, <code>'nan'</code> values</li> </ul> <p>Here's an example:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    positive: int = Field(gt=0)\n    non_negative: int = Field(ge=0)\n    negative: int = Field(lt=0)\n    non_positive: int = Field(le=0)\n    even: int = Field(multiple_of=2)\n    love_for_pydantic: float = Field(allow_inf_nan=True)\n\n\nfoo = Foo(\n    positive=1,\n    non_negative=0,\n    negative=-1,\n    non_positive=0,\n    even=2,\n    love_for_pydantic=float('inf'),\n)\nprint(foo)\n\"\"\"\npositive=1 non_negative=0 negative=-1 non_positive=0 even=2 love_for_pydantic=inf\n\"\"\"\n</code></pre> JSON Schema <p>In the generated JSON schema:</p> <ul> <li><code>gt</code> and <code>lt</code> constraints will be translated to <code>exclusiveMinimum</code> and <code>exclusiveMaximum</code>.</li> <li><code>ge</code> and <code>le</code> constraints will be translated to <code>minimum</code> and <code>maximum</code>.</li> <li><code>multiple_of</code> constraint will be translated to <code>multipleOf</code>.</li> </ul> <p>The above snippet will generate the following JSON Schema:</p> <pre><code>{\n  \"title\": \"Foo\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"positive\": {\n      \"title\": \"Positive\",\n      \"type\": \"integer\",\n      \"exclusiveMinimum\": 0\n    },\n    \"non_negative\": {\n      \"title\": \"Non Negative\",\n      \"type\": \"integer\",\n      \"minimum\": 0\n    },\n    \"negative\": {\n      \"title\": \"Negative\",\n      \"type\": \"integer\",\n      \"exclusiveMaximum\": 0\n    },\n    \"non_positive\": {\n      \"title\": \"Non Positive\",\n      \"type\": \"integer\",\n      \"maximum\": 0\n    },\n    \"even\": {\n      \"title\": \"Even\",\n      \"type\": \"integer\",\n      \"multipleOf\": 2\n    },\n    \"love_for_pydantic\": {\n      \"title\": \"Love For Pydantic\",\n      \"type\": \"number\"\n    }\n  },\n  \"required\": [\n    \"positive\",\n    \"non_negative\",\n    \"negative\",\n    \"non_positive\",\n    \"even\",\n    \"love_for_pydantic\"\n  ]\n}\n</code></pre> <p>See the JSON Schema Draft 2020-12 for more details.</p> <p>Constraints on compound types</p> <p>In case you use field constraints with compound types, an error can happen in some cases. To avoid potential issues, you can use <code>Annotated</code>:</p> <pre><code>from typing import Optional\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    positive: Optional[Annotated[int, Field(gt=0)]]\n    # Can error in some cases, not recommended:\n    non_negative: Optional[int] = Field(ge=0)\n</code></pre>"},{"location":"concepts/fields/#string-constraints","title":"String Constraints","text":"API Documentation <p><code>pydantic.types.StringConstraints</code></p> <p>There are fields that can be used to constrain strings:</p> <ul> <li><code>min_length</code>: Minimum length of the string.</li> <li><code>max_length</code>: Maximum length of the string.</li> <li><code>pattern</code>: A regular expression that the string must match.</li> </ul> <p>Here's an example:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    short: str = Field(min_length=3)\n    long: str = Field(max_length=10)\n    regex: str = Field(pattern=r'^\\d*$')  # (1)!\n\n\nfoo = Foo(short='foo', long='foobarbaz', regex='123')\nprint(foo)\n#&gt; short='foo' long='foobarbaz' regex='123'\n</code></pre> <ol> <li>Only digits are allowed.</li> </ol> JSON Schema <p>In the generated JSON schema:</p> <ul> <li><code>min_length</code> constraint will be translated to <code>minLength</code>.</li> <li><code>max_length</code> constraint will be translated to <code>maxLength</code>.</li> <li><code>pattern</code> constraint will be translated to <code>pattern</code>.</li> </ul> <p>The above snippet will generate the following JSON Schema:</p> <pre><code>{\n  \"title\": \"Foo\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"short\": {\n      \"title\": \"Short\",\n      \"type\": \"string\",\n      \"minLength\": 3\n    },\n    \"long\": {\n      \"title\": \"Long\",\n      \"type\": \"string\",\n      \"maxLength\": 10\n    },\n    \"regex\": {\n      \"title\": \"Regex\",\n      \"type\": \"string\",\n      \"pattern\": \"^\\\\d*$\"\n    }\n  },\n  \"required\": [\n    \"short\",\n    \"long\",\n    \"regex\"\n  ]\n}\n</code></pre>"},{"location":"concepts/fields/#decimal-constraints","title":"Decimal Constraints","text":"<p>There are fields that can be used to constrain decimals:</p> <ul> <li><code>max_digits</code>: Maximum number of digits within the <code>Decimal</code>. It does not include a zero before the decimal point or   trailing decimal zeroes.</li> <li><code>decimal_places</code>: Maximum number of decimal places allowed. It does not include trailing decimal zeroes.</li> </ul> <p>Here's an example:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    precise: Decimal = Field(max_digits=5, decimal_places=2)\n\n\nfoo = Foo(precise=Decimal('123.45'))\nprint(foo)\n#&gt; precise=Decimal('123.45')\n</code></pre>"},{"location":"concepts/fields/#dataclass-constraints","title":"Dataclass Constraints","text":"<p>There are fields that can be used to constrain dataclasses:</p> <ul> <li><code>init</code>: Whether the field should be included in the <code>__init__</code> of the dataclass.</li> <li><code>init_var</code>: Whether the field should be seen as an init-only field in the dataclass.</li> <li><code>kw_only</code>: Whether the field should be a keyword-only argument in the constructor of the dataclass.</li> </ul> <p>Here's an example:</p> <pre><code>from pydantic import BaseModel, Field\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass Foo:\n    bar: str\n    baz: str = Field(init_var=True)\n    qux: str = Field(kw_only=True)\n\n\nclass Model(BaseModel):\n    foo: Foo\n\n\nmodel = Model(foo=Foo('bar', baz='baz', qux='qux'))\nprint(model.model_dump())  # (1)!\n#&gt; {'foo': {'bar': 'bar', 'qux': 'qux'}}\n</code></pre> <ol> <li>The <code>baz</code> field is not included in the <code>model_dump()</code> output, since it is an init-only field.</li> </ol>"},{"location":"concepts/fields/#validate-default-values","title":"Validate Default Values","text":"<p>The parameter <code>validate_default</code> can be used to control whether the default value of the field should be validated.</p> <p>By default, the default value of the field is not validated.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass User(BaseModel):\n    age: int = Field(default='twelve', validate_default=True)\n\n\ntry:\n    user = User()\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for User\n    age\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='twelve', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/fields/#field-representation","title":"Field Representation","text":"<p>The parameter <code>repr</code> can be used to control whether the field should be included in the string representation of the model.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(repr=True)  # (1)!\n    age: int = Field(repr=False)\n\n\nuser = User(name='John', age=42)\nprint(user)\n#&gt; name='John'\n</code></pre> <ol> <li>This is the default value.</li> </ol>"},{"location":"concepts/fields/#discriminator","title":"Discriminator","text":"<p>The parameter <code>discriminator</code> can be used to control the field that will be used to discriminate between different models in a union. It takes either the name of a field or a <code>Discriminator</code> instance. The <code>Discriminator</code> approach can be useful when the discriminator fields aren't the same for all the models in the <code>Union</code>.</p> <p>The following example shows how to use <code>discriminator</code> with a field name:</p> Python 3.8 and abovePython 3.10 and above <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    age: int\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    age: int\n\n\nclass Model(BaseModel):\n    pet: Union[Cat, Dog] = Field(discriminator='pet_type')\n\n\nprint(Model.model_validate({'pet': {'pet_type': 'cat', 'age': 12}}))  # (1)!\n#&gt; pet=Cat(pet_type='cat', age=12)\n</code></pre> <ol> <li>See more about Validating data in the Models page.</li> </ol> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, Field\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    age: int\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    age: int\n\n\nclass Model(BaseModel):\n    pet: Cat | Dog = Field(discriminator='pet_type')\n\n\nprint(Model.model_validate({'pet': {'pet_type': 'cat', 'age': 12}}))  # (1)!\n#&gt; pet=Cat(pet_type='cat', age=12)\n</code></pre> <ol> <li>See more about Validating data in the Models page.</li> </ol> <p>The following example shows how to use the <code>discriminator</code> keyword argument with a <code>Discriminator</code> instance:</p> <pre><code>from typing import Literal, Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Discriminator, Field, Tag\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    age: int\n\n\nclass Dog(BaseModel):\n    pet_kind: Literal['dog']\n    age: int\n\n\ndef pet_discriminator(v):\n    if isinstance(v, dict):\n        return v.get('pet_type', v.get('pet_kind'))\n    return getattr(v, 'pet_type', getattr(v, 'pet_kind', None))\n\n\nclass Model(BaseModel):\n    pet: Union[Annotated[Cat, Tag('cat')], Annotated[Dog, Tag('dog')]] = Field(\n        discriminator=Discriminator(pet_discriminator)\n    )\n\n\nprint(repr(Model.model_validate({'pet': {'pet_type': 'cat', 'age': 12}})))\n#&gt; Model(pet=Cat(pet_type='cat', age=12))\n\nprint(repr(Model.model_validate({'pet': {'pet_kind': 'dog', 'age': 12}})))\n#&gt; Model(pet=Dog(pet_kind='dog', age=12))\n</code></pre> <p>You can also take advantage of <code>Annotated</code> to define your discriminated unions. See the Discriminated Unions docs for more details.</p>"},{"location":"concepts/fields/#strict-mode","title":"Strict Mode","text":"<p>The <code>strict</code> parameter on a <code>Field</code> specifies whether the field should be validated in \"strict mode\". In strict mode, Pydantic throws an error during validation instead of coercing data on the field where <code>strict=True</code>.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str = Field(strict=True)  # (1)!\n    age: int = Field(strict=False)\n\n\nuser = User(name='John', age='42')  # (2)!\nprint(user)\n#&gt; name='John' age=42\n</code></pre> <ol> <li>This is the default value.</li> <li>The <code>age</code> field is not validated in the strict mode. Therefore, it can be assigned a string.</li> </ol> <p>See Strict Mode for more details.</p> <p>See Conversion Table for more details on how Pydantic converts data in both strict and lax modes.</p>"},{"location":"concepts/fields/#immutability","title":"Immutability","text":"<p>The parameter <code>frozen</code> is used to emulate the frozen dataclass behaviour. It is used to prevent the field from being assigned a new value after the model is created (immutability).</p> <p>See the frozen dataclass documentation for more details.</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass User(BaseModel):\n    name: str = Field(frozen=True)\n    age: int\n\n\nuser = User(name='John', age=42)\n\ntry:\n    user.name = 'Jane'  # (1)!\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for User\n    name\n      Field is frozen [type=frozen_field, input_value='Jane', input_type=str]\n    \"\"\"\n</code></pre> <ol> <li>Since <code>name</code> field is frozen, the assignment is not allowed.</li> </ol>"},{"location":"concepts/fields/#exclude","title":"Exclude","text":"<p>The <code>exclude</code> parameter can be used to control which fields should be excluded from the model when exporting the model.</p> <p>See the following example:</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    name: str\n    age: int = Field(exclude=True)\n\n\nuser = User(name='John', age=42)\nprint(user.model_dump())  # (1)!\n#&gt; {'name': 'John'}\n</code></pre> <ol> <li>The <code>age</code> field is not included in the <code>model_dump()</code> output, since it is excluded.</li> </ol> <p>See the Serialization section for more details.</p>"},{"location":"concepts/fields/#deprecated-fields","title":"Deprecated fields","text":"<p>The <code>deprecated</code> parameter can be used to mark a field as being deprecated. Doing so will result in:</p> <ul> <li>a runtime deprecation warning emitted when accessing the field.</li> <li><code>\"deprecated\": true</code> being set in the generated JSON schema.</li> </ul> <p>You can set the <code>deprecated</code> parameter as one of:</p> <ul> <li>A string, which will be used as the deprecation message.</li> <li>An instance of the <code>warnings.deprecated</code> decorator (or the <code>typing_extensions</code> backport).</li> <li>A boolean, which will be used to mark the field as deprecated with a default <code>'deprecated'</code> deprecation message.</li> </ul>"},{"location":"concepts/fields/#deprecated-as-a-string","title":"<code>deprecated</code> as a string","text":"<pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\n\nclass Model(BaseModel):\n    deprecated_field: Annotated[int, Field(deprecated='This is deprecated')]\n\n\nprint(Model.model_json_schema()['properties']['deprecated_field'])\n#&gt; {'deprecated': True, 'title': 'Deprecated Field', 'type': 'integer'}\n</code></pre>"},{"location":"concepts/fields/#deprecated-via-the-warningsdeprecated-decorator","title":"<code>deprecated</code> via the <code>warnings.deprecated</code> decorator","text":"<p>Note</p> <p>You can only use the <code>deprecated</code> decorator in this way if you have <code>typing_extensions</code> &gt;= 4.9.0 installed.</p> <pre><code>import importlib.metadata\n\nfrom packaging.version import Version\nfrom typing_extensions import Annotated, deprecated\n\nfrom pydantic import BaseModel, Field\n\nif Version(importlib.metadata.version('typing_extensions')) &gt;= Version('4.9'):\n\n    class Model(BaseModel):\n        deprecated_field: Annotated[int, deprecated('This is deprecated')]\n\n        # Or explicitly using `Field`:\n        alt_form: Annotated[\n            int, Field(deprecated=deprecated('This is deprecated'))\n        ]\n</code></pre>"},{"location":"concepts/fields/#deprecated-as-a-boolean","title":"<code>deprecated</code> as a boolean","text":"<pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\n\nclass Model(BaseModel):\n    deprecated_field: Annotated[int, Field(deprecated=True)]\n\n\nprint(Model.model_json_schema()['properties']['deprecated_field'])\n#&gt; {'deprecated': True, 'title': 'Deprecated Field', 'type': 'integer'}\n</code></pre> <p>Support for <code>category</code> and <code>stacklevel</code></p> <p>The current implementation of this feature does not take into account the <code>category</code> and <code>stacklevel</code> arguments to the <code>deprecated</code> decorator. This might land in a future version of Pydantic.</p> <p>Accessing a deprecated field in validators</p> <p>When accessing a deprecated field inside a validator, the deprecation warning will be emitted. You can use <code>catch_warnings</code> to explicitly ignore it:</p> <pre><code>import warnings\n\nfrom typing_extensions import Self\n\nfrom pydantic import BaseModel, Field, model_validator\n\n\nclass Model(BaseModel):\n    deprecated_field: int = Field(deprecated='This is deprecated')\n\n    @model_validator(mode='after')\n    def validate_model(self) -&gt; Self:\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore', DeprecationWarning)\n            self.deprecated_field = self.deprecated_field * 2\n</code></pre>"},{"location":"concepts/fields/#customizing-json-schema","title":"Customizing JSON Schema","text":"<p>Some field parameters are used exclusively to customize the generated JSON schema. The parameters in question are:</p> <ul> <li><code>title</code></li> <li><code>description</code></li> <li><code>examples</code></li> <li><code>json_schema_extra</code></li> </ul> <p>Read more about JSON schema customization / modification with fields in the Customizing JSON Schema section of the JSON schema docs.</p>"},{"location":"concepts/fields/#the-computed_field-decorator","title":"The <code>computed_field</code> decorator","text":"API Documentation <p><code>computed_field</code></p> <p>The <code>computed_field</code> decorator can be used to include <code>property</code> or <code>cached_property</code> attributes when serializing a model or dataclass. The property will also be taken into account in the JSON Schema.</p> <p>Note</p> <p>Properties can be useful for fields that are computed from other fields, or for fields that are expensive to be computed (and thus, are cached if using <code>cached_property</code>).</p> <p>However, note that Pydantic will not perform any additional logic on the wrapped property (validation, cache invalidation, etc.).</p> <p>Here's an example:</p> <pre><code>from pydantic import BaseModel, computed_field\n\n\nclass Box(BaseModel):\n    width: float\n    height: float\n    depth: float\n\n    @computed_field\n    @property  # (1)!\n    def volume(self) -&gt; float:\n        return self.width * self.height * self.depth\n\n\nb = Box(width=1, height=2, depth=3)\nprint(b.model_dump())\n#&gt; {'width': 1.0, 'height': 2.0, 'depth': 3.0, 'volume': 6.0}\n</code></pre> <ol> <li>If not specified, <code>computed_field</code> will implicitly convert the method    to a <code>property</code>. However, it is preferable to explicitly use the <code>@property</code> decorator    for type checking purposes.</li> </ol> <p>As with regular fields, computed fields can be marked as being deprecated:</p> <pre><code>from typing_extensions import deprecated\n\nfrom pydantic import BaseModel, computed_field\n\n\nclass Box(BaseModel):\n    width: float\n    height: float\n    depth: float\n\n    @computed_field\n    @property\n    @deprecated(\"'volume' is deprecated\")\n    def volume(self) -&gt; float:\n        return self.width * self.height * self.depth\n</code></pre>"},{"location":"concepts/json/","title":"JSON","text":"<p>\ud83d\udea7 Work in Progress</p> <p>This page is a work in progress.</p>"},{"location":"concepts/json/#json","title":"JSON","text":""},{"location":"concepts/json/#json-parsing","title":"Json Parsing","text":"API Documentation <p><code>pydantic.main.BaseModel.model_validate_json</code> <code>pydantic.type_adapter.TypeAdapter.validate_json</code> <code>pydantic_core.from_json</code></p> <p>Pydantic provides builtin JSON parsing, which helps achieve:</p> <ul> <li>Significant performance improvements without the cost of using a 3rd party library</li> <li>Support for custom errors</li> <li>Support for <code>strict</code> specifications</li> </ul> <p>Here's an example of Pydantic's builtin JSON parsing via the <code>model_validate_json</code> method, showcasing the support for <code>strict</code> specifications while parsing JSON data that doesn't match the model's type annotations:</p> Python 3.8 and abovePython 3.9 and above <pre><code>from datetime import date\nfrom typing import Tuple\n\nfrom pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Event(BaseModel):\n    model_config = ConfigDict(strict=True)\n\n    when: date\n    where: Tuple[int, int]\n\n\njson_data = '{\"when\": \"1987-01-28\", \"where\": [51, -1]}'\nprint(Event.model_validate_json(json_data))  # (1)!\n#&gt; when=datetime.date(1987, 1, 28) where=(51, -1)\n\ntry:\n    Event.model_validate({'when': '1987-01-28', 'where': [51, -1]})  # (2)!\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for Event\n    when\n      Input should be a valid date [type=date_type, input_value='1987-01-28', input_type=str]\n    where\n      Input should be a valid tuple [type=tuple_type, input_value=[51, -1], input_type=list]\n    \"\"\"\n</code></pre> <ol> <li>JSON has no <code>date</code> or tuple types, but Pydantic knows that so allows strings and arrays as inputs respectively when parsing JSON directly.</li> <li>If you pass the same values to the <code>model_validate</code> method, Pydantic will raise a validation error because the <code>strict</code> configuration is enabled.</li> </ol> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Event(BaseModel):\n    model_config = ConfigDict(strict=True)\n\n    when: date\n    where: tuple[int, int]\n\n\njson_data = '{\"when\": \"1987-01-28\", \"where\": [51, -1]}'\nprint(Event.model_validate_json(json_data))  # (1)!\n#&gt; when=datetime.date(1987, 1, 28) where=(51, -1)\n\ntry:\n    Event.model_validate({'when': '1987-01-28', 'where': [51, -1]})  # (2)!\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for Event\n    when\n      Input should be a valid date [type=date_type, input_value='1987-01-28', input_type=str]\n    where\n      Input should be a valid tuple [type=tuple_type, input_value=[51, -1], input_type=list]\n    \"\"\"\n</code></pre> <ol> <li>JSON has no <code>date</code> or tuple types, but Pydantic knows that so allows strings and arrays as inputs respectively when parsing JSON directly.</li> <li>If you pass the same values to the <code>model_validate</code> method, Pydantic will raise a validation error because the <code>strict</code> configuration is enabled.</li> </ol> <p>In v2.5.0 and above, Pydantic uses <code>jiter</code>, a fast and iterable JSON parser, to parse JSON data. Using <code>jiter</code> compared to <code>serde</code> results in modest performance improvements that will get even better in the future.</p> <p>The <code>jiter</code> JSON parser is almost entirely compatible with the <code>serde</code> JSON parser, with one noticeable enhancement being that <code>jiter</code> supports deserialization of <code>inf</code> and <code>NaN</code> values. In the future, <code>jiter</code> is intended to enable support validation errors to include the location in the original JSON input which contained the invalid value.</p>"},{"location":"concepts/json/#partial-json-parsing","title":"Partial JSON Parsing","text":"<p>Starting in v2.7.0, Pydantic's JSON parser offers support for partial JSON parsing, which is exposed via <code>pydantic_core.from_json</code>. Here's an example of this feature in action:</p> <pre><code>from pydantic_core import from_json\n\npartial_json_data = '[\"aa\", \"bb\", \"c'  # (1)!\n\ntry:\n    result = from_json(partial_json_data, allow_partial=False)\nexcept ValueError as e:\n    print(e)  # (2)!\n    #&gt; EOF while parsing a string at line 1 column 15\n\nresult = from_json(partial_json_data, allow_partial=True)\nprint(result)  # (3)!\n#&gt; ['aa', 'bb']\n</code></pre> <ol> <li>The JSON list is incomplete - it's missing a closing <code>\"]</code></li> <li>When <code>allow_partial</code> is set to <code>False</code> (the default), a parsing error occurs.</li> <li>When <code>allow_partial</code> is set to <code>True</code>, part of the input is deserialized successfully.</li> </ol> <p>This also works for deserializing partial dictionaries. For example:</p> <pre><code>from pydantic_core import from_json\n\npartial_dog_json = '{\"breed\": \"lab\", \"name\": \"fluffy\", \"friends\": [\"buddy\", \"spot\", \"rufus\"], \"age'\ndog_dict = from_json(partial_dog_json, allow_partial=True)\nprint(dog_dict)\n#&gt; {'breed': 'lab', 'name': 'fluffy', 'friends': ['buddy', 'spot', 'rufus']}\n</code></pre> <p>Validating LLM Output</p> <p>This feature is particularly beneficial for validating LLM outputs. We've written some blog posts about this topic, which you can find here.</p> <p>In future versions of Pydantic, we expect to expand support for this feature through either Pydantic's other JSON validation functions (<code>pydantic.main.BaseModel.model_validate_json</code> and <code>pydantic.type_adapter.TypeAdapter.validate_json</code>) or model configuration. Stay tuned \ud83d\ude80!</p> <p>For now, you can use <code>pydantic_core.from_json</code> in combination with <code>pydantic.main.BaseModel.model_validate</code> to achieve the same result. Here's an example:</p> <pre><code>from pydantic_core import from_json\n\nfrom pydantic import BaseModel\n\n\nclass Dog(BaseModel):\n    breed: str\n    name: str\n    friends: list\n\n\npartial_dog_json = '{\"breed\": \"lab\", \"name\": \"fluffy\", \"friends\": [\"buddy\", \"spot\", \"rufus\"], \"age'\ndog = Dog.model_validate(from_json(partial_dog_json, allow_partial=True))\nprint(repr(dog))\n#&gt; Dog(breed='lab', name='fluffy', friends=['buddy', 'spot', 'rufus'])\n</code></pre> <p>Tip</p> <p>For partial JSON parsing to work reliably, all fields on the model should have default values.</p> <p>Check out the following example for a more in-depth look at how to use default values with partial JSON parsing:</p> <p>Using default values with partial JSON parsing</p> <pre><code>from typing import Any, Optional, Tuple\n\nimport pydantic_core\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, ValidationError, WrapValidator\n\n\ndef default_on_error(v, handler) -&gt; Any:\n    \"\"\"\n    Raise a PydanticUseDefault exception if the value is missing.\n\n    This is useful for avoiding errors from partial\n    JSON preventing successful validation.\n    \"\"\"\n    try:\n        return handler(v)\n    except ValidationError as exc:\n        # there might be other types of errors resulting from partial JSON parsing\n        # that you allow here, feel free to customize as needed\n        if all(e['type'] == 'missing' for e in exc.errors()):\n            raise pydantic_core.PydanticUseDefault()\n        else:\n            raise\n\n\nclass NestedModel(BaseModel):\n    x: int\n    y: str\n\n\nclass MyModel(BaseModel):\n    foo: Optional[str] = None\n    bar: Annotated[\n        Optional[Tuple[str, int]], WrapValidator(default_on_error)\n    ] = None\n    nested: Annotated[\n        Optional[NestedModel], WrapValidator(default_on_error)\n    ] = None\n\n\nm = MyModel.model_validate(\n    pydantic_core.from_json('{\"foo\": \"x\", \"bar\": [\"world\",', allow_partial=True)\n)\nprint(repr(m))\n#&gt; MyModel(foo='x', bar=None, nested=None)\n\n\nm = MyModel.model_validate(\n    pydantic_core.from_json(\n        '{\"foo\": \"x\", \"bar\": [\"world\", 1], \"nested\": {\"x\":', allow_partial=True\n    )\n)\nprint(repr(m))\n#&gt; MyModel(foo='x', bar=('world', 1), nested=None)\n</code></pre>"},{"location":"concepts/json/#caching-strings","title":"Caching Strings","text":"<p>Starting in v2.7.0, Pydantic's JSON parser offers support for configuring how Python strings are cached during JSON parsing and validation (when Python strings are constructed from Rust strings during Python validation, e.g. after <code>strip_whitespace=True</code>). The <code>cache_strings</code> setting is exposed via both model config and <code>pydantic_core.from_json</code>.</p> <p>The <code>cache_strings</code> setting can take any of the following values:</p> <ul> <li><code>True</code> or <code>'all'</code> (the default): cache all strings</li> <li><code>'keys'</code>: cache only dictionary keys, this only applies when used with <code>pydantic_core.from_json</code> or when parsing JSON using <code>Json</code></li> <li><code>False</code> or <code>'none'</code>: no caching</li> </ul> <p>Using the string caching feature results in performance improvements, but increases memory usage slightly.</p> <p>String Caching Details</p> <ol> <li>Strings are cached using a fully associative cache with a size of 16,384.</li> <li>Only strings where <code>len(string) &lt; 64</code> are cached.</li> <li>There is some overhead to looking up the cache, which is normally worth it to avoid constructing strings. However, if you know there will be very few repeated strings in your data, you might get a performance boost by disabling this setting with <code>cache_strings=False</code>.</li> </ol>"},{"location":"concepts/json/#json-serialization","title":"JSON Serialization","text":"API Documentation <p><code>pydantic.main.BaseModel.model_dump_json</code> <code>pydantic.type_adapter.TypeAdapter.dump_json</code> <code>pydantic_core.to_json</code></p> <p>For more information on JSON serialization, see the Serialization Concepts page.</p>"},{"location":"concepts/json_schema/","title":"JSON Schema","text":"API Documentation <p><code>pydantic.json_schema</code></p> <p>Pydantic allows automatic creation and customization of JSON schemas from models. The generated JSON schemas are compliant with the following specifications:</p> <ul> <li>JSON Schema Draft 2020-12</li> <li>OpenAPI Specification v3.1.0.</li> </ul>"},{"location":"concepts/json_schema/#generating-json-schema","title":"Generating JSON Schema","text":"<p>Use the following functions to generate JSON schema:</p> <ul> <li><code>BaseModel.model_json_schema</code> returns a jsonable dict of a model's schema.</li> <li><code>TypeAdapter.json_schema</code> returns a jsonable dict of an adapted type's schema.</li> </ul> <p>Note</p> <p>These methods are not to be confused with <code>BaseModel.model_dump_json</code> and <code>TypeAdapter.dump_json</code>, which serialize instances of the model or adapted type, respectively. These methods return JSON strings. In comparison, <code>BaseModel.model_json_schema</code> and <code>TypeAdapter.json_schema</code> return a jsonable dict representing the JSON schema of the model or adapted type, respectively.</p> <p>on the \"jsonable\" nature of JSON schema</p> <p>Regarding the \"jsonable\" nature of the <code>model_json_schema</code> results, calling <code>json.dumps(m.model_json_schema())</code>on some <code>BaseModel</code> <code>m</code> returns a valid JSON string. Similarly, for <code>TypeAdapter.json_schema</code>, calling <code>json.dumps(TypeAdapter(&lt;some_type&gt;).json_schema())</code> returns a valid JSON string.</p> <p>Tip</p> <p>Pydantic offers support for both of:</p> <ol> <li>Customizing JSON Schema</li> <li>Customizing the JSON Schema Generation Process</li> </ol> <p>The first approach generally has a more narrow scope, allowing for customization of the JSON schema for more specific cases and types. The second approach generally has a more broad scope, allowing for customization of the JSON schema generation process overall. The same effects can be achieved with either approach, but depending on your use case, one approach might offer a more simple solution than the other.</p> <p>Here's an example of generating JSON schema from a <code>BaseModel</code>:</p> Python 3.8 and abovePython 3.9 and abovePython 3.10 and above <pre><code>import json\nfrom enum import Enum\nfrom typing import Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\nfrom pydantic.config import ConfigDict\n\n\nclass FooBar(BaseModel):\n    count: int\n    size: Union[float, None] = None\n\n\nclass Gender(str, Enum):\n    male = 'male'\n    female = 'female'\n    other = 'other'\n    not_given = 'not_given'\n\n\nclass MainModel(BaseModel):\n    \"\"\"\n    This is the description of the main model\n    \"\"\"\n\n    model_config = ConfigDict(title='Main')\n\n    foo_bar: FooBar\n    gender: Annotated[Union[Gender, None], Field(alias='Gender')] = None\n    snap: int = Field(\n        42,\n        title='The Snap',\n        description='this is the value of snap',\n        gt=30,\n        lt=50,\n    )\n\n\nmain_model_schema = MainModel.model_json_schema()  # (1)!\nprint(json.dumps(main_model_schema, indent=2))  # (2)!\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"$defs\": {\n    \"FooBar\": {\n      \"properties\": {\n        \"count\": {\n          \"title\": \"Count\",\n          \"type\": \"integer\"\n        },\n        \"size\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Size\"\n        }\n      },\n      \"required\": [\n        \"count\"\n      ],\n      \"title\": \"FooBar\",\n      \"type\": \"object\"\n    },\n    \"Gender\": {\n      \"enum\": [\n        \"male\",\n        \"female\",\n        \"other\",\n        \"not_given\"\n      ],\n      \"title\": \"Gender\",\n      \"type\": \"string\"\n    }\n  },\n  \"description\": \"This is the description of the main model\",\n  \"properties\": {\n    \"foo_bar\": {\n      \"$ref\": \"#/$defs/FooBar\"\n    },\n    \"Gender\": {\n      \"anyOf\": [\n        {\n          \"$ref\": \"#/$defs/Gender\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null\n    },\n    \"snap\": {\n      \"default\": 42,\n      \"description\": \"this is the value of snap\",\n      \"exclusiveMaximum\": 50,\n      \"exclusiveMinimum\": 30,\n      \"title\": \"The Snap\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"foo_bar\"\n  ],\n  \"title\": \"Main\",\n  \"type\": \"object\"\n}\n</code></pre> <ol> <li>This produces a \"jsonable\" dict of <code>MainModel</code>'s schema.</li> <li>Calling <code>json.dumps</code> on the schema dict produces a JSON string.</li> </ol> <pre><code>import json\nfrom enum import Enum\nfrom typing import Union\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, Field\nfrom pydantic.config import ConfigDict\n\n\nclass FooBar(BaseModel):\n    count: int\n    size: Union[float, None] = None\n\n\nclass Gender(str, Enum):\n    male = 'male'\n    female = 'female'\n    other = 'other'\n    not_given = 'not_given'\n\n\nclass MainModel(BaseModel):\n    \"\"\"\n    This is the description of the main model\n    \"\"\"\n\n    model_config = ConfigDict(title='Main')\n\n    foo_bar: FooBar\n    gender: Annotated[Union[Gender, None], Field(alias='Gender')] = None\n    snap: int = Field(\n        42,\n        title='The Snap',\n        description='this is the value of snap',\n        gt=30,\n        lt=50,\n    )\n\n\nmain_model_schema = MainModel.model_json_schema()  # (1)!\nprint(json.dumps(main_model_schema, indent=2))  # (2)!\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"$defs\": {\n    \"FooBar\": {\n      \"properties\": {\n        \"count\": {\n          \"title\": \"Count\",\n          \"type\": \"integer\"\n        },\n        \"size\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Size\"\n        }\n      },\n      \"required\": [\n        \"count\"\n      ],\n      \"title\": \"FooBar\",\n      \"type\": \"object\"\n    },\n    \"Gender\": {\n      \"enum\": [\n        \"male\",\n        \"female\",\n        \"other\",\n        \"not_given\"\n      ],\n      \"title\": \"Gender\",\n      \"type\": \"string\"\n    }\n  },\n  \"description\": \"This is the description of the main model\",\n  \"properties\": {\n    \"foo_bar\": {\n      \"$ref\": \"#/$defs/FooBar\"\n    },\n    \"Gender\": {\n      \"anyOf\": [\n        {\n          \"$ref\": \"#/$defs/Gender\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null\n    },\n    \"snap\": {\n      \"default\": 42,\n      \"description\": \"this is the value of snap\",\n      \"exclusiveMaximum\": 50,\n      \"exclusiveMinimum\": 30,\n      \"title\": \"The Snap\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"foo_bar\"\n  ],\n  \"title\": \"Main\",\n  \"type\": \"object\"\n}\n</code></pre> <ol> <li>This produces a \"jsonable\" dict of <code>MainModel</code>'s schema.</li> <li>Calling <code>json.dumps</code> on the schema dict produces a JSON string.</li> </ol> <pre><code>import json\nfrom enum import Enum\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel, Field\nfrom pydantic.config import ConfigDict\n\n\nclass FooBar(BaseModel):\n    count: int\n    size: float | None = None\n\n\nclass Gender(str, Enum):\n    male = 'male'\n    female = 'female'\n    other = 'other'\n    not_given = 'not_given'\n\n\nclass MainModel(BaseModel):\n    \"\"\"\n    This is the description of the main model\n    \"\"\"\n\n    model_config = ConfigDict(title='Main')\n\n    foo_bar: FooBar\n    gender: Annotated[Gender | None, Field(alias='Gender')] = None\n    snap: int = Field(\n        42,\n        title='The Snap',\n        description='this is the value of snap',\n        gt=30,\n        lt=50,\n    )\n\n\nmain_model_schema = MainModel.model_json_schema()  # (1)!\nprint(json.dumps(main_model_schema, indent=2))  # (2)!\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"$defs\": {\n    \"FooBar\": {\n      \"properties\": {\n        \"count\": {\n          \"title\": \"Count\",\n          \"type\": \"integer\"\n        },\n        \"size\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Size\"\n        }\n      },\n      \"required\": [\n        \"count\"\n      ],\n      \"title\": \"FooBar\",\n      \"type\": \"object\"\n    },\n    \"Gender\": {\n      \"enum\": [\n        \"male\",\n        \"female\",\n        \"other\",\n        \"not_given\"\n      ],\n      \"title\": \"Gender\",\n      \"type\": \"string\"\n    }\n  },\n  \"description\": \"This is the description of the main model\",\n  \"properties\": {\n    \"foo_bar\": {\n      \"$ref\": \"#/$defs/FooBar\"\n    },\n    \"Gender\": {\n      \"anyOf\": [\n        {\n          \"$ref\": \"#/$defs/Gender\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null\n    },\n    \"snap\": {\n      \"default\": 42,\n      \"description\": \"this is the value of snap\",\n      \"exclusiveMaximum\": 50,\n      \"exclusiveMinimum\": 30,\n      \"title\": \"The Snap\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"foo_bar\"\n  ],\n  \"title\": \"Main\",\n  \"type\": \"object\"\n}\n</code></pre> <ol> <li>This produces a \"jsonable\" dict of <code>MainModel</code>'s schema.</li> <li>Calling <code>json.dumps</code> on the schema dict produces a JSON string.</li> </ol> <p>The <code>TypeAdapter</code> class lets you create an object with methods for validating, serializing, and producing JSON schemas for arbitrary types. This serves as a complete replacement for <code>schema_of</code> in Pydantic V1 (which is now deprecated).</p> <p>Here's an example of generating JSON schema from a <code>TypeAdapter</code>:</p> <pre><code>from typing import List\n\nfrom pydantic import TypeAdapter\n\nadapter = TypeAdapter(List[int])\nprint(adapter.json_schema())\n#&gt; {'items': {'type': 'integer'}, 'type': 'array'}\n</code></pre> <p>You can also generate JSON schemas for combinations of <code>BaseModel</code>s and <code>TypeAdapter</code>s, as shown in this example:</p> <pre><code>import json\nfrom typing import Union\n\nfrom pydantic import BaseModel, TypeAdapter\n\n\nclass Cat(BaseModel):\n    name: str\n    color: str\n\n\nclass Dog(BaseModel):\n    name: str\n    breed: str\n\n\nta = TypeAdapter(Union[Cat, Dog])\nta_schema = ta.json_schema()\nprint(json.dumps(ta_schema, indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"$defs\": {\n    \"Cat\": {\n      \"properties\": {\n        \"name\": {\n          \"title\": \"Name\",\n          \"type\": \"string\"\n        },\n        \"color\": {\n          \"title\": \"Color\",\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"name\",\n        \"color\"\n      ],\n      \"title\": \"Cat\",\n      \"type\": \"object\"\n    },\n    \"Dog\": {\n      \"properties\": {\n        \"name\": {\n          \"title\": \"Name\",\n          \"type\": \"string\"\n        },\n        \"breed\": {\n          \"title\": \"Breed\",\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"name\",\n        \"breed\"\n      ],\n      \"title\": \"Dog\",\n      \"type\": \"object\"\n    }\n  },\n  \"anyOf\": [\n    {\n      \"$ref\": \"#/$defs/Cat\"\n    },\n    {\n      \"$ref\": \"#/$defs/Dog\"\n    }\n  ]\n}\n</code></pre>"},{"location":"concepts/json_schema/#configuring-the-jsonschemamode","title":"Configuring the <code>JsonSchemaMode</code>","text":"<p>Specify the mode of JSON schema generation via the <code>mode</code> parameter in the <code>model_json_schema</code> and <code>TypeAdapter.json_schema</code> methods. By default, the mode is set to <code>'validation'</code>, which produces a JSON schema corresponding to the model's validation schema.</p> <p>The <code>JsonSchemaMode</code> is a type alias that represents the available options for the <code>mode</code> parameter:</p> <ul> <li><code>'validation'</code></li> <li><code>'serialization'</code></li> </ul> <p>Here's an example of how to specify the <code>mode</code> parameter, and how it affects the generated JSON schema:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: Decimal = Decimal('12.34')\n\n\nprint(Model.model_json_schema(mode='validation'))\n\"\"\"\n{\n    'properties': {\n        'a': {\n            'anyOf': [{'type': 'number'}, {'type': 'string'}],\n            'default': '12.34',\n            'title': 'A',\n        }\n    },\n    'title': 'Model',\n    'type': 'object',\n}\n\"\"\"\n\nprint(Model.model_json_schema(mode='serialization'))\n\"\"\"\n{\n    'properties': {'a': {'default': '12.34', 'title': 'A', 'type': 'string'}},\n    'title': 'Model',\n    'type': 'object',\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/json_schema/#customizing-json-schema","title":"Customizing JSON Schema","text":"<p>The generated JSON schema can be customized at both the field level and model level via:</p> <ol> <li>Field-level customization with the <code>Field</code> constructor</li> <li>Model-level customization with <code>model_config</code></li> </ol> <p>At both the field and model levels, you can use the <code>json_schema_extra</code> option to add extra information to the JSON schema. The Using <code>json_schema_extra</code> section below provides more details on this option.</p> <p>For custom types, Pydantic offers other tools for customizing JSON schema generation:</p> <ol> <li><code>WithJsonSchema</code> annotation</li> <li><code>SkipJsonSchema</code> annotation</li> <li>Implementing <code>__get_pydantic_core_schema__</code></li> <li>Implementing <code>__get_pydantic_json_schema__</code></li> </ol>"},{"location":"concepts/json_schema/#field-level-customization","title":"Field-Level Customization","text":"<p>Optionally, the <code>Field</code> function can be used to provide extra information about the field and validations.</p> <p>Some field parameters are used exclusively to customize the generated JSON Schema:</p> <ul> <li><code>title</code>: The title of the field.</li> <li><code>description</code>: The description of the field.</li> <li><code>examples</code>: The examples of the field.</li> <li><code>json_schema_extra</code>: Extra JSON Schema properties to be added to the field.</li> <li><code>field_title_generator</code>: A function that programmatically sets the field's title, based on its name and info.</li> </ul> <p>Here's an example:</p> <pre><code>import json\n\nfrom pydantic import BaseModel, EmailStr, Field, SecretStr\n\n\nclass User(BaseModel):\n    age: int = Field(description='Age of the user')\n    email: EmailStr = Field(examples=['marcelo@mail.com'])\n    name: str = Field(title='Username')\n    password: SecretStr = Field(\n        json_schema_extra={\n            'title': 'Password',\n            'description': 'Password of the user',\n            'examples': ['123456'],\n        }\n    )\n\n\nprint(json.dumps(User.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"properties\": {\n    \"age\": {\n      \"description\": \"Age of the user\",\n      \"title\": \"Age\",\n      \"type\": \"integer\"\n    },\n    \"email\": {\n      \"examples\": [\n        \"marcelo@mail.com\"\n      ],\n      \"format\": \"email\",\n      \"title\": \"Email\",\n      \"type\": \"string\"\n    },\n    \"name\": {\n      \"title\": \"Username\",\n      \"type\": \"string\"\n    },\n    \"password\": {\n      \"description\": \"Password of the user\",\n      \"examples\": [\n        \"123456\"\n      ],\n      \"format\": \"password\",\n      \"title\": \"Password\",\n      \"type\": \"string\",\n      \"writeOnly\": true\n    }\n  },\n  \"required\": [\n    \"age\",\n    \"email\",\n    \"name\",\n    \"password\"\n  ],\n  \"title\": \"User\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"concepts/json_schema/#unenforced-field-constraints","title":"Unenforced <code>Field</code> constraints","text":"<p>If Pydantic finds constraints which are not being enforced, an error will be raised. If you want to force the constraint to appear in the schema, even though it's not being checked upon parsing, you can use variadic arguments to <code>Field</code> with the raw schema attribute name:</p> <pre><code>from pydantic import BaseModel, Field, PositiveInt\n\ntry:\n    # this won't work since `PositiveInt` takes precedence over the\n    # constraints defined in `Field`, meaning they're ignored\n    class Model(BaseModel):\n        foo: PositiveInt = Field(..., lt=10)\n\nexcept ValueError as e:\n    print(e)\n\n\n# if you find yourself needing this, an alternative is to declare\n# the constraints in `Field` (or you could use `conint()`)\n# here both constraints will be enforced:\nclass ModelB(BaseModel):\n    # Here both constraints will be applied and the schema\n    # will be generated correctly\n    foo: int = Field(..., gt=0, lt=10)\n\n\nprint(ModelB.model_json_schema())\n\"\"\"\n{\n    'properties': {\n        'foo': {\n            'exclusiveMaximum': 10,\n            'exclusiveMinimum': 0,\n            'title': 'Foo',\n            'type': 'integer',\n        }\n    },\n    'required': ['foo'],\n    'title': 'ModelB',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <p>You can specify JSON schema modifications via the <code>Field</code> constructor via <code>typing.Annotated</code> as well:</p> <pre><code>import json\nfrom uuid import uuid4\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    id: Annotated[str, Field(default_factory=lambda: uuid4().hex)]\n    name: Annotated[str, Field(max_length=256)] = Field(\n        'Bar', title='CustomName'\n    )\n\n\nprint(json.dumps(Foo.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"properties\": {\n    \"id\": {\n      \"title\": \"Id\",\n      \"type\": \"string\"\n    },\n    \"name\": {\n      \"default\": \"Bar\",\n      \"maxLength\": 256,\n      \"title\": \"CustomName\",\n      \"type\": \"string\"\n    }\n  },\n  \"title\": \"Foo\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"concepts/json_schema/#programmatic-field-title-generation","title":"Programmatic field title generation","text":"<p>The <code>field_title_generator</code> parameter can be used to programmatically generate the title for a field based on its name and info.</p> <p>See the following example:</p> <pre><code>import json\n\nfrom pydantic import BaseModel, Field\nfrom pydantic.fields import FieldInfo\n\n\ndef make_title(field_name: str, field_info: FieldInfo) -&gt; str:\n    return field_name.upper()\n\n\nclass Person(BaseModel):\n    name: str = Field(field_title_generator=make_title)\n    age: int = Field(field_title_generator=make_title)\n\n\nprint(json.dumps(Person.model_json_schema(), indent=2))\n\"\"\"\n{\n  \"properties\": {\n    \"name\": {\n      \"title\": \"NAME\",\n      \"type\": \"string\"\n    },\n    \"age\": {\n      \"title\": \"AGE\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"name\",\n    \"age\"\n  ],\n  \"title\": \"Person\",\n  \"type\": \"object\"\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/json_schema/#model-level-customization","title":"Model-Level Customization","text":"<p>You can also use model config to customize JSON schema generation on a model. Specifically, the following config options are relevant:</p> <ul> <li><code>title</code></li> <li><code>json_schema_extra</code></li> <li><code>schema_generator</code></li> <li><code>json_schema_mode_override</code></li> <li><code>field_title_generator</code></li> <li><code>model_title_generator</code></li> </ul>"},{"location":"concepts/json_schema/#using-json_schema_extra","title":"Using <code>json_schema_extra</code>","text":"<p>The <code>json_schema_extra</code> option can be used to add extra information to the JSON schema, either at the Field level or at the Model level. You can pass a <code>dict</code> or a <code>Callable</code> to <code>json_schema_extra</code>.</p>"},{"location":"concepts/json_schema/#using-json_schema_extra-with-a-dict","title":"Using <code>json_schema_extra</code> with a <code>dict</code>","text":"<p>You can pass a <code>dict</code> to <code>json_schema_extra</code> to add extra information to the JSON schema:</p> <pre><code>import json\n\nfrom pydantic import BaseModel, ConfigDict\n\n\nclass Model(BaseModel):\n    a: str\n\n    model_config = ConfigDict(json_schema_extra={'examples': [{'a': 'Foo'}]})\n\n\nprint(json.dumps(Model.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"examples\": [\n    {\n      \"a\": \"Foo\"\n    }\n  ],\n  \"properties\": {\n    \"a\": {\n      \"title\": \"A\",\n      \"type\": \"string\"\n    }\n  },\n  \"required\": [\n    \"a\"\n  ],\n  \"title\": \"Model\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"concepts/json_schema/#using-json_schema_extra-with-a-callable","title":"Using <code>json_schema_extra</code> with a <code>Callable</code>","text":"<p>You can pass a <code>Callable</code> to <code>json_schema_extra</code> to modify the JSON schema with a function:</p> <pre><code>import json\n\nfrom pydantic import BaseModel, Field\n\n\ndef pop_default(s):\n    s.pop('default')\n\n\nclass Model(BaseModel):\n    a: int = Field(default=1, json_schema_extra=pop_default)\n\n\nprint(json.dumps(Model.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"properties\": {\n    \"a\": {\n      \"title\": \"A\",\n      \"type\": \"integer\"\n    }\n  },\n  \"title\": \"Model\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"concepts/json_schema/#merging-json_schema_extra","title":"Merging <code>json_schema_extra</code>","text":"<p>Starting in v2.9, Pydantic merges <code>json_schema_extra</code> dictionaries from annotated types. This pattern offers a more additive approach to merging rather than the previous override behavior. This can be quite helpful for cases of reusing json schema extra information across multiple types.</p> <p>We viewed this change largely as a bug fix, as it resolves unintentional differences in the <code>json_schema_extra</code> merging behavior between <code>BaseModel</code> and <code>TypeAdapter</code> instances - see this issue for more details.</p> <pre><code>import json\n\nfrom typing_extensions import Annotated, TypeAlias\n\nfrom pydantic import Field, TypeAdapter\n\nExternalType: TypeAlias = Annotated[\n    int, Field(..., json_schema_extra={'key1': 'value1'})\n]\n\nta = TypeAdapter(\n    Annotated[ExternalType, Field(..., json_schema_extra={'key2': 'value2'})]\n)\nprint(json.dumps(ta.json_schema(), indent=2))\n\"\"\"\n{\n  \"key1\": \"value1\",\n  \"key2\": \"value2\",\n  \"type\": \"integer\"\n}\n\"\"\"\n</code></pre> <p>If you would prefer for the last of your <code>json_schema_extra</code> specifications to override the previous ones, you can use a <code>callable</code> to make more significant changes, including adding or removing keys, or modifying values. You can use this pattern if you'd like to mimic the behavior of the <code>json_schema_extra</code> overrides present in Pydantic v2.8 and earlier:</p> <pre><code>import json\n\nfrom typing_extensions import Annotated, TypeAlias\n\nfrom pydantic import Field, TypeAdapter\nfrom pydantic.json_schema import JsonDict\n\nExternalType: TypeAlias = Annotated[\n    int, Field(..., json_schema_extra={'key1': 'value1', 'key2': 'value2'})\n]\n\n\ndef finalize_schema(s: JsonDict) -&gt; None:\n    s.pop('key1')\n    s['key2'] = s['key2'] + '-final'\n    s['key3'] = 'value3-final'\n\n\nta = TypeAdapter(\n    Annotated[ExternalType, Field(..., json_schema_extra=finalize_schema)]\n)\nprint(json.dumps(ta.json_schema(), indent=2))\n\"\"\"\n{\n  \"key2\": \"value2-final\",\n  \"key3\": \"value3-final\",\n  \"type\": \"integer\"\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/json_schema/#withjsonschema-annotation","title":"<code>WithJsonSchema</code> annotation","text":"API Documentation <p><code>pydantic.json_schema.WithJsonSchema</code></p> <p>Tip</p> <p>Using <code>WithJsonSchema</code>] is preferred over implementing <code>__get_pydantic_json_schema__</code> for custom types, as it's more simple and less error-prone.</p> <p>The <code>WithJsonSchema</code> annotation can be used to override the generated (base) JSON schema for a given type without the need to implement <code>__get_pydantic_core_schema__</code> or <code>__get_pydantic_json_schema__</code> on the type itself.</p> <p>This provides a way to set a JSON schema for types that would otherwise raise errors when producing a JSON schema, such as <code>Callable</code>, or types that have an <code>is-instance</code> core schema.</p> <p>For example, the use of a <code>PlainValidator</code> in the following example would otherwise raise an error when producing a JSON schema because the <code>PlainValidator</code> is a <code>Callable</code>. However, by using the <code>WithJsonSchema</code> annotation, we can override the generated JSON schema for the custom <code>MyInt</code> type:</p> <pre><code>import json\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, PlainValidator, WithJsonSchema\n\nMyInt = Annotated[\n    int,\n    PlainValidator(lambda v: int(v) + 1),\n    WithJsonSchema({'type': 'integer', 'examples': [1, 0, -1]}),\n]\n\n\nclass Model(BaseModel):\n    a: MyInt\n\n\nprint(Model(a='1').a)\n#&gt; 2\n\nprint(json.dumps(Model.model_json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"properties\": {\n    \"a\": {\n      \"examples\": [\n        1,\n        0,\n        -1\n      ],\n      \"title\": \"A\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"a\"\n  ],\n  \"title\": \"Model\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Note</p> <p>As discussed in this issue, in the future, it's likely that Pydantic will add builtin support for JSON schema generation for types like <code>PlainValidator</code>, but the <code>WithJsonSchema</code> annotation will still be useful for other custom types.</p>"},{"location":"concepts/json_schema/#skipjsonschema-annotation","title":"<code>SkipJsonSchema</code> annotation","text":"API Documentation <p><code>pydantic.json_schema.SkipJsonSchema</code></p> <p>The <code>SkipJsonSchema</code> annotation can be used to skip a including field (or part of a field's specifications) from the generated JSON schema. See the API docs for more details.</p>"},{"location":"concepts/json_schema/#implementing-__get_pydantic_core_schema__","title":"Implementing <code>__get_pydantic_core_schema__</code>","text":"<p>Custom types (used as <code>field_name: TheType</code> or <code>field_name: Annotated[TheType, ...]</code>) as well as <code>Annotated</code> metadata (used as <code>field_name: Annotated[int, SomeMetadata]</code>) can modify or override the generated schema by implementing <code>__get_pydantic_core_schema__</code>. This method receives two positional arguments:</p> <ol> <li>The type annotation that corresponds to this type (so in the case of <code>TheType[T][int]</code> it would be <code>TheType[int]</code>).</li> <li>A handler/callback to call the next implementer of <code>__get_pydantic_core_schema__</code>.</li> </ol> <p>The handler system works just like <code>mode='wrap'</code> validators. In this case the input is the type and the output is a <code>core_schema</code>.</p> <p>Here is an example of a custom type that overrides the generated <code>core_schema</code>:</p> <pre><code>from dataclasses import dataclass\nfrom typing import Any, Dict, List, Type\n\nfrom pydantic_core import core_schema\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\n@dataclass\nclass CompressedString:\n    dictionary: Dict[int, str]\n    text: List[int]\n\n    def build(self) -&gt; str:\n        return ' '.join([self.dictionary[key] for key in self.text])\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: Type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        assert source is CompressedString\n        return core_schema.no_info_after_validator_function(\n            cls._validate,\n            core_schema.str_schema(),\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                cls._serialize,\n                info_arg=False,\n                return_schema=core_schema.str_schema(),\n            ),\n        )\n\n    @staticmethod\n    def _validate(value: str) -&gt; 'CompressedString':\n        inverse_dictionary: Dict[str, int] = {}\n        text: List[int] = []\n        for word in value.split(' '):\n            if word not in inverse_dictionary:\n                inverse_dictionary[word] = len(inverse_dictionary)\n            text.append(inverse_dictionary[word])\n        return CompressedString(\n            {v: k for k, v in inverse_dictionary.items()}, text\n        )\n\n    @staticmethod\n    def _serialize(value: 'CompressedString') -&gt; str:\n        return value.build()\n\n\nclass MyModel(BaseModel):\n    value: CompressedString\n\n\nprint(MyModel.model_json_schema())\n\"\"\"\n{\n    'properties': {'value': {'title': 'Value', 'type': 'string'}},\n    'required': ['value'],\n    'title': 'MyModel',\n    'type': 'object',\n}\n\"\"\"\nprint(MyModel(value='fox fox fox dog fox'))\n\"\"\"\nvalue = CompressedString(dictionary={0: 'fox', 1: 'dog'}, text=[0, 0, 0, 1, 0])\n\"\"\"\n\nprint(MyModel(value='fox fox fox dog fox').model_dump(mode='json'))\n#&gt; {'value': 'fox fox fox dog fox'}\n</code></pre> <p>Since Pydantic would not know how to generate a schema for <code>CompressedString</code>, if you call <code>handler(source)</code> in its <code>__get_pydantic_core_schema__</code> method you would get a <code>pydantic.errors.PydanticSchemaGenerationError</code> error. This will be the case for most custom types, so you almost never want to call into <code>handler</code> for custom types.</p> <p>The process for <code>Annotated</code> metadata is much the same except that you can generally call into <code>handler</code> to have Pydantic handle generating the schema.</p> <pre><code>from dataclasses import dataclass\nfrom typing import Any, Sequence, Type\n\nfrom pydantic_core import core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler, ValidationError\n\n\n@dataclass\nclass RestrictCharacters:\n    alphabet: Sequence[str]\n\n    def __get_pydantic_core_schema__(\n        self, source: Type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        if not self.alphabet:\n            raise ValueError('Alphabet may not be empty')\n        schema = handler(\n            source\n        )  # get the CoreSchema from the type / inner constraints\n        if schema['type'] != 'str':\n            raise TypeError('RestrictCharacters can only be applied to strings')\n        return core_schema.no_info_after_validator_function(\n            self.validate,\n            schema,\n        )\n\n    def validate(self, value: str) -&gt; str:\n        if any(c not in self.alphabet for c in value):\n            raise ValueError(\n                f'{value!r} is not restricted to {self.alphabet!r}'\n            )\n        return value\n\n\nclass MyModel(BaseModel):\n    value: Annotated[str, RestrictCharacters('ABC')]\n\n\nprint(MyModel.model_json_schema())\n\"\"\"\n{\n    'properties': {'value': {'title': 'Value', 'type': 'string'}},\n    'required': ['value'],\n    'title': 'MyModel',\n    'type': 'object',\n}\n\"\"\"\nprint(MyModel(value='CBA'))\n#&gt; value='CBA'\n\ntry:\n    MyModel(value='XYZ')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for MyModel\n    value\n      Value error, 'XYZ' is not restricted to 'ABC' [type=value_error, input_value='XYZ', input_type=str]\n    \"\"\"\n</code></pre> <p>So far we have been wrapping the schema, but if you just want to modify it or ignore it you can as well.</p> <p>To modify the schema, first call the handler, then mutate the result:</p> <pre><code>from typing import Any, Type\n\nfrom pydantic_core import ValidationError, core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass SmallString:\n    def __get_pydantic_core_schema__(\n        self,\n        source: Type[Any],\n        handler: GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        schema = handler(source)\n        assert schema['type'] == 'str'\n        schema['max_length'] = 10  # modify in place\n        return schema\n\n\nclass MyModel(BaseModel):\n    value: Annotated[str, SmallString()]\n\n\ntry:\n    MyModel(value='too long!!!!!')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for MyModel\n    value\n      String should have at most 10 characters [type=string_too_long, input_value='too long!!!!!', input_type=str]\n    \"\"\"\n</code></pre> <p>Tip</p> <p>Note that you must return a schema, even if you are just mutating it in place.</p> <p>To override the schema completely, do not call the handler and return your own <code>CoreSchema</code>:</p> <pre><code>from typing import Any, Type\n\nfrom pydantic_core import ValidationError, core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass AllowAnySubclass:\n    def __get_pydantic_core_schema__(\n        self, source: Type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        # we can't call handler since it will fail for arbitrary types\n        def validate(value: Any) -&gt; Any:\n            if not isinstance(value, source):\n                raise ValueError(\n                    f'Expected an instance of {source}, got an instance of {type(value)}'\n                )\n\n        return core_schema.no_info_plain_validator_function(validate)\n\n\nclass Foo:\n    pass\n\n\nclass Model(BaseModel):\n    f: Annotated[Foo, AllowAnySubclass()]\n\n\nprint(Model(f=Foo()))\n#&gt; f=None\n\n\nclass NotFoo:\n    pass\n\n\ntry:\n    Model(f=NotFoo())\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    f\n      Value error, Expected an instance of &lt;class '__main__.Foo'&gt;, got an instance of &lt;class '__main__.NotFoo'&gt; [type=value_error, input_value=&lt;__main__.NotFoo object at 0x0123456789ab&gt;, input_type=NotFoo]\n    \"\"\"\n</code></pre> <p>As seen above, annotating a field with a <code>BaseModel</code> type can be used to modify or override the generated json schema. However, if you want to take advantage of storing metadata via <code>Annotated</code>, but you don't want to override the generated JSON schema, you can use the following approach with a no-op version of <code>__get_pydantic_core_schema__</code> implemented on the metadata class:</p> <pre><code>from typing import Type\n\nfrom pydantic_core import CoreSchema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass Metadata(BaseModel):\n    foo: str = 'metadata!'\n    bar: int = 100\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: Type[BaseModel], handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        if cls is not source_type:\n            return handler(source_type)\n        return super().__get_pydantic_core_schema__(source_type, handler)\n\n\nclass Model(BaseModel):\n    state: Annotated[int, Metadata()]\n\n\nm = Model.model_validate({'state': 2})\nprint(repr(m))\n#&gt; Model(state=2)\nprint(m.model_fields)\n\"\"\"\n{\n    'state': FieldInfo(\n        annotation=int,\n        required=True,\n        metadata=[Metadata(foo='metadata!', bar=100)],\n    )\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/json_schema/#implementing-__get_pydantic_json_schema__","title":"Implementing <code>__get_pydantic_json_schema__</code>","text":"<p>You can also implement <code>__get_pydantic_json_schema__</code> to modify or override the generated json schema. Modifying this method only affects the JSON schema - it doesn't affect the core schema, which is used for validation and serialization.</p> <p>Here's an example of modifying the generated JSON schema:</p> <pre><code>import json\nfrom typing import Any\n\nfrom pydantic_core import core_schema as cs\n\nfrom pydantic import GetCoreSchemaHandler, GetJsonSchemaHandler, TypeAdapter\nfrom pydantic.json_schema import JsonSchemaValue\n\n\nclass Person:\n    name: str\n    age: int\n\n    def __init__(self, name: str, age: int):\n        self.name = name\n        self.age = age\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: Any, handler: GetCoreSchemaHandler\n    ) -&gt; cs.CoreSchema:\n        return cs.typed_dict_schema(\n            {\n                'name': cs.typed_dict_field(cs.str_schema()),\n                'age': cs.typed_dict_field(cs.int_schema()),\n            },\n        )\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, core_schema: cs.CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; JsonSchemaValue:\n        json_schema = handler(core_schema)\n        json_schema = handler.resolve_ref_schema(json_schema)\n        json_schema['examples'] = [\n            {\n                'name': 'John Doe',\n                'age': 25,\n            }\n        ]\n        json_schema['title'] = 'Person'\n        return json_schema\n\n\nprint(json.dumps(TypeAdapter(Person).json_schema(), indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"examples\": [\n    {\n      \"age\": 25,\n      \"name\": \"John Doe\"\n    }\n  ],\n  \"properties\": {\n    \"name\": {\n      \"title\": \"Name\",\n      \"type\": \"string\"\n    },\n    \"age\": {\n      \"title\": \"Age\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"name\",\n    \"age\"\n  ],\n  \"title\": \"Person\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"concepts/json_schema/#using-field_title_generator","title":"Using <code>field_title_generator</code>","text":"<p>The <code>field_title_generator</code> parameter can be used to programmatically generate the title for a field based on its name and info. This is similar to the field level <code>field_title_generator</code>, but the <code>ConfigDict</code> option will be applied to all fields of the class.</p> <p>See the following example:</p> <pre><code>import json\n\nfrom pydantic import BaseModel, ConfigDict\n\n\nclass Person(BaseModel):\n    model_config = ConfigDict(\n        field_title_generator=lambda field_name, field_info: field_name.upper()\n    )\n    name: str\n    age: int\n\n\nprint(json.dumps(Person.model_json_schema(), indent=2))\n\"\"\"\n{\n  \"properties\": {\n    \"name\": {\n      \"title\": \"NAME\",\n      \"type\": \"string\"\n    },\n    \"age\": {\n      \"title\": \"AGE\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"name\",\n    \"age\"\n  ],\n  \"title\": \"Person\",\n  \"type\": \"object\"\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/json_schema/#using-model_title_generator","title":"Using <code>model_title_generator</code>","text":"<p>The <code>model_title_generator</code> config option is similar to the <code>field_title_generator</code> option, but it applies to the title of the model itself, and accepts the model class as input.</p> <p>See the following example:</p> <pre><code>import json\nfrom typing import Type\n\nfrom pydantic import BaseModel, ConfigDict\n\n\ndef make_title(model: Type) -&gt; str:\n    return f'Title-{model.__name__}'\n\n\nclass Person(BaseModel):\n    model_config = ConfigDict(model_title_generator=make_title)\n    name: str\n    age: int\n\n\nprint(json.dumps(Person.model_json_schema(), indent=2))\n\"\"\"\n{\n  \"properties\": {\n    \"name\": {\n      \"title\": \"Name\",\n      \"type\": \"string\"\n    },\n    \"age\": {\n      \"title\": \"Age\",\n      \"type\": \"integer\"\n    }\n  },\n  \"required\": [\n    \"name\",\n    \"age\"\n  ],\n  \"title\": \"Title-Person\",\n  \"type\": \"object\"\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/json_schema/#json-schema-types","title":"JSON schema types","text":"<p>Types, custom field types, and constraints (like <code>max_length</code>) are mapped to the corresponding spec formats in the following priority order (when there is an equivalent available):</p> <ol> <li>JSON Schema Core</li> <li>JSON Schema Validation</li> <li>OpenAPI Data Types</li> <li>The standard <code>format</code> JSON field is used to define Pydantic extensions for more complex <code>string</code> sub-types.</li> </ol> <p>The field schema mapping from Python or Pydantic to JSON schema is done as follows:</p> <p>{{ schema_mappings_table }}</p>"},{"location":"concepts/json_schema/#top-level-schema-generation","title":"Top-level schema generation","text":"<p>You can also generate a top-level JSON schema that only includes a list of models and related sub-models in its <code>$defs</code>:</p> <pre><code>import json\n\nfrom pydantic import BaseModel\nfrom pydantic.json_schema import models_json_schema\n\n\nclass Foo(BaseModel):\n    a: str = None\n\n\nclass Model(BaseModel):\n    b: Foo\n\n\nclass Bar(BaseModel):\n    c: int\n\n\n_, top_level_schema = models_json_schema(\n    [(Model, 'validation'), (Bar, 'validation')], title='My Schema'\n)\nprint(json.dumps(top_level_schema, indent=2))\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"$defs\": {\n    \"Bar\": {\n      \"properties\": {\n        \"c\": {\n          \"title\": \"C\",\n          \"type\": \"integer\"\n        }\n      },\n      \"required\": [\n        \"c\"\n      ],\n      \"title\": \"Bar\",\n      \"type\": \"object\"\n    },\n    \"Foo\": {\n      \"properties\": {\n        \"a\": {\n          \"default\": null,\n          \"title\": \"A\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Foo\",\n      \"type\": \"object\"\n    },\n    \"Model\": {\n      \"properties\": {\n        \"b\": {\n          \"$ref\": \"#/$defs/Foo\"\n        }\n      },\n      \"required\": [\n        \"b\"\n      ],\n      \"title\": \"Model\",\n      \"type\": \"object\"\n    }\n  },\n  \"title\": \"My Schema\"\n}\n</code></pre>"},{"location":"concepts/json_schema/#customizing-the-json-schema-generation-process","title":"Customizing the JSON Schema Generation Process","text":"API Documentation <p><code>pydantic.json_schema</code></p> <p>If you need custom schema generation, you can use a <code>schema_generator</code>, modifying the <code>GenerateJsonSchema</code> class as necessary for your application.</p> <p>The various methods that can be used to produce JSON schema accept a keyword argument <code>schema_generator: type[GenerateJsonSchema] = GenerateJsonSchema</code>, and you can pass your custom subclass to these methods in order to use your own approach to generating JSON schema.</p> <p><code>GenerateJsonSchema</code> implements the translation of a type's <code>pydantic-core</code> schema into a JSON schema. By design, this class breaks the JSON schema generation process into smaller methods that can be easily overridden in subclasses to modify the \"global\" approach to generating JSON schema.</p> <pre><code>from pydantic import BaseModel\nfrom pydantic.json_schema import GenerateJsonSchema\n\n\nclass MyGenerateJsonSchema(GenerateJsonSchema):\n    def generate(self, schema, mode='validation'):\n        json_schema = super().generate(schema, mode=mode)\n        json_schema['title'] = 'Customize title'\n        json_schema['$schema'] = self.schema_dialect\n        return json_schema\n\n\nclass MyModel(BaseModel):\n    x: int\n\n\nprint(MyModel.model_json_schema(schema_generator=MyGenerateJsonSchema))\n\"\"\"\n{\n    'properties': {'x': {'title': 'X', 'type': 'integer'}},\n    'required': ['x'],\n    'title': 'Customize title',\n    'type': 'object',\n    '$schema': 'https://json-schema.org/draft/2020-12/schema',\n}\n\"\"\"\n</code></pre> <p>Below is an approach you can use to exclude any fields from the schema that don't have valid json schemas:</p> <pre><code>from typing import Callable\n\nfrom pydantic_core import PydanticOmit, core_schema\n\nfrom pydantic import BaseModel\nfrom pydantic.json_schema import GenerateJsonSchema, JsonSchemaValue\n\n\nclass MyGenerateJsonSchema(GenerateJsonSchema):\n    def handle_invalid_for_json_schema(\n        self, schema: core_schema.CoreSchema, error_info: str\n    ) -&gt; JsonSchemaValue:\n        raise PydanticOmit\n\n\ndef example_callable():\n    return 1\n\n\nclass Example(BaseModel):\n    name: str = 'example'\n    function: Callable = example_callable\n\n\ninstance_example = Example()\n\nvalidation_schema = instance_example.model_json_schema(\n    schema_generator=MyGenerateJsonSchema, mode='validation'\n)\nprint(validation_schema)\n\"\"\"\n{\n    'properties': {\n        'name': {'default': 'example', 'title': 'Name', 'type': 'string'}\n    },\n    'title': 'Example',\n    'type': 'object',\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/json_schema/#customizing-the-refs-in-json-schema","title":"Customizing the <code>$ref</code>s in JSON Schema","text":"<p>The format of <code>$ref</code>s can be altered by calling <code>model_json_schema()</code> or <code>model_dump_json()</code> with the <code>ref_template</code> keyword argument. The definitions are always stored under the key <code>$defs</code>, but a specified prefix can be used for the references.</p> <p>This is useful if you need to extend or modify the JSON schema default definitions location. For example, with OpenAPI:</p> <pre><code>import json\n\nfrom pydantic import BaseModel\nfrom pydantic.type_adapter import TypeAdapter\n\n\nclass Foo(BaseModel):\n    a: int\n\n\nclass Model(BaseModel):\n    a: Foo\n\n\nadapter = TypeAdapter(Model)\n\nprint(\n    json.dumps(\n        adapter.json_schema(ref_template='#/components/schemas/{model}'),\n        indent=2,\n    )\n)\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"$defs\": {\n    \"Foo\": {\n      \"properties\": {\n        \"a\": {\n          \"title\": \"A\",\n          \"type\": \"integer\"\n        }\n      },\n      \"required\": [\n        \"a\"\n      ],\n      \"title\": \"Foo\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"a\": {\n      \"$ref\": \"#/components/schemas/Foo\"\n    }\n  },\n  \"required\": [\n    \"a\"\n  ],\n  \"title\": \"Model\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"concepts/json_schema/#miscellaneous-notes-on-json-schema-generation","title":"Miscellaneous Notes on JSON Schema Generation","text":"<ul> <li>The JSON schema for <code>Optional</code> fields indicates that the value <code>null</code> is allowed.</li> <li>The <code>Decimal</code> type is exposed in JSON schema (and serialized) as a string.</li> <li>Since the <code>namedtuple</code> type doesn't exist in JSON, a model's JSON schema does not preserve <code>namedtuple</code>s as <code>namedtuple</code>s.</li> <li>Sub-models used are added to the <code>$defs</code> JSON attribute and referenced, as per the spec.</li> <li>Sub-models with modifications (via the <code>Field</code> class) like a custom title, description, or default value,     are recursively included instead of referenced.</li> <li>The <code>description</code> for models is taken from either the docstring of the class or the argument <code>description</code> to     the <code>Field</code> class.</li> <li>The schema is generated by default using aliases as keys, but it can be generated using model     property names instead by calling <code>model_json_schema()</code> or     <code>model_dump_json()</code> with the <code>by_alias=False</code> keyword argument.</li> </ul>"},{"location":"concepts/models/","title":"Models","text":"API Documentation <p><code>pydantic.main.BaseModel</code></p> <p>One of the primary ways of defining schema in Pydantic is via models. Models are simply classes which inherit from <code>BaseModel</code> and define fields as annotated attributes.</p> <p>You can think of models as similar to structs in languages like C, or as the requirements of a single endpoint in an API.</p> <p>Models share many similarities with Python's dataclasses, but have been designed with some subtle-yet-important differences that streamline certain workflows related to validation, serialization, and JSON schema generation. You can find more discussion of this in the Dataclasses section of the docs.</p> <p>Untrusted data can be passed to a model and, after parsing and validation, Pydantic guarantees that the fields of the resultant model instance will conform to the field types defined on the model.</p> <p>Validation \u2014 a deliberate misnomer</p>"},{"location":"concepts/models/#tldr","title":"TL;DR","text":"<p>We use the term \"validation\" to refer to the process of instantiating a model (or other type) that adheres to specified types and constraints. This task, which Pydantic is well known for, is most widely recognized as \"validation\" in colloquial terms, even though in other contexts the term \"validation\" may be more restrictive.</p>"},{"location":"concepts/models/#the-long-version","title":"The long version","text":"<p>The potential confusion around the term \"validation\" arises from the fact that, strictly speaking, Pydantic's primary focus doesn't align precisely with the dictionary definition of \"validation\":</p> <p>In Pydantic, the term \"validation\" refers to the process of instantiating a model (or other type) that adheres to specified types and constraints. Pydantic guarantees the types and constraints of the output, not the input data. This distinction becomes apparent when considering that Pydantic's <code>ValidationError</code> is raised when data cannot be successfully parsed into a model instance.</p> <p>While this distinction may initially seem subtle, it holds practical significance. In some cases, \"validation\" goes beyond just model creation, and can include the copying and coercion of data. This can involve copying arguments passed to the constructor in order to perform coercion to a new type without mutating the original input data. For a more in-depth understanding of the implications for your usage, refer to the Data Conversion and Attribute Copies sections below.</p> <p>In essence, Pydantic's primary goal is to assure that the resulting structure post-processing (termed \"validation\") precisely conforms to the applied type hints. Given the widespread adoption of \"validation\" as the colloquial term for this process, we will consistently use it in our documentation.</p> <p>While the terms \"parse\" and \"validation\" were previously used interchangeably, moving forward, we aim to exclusively employ \"validate\", with \"parse\" reserved specifically for discussions related to JSON parsing.</p>"},{"location":"concepts/models/#validation","title":"validation","text":"<p>noun the action of checking or proving the validity or accuracy of something.</p>"},{"location":"concepts/models/#basic-model-usage","title":"Basic model usage","text":"<p>Note</p> <p>Pydantic relies heavily on the existing Python typing constructs to define models. If you are not familiar with those, the following resources can be useful:</p> <ul> <li>The Type System Guides</li> <li>The mypy documentation</li> </ul> <pre><code>from pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'Jane Doe'\n</code></pre> <p>In this example, <code>User</code> is a model with two fields:</p> <ul> <li><code>id</code>, which is an integer and is required</li> <li><code>name</code>, which is a string and is not required (it has a default value).</li> </ul> <p>The model can then be instantiated:</p> <pre><code>user = User(id='123')\n</code></pre> <p><code>user</code> is an instance of <code>User</code>. Initialization of the object will perform all parsing and validation. If no <code>ValidationError</code> exception is raised, you know the resulting model instance is valid.</p> <p>Fields of a model can be accessed as normal attributes of the <code>user</code> object:</p> <pre><code>assert user.name == 'Jane Doe'  # (1)!\nassert user.id == 123  # (2)!\nassert isinstance(user.id, int)\n</code></pre> <ol> <li><code>name</code> wasn't set when <code>user</code> was initialized, so the default value was used.    The <code>model_fields_set</code> attribute can be    inspected to check the field names explicitly set during instantiation.</li> <li>Note that the string <code>'123'</code> was coerced to an integer and its value is <code>123</code>.    More details on Pydantic's coercion logic can be found in the Data Conversion section.</li> </ol> <p>The model instance can be serialized using the <code>model_dump</code> method:</p> <pre><code>assert user.model_dump() == {'id': 123, 'name': 'Jane Doe'}\n</code></pre> <p>Calling dict on the instance will also provide a dictionary, but nested fields will not be recursively converted into dictionaries. <code>model_dump</code> also provides numerous arguments to customize the serialization result.</p> <p>By default, models are mutable and field values can be changed through attribute assignment:</p> <pre><code>user.id = 321\nassert user.id == 321\n</code></pre> <p>Warning</p> <p>When defining your models, watch out for naming collisions between your field name and its type annotation.</p> <p>For example, the following will not behave as expected and would yield a validation error:</p> <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel\n\n\nclass Boo(BaseModel):\n    int: Optional[int] = None\n\n\nm = Boo(int=123)  # Will fail to validate.\n</code></pre> <p>Because of how Python evaluates annotated assignment statements, the statement is equivalent to <code>int: None = None</code>, thus leading to a validation error.</p>"},{"location":"concepts/models/#model-methods-and-properties","title":"Model methods and properties","text":"<p>The example above only shows the tip of the iceberg of what models can do. Models possess the following methods and attributes:</p> <ul> <li><code>model_validate()</code>: Validates the given object against the Pydantic model. See Validating data.</li> <li><code>model_validate_json()</code>: Validates the given JSON data against the Pydantic model. See     Validating data.</li> <li><code>model_construct()</code>: Creates models without running validation. See     Creating models without validation.</li> <li><code>model_dump()</code>: Returns a dictionary of the model's fields and values. See     Serialization.</li> <li><code>model_dump_json()</code>: Returns a JSON string representation of <code>model_dump()</code>. See Serialization.</li> <li><code>model_copy()</code>: Returns a copy (by default, shallow copy) of the model. See     Serialization.</li> <li><code>model_json_schema()</code>: Returns a jsonable dictionary representing the model's JSON Schema. See JSON Schema.</li> <li><code>model_fields</code>: A mapping between field names and their definitions (<code>FieldInfo</code> instances).</li> <li><code>model_computed_fields</code>: A mapping between computed field names and their definitions (<code>ComputedFieldInfo</code> instances).</li> <li><code>model_extra</code>: The extra fields set during validation.</li> <li><code>model_fields_set</code>: The set of fields which were explicitly provided when the model was initialized.</li> <li><code>model_parametrized_name()</code>: Computes the class name for parametrizations of generic classes.</li> <li><code>model_post_init()</code>: Performs additional actions after the model is initialized.</li> <li><code>model_rebuild()</code>: Rebuilds the model schema, which also supports building recursive generic models.     See Rebuilding model schema.</li> </ul> <p>Note</p> <p>See the API documentation of <code>BaseModel</code> for the class definition including a full list of methods and attributes.</p> <p>Tip</p> <p>See Changes to <code>pydantic.BaseModel</code> in the Migration Guide for details on changes from Pydantic V1.</p>"},{"location":"concepts/models/#nested-models","title":"Nested models","text":"<p>More complex hierarchical data structures can be defined using models themselves as types in annotations.</p> <pre><code>from typing import List, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    count: int\n    size: Optional[float] = None\n\n\nclass Bar(BaseModel):\n    apple: str = 'x'\n    banana: str = 'y'\n\n\nclass Spam(BaseModel):\n    foo: Foo\n    bars: List[Bar]\n\n\nm = Spam(foo={'count': 4}, bars=[{'apple': 'x1'}, {'apple': 'x2'}])\nprint(m)\n\"\"\"\nfoo=Foo(count=4, size=None) bars=[Bar(apple='x1', banana='y'), Bar(apple='x2', banana='y')]\n\"\"\"\nprint(m.model_dump())\n\"\"\"\n{\n    'foo': {'count': 4, 'size': None},\n    'bars': [{'apple': 'x1', 'banana': 'y'}, {'apple': 'x2', 'banana': 'y'}],\n}\n\"\"\"\n</code></pre> <p>Self-referencing models are supported. For more details, see postponed annotations.</p>"},{"location":"concepts/models/#rebuilding-model-schema","title":"Rebuilding model schema","text":"<p>When you define a model class in your code, Pydantic will analyze the body of the class to collect a variety of information required to perform validation and serialization, gathered in a core schema. Notably, the model's type annotations are evaluated to understand the valid types for each field (more information can be found in the Architecture documentation). However, it might be the case that annotations refer to symbols not defined when the model class is being created. To circumvent this issue, the <code>model_rebuild()</code> method can be used:</p> <pre><code>from pydantic import BaseModel, PydanticUserError\n\n\nclass Foo(BaseModel):\n    x: 'Bar'  # (1)!\n\n\ntry:\n    Foo.model_json_schema()\nexcept PydanticUserError as e:\n    print(e)\n    \"\"\"\n    `Foo` is not fully defined; you should define `Bar`, then call `Foo.model_rebuild()`.\n\n    For further information visit https://errors.pydantic.dev/2/u/class-not-fully-defined\n    \"\"\"\n\n\nclass Bar(BaseModel):\n    pass\n\n\nFoo.model_rebuild()\nprint(Foo.model_json_schema())\n\"\"\"\n{\n    '$defs': {'Bar': {'properties': {}, 'title': 'Bar', 'type': 'object'}},\n    'properties': {'x': {'$ref': '#/$defs/Bar'}},\n    'required': ['x'],\n    'title': 'Foo',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <ol> <li><code>Bar</code> is not yet defined when the <code>Foo</code> class is being created. For this reason,    a string annotation    is being used. Alternatively, postponed annotations can be used with the <code>from __future__ import annotations</code> import    (see PEP 563).</li> </ol> <p>Pydantic tries to determine when this is necessary automatically and error if it wasn't done, but you may want to call <code>model_rebuild()</code> proactively when dealing with recursive models or generics.</p> <p>In V2, <code>model_rebuild()</code> replaced <code>update_forward_refs()</code> from V1. There are some slight differences with the new behavior. The biggest change is that when calling <code>model_rebuild()</code> on the outermost model, it builds a core schema used for validation of the whole model (nested models and all), so all types at all levels need to be ready before <code>model_rebuild()</code> is called.</p>"},{"location":"concepts/models/#arbitrary-class-instances","title":"Arbitrary class instances","text":"<p>(Formerly known as \"ORM Mode\"/<code>from_orm</code>).</p> <p>Pydantic models can also be created from arbitrary class instances by reading the instance attributes corresponding to the model field names. One common application of this functionality is integration with object-relational mappings (ORMs).</p> <p>To do this, set the <code>from_attributes</code> config value to <code>True</code> (see the documentation on Configuration for more details).</p> <p>The example here uses SQLAlchemy, but the same approach should work for any ORM.</p> <pre><code>from typing import List\n\nfrom sqlalchemy import ARRAY, String\nfrom sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, ConfigDict, StringConstraints\n\n\nclass Base(DeclarativeBase):\n    pass\n\n\nclass CompanyOrm(Base):\n    __tablename__ = 'companies'\n\n    id: Mapped[int] = mapped_column(primary_key=True, nullable=False)\n    public_key: Mapped[str] = mapped_column(\n        String(20), index=True, nullable=False, unique=True\n    )\n    domains: Mapped[List[str]] = mapped_column(ARRAY(String(255)))\n\n\nclass CompanyModel(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    id: int\n    public_key: Annotated[str, StringConstraints(max_length=20)]\n    domains: List[Annotated[str, StringConstraints(max_length=255)]]\n\n\nco_orm = CompanyOrm(\n    id=123,\n    public_key='foobar',\n    domains=['example.com', 'foobar.com'],\n)\nprint(co_orm)\n#&gt; &lt;__main__.CompanyOrm object at 0x0123456789ab&gt;\nco_model = CompanyModel.model_validate(co_orm)\nprint(co_model)\n#&gt; id=123 public_key='foobar' domains=['example.com', 'foobar.com']\n</code></pre>"},{"location":"concepts/models/#nested-attributes","title":"Nested attributes","text":"<p>When using attributes to parse models, model instances will be created from both top-level attributes and deeper-nested attributes as appropriate.</p> <p>Here is an example demonstrating the principle:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ConfigDict\n\n\nclass PetCls:\n    def __init__(self, *, name: str, species: str):\n        self.name = name\n        self.species = species\n\n\nclass PersonCls:\n    def __init__(self, *, name: str, age: float = None, pets: List[PetCls]):\n        self.name = name\n        self.age = age\n        self.pets = pets\n\n\nclass Pet(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    name: str\n    species: str\n\n\nclass Person(BaseModel):\n    model_config = ConfigDict(from_attributes=True)\n\n    name: str\n    age: float = None\n    pets: List[Pet]\n\n\nbones = PetCls(name='Bones', species='dog')\norion = PetCls(name='Orion', species='cat')\nanna = PersonCls(name='Anna', age=20, pets=[bones, orion])\nanna_model = Person.model_validate(anna)\nprint(anna_model)\n\"\"\"\nname='Anna' age=20.0 pets=[Pet(name='Bones', species='dog'), Pet(name='Orion', species='cat')]\n\"\"\"\n</code></pre>"},{"location":"concepts/models/#error-handling","title":"Error handling","text":"<p>Pydantic will raise a <code>ValidationError</code> exception whenever it finds an error in the data it's validating.</p> <p>A single exception will be raised regardless of the number of errors found, and that validation error will contain information about all of the errors and how they happened.</p> <p>See Error Handling for details on standard and custom errors.</p> <p>As a demonstration:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    list_of_ints: List[int]\n    a_float: float\n\n\ndata = dict(\n    list_of_ints=['1', 2, 'bad'],\n    a_float='not a float',\n)\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for Model\n    list_of_ints.2\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bad', input_type=str]\n    a_float\n      Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='not a float', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/models/#validating-data","title":"Validating data","text":"<p>Pydantic provides three methods on models classes for parsing data:</p> <ul> <li><code>model_validate()</code>: this is very similar to the <code>__init__</code> method of the model,   except it takes a dictionary or an object rather than keyword arguments. If the object passed cannot be validated,   or if it's not a dictionary or instance of the model in question, a <code>ValidationError</code> will be raised.</li> <li><code>model_validate_json()</code>: this validates the provided data as a JSON string or <code>bytes</code> object.   If your incoming data is a JSON payload, this is generally considered faster (instead of manually parsing the data as a dictionary).   Learn more about JSON parsing in the JSON section of the docs.</li> <li><code>model_validate_strings()</code>: this takes a dictionary (can be nested) with string keys and values and validates the data in JSON mode so that said strings can be coerced into the correct types.</li> </ul> <pre><code>from datetime import datetime\nfrom typing import Optional\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass User(BaseModel):\n    id: int\n    name: str = 'John Doe'\n    signup_ts: Optional[datetime] = None\n\n\nm = User.model_validate({'id': 123, 'name': 'James'})\nprint(m)\n#&gt; id=123 name='James' signup_ts=None\n\ntry:\n    User.model_validate(['not', 'a', 'dict'])\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for User\n      Input should be a valid dictionary or instance of User [type=model_type, input_value=['not', 'a', 'dict'], input_type=list]\n    \"\"\"\n\nm = User.model_validate_json('{\"id\": 123, \"name\": \"James\"}')\nprint(m)\n#&gt; id=123 name='James' signup_ts=None\n\ntry:\n    m = User.model_validate_json('{\"id\": 123, \"name\": 123}')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for User\n    name\n      Input should be a valid string [type=string_type, input_value=123, input_type=int]\n    \"\"\"\n\ntry:\n    m = User.model_validate_json('invalid JSON')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for User\n      Invalid JSON: expected value at line 1 column 1 [type=json_invalid, input_value='invalid JSON', input_type=str]\n    \"\"\"\n\nm = User.model_validate_strings({'id': '123', 'name': 'James'})\nprint(m)\n#&gt; id=123 name='James' signup_ts=None\n\nm = User.model_validate_strings(\n    {'id': '123', 'name': 'James', 'signup_ts': '2024-04-01T12:00:00'}\n)\nprint(m)\n#&gt; id=123 name='James' signup_ts=datetime.datetime(2024, 4, 1, 12, 0)\n\ntry:\n    m = User.model_validate_strings(\n        {'id': '123', 'name': 'James', 'signup_ts': '2024-04-01'}, strict=True\n    )\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for User\n    signup_ts\n      Input should be a valid datetime, invalid datetime separator, expected `T`, `t`, `_` or space [type=datetime_parsing, input_value='2024-04-01', input_type=str]\n    \"\"\"\n</code></pre> <p>If you want to validate serialized data in a format other than JSON, you should load the data into a dictionary yourself and then pass it to <code>model_validate</code>.</p> <p>Note</p> <p>Depending on the types and model configs involved, <code>model_validate</code> and <code>model_validate_json</code> may have different validation behavior. If you have data coming from a non-JSON source, but want the same validation behavior and errors you'd get from <code>model_validate_json</code>, our recommendation for now is to use either use <code>model_validate_json(json.dumps(data))</code>, or use <code>model_validate_strings</code> if the data takes the form of a (potentially nested) dictionary with string keys and values.</p> <p>Note</p> <p>If you're passing in an instance of a model to <code>model_validate</code>, you will want to consider setting <code>revalidate_instances</code> in the model's config. If you don't set this value, then validation will be skipped on model instances. See the below example:</p> <code>revalidate_instances='never'</code> <code>revalidate_instances='always'</code> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: int\n\n\nm = Model(a=0)\n# note: setting `validate_assignment` to `True` in the config can prevent this kind of misbehavior.\nm.a = 'not an int'\n\n# doesn't raise a validation error even though m is invalid\nm2 = Model.model_validate(m)\n</code></pre> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    a: int\n\n    model_config = ConfigDict(revalidate_instances='always')\n\n\nm = Model(a=0)\n# note: setting `validate_assignment` to `True` in the config can prevent this kind of misbehavior.\nm.a = 'not an int'\n\ntry:\n    m2 = Model.model_validate(m)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    a\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='not an int', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/models/#creating-models-without-validation","title":"Creating models without validation","text":"<p>Pydantic also provides the <code>model_construct()</code> method, which allows models to be created without validation. This can be useful in at least a few cases:</p> <ul> <li>when working with complex data that is already known to be valid (for performance reasons)</li> <li>when one or more of the validator functions are non-idempotent</li> <li>when one or more of the validator functions have side effects that you don't want to be triggered.</li> </ul> <p>Warning</p> <p><code>model_construct()</code> does not do any validation, meaning it can create models which are invalid. You should only ever use the <code>model_construct()</code> method with data which has already been validated, or that you definitely trust.</p> <p>Note</p> <p>In Pydantic V2, the performance gap between validation (either with direct instantiation or the <code>model_validate*</code> methods) and <code>model_construct()</code> has been narrowed considerably. For simple models, going with validation may even be faster. If you are using <code>model_construct()</code> for performance reasons, you may want to profile your use case before assuming it is actually faster.</p> <p>Note that for root models, the root value can be passed to <code>model_construct()</code> positionally, instead of using a keyword argument.</p> <p>Here are some additional notes on the behavior of <code>model_construct()</code>:</p> <ul> <li>When we say \"no validation is performed\" \u2014 this includes converting dictionaries to model instances. So if you have a field   referring to a model type, you will need to convert the inner dictionary to a model yourself.</li> <li>If you do not pass keyword arguments for fields with defaults, the default values will still be used.</li> <li>For models with private attributes, the <code>__pydantic_private__</code> dictionary will be populated the same as it would be when   creating the model with validation.</li> <li>No <code>__init__</code> method from the model or any of its parent classes will be called, even when a custom <code>__init__</code> method is defined.</li> </ul> <p>On extra fields behavior with <code>model_construct()</code></p> <ul> <li>For models with <code>extra</code> set to <code>'allow'</code>, data not corresponding to fields will be correctly stored in the <code>__pydantic_extra__</code> dictionary and saved to the model's <code>__dict__</code> attribute.</li> <li>For models with <code>extra</code> set to <code>'ignore'</code>, data not corresponding to fields will be ignored \u2014 that is, not stored in <code>__pydantic_extra__</code> or <code>__dict__</code> on the instance.</li> <li>Unlike when instiating the model with validation, a call to <code>model_construct()</code> with <code>extra</code> set to <code>'forbid'</code> doesn't raise an error in the presence of data not corresponding to fields. Rather, said input data is simply ignored.</li> </ul>"},{"location":"concepts/models/#generic-models","title":"Generic models","text":"<p>Pydantic supports the creation of generic models to make it easier to reuse a common model structure.</p> <p>In order to declare a generic model, you should follow the following steps:</p> <ol> <li>Declare one or more type variables to use to parameterize your model.</li> <li>Declare a pydantic model that inherits from <code>BaseModel</code> and <code>typing.Generic</code> (in this specific order),   and add the list of type variables you declared previously as parameters to the <code>Generic</code> parent.</li> <li>Use the type variables as annotations where you will want to replace them with other types.</li> </ol> <p>PEP 695 support</p> <p>Pydantic does not support the new syntax for generic classes (introduced by PEP 695), available since Python 3.12. Progress can be tracked in this issue.</p> <p>Here is an example using a generic Pydantic model to create an easily-reused HTTP response payload wrapper:</p> <pre><code>from typing import Generic, List, Optional, TypeVar\n\nfrom pydantic import BaseModel, ValidationError\n\nDataT = TypeVar('DataT')  # (1)!\n\n\nclass DataModel(BaseModel):\n    numbers: List[int]\n    people: List[str]\n\n\nclass Response(BaseModel, Generic[DataT]):  # (2)!\n    data: Optional[DataT] = None  # (3)!\n\n\nprint(Response[int](data=1))\n#&gt; data=1\nprint(Response[str](data='value'))\n#&gt; data='value'\nprint(Response[str](data='value').model_dump())\n#&gt; {'data': 'value'}\n\ndata = DataModel(numbers=[1, 2, 3], people=[])\nprint(Response[DataModel](data=data).model_dump())\n#&gt; {'data': {'numbers': [1, 2, 3], 'people': []}}\ntry:\n    Response[int](data='value')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Response[int]\n    data\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='value', input_type=str]\n    \"\"\"\n</code></pre> <ol> <li>Refers to step 1 described above.</li> <li>Refers to step 2 described above.</li> <li>Refers to step 3 described above.</li> </ol> <p>Any configuration, validation or serialization logic set on the generic model will also be applied to the parametrized classes, in the same way as when inheriting from a model class. Any custom methods or attributes will also be inherited.</p> <p>Generic models also integrate properly with type checkers, so you get all the type checking you would expect if you were to declare a distinct type for each parametrization.</p> <p>Note</p> <p>Internally, Pydantic creates subclasses of the generic model at runtime when the generic model class is parametrized. These classes are cached, so there should be minimal overhead introduced by the use of generics models.</p> <p>To inherit from a generic model and preserve the fact that it is generic, the subclass must also inherit from <code>Generic</code>:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel\n\nTypeX = TypeVar('TypeX')\n\n\nclass BaseClass(BaseModel, Generic[TypeX]):\n    X: TypeX\n\n\nclass ChildClass(BaseClass[TypeX], Generic[TypeX]):\n    pass\n\n\n# Parametrize `TypeX` with `int`:\nprint(ChildClass[int](X=1))\n#&gt; X=1\n</code></pre> <p>You can also create a generic subclass of a model that partially or fully replaces the type variables in the superclass:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel\n\nTypeX = TypeVar('TypeX')\nTypeY = TypeVar('TypeY')\nTypeZ = TypeVar('TypeZ')\n\n\nclass BaseClass(BaseModel, Generic[TypeX, TypeY]):\n    x: TypeX\n    y: TypeY\n\n\nclass ChildClass(BaseClass[int, TypeY], Generic[TypeY, TypeZ]):\n    z: TypeZ\n\n\n# Parametrize `TypeY` with `str`:\nprint(ChildClass[str, int](x='1', y='y', z='3'))\n#&gt; x=1 y='y' z=3\n</code></pre> <p>If the name of the concrete subclasses is important, you can also override the default name generation by overriding the <code>model_parametrized_name()</code> method:</p> <pre><code>from typing import Any, Generic, Tuple, Type, TypeVar\n\nfrom pydantic import BaseModel\n\nDataT = TypeVar('DataT')\n\n\nclass Response(BaseModel, Generic[DataT]):\n    data: DataT\n\n    @classmethod\n    def model_parametrized_name(cls, params: Tuple[Type[Any], ...]) -&gt; str:\n        return f'{params[0].__name__.title()}Response'\n\n\nprint(repr(Response[int](data=1)))\n#&gt; IntResponse(data=1)\nprint(repr(Response[str](data='a')))\n#&gt; StrResponse(data='a')\n</code></pre> <p>You can use parametrized generic models as types in other models:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel\n\nT = TypeVar('T')\n\n\nclass ResponseModel(BaseModel, Generic[T]):\n    content: T\n\n\nclass Product(BaseModel):\n    name: str\n    price: float\n\n\nclass Order(BaseModel):\n    id: int\n    product: ResponseModel[Product]\n\n\nproduct = Product(name='Apple', price=0.5)\nresponse = ResponseModel[Product](content=product)\norder = Order(id=1, product=response)\nprint(repr(order))\n\"\"\"\nOrder(id=1, product=ResponseModel[Product](content=Product(name='Apple', price=0.5)))\n\"\"\"\n</code></pre> <p>Tip</p> <p>When using a parametrized generic model as a type in another model (like <code>product: ResponseModel[Product]</code>), make sure to parametrize said generic model when you initialize the model instance (like <code>response = ResponseModel[Product](content=product)</code>). If you don't, a <code>ValidationError</code> will be raised, as Pydantic doesn't infer the type of the generic model based on the data passed to it.</p> <p>Using the same type variable in nested models allows you to enforce typing relationships at different points in your model:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel, ValidationError\n\nT = TypeVar('T')\n\n\nclass InnerT(BaseModel, Generic[T]):\n    inner: T\n\n\nclass OuterT(BaseModel, Generic[T]):\n    outer: T\n    nested: InnerT[T]\n\n\nnested = InnerT[int](inner=1)\nprint(OuterT[int](outer=1, nested=nested))\n#&gt; outer=1 nested=InnerT[int](inner=1)\ntry:\n    nested = InnerT[str](inner='a')\n    print(OuterT[int](outer='a', nested=nested))\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for OuterT[int]\n    outer\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    nested\n      Input should be a valid dictionary or instance of InnerT[int] [type=model_type, input_value=InnerT[str](inner='a'), input_type=InnerT[str]]\n    \"\"\"\n</code></pre> <p>Warning</p> <p>While it may not raise an error, we strongly advise against using parametrized generics in <code>isinstance()</code> checks.</p> <p>For example, you should not do <code>isinstance(my_model, MyGenericModel[int])</code>. However, it is fine to do <code>isinstance(my_model, MyGenericModel)</code> (note that, for standard generics, it would raise an error to do a subclass check with a parameterized generic class).</p> <p>If you need to perform <code>isinstance()</code> checks against parametrized generics, you can do this by subclassing the parametrized generic class:</p> <pre><code>class MyIntModel(MyGenericModel[int]): ...\n\nisinstance(my_model, MyIntModel)\n</code></pre>"},{"location":"concepts/models/#validation-of-unparametrized-type-variables","title":"Validation of unparametrized type variables","text":"<p>When leaving type variables unparametrized, Pydantic treats generic models similarly to how it treats built-in generic types like <code>list</code> and <code>dict</code>:</p> <ul> <li>If the type variable is bound   or constrained to a specific type,   it will be used.</li> <li>If the type variable has a default type (as specified by PEP 696), it will be used.</li> <li>For unbound or unconstrained type variables, Pydantic will fallback to <code>Any</code>.</li> </ul> <pre><code>from typing import Generic\n\nfrom typing_extensions import TypeVar\n\nfrom pydantic import BaseModel, ValidationError\n\nT = TypeVar('T')\nU = TypeVar('U', bound=int)\nV = TypeVar('V', default=str)\n\n\nclass Model(BaseModel, Generic[T, U, V]):\n    t: T\n    u: U\n    v: V\n\n\nprint(Model(t='t', u=1, v='v'))\n#&gt; t='t' u=1 v='v'\n\ntry:\n    Model(t='t', u='u', v=1)\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    2 validation errors for Model\n    u\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='u', input_type=str]\n    v\n      Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    \"\"\"\n</code></pre> <p>Warning</p> <p>In some cases, validation against an unparametrized generic model can lead to data loss. Specifically, if a subtype of the type variable upper bound, constraints, or default is being used and the model isn't explicitly parametrized, the resulting type will not be the one being provided:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel\n\nItemT = TypeVar('ItemT', bound='ItemBase')\n\n\nclass ItemBase(BaseModel): ...\n\n\nclass IntItem(ItemBase):\n    value: int\n\n\nclass ItemHolder(BaseModel, Generic[ItemT]):\n    item: ItemT\n\n\nloaded_data = {'item': {'value': 1}}\n\n\nprint(ItemHolder(**loaded_data))  # (1)!\n#&gt; item=ItemBase()\n\nprint(ItemHolder[IntItem](**loaded_data))  # (2)!\n#&gt; item=IntItem(value=1)\n</code></pre> <ol> <li>When the generic isn't parametrized, the input data is validated against the <code>ItemT</code> upper bound.    Given that <code>ItemBase</code> has no fields, the <code>item</code> field information is lost.</li> <li>In this case, the type variable is explicitly parametrized, so the input data is validated against the <code>IntItem</code> class.</li> </ol>"},{"location":"concepts/models/#serialization-of-unparametrized-type-variables","title":"Serialization of unparametrized type variables","text":"<p>The behavior of serialization differs when using type variables with upper bounds, constraints, or a default value:</p> <p>If a Pydantic model is used in a type variable upper bound and the type variable is never parametrized, then Pydantic will use the upper bound for validation but treat the value as <code>Any</code> in terms of serialization:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel\n\n\nclass ErrorDetails(BaseModel):\n    foo: str\n\n\nErrorDataT = TypeVar('ErrorDataT', bound=ErrorDetails)\n\n\nclass Error(BaseModel, Generic[ErrorDataT]):\n    message: str\n    details: ErrorDataT\n\n\nclass MyErrorDetails(ErrorDetails):\n    bar: str\n\n\n# serialized as Any\nerror = Error(\n    message='We just had an error',\n    details=MyErrorDetails(foo='var', bar='var2'),\n)\nassert error.model_dump() == {\n    'message': 'We just had an error',\n    'details': {\n        'foo': 'var',\n        'bar': 'var2',\n    },\n}\n\n# serialized using the concrete parametrization\n# note that `'bar': 'var2'` is missing\nerror = Error[ErrorDetails](\n    message='We just had an error',\n    details=ErrorDetails(foo='var'),\n)\nassert error.model_dump() == {\n    'message': 'We just had an error',\n    'details': {\n        'foo': 'var',\n    },\n}\n</code></pre> <p>Here's another example of the above behavior, enumerating all permutations regarding bound specification and generic type parametrization:</p> <pre><code>from typing import Generic, TypeVar\n\nfrom pydantic import BaseModel\n\nTBound = TypeVar('TBound', bound=BaseModel)\nTNoBound = TypeVar('TNoBound')\n\n\nclass IntValue(BaseModel):\n    value: int\n\n\nclass ItemBound(BaseModel, Generic[TBound]):\n    item: TBound\n\n\nclass ItemNoBound(BaseModel, Generic[TNoBound]):\n    item: TNoBound\n\n\nitem_bound_inferred = ItemBound(item=IntValue(value=3))\nitem_bound_explicit = ItemBound[IntValue](item=IntValue(value=3))\nitem_no_bound_inferred = ItemNoBound(item=IntValue(value=3))\nitem_no_bound_explicit = ItemNoBound[IntValue](item=IntValue(value=3))\n\n# calling `print(x.model_dump())` on any of the above instances results in the following:\n#&gt; {'item': {'value': 3}}\n</code></pre> <p>However, if constraints or a default value (as per PEP 696) is being used, then the default type or constraints will be used for both validation and serialization if the type variable is not parametrized. You can override this behavior using <code>SerializeAsAny</code>:</p> <pre><code>from typing import Generic\n\nfrom typing_extensions import TypeVar\n\nfrom pydantic import BaseModel, SerializeAsAny\n\n\nclass ErrorDetails(BaseModel):\n    foo: str\n\n\nErrorDataT = TypeVar('ErrorDataT', default=ErrorDetails)\n\n\nclass Error(BaseModel, Generic[ErrorDataT]):\n    message: str\n    details: ErrorDataT\n\n\nclass MyErrorDetails(ErrorDetails):\n    bar: str\n\n\n# serialized using the default's serializer\nerror = Error(\n    message='We just had an error',\n    details=MyErrorDetails(foo='var', bar='var2'),\n)\nassert error.model_dump() == {\n    'message': 'We just had an error',\n    'details': {\n        'foo': 'var',\n    },\n}\n# If `ErrorDataT` was using an upper bound, `bar` would be present in `details`.\n\n\nclass SerializeAsAnyError(BaseModel, Generic[ErrorDataT]):\n    message: str\n    details: SerializeAsAny[ErrorDataT]\n\n\n# serialized as Any\nerror = SerializeAsAnyError(\n    message='We just had an error',\n    details=MyErrorDetails(foo='var', bar='baz'),\n)\nassert error.model_dump() == {\n    'message': 'We just had an error',\n    'details': {\n        'foo': 'var',\n        'bar': 'baz',\n    },\n}\n</code></pre>"},{"location":"concepts/models/#dynamic-model-creation","title":"Dynamic model creation","text":"API Documentation <p><code>pydantic.main.create_model</code></p> <p>There are some occasions where it is desirable to create a model using runtime information to specify the fields. For this Pydantic provides the <code>create_model</code> function to allow models to be created on the fly:</p> <pre><code>from pydantic import BaseModel, create_model\n\nDynamicFoobarModel = create_model(\n    'DynamicFoobarModel', foo=(str, ...), bar=(int, 123)\n)\n\n\nclass StaticFoobarModel(BaseModel):\n    foo: str\n    bar: int = 123\n</code></pre> <p>Here <code>StaticFoobarModel</code> and <code>DynamicFoobarModel</code> are identical.</p> <p>Fields are defined by one of the following tuple forms:</p> <ul> <li><code>(&lt;type&gt;, &lt;default value&gt;)</code></li> <li><code>(&lt;type&gt;, Field(...))</code></li> <li><code>typing.Annotated[&lt;type&gt;, Field(...)]</code></li> </ul> <p>Using a <code>Field(...)</code> call as the second argument in the tuple (the default value) allows for more advanced field configuration. Thus, the following are analogous:</p> <pre><code>from pydantic import BaseModel, Field, create_model\n\nDynamicModel = create_model(\n    'DynamicModel',\n    foo=(str, Field(..., description='foo description', alias='FOO')),\n)\n\n\nclass StaticModel(BaseModel):\n    foo: str = Field(..., description='foo description', alias='FOO')\n</code></pre> <p>The special keyword arguments <code>__config__</code> and <code>__base__</code> can be used to customize the new model. This includes extending a base model with extra fields.</p> <pre><code>from pydantic import BaseModel, create_model\n\n\nclass FooModel(BaseModel):\n    foo: str\n    bar: int = 123\n\n\nBarModel = create_model(\n    'BarModel',\n    apple=(str, 'russet'),\n    banana=(str, 'yellow'),\n    __base__=FooModel,\n)\nprint(BarModel)\n#&gt; &lt;class '__main__.BarModel'&gt;\nprint(BarModel.model_fields.keys())\n#&gt; dict_keys(['foo', 'bar', 'apple', 'banana'])\n</code></pre> <p>You can also add validators by passing a dict to the <code>__validators__</code> argument.</p> <pre><code>from pydantic import ValidationError, create_model, field_validator\n\n\ndef username_alphanumeric(cls, v):\n    assert v.isalnum(), 'must be alphanumeric'\n    return v\n\n\nvalidators = {\n    'username_validator': field_validator('username')(username_alphanumeric)\n}\n\nUserModel = create_model(\n    'UserModel', username=(str, ...), __validators__=validators\n)\n\nuser = UserModel(username='scolvin')\nprint(user)\n#&gt; username='scolvin'\n\ntry:\n    UserModel(username='scolvi%n')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for UserModel\n    username\n      Assertion failed, must be alphanumeric [type=assertion_error, input_value='scolvi%n', input_type=str]\n    \"\"\"\n</code></pre> <p>Note</p> <p>To pickle a dynamically created model:</p> <ul> <li>the model must be defined globally</li> <li>it must provide <code>__module__</code></li> </ul>"},{"location":"concepts/models/#rootmodel-and-custom-root-types","title":"<code>RootModel</code> and custom root types","text":"API Documentation <p><code>pydantic.root_model.RootModel</code></p> <p>Pydantic models can be defined with a \"custom root type\" by subclassing <code>pydantic.RootModel</code>.</p> <p>The root type can be any type supported by Pydantic, and is specified by the generic parameter to <code>RootModel</code>. The root value can be passed to the model <code>__init__</code> or <code>model_validate</code> via the first and only argument.</p> <p>Here's an example of how this works:</p> <pre><code>from typing import Dict, List\n\nfrom pydantic import RootModel\n\nPets = RootModel[List[str]]\nPetsByName = RootModel[Dict[str, str]]\n\n\nprint(Pets(['dog', 'cat']))\n#&gt; root=['dog', 'cat']\nprint(Pets(['dog', 'cat']).model_dump_json())\n#&gt; [\"dog\",\"cat\"]\nprint(Pets.model_validate(['dog', 'cat']))\n#&gt; root=['dog', 'cat']\nprint(Pets.model_json_schema())\n\"\"\"\n{'items': {'type': 'string'}, 'title': 'RootModel[List[str]]', 'type': 'array'}\n\"\"\"\n\nprint(PetsByName({'Otis': 'dog', 'Milo': 'cat'}))\n#&gt; root={'Otis': 'dog', 'Milo': 'cat'}\nprint(PetsByName({'Otis': 'dog', 'Milo': 'cat'}).model_dump_json())\n#&gt; {\"Otis\":\"dog\",\"Milo\":\"cat\"}\nprint(PetsByName.model_validate({'Otis': 'dog', 'Milo': 'cat'}))\n#&gt; root={'Otis': 'dog', 'Milo': 'cat'}\n</code></pre> <p>If you want to access items in the <code>root</code> field directly or to iterate over the items, you can implement custom <code>__iter__</code> and <code>__getitem__</code> functions, as shown in the following example.</p> <pre><code>from typing import List\n\nfrom pydantic import RootModel\n\n\nclass Pets(RootModel):\n    root: List[str]\n\n    def __iter__(self):\n        return iter(self.root)\n\n    def __getitem__(self, item):\n        return self.root[item]\n\n\npets = Pets.model_validate(['dog', 'cat'])\nprint(pets[0])\n#&gt; dog\nprint([pet for pet in pets])\n#&gt; ['dog', 'cat']\n</code></pre> <p>You can also create subclasses of the parametrized root model directly:</p> <pre><code>from typing import List\n\nfrom pydantic import RootModel\n\n\nclass Pets(RootModel[List[str]]):\n    def describe(self) -&gt; str:\n        return f'Pets: {\", \".join(self.root)}'\n\n\nmy_pets = Pets.model_validate(['dog', 'cat'])\n\nprint(my_pets.describe())\n#&gt; Pets: dog, cat\n</code></pre>"},{"location":"concepts/models/#faux-immutability","title":"Faux immutability","text":"<p>Models can be configured to be immutable via <code>model_config['frozen'] = True</code>. When this is set, attempting to change the values of instance attributes will raise errors. See the API reference for more details.</p> <p>Note</p> <p>This behavior was achieved in Pydantic V1 via the config setting <code>allow_mutation = False</code>. This config flag is deprecated in Pydantic V2, and has been replaced with <code>frozen</code>.</p> <p>Warning</p> <p>In Python, immutability is not enforced. Developers have the ability to modify objects that are conventionally considered \"immutable\" if they choose to do so.</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass FooBarModel(BaseModel):\n    model_config = ConfigDict(frozen=True)\n\n    a: str\n    b: dict\n\n\nfoobar = FooBarModel(a='hello', b={'apple': 'pear'})\n\ntry:\n    foobar.a = 'different'\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for FooBarModel\n    a\n      Instance is frozen [type=frozen_instance, input_value='different', input_type=str]\n    \"\"\"\n\nprint(foobar.a)\n#&gt; hello\nprint(foobar.b)\n#&gt; {'apple': 'pear'}\nfoobar.b['apple'] = 'grape'\nprint(foobar.b)\n#&gt; {'apple': 'grape'}\n</code></pre> <p>Trying to change <code>a</code> caused an error, and <code>a</code> remains unchanged. However, the dict <code>b</code> is mutable, and the immutability of <code>foobar</code> doesn't stop <code>b</code> from being changed.</p>"},{"location":"concepts/models/#abstract-base-classes","title":"Abstract base classes","text":"<p>Pydantic models can be used alongside Python's Abstract Base Classes (ABCs).</p> <pre><code>import abc\n\nfrom pydantic import BaseModel\n\n\nclass FooBarModel(BaseModel, abc.ABC):\n    a: str\n    b: int\n\n    @abc.abstractmethod\n    def my_abstract_method(self):\n        pass\n</code></pre>"},{"location":"concepts/models/#field-ordering","title":"Field ordering","text":"<p>Field order affects models in the following ways:</p> <ul> <li>field order is preserved in the model schema</li> <li>field order is preserved in validation errors</li> <li>field order is preserved by <code>.model_dump()</code> and <code>.model_dump_json()</code> etc.</li> </ul> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    a: int\n    b: int = 2\n    c: int = 1\n    d: int = 0\n    e: float\n\n\nprint(Model.model_fields.keys())\n#&gt; dict_keys(['a', 'b', 'c', 'd', 'e'])\nm = Model(e=2, a=1)\nprint(m.model_dump())\n#&gt; {'a': 1, 'b': 2, 'c': 1, 'd': 0, 'e': 2.0}\ntry:\n    Model(a='x', b='x', c='x', d='x', e='x')\nexcept ValidationError as err:\n    error_locations = [e['loc'] for e in err.errors()]\n\nprint(error_locations)\n#&gt; [('a',), ('b',), ('c',), ('d',), ('e',)]\n</code></pre>"},{"location":"concepts/models/#required-fields","title":"Required fields","text":"<p>To declare a field as required, you may declare it using an annotation, or an annotation in combination with a <code>Field</code> specification. You may also use <code>Ellipsis</code>/<code>...</code> to emphasize that a field is required, especially when using the <code>Field</code> constructor.</p> <p>The <code>Field</code> function is primarily used to configure settings like <code>alias</code> or <code>description</code> for an attribute. The constructor supports <code>Ellipsis</code>/<code>...</code> as the sole positional argument. This is used as a way to indicate that said field is mandatory, though it's the type hint that enforces this requirement.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Model(BaseModel):\n    a: int\n    b: int = ...\n    c: int = Field(..., alias='C')\n</code></pre> <p>Here <code>a</code>, <code>b</code> and <code>c</code> are all required. However, this use of <code>b: int = ...</code> does not work properly with mypy, and as of v1.0 should be avoided in most cases.</p> <p>Note</p> <p>In Pydantic V1, fields annotated with <code>Optional</code> or <code>Any</code> would be given an implicit default of <code>None</code> even if no default was explicitly specified. This behavior has changed in Pydantic V2, and there are no longer any type annotations that will result in a field having an implicit default value.</p> <p>See the migration guide for more details on changes to required and nullable fields.</p>"},{"location":"concepts/models/#fields-with-non-hashable-default-values","title":"Fields with non-hashable default values","text":"<p>A common source of bugs in python is to use a mutable object as a default value for a function or method argument, as the same instance ends up being reused in each call.</p> <p>The <code>dataclasses</code> module actually raises an error in this case, indicating that you should use the <code>default_factory</code> argument to <code>dataclasses.field</code>.</p> <p>Pydantic also supports the use of a <code>default_factory</code> for non-hashable default values, but it is not required. In the event that the default value is not hashable, Pydantic will deepcopy the default value when creating each instance of the model:</p> <pre><code>from typing import Dict, List\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    item_counts: List[Dict[str, int]] = [{}]\n\n\nm1 = Model()\nm1.item_counts[0]['a'] = 1\nprint(m1.item_counts)\n#&gt; [{'a': 1}]\n\nm2 = Model()\nprint(m2.item_counts)\n#&gt; [{}]\n</code></pre>"},{"location":"concepts/models/#fields-with-dynamic-default-values","title":"Fields with dynamic default values","text":"<p>When declaring a field with a default value, you may want it to be dynamic (i.e. different for each model). To do this, you may want to use a <code>default_factory</code>.</p> <p>Here is an example:</p> <pre><code>from datetime import datetime, timezone\nfrom uuid import UUID, uuid4\n\nfrom pydantic import BaseModel, Field\n\n\ndef datetime_now() -&gt; datetime:\n    return datetime.now(timezone.utc)\n\n\nclass Model(BaseModel):\n    uid: UUID = Field(default_factory=uuid4)\n    updated: datetime = Field(default_factory=datetime_now)\n\n\nm1 = Model()\nm2 = Model()\nassert m1.uid != m2.uid\n</code></pre> <p>You can find more information in the documentation of the <code>Field</code> function.</p>"},{"location":"concepts/models/#automatically-excluded-attributes","title":"Automatically excluded attributes","text":""},{"location":"concepts/models/#class-vars","title":"Class vars","text":"<p>Attributes annotated with <code>typing.ClassVar</code> are properly treated by Pydantic as class variables, and will not become fields on model instances:</p> <pre><code>from typing import ClassVar\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    x: int = 2\n    y: ClassVar[int] = 1\n\n\nm = Model()\nprint(m)\n#&gt; x=2\nprint(Model.y)\n#&gt; 1\n</code></pre>"},{"location":"concepts/models/#private-model-attributes","title":"Private model attributes","text":"API Documentation <p><code>pydantic.fields.PrivateAttr</code></p> <p>Attributes whose name has a leading underscore are not treated as fields by Pydantic, and are not included in the model schema. Instead, these are converted into a \"private attribute\" which is not validated or even set during calls to <code>__init__</code>, <code>model_validate</code>, etc.</p> <p>Note</p> <p>As of Pydantic v2.1.0, you will receive a NameError if trying to use the <code>Field</code> function with a private attribute. Because private attributes are not treated as fields, the Field() function cannot be applied.</p> <p>Here is an example of usage:</p> <pre><code>from datetime import datetime\nfrom random import randint\n\nfrom pydantic import BaseModel, PrivateAttr\n\n\nclass TimeAwareModel(BaseModel):\n    _processed_at: datetime = PrivateAttr(default_factory=datetime.now)\n    _secret_value: str\n\n    def __init__(self, **data):\n        super().__init__(**data)\n        # this could also be done with default_factory\n        self._secret_value = randint(1, 5)\n\n\nm = TimeAwareModel()\nprint(m._processed_at)\n#&gt; 2032-01-02 03:04:05.000006\nprint(m._secret_value)\n#&gt; 3\n</code></pre> <p>Private attribute names must start with underscore to prevent conflicts with model fields. However, dunder names (such as <code>__attr__</code>) are not supported.</p>"},{"location":"concepts/models/#data-conversion","title":"Data conversion","text":"<p>Pydantic may cast input data to force it to conform to model field types, and in some cases this may result in a loss of information. For example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: int\n    b: float\n    c: str\n\n\nprint(Model(a=3.000, b='2.72', c=b'binary data').model_dump())\n#&gt; {'a': 3, 'b': 2.72, 'c': 'binary data'}\n</code></pre> <p>This is a deliberate decision of Pydantic, and is frequently the most useful approach. See here for a longer discussion on the subject.</p> <p>Nevertheless, strict type checking is also supported.</p>"},{"location":"concepts/models/#model-signature","title":"Model signature","text":"<p>All Pydantic models will have their signature generated based on their fields:</p> <pre><code>import inspect\n\nfrom pydantic import BaseModel, Field\n\n\nclass FooModel(BaseModel):\n    id: int\n    name: str = None\n    description: str = 'Foo'\n    apple: int = Field(alias='pear')\n\n\nprint(inspect.signature(FooModel))\n#&gt; (*, id: int, name: str = None, description: str = 'Foo', pear: int) -&gt; None\n</code></pre> <p>An accurate signature is useful for introspection purposes and libraries like <code>FastAPI</code> or <code>hypothesis</code>.</p> <p>The generated signature will also respect custom <code>__init__</code> functions:</p> <pre><code>import inspect\n\nfrom pydantic import BaseModel\n\n\nclass MyModel(BaseModel):\n    id: int\n    info: str = 'Foo'\n\n    def __init__(self, id: int = 1, *, bar: str, **data) -&gt; None:\n        \"\"\"My custom init!\"\"\"\n        super().__init__(id=id, bar=bar, **data)\n\n\nprint(inspect.signature(MyModel))\n#&gt; (id: int = 1, *, bar: str, info: str = 'Foo') -&gt; None\n</code></pre> <p>To be included in the signature, a field's alias or name must be a valid Python identifier. Pydantic will prioritize a field's alias over its name when generating the signature, but may use the field name if the alias is not a valid Python identifier.</p> <p>If a field's alias and name are both not valid identifiers (which may be possible through exotic use of <code>create_model</code>), a <code>**data</code> argument will be added. In addition, the <code>**data</code> argument will always be present in the signature if <code>model_config['extra'] == 'allow'</code>.</p>"},{"location":"concepts/models/#structural-pattern-matching","title":"Structural pattern matching","text":"<p>Pydantic supports structural pattern matching for models, as introduced by PEP 636 in Python 3.10.</p> <pre><code>from pydantic import BaseModel\n\n\nclass Pet(BaseModel):\n    name: str\n    species: str\n\n\na = Pet(name='Bones', species='dog')\n\nmatch a:\n    # match `species` to 'dog', declare and initialize `dog_name`\n    case Pet(species='dog', name=dog_name):\n        print(f'{dog_name} is a dog')\n#&gt; Bones is a dog\n    # default case\n    case _:\n        print('No dog matched')\n</code></pre> <p>Note</p> <p>A match-case statement may seem as if it creates a new model, but don't be fooled; it is just syntactic sugar for getting an attribute and either comparing it or declaring and initializing it.</p>"},{"location":"concepts/models/#attribute-copies","title":"Attribute copies","text":"<p>In many cases, arguments passed to the constructor will be copied in order to perform validation and, where necessary, coercion.</p> <p>In this example, note that the ID of the list changes after the class is constructed because it has been copied during validation:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel\n\n\nclass C1:\n    arr = []\n\n    def __init__(self, in_arr):\n        self.arr = in_arr\n\n\nclass C2(BaseModel):\n    arr: List[int]\n\n\narr_orig = [1, 9, 10, 3]\n\n\nc1 = C1(arr_orig)\nc2 = C2(arr=arr_orig)\nprint('id(c1.arr) == id(c2.arr):', id(c1.arr) == id(c2.arr))\n#&gt; id(c1.arr) == id(c2.arr): False\n</code></pre> <p>Note</p> <p>There are some situations where Pydantic does not copy attributes, such as when passing models \u2014 we use the model as is. You can override this behaviour by setting <code>model_config['revalidate_instances'] = 'always'</code>.</p>"},{"location":"concepts/models/#extra-fields","title":"Extra fields","text":"<p>By default, Pydantic models won't error when you provide data for unrecognized fields, they will just be ignored:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    x: int\n\n\nm = Model(x=1, y='a')\nassert m.model_dump() == {'x': 1}\n</code></pre> <p>If you want this to raise an error, you can achieve this via <code>model_config</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n    model_config = ConfigDict(extra='forbid')\n\n\ntry:\n    Model(x=1, y='a')\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for Model\n    y\n      Extra inputs are not permitted [type=extra_forbidden, input_value='a', input_type=str]\n    \"\"\"\n</code></pre> <p>To instead preserve any extra data provided, you can set <code>extra='allow'</code>. The extra fields will then be stored in <code>BaseModel.__pydantic_extra__</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass Model(BaseModel):\n    x: int\n\n    model_config = ConfigDict(extra='allow')\n\n\nm = Model(x=1, y='a')\nassert m.__pydantic_extra__ == {'y': 'a'}\n</code></pre> <p>By default, no validation will be applied to these extra items, but you can set a type for the values by overriding the type annotation for <code>__pydantic_extra__</code>:</p> <pre><code>from typing import Dict\n\nfrom pydantic import BaseModel, ConfigDict, Field, ValidationError\n\n\nclass Model(BaseModel):\n    __pydantic_extra__: Dict[str, int] = Field(init=False)  # (1)!\n\n    x: int\n\n    model_config = ConfigDict(extra='allow')\n\n\ntry:\n    Model(x=1, y='a')\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for Model\n    y\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    \"\"\"\n\nm = Model(x=1, y='2')\nassert m.x == 1\nassert m.y == 2\nassert m.model_dump() == {'x': 1, 'y': 2}\nassert m.__pydantic_extra__ == {'y': 2}\n</code></pre> <ol> <li>The <code>= Field(init=False)</code> does not have any effect at runtime, but prevents the <code>__pydantic_extra__</code> field from being treated as an argument to the model's <code>__init__</code> method by type-checkers.</li> </ol> <p>The same configurations apply to <code>TypedDict</code> and <code>dataclass</code>' except the config is controlled by setting the <code>__pydantic_config__</code> attribute of the class to a valid <code>ConfigDict</code>.</p>"},{"location":"concepts/performance/","title":"Performance tips","text":"<p>In most cases Pydantic won't be your bottle neck, only follow this if you're sure it's necessary.</p>"},{"location":"concepts/performance/#in-general-use-model_validate_json-not-model_validatejsonloads","title":"In general, use <code>model_validate_json()</code> not <code>model_validate(json.loads(...))</code>","text":"<p>On <code>model_validate(json.loads(...))</code>, the JSON is parsed in Python, then converted to a dict, then it's validated internally. On the other hand, <code>model_validate_json()</code> already performs the validation internally.</p> <p>There are a few cases where <code>model_validate(json.loads(...))</code> may be faster. Specifically, when using a <code>'before'</code> or <code>'wrap'</code> validator on a model, validation may be faster with the two step method. You can read more about these special cases in this discussion.</p> <p>Many performance improvements are currently in the works for <code>pydantic-core</code>, as discussed here. Once these changes are merged, we should be at the point where <code>model_validate_json()</code> is always faster than <code>model_validate(json.loads(...))</code>.</p>"},{"location":"concepts/performance/#typeadapter-instantiated-once","title":"<code>TypeAdapter</code> instantiated once","text":"<p>The idea here is to avoid constructing validators and serializers more than necessary. Each time a <code>TypeAdapter</code> is instantiated, it will construct a new validator and serializer. If you're using a <code>TypeAdapter</code> in a function, it will be instantiated each time the function is called. Instead, instantiate it once, and reuse it.</p>  Bad Good <pre><code>from typing import List\n\nfrom pydantic import TypeAdapter\n\n\ndef my_func():\n    adapter = TypeAdapter(List[int])\n    # do something with adapter\n</code></pre> <pre><code>from typing import List\n\nfrom pydantic import TypeAdapter\n\nadapter = TypeAdapter(List[int])\n\ndef my_func():\n    ...\n    # do something with adapter\n</code></pre>"},{"location":"concepts/performance/#sequence-vs-list-or-tuple-mapping-vs-dict","title":"<code>Sequence</code> vs <code>list</code> or <code>tuple</code> - <code>Mapping</code> vs <code>dict</code>","text":"<p>When using <code>Sequence</code>, Pydantic calls <code>isinstance(value, Sequence)</code> to check if the value is a sequence. Also, Pydantic will try to validate against different types of sequences, like <code>list</code> and <code>tuple</code>. If you know the value is a <code>list</code> or <code>tuple</code>, use <code>list</code> or <code>tuple</code> instead of <code>Sequence</code>.</p> <p>The same applies to <code>Mapping</code> and <code>dict</code>. If you know the value is a <code>dict</code>, use <code>dict</code> instead of <code>Mapping</code>.</p>"},{"location":"concepts/performance/#dont-do-validation-when-you-dont-have-to-use-any-to-keep-the-value-unchanged","title":"Don't do validation when you don't have to - use <code>Any</code> to keep the value unchanged","text":"<p>If you don't need to validate a value, use <code>Any</code> to keep the value unchanged.</p> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: Any\n\n\nmodel = Model(a=1)\n</code></pre>"},{"location":"concepts/performance/#avoid-extra-information-via-subclasses-of-primitives","title":"Avoid extra information via subclasses of primitives","text":"Don't do thisDo this <pre><code>class CompletedStr(str):\n    def __init__(self, s: str):\n        self.s = s\n        self.done = False\n</code></pre> <pre><code>from pydantic import BaseModel\n\n\nclass CompletedModel(BaseModel):\n    s: str\n    done: bool = False\n</code></pre>"},{"location":"concepts/performance/#use-tagged-union-not-union","title":"Use tagged union, not union","text":"<p>Tagged union (or discriminated union) is a union with a field that indicates which type it is.</p> <pre><code>from typing import Any, Literal\n\nfrom pydantic import BaseModel, Field\n\n\nclass DivModel(BaseModel):\n    el_type: Literal['div'] = 'div'\n    class_name: str | None = None\n    children: list[Any] | None = None\n\n\nclass SpanModel(BaseModel):\n    el_type: Literal['span'] = 'span'\n    class_name: str | None = None\n    contents: str | None = None\n\n\nclass ButtonModel(BaseModel):\n    el_type: Literal['button'] = 'button'\n    class_name: str | None = None\n    contents: str | None = None\n\n\nclass InputModel(BaseModel):\n    el_type: Literal['input'] = 'input'\n    class_name: str | None = None\n    value: str | None = None\n\n\nclass Html(BaseModel):\n    contents: DivModel | SpanModel | ButtonModel | InputModel = Field(\n        discriminator='el_type'\n    )\n</code></pre> <p>See Discriminated Unions for more details.</p>"},{"location":"concepts/performance/#use-typeddict-over-nested-models","title":"Use <code>TypedDict</code> over nested models","text":"<p>Instead of using nested models, use <code>TypedDict</code> to define the structure of the data.</p> Performance comparison <p>With a simple benchmark, <code>TypedDict</code> is about ~2.5x faster than nested models:</p> <pre><code>from timeit import timeit\n\nfrom typing_extensions import TypedDict\n\nfrom pydantic import BaseModel, TypeAdapter\n\n\nclass A(TypedDict):\n    a: str\n    b: int\n\n\nclass TypedModel(TypedDict):\n    a: A\n\n\nclass B(BaseModel):\n    a: str\n    b: int\n\n\nclass Model(BaseModel):\n    b: B\n\n\nta = TypeAdapter(TypedModel)\nresult1 = timeit(\n    lambda: ta.validate_python({'a': {'a': 'a', 'b': 2}}), number=10000\n)\nresult2 = timeit(\n    lambda: Model.model_validate({'b': {'a': 'a', 'b': 2}}), number=10000\n)\nprint(result2 / result1)\n</code></pre>"},{"location":"concepts/performance/#avoid-wrap-validators-if-you-really-care-about-performance","title":"Avoid wrap validators if you really care about performance","text":"<p>Wrap validators are generally slower than other validators. This is because they require that data is materialized in Python during validation. Wrap validators can be incredibly useful for complex validation logic, but if you're looking for the best performance, you should avoid them.</p>"},{"location":"concepts/performance/#failing-early-with-failfast","title":"Failing early with <code>FailFast</code>","text":"<p>Starting in v2.8+, you can apply the <code>FailFast</code> annotation to sequence types to fail early if any item in the sequence fails validation. If you use this annotation, you won't get validation errors for the rest of the items in the sequence if one fails, so you're effectively trading off visibility for performance.</p> <pre><code>from typing import List\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import FailFast, TypeAdapter, ValidationError\n\nta = TypeAdapter(Annotated[List[bool], FailFast()])\ntry:\n    ta.validate_python([True, 'invalid', False, 'also invalid'])\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for list[bool]\n    1\n      Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='invalid', input_type=str]\n    \"\"\"\n</code></pre> <p>Read more about <code>FailFast</code> here.</p>"},{"location":"concepts/postponed_annotations/","title":"Postponed Annotations","text":"<p>Postponed annotations (as described in PEP563) \"just work\".</p> <pre><code>from __future__ import annotations\n\nfrom typing import Any\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: list[int]\n    b: Any\n\n\nprint(Model(a=('1', 2, 3), b='ok'))\n#&gt; a=[1, 2, 3] b='ok'\n</code></pre> <p>Internally, Pydantic will call a method similar to <code>typing.get_type_hints</code> to resolve annotations.</p> <p>Even without using <code>from __future__ import annotations</code>, in cases where the referenced type is not yet defined, a <code>ForwardRef</code> or string can be used:</p> <pre><code>from typing import ForwardRef\n\nfrom pydantic import BaseModel\n\nFoo = ForwardRef('Foo')\n\n\nclass Foo(BaseModel):\n    a: int = 123\n    b: Foo = None\n\n\nprint(Foo())\n#&gt; a=123 b=None\nprint(Foo(b={'a': '321'}))\n#&gt; a=123 b=Foo(a=321, b=None)\n</code></pre>"},{"location":"concepts/postponed_annotations/#self-referencing-or-recursive-models","title":"Self-referencing (or \"Recursive\") Models","text":"<p>Models with self-referencing fields are also supported. Self-referencing fields will be automatically resolved after model creation.</p> <p>Within the model, you can refer to the not-yet-constructed model using a string:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    a: int = 123\n    #: The sibling of `Foo` is referenced by string\n    sibling: 'Foo' = None\n\n\nprint(Foo())\n#&gt; a=123 sibling=None\nprint(Foo(sibling={'a': '321'}))\n#&gt; a=123 sibling=Foo(a=321, sibling=None)\n</code></pre> <p>If you use <code>from __future__ import annotations</code>, you can also just refer to the model by its type name:</p> <pre><code>from __future__ import annotations\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    a: int = 123\n    #: The sibling of `Foo` is referenced directly by type\n    sibling: Foo = None\n\n\nprint(Foo())\n#&gt; a=123 sibling=None\nprint(Foo(sibling={'a': '321'}))\n#&gt; a=123 sibling=Foo(a=321, sibling=None)\n</code></pre>"},{"location":"concepts/postponed_annotations/#cyclic-references","title":"Cyclic references","text":"<p>When working with self-referencing recursive models, it is possible that you might encounter cyclic references in validation inputs. For example, this can happen when validating ORM instances with back-references from attributes.</p> <p>Rather than raising a Python <code>RecursionError</code> while attempting to validate data with cyclic references, Pydantic is able to detect the cyclic reference and raise an appropriate <code>ValidationError</code>:</p> <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass ModelA(BaseModel):\n    b: 'Optional[ModelB]' = None\n\n\nclass ModelB(BaseModel):\n    a: Optional[ModelA] = None\n\n\ncyclic_data = {}\ncyclic_data['a'] = {'b': cyclic_data}\nprint(cyclic_data)\n#&gt; {'a': {'b': {...}}}\n\ntry:\n    ModelB.model_validate(cyclic_data)\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for ModelB\n    a.b\n      Recursion error - cyclic reference detected [type=recursion_loop, input_value={'a': {'b': {...}}}, input_type=dict]\n    \"\"\"\n</code></pre> <p>Because this error is raised without actually exceeding the maximum recursion depth, you can catch and handle the raised <code>ValidationError</code> without needing to worry about the limited remaining recursion depth:</p> <pre><code>from contextlib import contextmanager\nfrom dataclasses import field\nfrom typing import Iterator, List\n\nfrom pydantic import BaseModel, ValidationError, field_validator\n\n\ndef is_recursion_validation_error(exc: ValidationError) -&gt; bool:\n    errors = exc.errors()\n    return len(errors) == 1 and errors[0]['type'] == 'recursion_loop'\n\n\n@contextmanager\ndef suppress_recursion_validation_error() -&gt; Iterator[None]:\n    try:\n        yield\n    except ValidationError as exc:\n        if not is_recursion_validation_error(exc):\n            raise exc\n\n\nclass Node(BaseModel):\n    id: int\n    children: List['Node'] = field(default_factory=list)\n\n    @field_validator('children', mode='wrap')\n    @classmethod\n    def drop_cyclic_references(cls, children, h):\n        try:\n            return h(children)\n        except ValidationError as exc:\n            if not (\n                is_recursion_validation_error(exc)\n                and isinstance(children, list)\n            ):\n                raise exc\n\n            value_without_cyclic_refs = []\n            for child in children:\n                with suppress_recursion_validation_error():\n                    value_without_cyclic_refs.extend(h([child]))\n            return h(value_without_cyclic_refs)\n\n\n# Create data with cyclic references representing the graph 1 -&gt; 2 -&gt; 3 -&gt; 1\nnode_data = {'id': 1, 'children': [{'id': 2, 'children': [{'id': 3}]}]}\nnode_data['children'][0]['children'][0]['children'] = [node_data]\n\nprint(Node.model_validate(node_data))\n#&gt; id=1 children=[Node(id=2, children=[Node(id=3, children=[])])]\n</code></pre> <p>Similarly, if Pydantic encounters a recursive reference during serialization, rather than waiting for the maximum recursion depth to be exceeded, a <code>ValueError</code> is raised immediately:</p> <pre><code>from pydantic import TypeAdapter\n\n# Create data with cyclic references representing the graph 1 -&gt; 2 -&gt; 3 -&gt; 1\nnode_data = {'id': 1, 'children': [{'id': 2, 'children': [{'id': 3}]}]}\nnode_data['children'][0]['children'][0]['children'] = [node_data]\n\ntry:\n    # Try serializing the circular reference as JSON\n    TypeAdapter(dict).dump_json(node_data)\nexcept ValueError as exc:\n    print(exc)\n    \"\"\"\n    Error serializing to JSON: ValueError: Circular reference detected (id repeated)\n    \"\"\"\n</code></pre> <p>This can also be handled if desired:</p> <pre><code>from dataclasses import field\nfrom typing import Any, List\n\nfrom pydantic import (\n    SerializerFunctionWrapHandler,\n    TypeAdapter,\n    field_serializer,\n)\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass NodeReference:\n    id: int\n\n\n@dataclass\nclass Node(NodeReference):\n    children: List['Node'] = field(default_factory=list)\n\n    @field_serializer('children', mode='wrap')\n    def serialize(\n        self, children: List['Node'], handler: SerializerFunctionWrapHandler\n    ) -&gt; Any:\n        \"\"\"\n        Serialize a list of nodes, handling circular references by excluding the children.\n        \"\"\"\n        try:\n            return handler(children)\n        except ValueError as exc:\n            if not str(exc).startswith('Circular reference'):\n                raise exc\n\n            result = []\n            for node in children:\n                try:\n                    serialized = handler([node])\n                except ValueError as exc:\n                    if not str(exc).startswith('Circular reference'):\n                        raise exc\n                    result.append({'id': node.id})\n                else:\n                    result.append(serialized)\n            return result\n\n\n# Create a cyclic graph:\nnodes = [Node(id=1), Node(id=2), Node(id=3)]\nnodes[0].children.append(nodes[1])\nnodes[1].children.append(nodes[2])\nnodes[2].children.append(nodes[0])\n\nprint(nodes[0])\n#&gt; Node(id=1, children=[Node(id=2, children=[Node(id=3, children=[...])])])\n\n# Serialize the cyclic graph:\nprint(TypeAdapter(Node).dump_python(nodes[0]))\n\"\"\"\n{\n    'id': 1,\n    'children': [{'id': 2, 'children': [{'id': 3, 'children': [{'id': 1}]}]}],\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/pydantic_settings/","title":"Settings Management","text":"<p>Pydantic Settings provides optional Pydantic features for loading a settings or config class from environment variables or secrets files.</p>"},{"location":"concepts/pydantic_settings/#installation","title":"Installation","text":"<p>Installation is as simple as:</p> <pre><code>pip install pydantic-settings\n</code></pre>"},{"location":"concepts/pydantic_settings/#usage","title":"Usage","text":"<p>If you create a model that inherits from <code>BaseSettings</code>, the model initialiser will attempt to determine the values of any fields not passed as keyword arguments by reading from the environment. (Default values will still be used if the matching environment variable is not set.)</p> <p>This makes it easy to:</p> <ul> <li>Create a clearly-defined, type-hinted application configuration class</li> <li>Automatically read modifications to the configuration from environment variables</li> <li>Manually override specific settings in the initialiser where desired (e.g. in unit tests)</li> </ul> <p>For example:</p> <pre><code>from typing import Any, Callable, Set\n\nfrom pydantic import (\n    AliasChoices,\n    AmqpDsn,\n    BaseModel,\n    Field,\n    ImportString,\n    PostgresDsn,\n    RedisDsn,\n)\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass SubModel(BaseModel):\n    foo: str = 'bar'\n    apple: int = 1\n\n\nclass Settings(BaseSettings):\n    auth_key: str = Field(validation_alias='my_auth_key')  # (1)!\n\n    api_key: str = Field(alias='my_api_key')  # (2)!\n\n    redis_dsn: RedisDsn = Field(\n        'redis://user:pass@localhost:6379/1',\n        validation_alias=AliasChoices('service_redis_dsn', 'redis_url'),  # (3)!\n    )\n    pg_dsn: PostgresDsn = 'postgres://user:pass@localhost:5432/foobar'\n    amqp_dsn: AmqpDsn = 'amqp://user:pass@localhost:5672/'\n\n    special_function: ImportString[Callable[[Any], Any]] = 'math.cos'  # (4)!\n\n    # to override domains:\n    # export my_prefix_domains='[\"foo.com\", \"bar.com\"]'\n    domains: Set[str] = set()\n\n    # to override more_settings:\n    # export my_prefix_more_settings='{\"foo\": \"x\", \"apple\": 1}'\n    more_settings: SubModel = SubModel()\n\n    model_config = SettingsConfigDict(env_prefix='my_prefix_')  # (5)!\n\n\nprint(Settings().model_dump())\n\"\"\"\n{\n    'auth_key': 'xxx',\n    'api_key': 'xxx',\n    'redis_dsn': Url('redis://user:pass@localhost:6379/1'),\n    'pg_dsn': MultiHostUrl('postgres://user:pass@localhost:5432/foobar'),\n    'amqp_dsn': Url('amqp://user:pass@localhost:5672/'),\n    'special_function': math.cos,\n    'domains': set(),\n    'more_settings': {'foo': 'bar', 'apple': 1},\n}\n\"\"\"\n</code></pre> <ol> <li> <p>The environment variable name is overridden using <code>validation_alias</code>. In this case, the environment variable    <code>my_auth_key</code> will be read instead of <code>auth_key</code>.</p> <p>Check the <code>Field</code> documentation for more information.</p> </li> <li> <p>The environment variable name is overridden using <code>alias</code>. In this case, the environment variable    <code>my_api_key</code> will be used for both validation and serialization instead of <code>api_key</code>.</p> </li> </ol> <p>Check the <code>Field</code> documentation for more information.</p> <ol> <li> <p>The <code>AliasChoices</code> class allows to have multiple environment variable names for a single field.    The first environment variable that is found will be used.</p> <p>Check the <code>AliasChoices</code> for more information.</p> </li> <li> <p>The <code>ImportString</code> class allows to import an object from a string.    In this case, the environment variable <code>special_function</code> will be read and the function <code>math.cos</code> will be imported.</p> </li> <li> <p>The <code>env_prefix</code> config setting allows to set a prefix for all environment variables.</p> <p>Check the Environment variable names documentation for more information.</p> </li> </ol>"},{"location":"concepts/pydantic_settings/#validation-of-default-values","title":"Validation of default values","text":"<p>Unlike pydantic <code>BaseModel</code>, default values of <code>BaseSettings</code> fields are validated by default. You can disable this behaviour by setting <code>validate_default=False</code> either in <code>model_config</code> or on field level by <code>Field(validate_default=False)</code>:</p> <pre><code>from pydantic import Field\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(validate_default=False)\n\n    # default won't be validated\n    foo: int = 'test'\n\n\nprint(Settings())\n#&gt; foo='test'\n\n\nclass Settings1(BaseSettings):\n    # default won't be validated\n    foo: int = Field('test', validate_default=False)\n\n\nprint(Settings1())\n#&gt; foo='test'\n</code></pre> <p>Check the Validation of default values for more information.</p>"},{"location":"concepts/pydantic_settings/#environment-variable-names","title":"Environment variable names","text":"<p>By default, the environment variable name is the same as the field name.</p> <p>You can change the prefix for all environment variables by setting the <code>env_prefix</code> config setting, or via the <code>_env_prefix</code> keyword argument on instantiation:</p> <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_prefix='my_prefix_')\n\n    auth_key: str = 'xxx'  # will be read from `my_prefix_auth_key`\n</code></pre> <p>Note</p> <p>The default <code>env_prefix</code> is <code>''</code> (empty string).</p> <p>If you want to change the environment variable name for a single field, you can use an alias.</p> <p>There are two ways to do this:</p> <ul> <li>Using <code>Field(alias=...)</code> (see <code>api_key</code> above)</li> <li>Using <code>Field(validation_alias=...)</code> (see <code>auth_key</code> above)</li> </ul> <p>Check the <code>Field</code> aliases documentation for more information about aliases.</p> <p><code>env_prefix</code> does not apply to fields with alias. It means the environment variable name is the same as field alias:</p> <pre><code>from pydantic import Field\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_prefix='my_prefix_')\n\n    foo: str = Field('xxx', alias='FooAlias')  # (1)!\n</code></pre> <ol> <li><code>env_prefix</code> will be ignored and the value will be read from <code>FooAlias</code> environment variable.</li> </ol>"},{"location":"concepts/pydantic_settings/#case-sensitivity","title":"Case-sensitivity","text":"<p>By default, environment variable names are case-insensitive.</p> <p>If you want to make environment variable names case-sensitive, you can set the <code>case_sensitive</code> config setting:</p> <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(case_sensitive=True)\n\n    redis_host: str = 'localhost'\n</code></pre> <p>When <code>case_sensitive</code> is <code>True</code>, the environment variable names must match field names (optionally with a prefix), so in this example <code>redis_host</code> could only be modified via <code>export redis_host</code>. If you want to name environment variables all upper-case, you should name attribute all upper-case too. You can still name environment variables anything you like through <code>Field(validation_alias=...)</code>.</p> <p>Case-sensitivity can also be set via the <code>_case_sensitive</code> keyword argument on instantiation.</p> <p>In case of nested models, the <code>case_sensitive</code> setting will be applied to all nested models.</p> <pre><code>import os\n\nfrom pydantic import BaseModel, ValidationError\n\nfrom pydantic_settings import BaseSettings\n\n\nclass RedisSettings(BaseModel):\n    host: str\n    port: int\n\n\nclass Settings(BaseSettings, case_sensitive=True):\n    redis: RedisSettings\n\n\nos.environ['redis'] = '{\"host\": \"localhost\", \"port\": 6379}'\nprint(Settings().model_dump())\n#&gt; {'redis': {'host': 'localhost', 'port': 6379}}\nos.environ['redis'] = '{\"HOST\": \"localhost\", \"port\": 6379}'  # (1)!\ntry:\n    Settings()\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Settings\n    redis.host\n      Field required [type=missing, input_value={'HOST': 'localhost', 'port': 6379}, input_type=dict]\n        For further information visit https://errors.pydantic.dev/2/v/missing\n    \"\"\"\n</code></pre> <ol> <li>Note that the <code>host</code> field is not found because the environment variable name is <code>HOST</code> (all upper-case).</li> </ol> <p>Note</p> <p>On Windows, Python's <code>os</code> module always treats environment variables as case-insensitive, so the <code>case_sensitive</code> config setting will have no effect - settings will always be updated ignoring case.</p>"},{"location":"concepts/pydantic_settings/#parsing-environment-variable-values","title":"Parsing environment variable values","text":"<p>By default environment variables are parsed verbatim, including if the value is empty. You can choose to ignore empty environment variables by setting the <code>env_ignore_empty</code> config setting to <code>True</code>. This can be useful if you would prefer to use the default value for a field rather than an empty value from the environment.</p> <p>For most simple field types (such as <code>int</code>, <code>float</code>, <code>str</code>, etc.), the environment variable value is parsed the same way it would be if passed directly to the initialiser (as a string).</p> <p>Complex types like <code>list</code>, <code>set</code>, <code>dict</code>, and sub-models are populated from the environment by treating the environment variable's value as a JSON-encoded string.</p> <p>Another way to populate nested complex variables is to configure your model with the <code>env_nested_delimiter</code> config setting, then use an environment variable with a name pointing to the nested module fields. What it does is simply explodes your variable into nested models or dicts. So if you define a variable <code>FOO__BAR__BAZ=123</code> it will convert it into <code>FOO={'BAR': {'BAZ': 123}}</code> If you have multiple variables with the same structure they will be merged.</p> <p>Note</p> <p>Sub model has to inherit from <code>pydantic.BaseModel</code>, Otherwise <code>pydantic-settings</code> will initialize sub model, collects values for sub model fields separately, and you may get unexpected results.</p> <p>As an example, given the following environment variables: <pre><code># your environment\nexport V0=0\nexport SUB_MODEL='{\"v1\": \"json-1\", \"v2\": \"json-2\"}'\nexport SUB_MODEL__V2=nested-2\nexport SUB_MODEL__V3=3\nexport SUB_MODEL__DEEP__V4=v4\n</code></pre></p> <p>You could load them into the following settings model:</p> <pre><code>from pydantic import BaseModel\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass DeepSubModel(BaseModel):  # (1)!\n    v4: str\n\n\nclass SubModel(BaseModel):  # (2)!\n    v1: str\n    v2: bytes\n    v3: int\n    deep: DeepSubModel\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_nested_delimiter='__')\n\n    v0: str\n    sub_model: SubModel\n\n\nprint(Settings().model_dump())\n\"\"\"\n{\n    'v0': '0',\n    'sub_model': {'v1': 'json-1', 'v2': b'nested-2', 'v3': 3, 'deep': {'v4': 'v4'}},\n}\n\"\"\"\n</code></pre> <ol> <li> <p>Sub model has to inherit from <code>pydantic.BaseModel</code>.</p> </li> <li> <p>Sub model has to inherit from <code>pydantic.BaseModel</code>.</p> </li> </ol> <p><code>env_nested_delimiter</code> can be configured via the <code>model_config</code> as shown above, or via the <code>_env_nested_delimiter</code> keyword argument on instantiation.</p> <p>Nested environment variables take precedence over the top-level environment variable JSON (e.g. in the example above, <code>SUB_MODEL__V2</code> trumps <code>SUB_MODEL</code>).</p> <p>You may also populate a complex type by providing your own source class.</p> <pre><code>import json\nimport os\nfrom typing import Any, List, Tuple, Type\n\nfrom pydantic.fields import FieldInfo\n\nfrom pydantic_settings import (\n    BaseSettings,\n    EnvSettingsSource,\n    PydanticBaseSettingsSource,\n)\n\n\nclass MyCustomSource(EnvSettingsSource):\n    def prepare_field_value(\n        self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool\n    ) -&gt; Any:\n        if field_name == 'numbers':\n            return [int(x) for x in value.split(',')]\n        return json.loads(value)\n\n\nclass Settings(BaseSettings):\n    numbers: List[int]\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return (MyCustomSource(settings_cls),)\n\n\nos.environ['numbers'] = '1,2,3'\nprint(Settings().model_dump())\n#&gt; {'numbers': [1, 2, 3]}\n</code></pre>"},{"location":"concepts/pydantic_settings/#nested-model-default-partial-updates","title":"Nested model default partial updates","text":"<p>By default, Pydantic settings does not allow partial updates to nested model default objects. This behavior can be overriden by setting the <code>nested_model_default_partial_update</code> flag to <code>True</code>, which will allow partial updates on nested model default object fields.</p> <pre><code>import os\n\nfrom pydantic import BaseModel\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass SubModel(BaseModel):\n    val: int = 0\n    flag: bool = False\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(\n        env_nested_delimiter='__', nested_model_default_partial_update=True\n    )\n\n    nested_model: SubModel = SubModel()\n\n\n# Apply a partial update to the default object using environment variables\nos.environ['NESTED_MODEL__FLAG'] = 'True'\n\nassert Settings().model_dump() == {'nested_model': {'val': 0, 'flag': True}}\n</code></pre>"},{"location":"concepts/pydantic_settings/#dotenv-env-support","title":"Dotenv (.env) support","text":"<p>Dotenv files (generally named <code>.env</code>) are a common pattern that make it easy to use environment variables in a platform-independent manner.</p> <p>A dotenv file follows the same general principles of all environment variables, and it looks like this:</p> .env<pre><code># ignore comment\nENVIRONMENT=\"production\"\nREDIS_ADDRESS=localhost:6379\nMEANING_OF_LIFE=42\nMY_VAR='Hello world'\n</code></pre> <p>Once you have your <code>.env</code> file filled with variables, pydantic supports loading it in two ways:</p> <ol> <li>Setting the <code>env_file</code> (and <code>env_file_encoding</code> if you don't want the default encoding of your OS) on <code>model_config</code> in the <code>BaseSettings</code> class:    <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_file='.env', env_file_encoding='utf-8')\n</code></pre></li> <li>Instantiating the <code>BaseSettings</code> derived class with the <code>_env_file</code> keyword argument (and the <code>_env_file_encoding</code> if needed):    <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_file='.env', env_file_encoding='utf-8')\n\n\nsettings = Settings(_env_file='prod.env', _env_file_encoding='utf-8')\n</code></pre> In either case, the value of the passed argument can be any valid path or filename, either absolute or relative to the current working directory. From there, pydantic will handle everything for you by loading in your variables and validating them.</li> </ol> <p>Note</p> <p>If a filename is specified for <code>env_file</code>, Pydantic will only check the current working directory and won't check any parent directories for the <code>.env</code> file.</p> <p>Even when using a dotenv file, pydantic will still read environment variables as well as the dotenv file, environment variables will always take priority over values loaded from a dotenv file.</p> <p>Passing a file path via the <code>_env_file</code> keyword argument on instantiation (method 2) will override the value (if any) set on the <code>model_config</code> class. If the above snippets were used in conjunction, <code>prod.env</code> would be loaded while <code>.env</code> would be ignored.</p> <p>If you need to load multiple dotenv files, you can pass multiple file paths as a tuple or list. The files will be loaded in order, with each file overriding the previous one.</p> <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(\n        # `.env.prod` takes priority over `.env`\n        env_file=('.env', '.env.prod')\n    )\n</code></pre> <p>You can also use the keyword argument override to tell Pydantic not to load any file at all (even if one is set in the <code>model_config</code> class) by passing <code>None</code> as the instantiation keyword argument, e.g. <code>settings = Settings(_env_file=None)</code>.</p> <p>Because python-dotenv is used to parse the file, bash-like semantics such as <code>export</code> can be used which (depending on your OS and environment) may allow your dotenv file to also be used with <code>source</code>, see python-dotenv's documentation for more details.</p> <p>Pydantic settings consider <code>extra</code> config in case of dotenv file. It means if you set the <code>extra=forbid</code> (default) on <code>model_config</code> and your dotenv file contains an entry for a field that is not defined in settings model, it will raise <code>ValidationError</code> in settings construction.</p> <p>For compatibility with pydantic 1.x BaseSettings you should use <code>extra=ignore</code>: <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_file='.env', extra='ignore')\n</code></pre></p> <p>Note</p> <p>Pydantic settings loads all the values from dotenv file and passes it to the model, regardless of the model's <code>env_prefix</code>. So if you provide extra values in a dotenv file, whether they start with <code>env_prefix</code> or not, a <code>ValidationError</code> will be raised.</p>"},{"location":"concepts/pydantic_settings/#command-line-support","title":"Command Line Support","text":"<p>Pydantic settings provides integrated CLI support, making it easy to quickly define CLI applications using Pydantic models. There are two primary use cases for Pydantic settings CLI:</p> <ol> <li>When using a CLI to override fields in Pydantic models.</li> <li>When using Pydantic models to define CLIs.</li> </ol> <p>By default, the experience is tailored towards use case #1 and builds on the foundations established in parsing environment variables. If your use case primarily falls into #2, you will likely want to enable enforcing required arguments at the CLI and nested model default partial updates.</p>"},{"location":"concepts/pydantic_settings/#the-basics","title":"The Basics","text":"<p>To get started, let's revisit the example presented in parsing environment variables but using a Pydantic settings CLI:</p> <pre><code>import sys\n\nfrom pydantic import BaseModel\n\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass DeepSubModel(BaseModel):\n    v4: str\n\n\nclass SubModel(BaseModel):\n    v1: str\n    v2: bytes\n    v3: int\n    deep: DeepSubModel\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(cli_parse_args=True)\n\n    v0: str\n    sub_model: SubModel\n\n\nsys.argv = [\n    'example.py',\n    '--v0=0',\n    '--sub_model={\"v1\": \"json-1\", \"v2\": \"json-2\"}',\n    '--sub_model.v2=nested-2',\n    '--sub_model.v3=3',\n    '--sub_model.deep.v4=v4',\n]\n\nprint(Settings().model_dump())\n\"\"\"\n{\n    'v0': '0',\n    'sub_model': {'v1': 'json-1', 'v2': b'nested-2', 'v3': 3, 'deep': {'v4': 'v4'}},\n}\n\"\"\"\n</code></pre> <p>To enable CLI parsing, we simply set the <code>cli_parse_args</code> flag to a valid value, which retains similar conotations as defined in <code>argparse</code>. Alternatively, we can also directly provide the args to parse at time of instantiation:</p> <pre><code>from pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings):\n    this_foo: str\n\n\nprint(Settings(_cli_parse_args=['--this_foo', 'is such a foo']).model_dump())\n#&gt; {'this_foo': 'is such a foo'}\n</code></pre> <p>Note that a CLI settings source is the topmost source by default unless its priority value is customised:</p> <pre><code>import os\nimport sys\nfrom typing import Tuple, Type\n\nfrom pydantic_settings import (\n    BaseSettings,\n    CliSettingsSource,\n    PydanticBaseSettingsSource,\n)\n\n\nclass Settings(BaseSettings):\n    my_foo: str\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return env_settings, CliSettingsSource(settings_cls, cli_parse_args=True)\n\n\nos.environ['MY_FOO'] = 'from environment'\n\nsys.argv = ['example.py', '--my_foo=from cli']\n\nprint(Settings().model_dump())\n#&gt; {'my_foo': 'from environment'}\n</code></pre>"},{"location":"concepts/pydantic_settings/#lists","title":"Lists","text":"<p>CLI argument parsing of lists supports intermixing of any of the below three styles:</p> <ul> <li>JSON style <code>--field='[1,2]'</code></li> <li>Argparse style <code>--field 1 --field 2</code></li> <li>Lazy style <code>--field=1,2</code></li> </ul> <pre><code>import sys\nfrom typing import List\n\nfrom pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings, cli_parse_args=True):\n    my_list: List[int]\n\n\nsys.argv = ['example.py', '--my_list', '[1,2]']\nprint(Settings().model_dump())\n#&gt; {'my_list': [1, 2]}\n\nsys.argv = ['example.py', '--my_list', '1', '--my_list', '2']\nprint(Settings().model_dump())\n#&gt; {'my_list': [1, 2]}\n\nsys.argv = ['example.py', '--my_list', '1,2']\nprint(Settings().model_dump())\n#&gt; {'my_list': [1, 2]}\n</code></pre>"},{"location":"concepts/pydantic_settings/#dictionaries","title":"Dictionaries","text":"<p>CLI argument parsing of dictionaries supports intermixing of any of the below two styles:</p> <ul> <li>JSON style <code>--field='{\"k1\": 1, \"k2\": 2}'</code></li> <li>Environment variable style <code>--field k1=1 --field k2=2</code></li> </ul> <p>These can be used in conjunction with list forms as well, e.g:</p> <ul> <li><code>--field k1=1,k2=2 --field k3=3 --field '{\"k4\": 4}'</code> etc.</li> </ul> <pre><code>import sys\nfrom typing import Dict\n\nfrom pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings, cli_parse_args=True):\n    my_dict: Dict[str, int]\n\n\nsys.argv = ['example.py', '--my_dict', '{\"k1\":1,\"k2\":2}']\nprint(Settings().model_dump())\n#&gt; {'my_dict': {'k1': 1, 'k2': 2}}\n\nsys.argv = ['example.py', '--my_dict', 'k1=1', '--my_dict', 'k2=2']\nprint(Settings().model_dump())\n#&gt; {'my_dict': {'k1': 1, 'k2': 2}}\n</code></pre>"},{"location":"concepts/pydantic_settings/#literals-and-enums","title":"Literals and Enums","text":"<p>CLI argument parsing of literals and enums are converted into CLI choices.</p> <pre><code>import sys\nfrom enum import IntEnum\nfrom typing import Literal\n\nfrom pydantic_settings import BaseSettings\n\n\nclass Fruit(IntEnum):\n    pear = 0\n    kiwi = 1\n    lime = 2\n\n\nclass Settings(BaseSettings, cli_parse_args=True):\n    fruit: Fruit\n    pet: Literal['dog', 'cat', 'bird']\n\n\nsys.argv = ['example.py', '--fruit', 'lime', '--pet', 'cat']\nprint(Settings().model_dump())\n#&gt; {'fruit': &lt;Fruit.lime: 2&gt;, 'pet': 'cat'}\n</code></pre>"},{"location":"concepts/pydantic_settings/#aliases","title":"Aliases","text":"<p>Pydantic field aliases are added as CLI argument aliases. Aliases of length one are converted into short options.</p> <pre><code>import sys\n\nfrom pydantic import AliasChoices, AliasPath, Field\n\nfrom pydantic_settings import BaseSettings\n\n\nclass User(BaseSettings, cli_parse_args=True):\n    first_name: str = Field(\n        validation_alias=AliasChoices('f', 'fname', AliasPath('name', 0))\n    )\n    last_name: str = Field(\n        validation_alias=AliasChoices('l', 'lname', AliasPath('name', 1))\n    )\n\n\nsys.argv = ['example.py', '--fname', 'John', '--lname', 'Doe']\nprint(User().model_dump())\n#&gt; {'first_name': 'John', 'last_name': 'Doe'}\n\nsys.argv = ['example.py', '-f', 'John', '-l', 'Doe']\nprint(User().model_dump())\n#&gt; {'first_name': 'John', 'last_name': 'Doe'}\n\nsys.argv = ['example.py', '--name', 'John,Doe']\nprint(User().model_dump())\n#&gt; {'first_name': 'John', 'last_name': 'Doe'}\n\nsys.argv = ['example.py', '--name', 'John', '--lname', 'Doe']\nprint(User().model_dump())\n#&gt; {'first_name': 'John', 'last_name': 'Doe'}\n</code></pre>"},{"location":"concepts/pydantic_settings/#subcommands-and-positional-arguments","title":"Subcommands and Positional Arguments","text":"<p>Subcommands and positional arguments are expressed using the <code>CliSubCommand</code> and <code>CliPositionalArg</code> annotations. These annotations can only be applied to required fields (i.e. fields that do not have a default value). Furthermore, subcommands must be a valid type derived from either a pydantic <code>BaseModel</code> or pydantic.dataclasses <code>dataclass</code>.</p> <p>Parsed subcommands can be retrieved from model instances using the <code>get_subcommand</code> utility function. If a subcommand is not required, set the <code>is_required</code> flag to <code>False</code> to disable raising an error if no subcommand is found.</p> <p>Note</p> <p>CLI settings subcommands are limited to a single subparser per model. In other words, all subcommands for a model are grouped under a single subparser; it does not allow for multiple subparsers with each subparser having its own set of subcommands. For more information on subparsers, see argparse subcommands.</p> <p>Note</p> <p><code>CliSubCommand</code> and <code>CliPositionalArg</code> are always case sensitive and do not support aliases.</p> <pre><code>import sys\n\nfrom pydantic import BaseModel\n\nfrom pydantic_settings import (\n    BaseSettings,\n    CliPositionalArg,\n    CliSubCommand,\n    SettingsError,\n    get_subcommand,\n)\n\n\nclass Init(BaseModel):\n    directory: CliPositionalArg[str]\n\n\nclass Clone(BaseModel):\n    repository: CliPositionalArg[str]\n    directory: CliPositionalArg[str]\n\n\nclass Git(BaseSettings, cli_parse_args=True, cli_exit_on_error=False):\n    clone: CliSubCommand[Clone]\n    init: CliSubCommand[Init]\n\n\n# Run without subcommands\nsys.argv = ['example.py']\ncmd = Git()\nassert cmd.model_dump() == {'clone': None, 'init': None}\n\ntry:\n    # Will raise an error since no subcommand was provided\n    get_subcommand(cmd).model_dump()\nexcept SettingsError as err:\n    assert str(err) == 'Error: CLI subcommand is required {clone, init}'\n\n# Will not raise an error since subcommand is not required\nassert get_subcommand(cmd, is_required=False) is None\n\n\n# Run the clone subcommand\nsys.argv = ['example.py', 'clone', 'repo', 'dest']\ncmd = Git()\nassert cmd.model_dump() == {\n    'clone': {'repository': 'repo', 'directory': 'dest'},\n    'init': None,\n}\n\n# Returns the subcommand model instance (in this case, 'clone')\nassert get_subcommand(cmd).model_dump() == {\n    'directory': 'dest',\n    'repository': 'repo',\n}\n</code></pre>"},{"location":"concepts/pydantic_settings/#customizing-the-cli-experience","title":"Customizing the CLI Experience","text":"<p>The below flags can be used to customise the CLI experience to your needs.</p>"},{"location":"concepts/pydantic_settings/#change-the-displayed-program-name","title":"Change the Displayed Program Name","text":"<p>Change the default program name displayed in the help text usage by setting <code>cli_prog_name</code>. By default, it will derive the name of the currently executing program from <code>sys.argv[0]</code>, just like argparse.</p> <pre><code>import sys\n\nfrom pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings, cli_parse_args=True, cli_prog_name='appdantic'):\n    pass\n\n\ntry:\n    sys.argv = ['example.py', '--help']\n    Settings()\nexcept SystemExit as e:\n    print(e)\n    #&gt; 0\n\"\"\"\nusage: appdantic [-h]\n\noptions:\n  -h, --help  show this help message and exit\n\"\"\"\n</code></pre>"},{"location":"concepts/pydantic_settings/#cli-boolean-flags","title":"CLI Boolean Flags","text":"<p>Change whether boolean fields should be explicit or implicit by default using the <code>cli_implicit_flags</code> setting. By default, boolean fields are \"explicit\", meaning a boolean value must be explicitly provided on the CLI, e.g. <code>--flag=True</code>. Conversely, boolean fields that are \"implicit\" derive the value from the flag itself, e.g. <code>--flag,--no-flag</code>, which removes the need for an explicit value to be passed.</p> <p>Additionally, the provided <code>CliImplicitFlag</code> and <code>CliExplicitFlag</code> annotations can be used for more granular control when necessary.</p> <p>Note</p> <p>For <code>python &lt; 3.9</code>:   * The <code>--no-flag</code> option is not generated due to an underlying <code>argparse</code> limitation.   * The <code>CliImplicitFlag</code> and <code>CliExplicitFlag</code> annotations can only be applied to optional bool fields.</p> <pre><code>from pydantic_settings import BaseSettings, CliExplicitFlag, CliImplicitFlag\n\n\nclass ExplicitSettings(BaseSettings, cli_parse_args=True):\n    \"\"\"Boolean fields are explicit by default.\"\"\"\n\n    explicit_req: bool\n    \"\"\"\n    --explicit_req bool   (required)\n    \"\"\"\n\n    explicit_opt: bool = False\n    \"\"\"\n    --explicit_opt bool   (default: False)\n    \"\"\"\n\n    # Booleans are explicit by default, so must override implicit flags with annotation\n    implicit_req: CliImplicitFlag[bool]\n    \"\"\"\n    --implicit_req, --no-implicit_req (required)\n    \"\"\"\n\n    implicit_opt: CliImplicitFlag[bool] = False\n    \"\"\"\n    --implicit_opt, --no-implicit_opt (default: False)\n    \"\"\"\n\n\nclass ImplicitSettings(BaseSettings, cli_parse_args=True, cli_implicit_flags=True):\n    \"\"\"With cli_implicit_flags=True, boolean fields are implicit by default.\"\"\"\n\n    # Booleans are implicit by default, so must override explicit flags with annotation\n    explicit_req: CliExplicitFlag[bool]\n    \"\"\"\n    --explicit_req bool   (required)\n    \"\"\"\n\n    explicit_opt: CliExplicitFlag[bool] = False\n    \"\"\"\n    --explicit_opt bool   (default: False)\n    \"\"\"\n\n    implicit_req: bool\n    \"\"\"\n    --implicit_req, --no-implicit_req (required)\n    \"\"\"\n\n    implicit_opt: bool = False\n    \"\"\"\n    --implicit_opt, --no-implicit_opt (default: False)\n    \"\"\"\n</code></pre>"},{"location":"concepts/pydantic_settings/#change-whether-cli-should-exit-on-error","title":"Change Whether CLI Should Exit on Error","text":"<p>Change whether the CLI internal parser will exit on error or raise a <code>SettingsError</code> exception by using <code>cli_exit_on_error</code>. By default, the CLI internal parser will exit on error.</p> <pre><code>import sys\n\nfrom pydantic_settings import BaseSettings, SettingsError\n\n\nclass Settings(BaseSettings, cli_parse_args=True, cli_exit_on_error=False): ...\n\n\ntry:\n    sys.argv = ['example.py', '--bad-arg']\n    Settings()\nexcept SettingsError as e:\n    print(e)\n    #&gt; error parsing CLI: unrecognized arguments: --bad-arg\n</code></pre>"},{"location":"concepts/pydantic_settings/#enforce-required-arguments-at-cli","title":"Enforce Required Arguments at CLI","text":"<p>Pydantic settings is designed to pull values in from various sources when instantating a model. This means a field that is required is not strictly required from any single source (e.g. the CLI). Instead, all that matters is that one of the sources provides the required value.</p> <p>However, if your use case aligns more with #2, using Pydantic models to define CLIs, you will likely want required fields to be strictly required at the CLI. We can enable this behavior by using <code>cli_enforce_required</code>.</p> <pre><code>import os\nimport sys\n\nfrom pydantic import Field\n\nfrom pydantic_settings import BaseSettings, SettingsError\n\n\nclass Settings(\n    BaseSettings,\n    cli_parse_args=True,\n    cli_enforce_required=True,\n    cli_exit_on_error=False,\n):\n    my_required_field: str = Field(description='a top level required field')\n\n\nos.environ['MY_REQUIRED_FIELD'] = 'hello from environment'\n\ntry:\n    sys.argv = ['example.py']\n    Settings()\nexcept SettingsError as e:\n    print(e)\n    #&gt; error parsing CLI: the following arguments are required: --my_required_field\n</code></pre>"},{"location":"concepts/pydantic_settings/#change-the-none-type-parse-string","title":"Change the None Type Parse String","text":"<p>Change the CLI string value that will be parsed (e.g. \"null\", \"void\", \"None\", etc.) into <code>None</code> by setting <code>cli_parse_none_str</code>. By default it will use the <code>env_parse_none_str</code> value if set. Otherwise, it will default to \"null\" if <code>cli_avoid_json</code> is <code>False</code>, and \"None\" if <code>cli_avoid_json</code> is <code>True</code>.</p> <pre><code>import sys\nfrom typing import Optional\n\nfrom pydantic import Field\n\nfrom pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings, cli_parse_args=True, cli_parse_none_str='void'):\n    v1: Optional[int] = Field(description='the top level v0 option')\n\n\nsys.argv = ['example.py', '--v1', 'void']\nprint(Settings().model_dump())\n#&gt; {'v1': None}\n</code></pre>"},{"location":"concepts/pydantic_settings/#hide-none-type-values","title":"Hide None Type Values","text":"<p>Hide <code>None</code> values from the CLI help text by enabling <code>cli_hide_none_type</code>.</p> <pre><code>import sys\nfrom typing import Optional\n\nfrom pydantic import Field\n\nfrom pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings, cli_parse_args=True, cli_hide_none_type=True):\n    v0: Optional[str] = Field(description='the top level v0 option')\n\n\ntry:\n    sys.argv = ['example.py', '--help']\n    Settings()\nexcept SystemExit as e:\n    print(e)\n    #&gt; 0\n\"\"\"\nusage: example.py [-h] [--v0 str]\n\noptions:\n  -h, --help  show this help message and exit\n  --v0 str    the top level v0 option (required)\n\"\"\"\n</code></pre>"},{"location":"concepts/pydantic_settings/#avoid-adding-json-cli-options","title":"Avoid Adding JSON CLI Options","text":"<p>Avoid adding complex fields that result in JSON strings at the CLI by enabling <code>cli_avoid_json</code>.</p> <pre><code>import sys\n\nfrom pydantic import BaseModel, Field\n\nfrom pydantic_settings import BaseSettings\n\n\nclass SubModel(BaseModel):\n    v1: int = Field(description='the sub model v1 option')\n\n\nclass Settings(BaseSettings, cli_parse_args=True, cli_avoid_json=True):\n    sub_model: SubModel = Field(\n        description='The help summary for SubModel related options'\n    )\n\n\ntry:\n    sys.argv = ['example.py', '--help']\n    Settings()\nexcept SystemExit as e:\n    print(e)\n    #&gt; 0\n\"\"\"\nusage: example.py [-h] [--sub_model.v1 int]\n\noptions:\n  -h, --help          show this help message and exit\n\nsub_model options:\n  The help summary for SubModel related options\n\n  --sub_model.v1 int  the sub model v1 option (required)\n\"\"\"\n</code></pre>"},{"location":"concepts/pydantic_settings/#use-class-docstring-for-group-help-text","title":"Use Class Docstring for Group Help Text","text":"<p>By default, when populating the group help text for nested models it will pull from the field descriptions. Alternatively, we can also configure CLI settings to pull from the class docstring instead.</p> <p>Note</p> <p>If the field is a union of nested models the group help text will always be pulled from the field description; even if <code>cli_use_class_docs_for_groups</code> is set to <code>True</code>.</p> <pre><code>import sys\n\nfrom pydantic import BaseModel, Field\n\nfrom pydantic_settings import BaseSettings\n\n\nclass SubModel(BaseModel):\n    \"\"\"The help text from the class docstring.\"\"\"\n\n    v1: int = Field(description='the sub model v1 option')\n\n\nclass Settings(BaseSettings, cli_parse_args=True, cli_use_class_docs_for_groups=True):\n    \"\"\"My application help text.\"\"\"\n\n    sub_model: SubModel = Field(description='The help text from the field description')\n\n\ntry:\n    sys.argv = ['example.py', '--help']\n    Settings()\nexcept SystemExit as e:\n    print(e)\n    #&gt; 0\n\"\"\"\nusage: example.py [-h] [--sub_model JSON] [--sub_model.v1 int]\n\nMy application help text.\n\noptions:\n  -h, --help          show this help message and exit\n\nsub_model options:\n  The help text from the class docstring.\n\n  --sub_model JSON    set sub_model from JSON string\n  --sub_model.v1 int  the sub model v1 option (required)\n\"\"\"\n</code></pre>"},{"location":"concepts/pydantic_settings/#integrating-with-existing-parsers","title":"Integrating with Existing Parsers","text":"<p>A CLI settings source can be integrated with existing parsers by overriding the default CLI settings source with a user defined one that specifies the <code>root_parser</code> object.</p> <pre><code>import sys\nfrom argparse import ArgumentParser\n\nfrom pydantic_settings import BaseSettings, CliSettingsSource\n\nparser = ArgumentParser()\nparser.add_argument('--food', choices=['pear', 'kiwi', 'lime'])\n\n\nclass Settings(BaseSettings):\n    name: str = 'Bob'\n\n\n# Set existing `parser` as the `root_parser` object for the user defined settings source\ncli_settings = CliSettingsSource(Settings, root_parser=parser)\n\n# Parse and load CLI settings from the command line into the settings source.\nsys.argv = ['example.py', '--food', 'kiwi', '--name', 'waldo']\nprint(Settings(_cli_settings_source=cli_settings(args=True)).model_dump())\n#&gt; {'name': 'waldo'}\n\n# Load CLI settings from pre-parsed arguments. i.e., the parsing occurs elsewhere and we\n# just need to load the pre-parsed args into the settings source.\nparsed_args = parser.parse_args(['--food', 'kiwi', '--name', 'ralph'])\nprint(Settings(_cli_settings_source=cli_settings(parsed_args=parsed_args)).model_dump())\n#&gt; {'name': 'ralph'}\n</code></pre> <p>A <code>CliSettingsSource</code> connects with a <code>root_parser</code> object by using parser methods to add <code>settings_cls</code> fields as command line arguments. The <code>CliSettingsSource</code> internal parser representation is based on the <code>argparse</code> library, and therefore, requires parser methods that support the same attributes as their <code>argparse</code> counterparts. The available parser methods that can be customised, along with their argparse counterparts (the defaults), are listed below:</p> <ul> <li><code>parse_args_method</code> - (<code>argparse.ArgumentParser.parse_args</code>)</li> <li><code>add_argument_method</code> - (<code>argparse.ArgumentParser.add_argument</code>)</li> <li><code>add_argument_group_method</code> - (<code>argparse.ArgumentParser.add_argument_group</code>)</li> <li><code>add_parser_method</code> - (<code>argparse._SubParsersAction.add_parser</code>)</li> <li><code>add_subparsers_method</code> - (<code>argparse.ArgumentParser.add_subparsers</code>)</li> <li><code>formatter_class</code> - (<code>argparse.RawDescriptionHelpFormatter</code>)</li> </ul> <p>For a non-argparse parser the parser methods can be set to <code>None</code> if not supported. The CLI settings will only raise an error when connecting to the root parser if a parser method is necessary but set to <code>None</code>.</p>"},{"location":"concepts/pydantic_settings/#secrets","title":"Secrets","text":"<p>Placing secret values in files is a common pattern to provide sensitive configuration to an application.</p> <p>A secret file follows the same principal as a dotenv file except it only contains a single value and the file name is used as the key. A secret file will look like the following:</p> /var/run/database_password<pre><code>super_secret_database_password\n</code></pre> <p>Once you have your secret files, pydantic supports loading it in two ways:</p> <ol> <li>Setting the <code>secrets_dir</code> on <code>model_config</code> in a <code>BaseSettings</code> class to the directory where your secret files are stored.    <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(secrets_dir='/var/run')\n\n    database_password: str\n</code></pre></li> <li>Instantiating the <code>BaseSettings</code> derived class with the <code>_secrets_dir</code> keyword argument:    <pre><code>settings = Settings(_secrets_dir='/var/run')\n</code></pre></li> </ol> <p>In either case, the value of the passed argument can be any valid directory, either absolute or relative to the current working directory. Note that a non existent directory will only generate a warning. From there, pydantic will handle everything for you by loading in your variables and validating them.</p> <p>Even when using a secrets directory, pydantic will still read environment variables from a dotenv file or the environment, a dotenv file and environment variables will always take priority over values loaded from the secrets directory.</p> <p>Passing a file path via the <code>_secrets_dir</code> keyword argument on instantiation (method 2) will override the value (if any) set on the <code>model_config</code> class.</p>"},{"location":"concepts/pydantic_settings/#use-case-docker-secrets","title":"Use Case: Docker Secrets","text":"<p>Docker Secrets can be used to provide sensitive configuration to an application running in a Docker container. To use these secrets in a pydantic application the process is simple. More information regarding creating, managing and using secrets in Docker see the official Docker documentation.</p> <p>First, define your <code>Settings</code> class with a <code>SettingsConfigDict</code> that specifies the secrets directory.</p> <pre><code>from pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(secrets_dir='/run/secrets')\n\n    my_secret_data: str\n</code></pre> <p>Note</p> <p>By default Docker uses <code>/run/secrets</code> as the target mount point. If you want to use a different location, change <code>Config.secrets_dir</code> accordingly.</p> <p>Then, create your secret via the Docker CLI <pre><code>printf \"This is a secret\" | docker secret create my_secret_data -\n</code></pre></p> <p>Last, run your application inside a Docker container and supply your newly created secret <pre><code>docker service create --name pydantic-with-secrets --secret my_secret_data pydantic-app:latest\n</code></pre></p>"},{"location":"concepts/pydantic_settings/#azure-key-vault","title":"Azure Key Vault","text":"<p>You must set two parameters:</p> <ul> <li><code>url</code>: For example, <code>https://my-resource.vault.azure.net/</code>.</li> <li><code>credential</code>: If you use <code>DefaultAzureCredential</code>, in local you can execute <code>az login</code> to get your identity credentials. The identity must have a role assignment (the recommended one is <code>Key Vault Secrets User</code>), so you can access the secrets.</li> </ul> <p>You must have the same naming convention in the field name as in the Key Vault secret name. For example, if the secret is named <code>SqlServerPassword</code>, the field name must be the same. You can use an alias too.</p> <p>In Key Vault, nested models are supported with the <code>--</code> separator. For example, <code>SqlServer--Password</code>.</p> <p>Key Vault arrays (e.g. <code>MySecret--0</code>, <code>MySecret--1</code>) are not supported.</p> <pre><code>import os\nfrom typing import Tuple, Type\n\nfrom azure.identity import DefaultAzureCredential\nfrom pydantic import BaseModel\n\nfrom pydantic_settings import (\n    AzureKeyVaultSettingsSource,\n    BaseSettings,\n    PydanticBaseSettingsSource,\n)\n\n\nclass SubModel(BaseModel):\n    a: str\n\n\nclass AzureKeyVaultSettings(BaseSettings):\n    foo: str\n    bar: int\n    sub: SubModel\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        az_key_vault_settings = AzureKeyVaultSettingsSource(\n            settings_cls,\n            os.environ['AZURE_KEY_VAULT_URL'],\n            DefaultAzureCredential(),\n        )\n        return (\n            init_settings,\n            env_settings,\n            dotenv_settings,\n            file_secret_settings,\n            az_key_vault_settings,\n        )\n</code></pre>"},{"location":"concepts/pydantic_settings/#other-settings-source","title":"Other settings source","text":"<p>Other settings sources are available for common configuration files:</p> <ul> <li><code>JsonConfigSettingsSource</code> using <code>json_file</code> and <code>json_file_encoding</code> arguments</li> <li><code>PyprojectTomlConfigSettingsSource</code> using (optional) <code>pyproject_toml_depth</code> and (optional) <code>pyproject_toml_table_header</code> arguments</li> <li><code>TomlConfigSettingsSource</code> using <code>toml_file</code> argument</li> <li><code>YamlConfigSettingsSource</code> using <code>yaml_file</code> and yaml_file_encoding arguments</li> </ul> <p>You can also provide multiple files by providing a list of path: <pre><code>toml_file = ['config.default.toml', 'config.custom.toml']\n</code></pre> To use them, you can use the same mechanism described here</p> <pre><code>from typing import Tuple, Type\n\nfrom pydantic import BaseModel\n\nfrom pydantic_settings import (\n    BaseSettings,\n    PydanticBaseSettingsSource,\n    SettingsConfigDict,\n    TomlConfigSettingsSource,\n)\n\n\nclass Nested(BaseModel):\n    nested_field: str\n\n\nclass Settings(BaseSettings):\n    foobar: str\n    nested: Nested\n    model_config = SettingsConfigDict(toml_file='config.toml')\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return (TomlConfigSettingsSource(settings_cls),)\n</code></pre> <p>This will be able to read the following \"config.toml\" file, located in your working directory:</p> <pre><code>foobar = \"Hello\"\n[nested]\nnested_field = \"world!\"\n</code></pre>"},{"location":"concepts/pydantic_settings/#pyprojecttoml","title":"pyproject.toml","text":"<p>\"pyproject.toml\" is a standardized file for providing configuration values in Python projects. PEP 518 defines a <code>[tool]</code> table that can be used to provide arbitrary tool configuration. While encouraged to use the <code>[tool]</code> table, <code>PyprojectTomlConfigSettingsSource</code> can be used to load variables from any location with in \"pyproject.toml\" file.</p> <p>This is controlled by providing <code>SettingsConfigDict(pyproject_toml_table_header=tuple[str, ...])</code> where the value is a tuple of header parts. By default, <code>pyproject_toml_table_header=('tool', 'pydantic-settings')</code> which will load variables from the <code>[tool.pydantic-settings]</code> table.</p> <pre><code>from typing import Tuple, Type\n\nfrom pydantic_settings import (\n    BaseSettings,\n    PydanticBaseSettingsSource,\n    PyprojectTomlConfigSettingsSource,\n    SettingsConfigDict,\n)\n\n\nclass Settings(BaseSettings):\n    \"\"\"Example loading values from the table used by default.\"\"\"\n\n    field: str\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return (PyprojectTomlConfigSettingsSource(settings_cls),)\n\n\nclass SomeTableSettings(Settings):\n    \"\"\"Example loading values from a user defined table.\"\"\"\n\n    model_config = SettingsConfigDict(\n        pyproject_toml_table_header=('tool', 'some-table')\n    )\n\n\nclass RootSettings(Settings):\n    \"\"\"Example loading values from the root of a pyproject.toml file.\"\"\"\n\n    model_config = SettingsConfigDict(extra='ignore', pyproject_toml_table_header=())\n</code></pre> <p>This will be able to read the following \"pyproject.toml\" file, located in your working directory, resulting in <code>Settings(field='default-table')</code>, <code>SomeTableSettings(field='some-table')</code>, &amp; <code>RootSettings(field='root')</code>:</p> <pre><code>field = \"root\"\n\n[tool.pydantic-settings]\nfield = \"default-table\"\n\n[tool.some-table]\nfield = \"some-table\"\n</code></pre> <p>By default, <code>PyprojectTomlConfigSettingsSource</code> will only look for a \"pyproject.toml\" in the your current working directory. However, there are two options to change this behavior.</p> <ul> <li><code>SettingsConfigDict(pyproject_toml_depth=&lt;int&gt;)</code> can be provided to check <code>&lt;int&gt;</code> number of directories up in the directory tree for a \"pyproject.toml\" if one is not found in the current working directory.   By default, no parent directories are checked.</li> <li>An explicit file path can be provided to the source when it is instantiated (e.g. <code>PyprojectTomlConfigSettingsSource(settings_cls, Path('~/.config').resolve() / 'pyproject.toml')</code>).   If a file path is provided this way, it will be treated as absolute (no other locations are checked).</li> </ul> <pre><code>from pathlib import Path\nfrom typing import Tuple, Type\n\nfrom pydantic_settings import (\n    BaseSettings,\n    PydanticBaseSettingsSource,\n    PyprojectTomlConfigSettingsSource,\n    SettingsConfigDict,\n)\n\n\nclass DiscoverSettings(BaseSettings):\n    \"\"\"Example of discovering a pyproject.toml in parent directories in not in `Path.cwd()`.\"\"\"\n\n    model_config = SettingsConfigDict(pyproject_toml_depth=2)\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return (PyprojectTomlConfigSettingsSource(settings_cls),)\n\n\nclass ExplicitFilePathSettings(BaseSettings):\n    \"\"\"Example of explicitly providing the path to the file to load.\"\"\"\n\n    field: str\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return (\n            PyprojectTomlConfigSettingsSource(\n                settings_cls, Path('~/.config').resolve() / 'pyproject.toml'\n            ),\n        )\n</code></pre>"},{"location":"concepts/pydantic_settings/#field-value-priority","title":"Field value priority","text":"<p>In the case where a value is specified for the same <code>Settings</code> field in multiple ways, the selected value is determined as follows (in descending order of priority):</p> <ol> <li>If <code>cli_parse_args</code> is enabled, arguments passed in at the CLI.</li> <li>Arguments passed to the <code>Settings</code> class initialiser.</li> <li>Environment variables, e.g. <code>my_prefix_special_function</code> as described above.</li> <li>Variables loaded from a dotenv (<code>.env</code>) file.</li> <li>Variables loaded from the secrets directory.</li> <li>The default field values for the <code>Settings</code> model.</li> </ol>"},{"location":"concepts/pydantic_settings/#customise-settings-sources","title":"Customise settings sources","text":"<p>If the default order of priority doesn't match your needs, it's possible to change it by overriding the <code>settings_customise_sources</code> method of your <code>Settings</code> .</p> <p><code>settings_customise_sources</code> takes four callables as arguments and returns any number of callables as a tuple. In turn these callables are called to build the inputs to the fields of the settings class.</p> <p>Each callable should take an instance of the settings class as its sole argument and return a <code>dict</code>.</p>"},{"location":"concepts/pydantic_settings/#changing-priority","title":"Changing Priority","text":"<p>The order of the returned callables decides the priority of inputs; first item is the highest priority.</p> <pre><code>from typing import Tuple, Type\n\nfrom pydantic import PostgresDsn\n\nfrom pydantic_settings import BaseSettings, PydanticBaseSettingsSource\n\n\nclass Settings(BaseSettings):\n    database_dsn: PostgresDsn\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return env_settings, init_settings, file_secret_settings\n\n\nprint(Settings(database_dsn='postgres://postgres@localhost:5432/kwargs_db'))\n#&gt; database_dsn=MultiHostUrl('postgres://postgres@localhost:5432/kwargs_db')\n</code></pre> <p>By flipping <code>env_settings</code> and <code>init_settings</code>, environment variables now have precedence over <code>__init__</code> kwargs.</p>"},{"location":"concepts/pydantic_settings/#adding-sources","title":"Adding sources","text":"<p>As explained earlier, pydantic ships with multiples built-in settings sources. However, you may occasionally need to add your own custom sources, <code>settings_customise_sources</code> makes this very easy:</p> <pre><code>import json\nfrom pathlib import Path\nfrom typing import Any, Dict, Tuple, Type\n\nfrom pydantic.fields import FieldInfo\n\nfrom pydantic_settings import (\n    BaseSettings,\n    PydanticBaseSettingsSource,\n    SettingsConfigDict,\n)\n\n\nclass JsonConfigSettingsSource(PydanticBaseSettingsSource):\n    \"\"\"\n    A simple settings source class that loads variables from a JSON file\n    at the project's root.\n\n    Here we happen to choose to use the `env_file_encoding` from Config\n    when reading `config.json`\n    \"\"\"\n\n    def get_field_value(\n        self, field: FieldInfo, field_name: str\n    ) -&gt; Tuple[Any, str, bool]:\n        encoding = self.config.get('env_file_encoding')\n        file_content_json = json.loads(\n            Path('tests/example_test_config.json').read_text(encoding)\n        )\n        field_value = file_content_json.get(field_name)\n        return field_value, field_name, False\n\n    def prepare_field_value(\n        self, field_name: str, field: FieldInfo, value: Any, value_is_complex: bool\n    ) -&gt; Any:\n        return value\n\n    def __call__(self) -&gt; Dict[str, Any]:\n        d: Dict[str, Any] = {}\n\n        for field_name, field in self.settings_cls.model_fields.items():\n            field_value, field_key, value_is_complex = self.get_field_value(\n                field, field_name\n            )\n            field_value = self.prepare_field_value(\n                field_name, field, field_value, value_is_complex\n            )\n            if field_value is not None:\n                d[field_key] = field_value\n\n        return d\n\n\nclass Settings(BaseSettings):\n    model_config = SettingsConfigDict(env_file_encoding='utf-8')\n\n    foobar: str\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        return (\n            init_settings,\n            JsonConfigSettingsSource(settings_cls),\n            env_settings,\n            file_secret_settings,\n        )\n\n\nprint(Settings())\n#&gt; foobar='test'\n</code></pre>"},{"location":"concepts/pydantic_settings/#accesing-the-result-of-previous-sources","title":"Accesing the result of previous sources","text":"<p>Each source of settings can access the output of the previous ones.</p> <pre><code>from typing import Any, Dict, Tuple\n\nfrom pydantic.fields import FieldInfo\n\nfrom pydantic_settings import PydanticBaseSettingsSource\n\n\nclass MyCustomSource(PydanticBaseSettingsSource):\n    def get_field_value(\n        self, field: FieldInfo, field_name: str\n    ) -&gt; Tuple[Any, str, bool]: ...\n\n    def __call__(self) -&gt; Dict[str, Any]:\n        # Retrieve the aggregated settings from previous sources\n        current_state = self.current_state\n        current_state.get('some_setting')\n\n        # Retrive settings from all sources individually\n        # self.settings_sources_data[\"SettingsSourceName\"]: Dict[str, Any]\n        settings_sources_data = self.settings_sources_data\n        settings_sources_data['SomeSettingsSource'].get('some_setting')\n\n        # Your code here...\n</code></pre>"},{"location":"concepts/pydantic_settings/#removing-sources","title":"Removing sources","text":"<p>You might also want to disable a source:</p> <pre><code>from typing import Tuple, Type\n\nfrom pydantic import ValidationError\n\nfrom pydantic_settings import BaseSettings, PydanticBaseSettingsSource\n\n\nclass Settings(BaseSettings):\n    my_api_key: str\n\n    @classmethod\n    def settings_customise_sources(\n        cls,\n        settings_cls: Type[BaseSettings],\n        init_settings: PydanticBaseSettingsSource,\n        env_settings: PydanticBaseSettingsSource,\n        dotenv_settings: PydanticBaseSettingsSource,\n        file_secret_settings: PydanticBaseSettingsSource,\n    ) -&gt; Tuple[PydanticBaseSettingsSource, ...]:\n        # here we choose to ignore arguments from init_settings\n        return env_settings, file_secret_settings\n\n\ntry:\n    Settings(my_api_key='this is ignored')\nexcept ValidationError as exc_info:\n    print(exc_info)\n    \"\"\"\n    1 validation error for Settings\n    my_api_key\n      Field required [type=missing, input_value={}, input_type=dict]\n        For further information visit https://errors.pydantic.dev/2/v/missing\n    \"\"\"\n</code></pre>"},{"location":"concepts/pydantic_settings/#in-place-reloading","title":"In-place reloading","text":"<p>In case you want to reload in-place an existing setting, you can do it by using its <code>__init__</code> method :</p> <pre><code>import os\n\nfrom pydantic import Field\n\nfrom pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings):\n    foo: str = Field('foo')\n\n\nmutable_settings = Settings()\n\nprint(mutable_settings.foo)\n#&gt; foo\n\nos.environ['foo'] = 'bar'\nprint(mutable_settings.foo)\n#&gt; foo\n\nmutable_settings.__init__()\nprint(mutable_settings.foo)\n#&gt; bar\n\nos.environ.pop('foo')\nmutable_settings.__init__()\nprint(mutable_settings.foo)\n#&gt; foo\n</code></pre>"},{"location":"concepts/serialization/","title":"Serialization","text":"<p>Beyond accessing model attributes directly via their field names (e.g. <code>model.foobar</code>), models can be converted, dumped, serialized, and exported in a number of ways.</p> <p>Serialize versus dump</p> <p>Pydantic uses the terms \"serialize\" and \"dump\" interchangeably. Both refer to the process of converting a model to a dictionary or JSON-encoded string.</p> <p>Outside of Pydantic, the word \"serialize\" usually refers to converting in-memory data into a string or bytes. However, in the context of Pydantic, there is a very close relationship between converting an object from a more structured form \u2014 such as a Pydantic model, a dataclass, etc. \u2014 into a less structured form comprised of Python built-ins such as dict.</p> <p>While we could (and on occasion, do) distinguish between these scenarios by using the word \"dump\" when converting to primitives and \"serialize\" when converting to string, for practical purposes, we frequently use the word \"serialize\" to refer to both of these situations, even though it does not always imply conversion to a string or bytes.</p>"},{"location":"concepts/serialization/#modelmodel_dump","title":"<code>model.model_dump(...)</code>","text":"API Documentation <p><code>pydantic.main.BaseModel.model_dump</code></p> <p>This is the primary way of converting a model to a dictionary. Sub-models will be recursively converted to dictionaries.</p> <p>Note</p> <p>The one exception to sub-models being converted to dictionaries is that <code>RootModel</code> and its subclasses will have the <code>root</code> field value dumped directly, without a wrapping dictionary. This is also done recursively.</p> <p>Note</p> <p>You can use computed fields to include <code>property</code> and <code>cached_property</code> data in the <code>model.model_dump(...)</code> output.</p> <p>Example:</p> <pre><code>from typing import Any, List, Optional\n\nfrom pydantic import BaseModel, Field, Json\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    banana: Optional[float] = 1.1\n    foo: str = Field(serialization_alias='foo_alias')\n    bar: BarModel\n\n\nm = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123})\n\n# returns a dictionary:\nprint(m.model_dump())\n#&gt; {'banana': 3.14, 'foo': 'hello', 'bar': {'whatever': 123}}\nprint(m.model_dump(include={'foo', 'bar'}))\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(m.model_dump(exclude={'foo', 'bar'}))\n#&gt; {'banana': 3.14}\nprint(m.model_dump(by_alias=True))\n#&gt; {'banana': 3.14, 'foo_alias': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_unset=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(banana=1.1, foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_defaults=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_defaults=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\nprint(\n    FooBarModel(banana=None, foo='hello', bar={'whatever': 123}).model_dump(\n        exclude_none=True\n    )\n)\n#&gt; {'foo': 'hello', 'bar': {'whatever': 123}}\n\n\nclass Model(BaseModel):\n    x: List[Json[Any]]\n\n\nprint(Model(x=['{\"a\": 1}', '[1, 2]']).model_dump())\n#&gt; {'x': [{'a': 1}, [1, 2]]}\nprint(Model(x=['{\"a\": 1}', '[1, 2]']).model_dump(round_trip=True))\n#&gt; {'x': ['{\"a\":1}', '[1,2]']}\n</code></pre>"},{"location":"concepts/serialization/#modelmodel_dump_json","title":"<code>model.model_dump_json(...)</code>","text":"API Documentation <p><code>pydantic.main.BaseModel.model_dump_json</code></p> <p>The <code>.model_dump_json()</code> method serializes a model directly to a JSON-encoded string that is equivalent to the result produced by <code>.model_dump()</code>.</p> <p>See arguments for more information.</p> <p>Note</p> <p>Pydantic can serialize many commonly used types to JSON that would otherwise be incompatible with a simple <code>json.dumps(foobar)</code> (e.g. <code>datetime</code>, <code>date</code> or <code>UUID</code>) .</p> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    foo: datetime\n    bar: BarModel\n\n\nm = FooBarModel(foo=datetime(2032, 6, 1, 12, 13, 14), bar={'whatever': 123})\nprint(m.model_dump_json())\n#&gt; {\"foo\":\"2032-06-01T12:13:14\",\"bar\":{\"whatever\":123}}\nprint(m.model_dump_json(indent=2))\n\"\"\"\n{\n  \"foo\": \"2032-06-01T12:13:14\",\n  \"bar\": {\n    \"whatever\": 123\n  }\n}\n\"\"\"\n</code></pre>"},{"location":"concepts/serialization/#dictmodel-and-iteration","title":"<code>dict(model)</code> and iteration","text":"<p>Pydantic models can also be converted to dictionaries using <code>dict(model)</code>, and you can also iterate over a model's fields using <code>for field_name, field_value in model:</code>. With this approach the raw field values are returned, so sub-models will not be converted to dictionaries.</p> <p>Example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    banana: float\n    foo: str\n    bar: BarModel\n\n\nm = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123})\n\nprint(dict(m))\n#&gt; {'banana': 3.14, 'foo': 'hello', 'bar': BarModel(whatever=123)}\nfor name, value in m:\n    print(f'{name}: {value}')\n    #&gt; banana: 3.14\n    #&gt; foo: hello\n    #&gt; bar: whatever=123\n</code></pre> <p>Note also that <code>RootModel</code> does get converted to a dictionary with the key <code>'root'</code>.</p>"},{"location":"concepts/serialization/#custom-serializers","title":"Custom serializers","text":"<p>Pydantic provides several functional serializers to customise how a model is serialized to a dictionary or JSON.</p> <ul> <li><code>@field_serializer</code></li> <li><code>@model_serializer</code></li> <li><code>PlainSerializer</code></li> <li><code>WrapSerializer</code></li> </ul> <p>Serialization can be customised on a field using the <code>@field_serializer</code> decorator, and on a model using the <code>@model_serializer</code> decorator.</p> <pre><code>from datetime import datetime, timedelta, timezone\nfrom typing import Any, Dict\n\nfrom pydantic import BaseModel, ConfigDict, field_serializer, model_serializer\n\n\nclass WithCustomEncoders(BaseModel):\n    model_config = ConfigDict(ser_json_timedelta='iso8601')\n\n    dt: datetime\n    diff: timedelta\n\n    @field_serializer('dt')\n    def serialize_dt(self, dt: datetime, _info):\n        return dt.timestamp()\n\n\nm = WithCustomEncoders(\n    dt=datetime(2032, 6, 1, tzinfo=timezone.utc), diff=timedelta(hours=100)\n)\nprint(m.model_dump_json())\n#&gt; {\"dt\":1969660800.0,\"diff\":\"P4DT4H\"}\n\n\nclass Model(BaseModel):\n    x: str\n\n    @model_serializer\n    def ser_model(self) -&gt; Dict[str, Any]:\n        return {'x': f'serialized {self.x}'}\n\n\nprint(Model(x='test value').model_dump_json())\n#&gt; {\"x\":\"serialized test value\"}\n</code></pre> <p>Note</p> <p>A single serializer can also be called on all fields by passing the special value '*' to the <code>@field_serializer</code> decorator.</p> <p>In addition, <code>PlainSerializer</code> and <code>WrapSerializer</code> enable you to use a function to modify the output of serialization.</p> <p>Both serializers accept optional arguments including:</p> <ul> <li><code>return_type</code> specifies the return type for the function. If omitted it will be inferred from the type annotation.</li> <li><code>when_used</code> specifies when this serializer should be used. Accepts a string with values 'always',     'unless-none', 'json', and 'json-unless-none'. Defaults to 'always'.</li> </ul> <p><code>PlainSerializer</code> uses a simple function to modify the output of serialization.</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel\nfrom pydantic.functional_serializers import PlainSerializer\n\nFancyInt = Annotated[\n    int, PlainSerializer(lambda x: f'{x:,}', return_type=str, when_used='json')\n]\n\n\nclass MyModel(BaseModel):\n    x: FancyInt\n\n\nprint(MyModel(x=1234).model_dump())\n#&gt; {'x': 1234}\n\nprint(MyModel(x=1234).model_dump(mode='json'))\n#&gt; {'x': '1,234'}\n</code></pre> <p><code>WrapSerializer</code> receives the raw inputs along with a handler function that applies the standard serialization logic, and can modify the resulting value before returning it as the final output of serialization.</p> <pre><code>from typing import Any\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, SerializerFunctionWrapHandler\nfrom pydantic.functional_serializers import WrapSerializer\n\n\ndef ser_wrap(v: Any, nxt: SerializerFunctionWrapHandler) -&gt; str:\n    return f'{nxt(v + 1):,}'\n\n\nFancyInt = Annotated[int, WrapSerializer(ser_wrap, when_used='json')]\n\n\nclass MyModel(BaseModel):\n    x: FancyInt\n\n\nprint(MyModel(x=1234).model_dump())\n#&gt; {'x': 1234}\n\nprint(MyModel(x=1234).model_dump(mode='json'))\n#&gt; {'x': '1,235'}\n</code></pre>"},{"location":"concepts/serialization/#overriding-the-return-type-when-dumping-a-model","title":"Overriding the return type when dumping a model","text":"<p>While the return value of <code>.model_dump()</code> can usually be described as <code>dict[str, Any]</code>, through the use of <code>@model_serializer</code> you can actually cause it to return a value that doesn't match this signature: <pre><code>from pydantic import BaseModel, model_serializer\n\n\nclass Model(BaseModel):\n    x: str\n\n    @model_serializer\n    def ser_model(self) -&gt; str:\n        return self.x\n\n\nprint(Model(x='not a dict').model_dump())\n#&gt; not a dict\n</code></pre></p> <p>If you want to do this and still get proper type-checking for this method, you can override <code>.model_dump()</code> in an <code>if TYPE_CHECKING:</code> block:</p> <pre><code>from typing import TYPE_CHECKING, Any, Literal\n\nfrom pydantic import BaseModel, model_serializer\n\n\nclass Model(BaseModel):\n    x: str\n\n    @model_serializer\n    def ser_model(self) -&gt; str:\n        return self.x\n\n    if TYPE_CHECKING:\n        # Ensure type checkers see the correct return type\n        def model_dump(\n            self,\n            *,\n            mode: Literal['json', 'python'] | str = 'python',\n            include: Any = None,\n            exclude: Any = None,\n            by_alias: bool = False,\n            exclude_unset: bool = False,\n            exclude_defaults: bool = False,\n            exclude_none: bool = False,\n            round_trip: bool = False,\n            warnings: bool = True,\n        ) -&gt; str: ...\n</code></pre> <p>This trick is actually used in <code>RootModel</code> for precisely this purpose.</p>"},{"location":"concepts/serialization/#serializing-subclasses","title":"Serializing subclasses","text":""},{"location":"concepts/serialization/#subclasses-of-standard-types","title":"Subclasses of standard types","text":"<p>Subclasses of standard types are automatically dumped like their super-classes:</p> <pre><code>from datetime import date, timedelta\nfrom typing import Any, Type\n\nfrom pydantic_core import core_schema\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\nclass DayThisYear(date):\n    \"\"\"\n    Contrived example of a special type of date that\n    takes an int and interprets it as a day in the current year\n    \"\"\"\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: Type[Any], handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        return core_schema.no_info_after_validator_function(\n            cls.validate,\n            core_schema.int_schema(),\n            serialization=core_schema.format_ser_schema('%Y-%m-%d'),\n        )\n\n    @classmethod\n    def validate(cls, v: int):\n        return date(2023, 1, 1) + timedelta(days=v)\n\n\nclass FooModel(BaseModel):\n    date: DayThisYear\n\n\nm = FooModel(date=300)\nprint(m.model_dump_json())\n#&gt; {\"date\":\"2023-10-28\"}\n</code></pre>"},{"location":"concepts/serialization/#subclass-instances-for-fields-of-basemodel-dataclasses-typeddict","title":"Subclass instances for fields of <code>BaseModel</code>, dataclasses, <code>TypedDict</code>","text":"<p>When using fields whose annotations are themselves struct-like types (e.g., <code>BaseModel</code> subclasses, dataclasses, etc.), the default behavior is to serialize the attribute value as though it was an instance of the annotated type, even if it is a subclass. More specifically, only the fields from the annotated type will be included in the dumped object:</p> <pre><code>from pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n\n\nclass UserLogin(User):\n    password: str\n\n\nclass OuterModel(BaseModel):\n    user: User\n\n\nuser = UserLogin(name='pydantic', password='hunter2')\n\nm = OuterModel(user=user)\nprint(m)\n#&gt; user=UserLogin(name='pydantic', password='hunter2')\nprint(m.model_dump())  # note: the password field is not included\n#&gt; {'user': {'name': 'pydantic'}}\n</code></pre> <p>Migration Warning</p> <p>This behavior is different from how things worked in Pydantic V1, where we would always include all (subclass) fields when recursively dumping models to dicts. The motivation behind this change in behavior is that it helps ensure that you know precisely which fields could be included when serializing, even if subclasses get passed when instantiating the object. In particular, this can help prevent surprises when adding sensitive information like secrets as fields of subclasses.</p>"},{"location":"concepts/serialization/#serializing-with-duck-typing","title":"Serializing with duck-typing \ud83e\udd86","text":"<p>What is serialization with duck typing?</p> <p>Duck-typing serialization is the behavior of serializing an object based on the fields present in the object itself, rather than the fields present in the schema of the object. This means that when an object is serialized, fields present in a subclass, but not in the original schema, will be included in the serialized output.</p> <p>This behavior was the default in Pydantic V1, but was changed in V2 to help ensure that you know precisely which fields would be included when serializing, even if subclasses get passed when instantiating the object. This helps prevent security risks when serializing subclasses with sensitive information, for example.</p> <p>If you want v1-style duck-typing serialization behavior, you can use a runtime setting, or annotate individual types.</p> <ul> <li>Field / type level: use the <code>SerializeAsAny</code> annotation</li> <li>Runtime level: use the <code>serialize_as_any</code> flag when calling <code>model_dump()</code> or <code>model_dump_json()</code></li> </ul> <p>We discuss these options below in more detail:</p>"},{"location":"concepts/serialization/#serializeasany-annotation","title":"<code>SerializeAsAny</code> annotation:","text":"<p>If you want duck-typing serialization behavior, this can be done using the <code>SerializeAsAny</code> annotation on a type:</p> <pre><code>from pydantic import BaseModel, SerializeAsAny\n\n\nclass User(BaseModel):\n    name: str\n\n\nclass UserLogin(User):\n    password: str\n\n\nclass OuterModel(BaseModel):\n    as_any: SerializeAsAny[User]\n    as_user: User\n\n\nuser = UserLogin(name='pydantic', password='password')\n\nprint(OuterModel(as_any=user, as_user=user).model_dump())\n\"\"\"\n{\n    'as_any': {'name': 'pydantic', 'password': 'password'},\n    'as_user': {'name': 'pydantic'},\n}\n\"\"\"\n</code></pre> <p>When a field is annotated as <code>SerializeAsAny[&lt;SomeType&gt;]</code>, the validation behavior will be the same as if it was annotated as <code>&lt;SomeType&gt;</code>, and type-checkers like mypy will treat the attribute as having the appropriate type as well. But when serializing, the field will be serialized as though the type hint for the field was <code>Any</code>, which is where the name comes from.</p>"},{"location":"concepts/serialization/#serialize_as_any-runtime-setting","title":"<code>serialize_as_any</code> runtime setting","text":"<p>The <code>serialize_as_any</code> runtime setting can be used to serialize model data with or without duck typed serialization behavior. <code>serialize_as_any</code> can be passed as a keyword argument to the <code>model_dump()</code> and <code>model_dump_json</code> methods of <code>BaseModel</code>s and <code>RootModel</code>s. It can also be passed as a keyword argument to the <code>dump_python()</code> and <code>dump_json()</code> methods of <code>TypeAdapter</code>s.</p> <p>If <code>serialize_as_any</code> is set to <code>True</code>, the model will be serialized using duck typed serialization behavior, which means that the model will ignore the schema and instead ask the object itself how it should be serialized. In particular, this means that when model subclasses are serialized, fields present in the subclass but not in the original schema will be included.</p> <p>If <code>serialize_as_any</code> is set to <code>False</code> (which is the default), the model will be serialized using the schema, which means that fields present in a subclass but not in the original schema will be ignored.</p> <p>Why is this flag useful?</p> <p>Sometimes, you want to make sure that no matter what fields might have been added in subclasses, the serialized object will only have the fields listed in the original type definition. This can be useful if you add something like a <code>password: str</code> field in a subclass that you don't want to accidentally include in the serialized output.</p> <p>For example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n\n\nclass UserLogin(User):\n    password: str\n\n\nclass OuterModel(BaseModel):\n    user1: User\n    user2: User\n\n\nuser = UserLogin(name='pydantic', password='password')\n\nouter_model = OuterModel(user1=user, user2=user)\nprint(outer_model.model_dump(serialize_as_any=True))  # (1)!\n\"\"\"\n{\n    'user1': {'name': 'pydantic', 'password': 'password'},\n    'user2': {'name': 'pydantic', 'password': 'password'},\n}\n\"\"\"\n\nprint(outer_model.model_dump(serialize_as_any=False))  # (2)!\n#&gt; {'user1': {'name': 'pydantic'}, 'user2': {'name': 'pydantic'}}\n</code></pre> <ol> <li>With <code>serialize_as_any</code> set to <code>True</code>, the result matches that of V1.</li> <li>With <code>serialize_as_any</code> set to <code>False</code> (the V2 default), fields present on the subclass, but not the base class, are not included in serialization.</li> </ol> <p>This setting even takes effect with nested and recursive patterns as well. For example:</p> Python 3.8 and abovePython 3.9 and above <pre><code>from typing import List\n\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n    friends: List['User']\n\n\nclass UserLogin(User):\n    password: str\n\n\nclass OuterModel(BaseModel):\n    user: User\n\n\nuser = UserLogin(\n    name='samuel',\n    password='pydantic-pw',\n    friends=[UserLogin(name='sebastian', password='fastapi-pw', friends=[])],\n)\n\nprint(OuterModel(user=user).model_dump(serialize_as_any=True))  # (1)!\n\"\"\"\n{\n    'user': {\n        'name': 'samuel',\n        'friends': [\n            {'name': 'sebastian', 'friends': [], 'password': 'fastapi-pw'}\n        ],\n        'password': 'pydantic-pw',\n    }\n}\n\"\"\"\n\nprint(OuterModel(user=user).model_dump(serialize_as_any=False))  # (2)!\n\"\"\"\n{'user': {'name': 'samuel', 'friends': [{'name': 'sebastian', 'friends': []}]}}\n\"\"\"\n</code></pre> <ol> <li>Even nested <code>User</code> model instances are dumped with fields unique to <code>User</code> subclasses.</li> <li>Even nested <code>User</code> model instances are dumped without fields unique to <code>User</code> subclasses.</li> </ol> <pre><code>from pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n    friends: list['User']\n\n\nclass UserLogin(User):\n    password: str\n\n\nclass OuterModel(BaseModel):\n    user: User\n\n\nuser = UserLogin(\n    name='samuel',\n    password='pydantic-pw',\n    friends=[UserLogin(name='sebastian', password='fastapi-pw', friends=[])],\n)\n\nprint(OuterModel(user=user).model_dump(serialize_as_any=True))  # (1)!\n\"\"\"\n{\n    'user': {\n        'name': 'samuel',\n        'friends': [\n            {'name': 'sebastian', 'friends': [], 'password': 'fastapi-pw'}\n        ],\n        'password': 'pydantic-pw',\n    }\n}\n\"\"\"\n\nprint(OuterModel(user=user).model_dump(serialize_as_any=False))  # (2)!\n\"\"\"\n{'user': {'name': 'samuel', 'friends': [{'name': 'sebastian', 'friends': []}]}}\n\"\"\"\n</code></pre> <ol> <li>Even nested <code>User</code> model instances are dumped with fields unique to <code>User</code> subclasses.</li> <li>Even nested <code>User</code> model instances are dumped without fields unique to <code>User</code> subclasses.</li> </ol> <p>Note</p> <p>The behavior of the <code>serialize_as_any</code> runtime flag is almost the same as the behavior of the <code>SerializeAsAny</code> annotation. There are a few nuanced differences that we're working to resolve, but for the most part, you can expect the same behavior from both. See more about the differences in this active issue</p>"},{"location":"concepts/serialization/#overriding-the-serialize_as_any-default-false","title":"Overriding the <code>serialize_as_any</code> default (False)","text":"<p>You can override the default setting for <code>serialize_as_any</code> by configuring a subclass of <code>BaseModel</code> that overrides the default for the <code>serialize_as_any</code> argument to <code>model_dump()</code> and <code>model_dump_json()</code>, and then use that as the base class (instead of <code>pydantic.BaseModel</code>) for any model you want to have this default behavior.</p> <p>For example, you could do the following if you want to use duck-typing serialization by default:</p> Python 3.8 and abovePython 3.9 and above <pre><code>from typing import Any, Dict\n\nfrom pydantic import BaseModel, SecretStr\n\n\nclass MyBaseModel(BaseModel):\n    def model_dump(self, **kwargs) -&gt; Dict[str, Any]:\n        return super().model_dump(serialize_as_any=True, **kwargs)\n\n    def model_dump_json(self, **kwargs) -&gt; str:\n        return super().model_dump_json(serialize_as_any=True, **kwargs)\n\n\nclass User(MyBaseModel):\n    name: str\n\n\nclass UserInfo(User):\n    password: SecretStr\n\n\nclass OuterModel(MyBaseModel):\n    user: User\n\n\nu = OuterModel(user=UserInfo(name='John', password='secret_pw'))\nprint(u.model_dump_json())  # (1)!\n#&gt; {\"user\":{\"name\":\"John\",\"password\":\"**********\"}}\n</code></pre> <ol> <li>By default, <code>model_dump_json</code> will use duck-typing serialization behavior, which means that the <code>password</code> field is included in the output.</li> </ol> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel, SecretStr\n\n\nclass MyBaseModel(BaseModel):\n    def model_dump(self, **kwargs) -&gt; dict[str, Any]:\n        return super().model_dump(serialize_as_any=True, **kwargs)\n\n    def model_dump_json(self, **kwargs) -&gt; str:\n        return super().model_dump_json(serialize_as_any=True, **kwargs)\n\n\nclass User(MyBaseModel):\n    name: str\n\n\nclass UserInfo(User):\n    password: SecretStr\n\n\nclass OuterModel(MyBaseModel):\n    user: User\n\n\nu = OuterModel(user=UserInfo(name='John', password='secret_pw'))\nprint(u.model_dump_json())  # (1)!\n#&gt; {\"user\":{\"name\":\"John\",\"password\":\"**********\"}}\n</code></pre> <ol> <li>By default, <code>model_dump_json</code> will use duck-typing serialization behavior, which means that the <code>password</code> field is included in the output.</li> </ol>"},{"location":"concepts/serialization/#pickledumpsmodel","title":"<code>pickle.dumps(model)</code>","text":"<p>Pydantic models support efficient pickling and unpickling.</p> <pre><code>import pickle\n\nfrom pydantic import BaseModel\n\n\nclass FooBarModel(BaseModel):\n    a: str\n    b: int\n\n\nm = FooBarModel(a='hello', b=123)\nprint(m)\n#&gt; a='hello' b=123\ndata = pickle.dumps(m)\nprint(data[:20])\n#&gt; b'\\x80\\x04\\x95\\x95\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main_'\nm2 = pickle.loads(data)\nprint(m2)\n#&gt; a='hello' b=123\n</code></pre>"},{"location":"concepts/serialization/#advanced-include-and-exclude","title":"Advanced include and exclude","text":"<p>The <code>model_dump</code> and <code>model_dump_json</code> methods support <code>include</code> and <code>exclude</code> arguments which can either be sets or dictionaries. This allows nested selection of which fields to export:</p> <pre><code>from pydantic import BaseModel, SecretStr\n\n\nclass User(BaseModel):\n    id: int\n    username: str\n    password: SecretStr\n\n\nclass Transaction(BaseModel):\n    id: str\n    user: User\n    value: int\n\n\nt = Transaction(\n    id='1234567890',\n    user=User(id=42, username='JohnDoe', password='hashedpassword'),\n    value=9876543210,\n)\n\n# using a set:\nprint(t.model_dump(exclude={'user', 'value'}))\n#&gt; {'id': '1234567890'}\n\n# using a dict:\nprint(t.model_dump(exclude={'user': {'username', 'password'}, 'value': True}))\n#&gt; {'id': '1234567890', 'user': {'id': 42}}\n\nprint(t.model_dump(include={'id': True, 'user': {'id'}}))\n#&gt; {'id': '1234567890', 'user': {'id': 42}}\n</code></pre> <p>The <code>True</code> indicates that we want to exclude or include an entire key, just as if we included it in a set. This can be done at any depth level.</p> <p>Special care must be taken when including or excluding fields from a list or tuple of submodels or dictionaries. In this scenario, <code>model_dump</code> and related methods expect integer keys for element-wise inclusion or exclusion. To exclude a field from every member of a list or tuple, the dictionary key <code>'__all__'</code> can be used, as shown here:</p> <pre><code>import datetime\nfrom typing import List\n\nfrom pydantic import BaseModel, SecretStr\n\n\nclass Country(BaseModel):\n    name: str\n    phone_code: int\n\n\nclass Address(BaseModel):\n    post_code: int\n    country: Country\n\n\nclass CardDetails(BaseModel):\n    number: SecretStr\n    expires: datetime.date\n\n\nclass Hobby(BaseModel):\n    name: str\n    info: str\n\n\nclass User(BaseModel):\n    first_name: str\n    second_name: str\n    address: Address\n    card_details: CardDetails\n    hobbies: List[Hobby]\n\n\nuser = User(\n    first_name='John',\n    second_name='Doe',\n    address=Address(\n        post_code=123456, country=Country(name='USA', phone_code=1)\n    ),\n    card_details=CardDetails(\n        number='4212934504460000', expires=datetime.date(2020, 5, 1)\n    ),\n    hobbies=[\n        Hobby(name='Programming', info='Writing code and stuff'),\n        Hobby(name='Gaming', info='Hell Yeah!!!'),\n    ],\n)\n\nexclude_keys = {\n    'second_name': True,\n    'address': {'post_code': True, 'country': {'phone_code'}},\n    'card_details': True,\n    # You can exclude fields from specific members of a tuple/list by index:\n    'hobbies': {-1: {'info'}},\n}\n\ninclude_keys = {\n    'first_name': True,\n    'address': {'country': {'name'}},\n    'hobbies': {0: True, -1: {'name'}},\n}\n\n# would be the same as user.model_dump(exclude=exclude_keys) in this case:\nprint(user.model_dump(include=include_keys))\n\"\"\"\n{\n    'first_name': 'John',\n    'address': {'country': {'name': 'USA'}},\n    'hobbies': [\n        {'name': 'Programming', 'info': 'Writing code and stuff'},\n        {'name': 'Gaming'},\n    ],\n}\n\"\"\"\n\n# To exclude a field from all members of a nested list or tuple, use \"__all__\":\nprint(user.model_dump(exclude={'hobbies': {'__all__': {'info'}}}))\n\"\"\"\n{\n    'first_name': 'John',\n    'second_name': 'Doe',\n    'address': {\n        'post_code': 123456,\n        'country': {'name': 'USA', 'phone_code': 1},\n    },\n    'card_details': {\n        'number': SecretStr('**********'),\n        'expires': datetime.date(2020, 5, 1),\n    },\n    'hobbies': [{'name': 'Programming'}, {'name': 'Gaming'}],\n}\n\"\"\"\n</code></pre> <p>The same holds for the <code>model_dump_json</code> method.</p>"},{"location":"concepts/serialization/#model-and-field-level-include-and-exclude","title":"Model- and field-level include and exclude","text":"<p>In addition to the explicit arguments <code>exclude</code> and <code>include</code> passed to <code>model_dump</code> and <code>model_dump_json</code> methods, we can also pass the <code>exclude: bool</code> arguments directly to the <code>Field</code> constructor:</p> <p>Setting <code>exclude</code> on the field constructor (<code>Field(..., exclude=True)</code>) takes priority over the <code>exclude</code>/<code>include</code> on <code>model_dump</code> and <code>model_dump_json</code>:</p> <pre><code>from pydantic import BaseModel, Field, SecretStr\n\n\nclass User(BaseModel):\n    id: int\n    username: str\n    password: SecretStr = Field(..., exclude=True)\n\n\nclass Transaction(BaseModel):\n    id: str\n    value: int = Field(exclude=True)\n\n\nt = Transaction(\n    id='1234567890',\n    value=9876543210,\n)\n\nprint(t.model_dump())\n#&gt; {'id': '1234567890'}\nprint(t.model_dump(include={'id': True, 'value': True}))  # (1)!\n#&gt; {'id': '1234567890'}\n</code></pre> <ol> <li><code>value</code> excluded from the output because it excluded in <code>Field</code>.</li> </ol> <p>That being said, setting <code>exclude</code> on the field constructor (<code>Field(..., exclude=True)</code>) does not take priority over the <code>exclude_unset</code>, <code>exclude_none</code>, and <code>exclude_default</code> parameters on <code>model_dump</code> and <code>model_dump_json</code>:</p> Python 3.8 and abovePython 3.10 and above <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel, Field\n\n\nclass Person(BaseModel):\n    name: str\n    age: Optional[int] = Field(None, exclude=False)\n\n\nperson = Person(name='Jeremy')\n\nprint(person.model_dump())\n#&gt; {'name': 'Jeremy', 'age': None}\nprint(person.model_dump(exclude_none=True))  # (1)!\n#&gt; {'name': 'Jeremy'}\nprint(person.model_dump(exclude_unset=True))  # (2)!\n#&gt; {'name': 'Jeremy'}\nprint(person.model_dump(exclude_defaults=True))  # (3)!\n#&gt; {'name': 'Jeremy'}\n</code></pre> <ol> <li><code>age</code> excluded from the output because <code>exclude_none</code> was set to <code>True</code>, and <code>age</code> is <code>None</code>.</li> <li><code>age</code> excluded from the output because <code>exclude_unset</code> was set to <code>True</code>, and <code>age</code> was not set in the Person constructor.</li> <li><code>age</code> excluded from the output because <code>exclude_defaults</code> was set to <code>True</code>, and <code>age</code> takes the default value of <code>None</code>.</li> </ol> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Person(BaseModel):\n    name: str\n    age: int | None = Field(None, exclude=False)\n\n\nperson = Person(name='Jeremy')\n\nprint(person.model_dump())\n#&gt; {'name': 'Jeremy', 'age': None}\nprint(person.model_dump(exclude_none=True))  # (1)!\n#&gt; {'name': 'Jeremy'}\nprint(person.model_dump(exclude_unset=True))  # (2)!\n#&gt; {'name': 'Jeremy'}\nprint(person.model_dump(exclude_defaults=True))  # (3)!\n#&gt; {'name': 'Jeremy'}\n</code></pre> <ol> <li><code>age</code> excluded from the output because <code>exclude_none</code> was set to <code>True</code>, and <code>age</code> is <code>None</code>.</li> <li><code>age</code> excluded from the output because <code>exclude_unset</code> was set to <code>True</code>, and <code>age</code> was not set in the Person constructor.</li> <li><code>age</code> excluded from the output because <code>exclude_defaults</code> was set to <code>True</code>, and <code>age</code> takes the default value of <code>None</code>.</li> </ol>"},{"location":"concepts/serialization/#serialization-context","title":"Serialization Context","text":"<p>You can pass a context object to the serialization methods which can be accessed from the <code>info</code> argument to decorated serializer functions. This is useful when you need to dynamically update the serialization behavior during runtime. For example, if you wanted a field to be dumped depending on a dynamically controllable set of allowed values, this could be done by passing the allowed values by context:</p> <pre><code>from pydantic import BaseModel, SerializationInfo, field_serializer\n\n\nclass Model(BaseModel):\n    text: str\n\n    @field_serializer('text')\n    def remove_stopwords(self, v: str, info: SerializationInfo):\n        context = info.context\n        if context:\n            stopwords = context.get('stopwords', set())\n            v = ' '.join(w for w in v.split() if w.lower() not in stopwords)\n        return v\n\n\nmodel = Model.model_construct(**{'text': 'This is an example document'})\nprint(model.model_dump())  # no context\n#&gt; {'text': 'This is an example document'}\nprint(model.model_dump(context={'stopwords': ['this', 'is', 'an']}))\n#&gt; {'text': 'example document'}\nprint(model.model_dump(context={'stopwords': ['document']}))\n#&gt; {'text': 'This is an example'}\n</code></pre> <p>Similarly, you can use a context for validation.</p>"},{"location":"concepts/serialization/#model_copy","title":"<code>model_copy(...)</code>   API Documentation <p><code>pydantic.main.BaseModel.model_copy</code></p>  <p><code>model_copy()</code> allows models to be duplicated (with optional updates), which is particularly useful when working with frozen models.</p> <p>Example:</p> <pre><code>from pydantic import BaseModel\n\n\nclass BarModel(BaseModel):\n    whatever: int\n\n\nclass FooBarModel(BaseModel):\n    banana: float\n    foo: str\n    bar: BarModel\n\n\nm = FooBarModel(banana=3.14, foo='hello', bar={'whatever': 123})\n\nprint(m.model_copy(update={'banana': 0}))\n#&gt; banana=0 foo='hello' bar=BarModel(whatever=123)\nprint(id(m.bar) == id(m.model_copy().bar))\n#&gt; True\n# normal copy gives the same object reference for bar\nprint(id(m.bar) == id(m.model_copy(deep=True).bar))\n#&gt; False\n# deep copy gives a new object reference for `bar`\n</code></pre>","text":""},{"location":"concepts/strict_mode/","title":"Strict Mode","text":"API Documentation <p><code>pydantic.types.Strict</code></p> <p>By default, Pydantic will attempt to coerce values to the desired type when possible. For example, you can pass the string <code>\"123\"</code> as the input to an <code>int</code> field, and it will be converted to <code>123</code>. This coercion behavior is useful in many scenarios \u2014 think: UUIDs, URL parameters, HTTP headers, environment variables, user input, etc.</p> <p>However, there are also situations where this is not desirable, and you want Pydantic to error instead of coercing data.</p> <p>To better support this use case, Pydantic provides a \"strict mode\" that can be enabled on a per-model, per-field, or even per-validation-call basis. When strict mode is enabled, Pydantic will be much less lenient when coercing data, and will instead error if the data is not of the correct type.</p> <p>Here is a brief example showing the difference between validation behavior in strict and the default/\"lax\" mode:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass MyModel(BaseModel):\n    x: int\n\n\nprint(MyModel.model_validate({'x': '123'}))  # lax mode\n#&gt; x=123\n\ntry:\n    MyModel.model_validate({'x': '123'}, strict=True)  # strict mode\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for MyModel\n    x\n      Input should be a valid integer [type=int_type, input_value='123', input_type=str]\n    \"\"\"\n</code></pre> <p>There are various ways to get strict-mode validation while using Pydantic, which will be discussed in more detail below:</p> <ul> <li>Passing <code>strict=True</code> to the validation methods, such as <code>BaseModel.model_validate</code>,   <code>TypeAdapter.validate_python</code>, and similar for JSON</li> <li>Using <code>Field(strict=True)</code> with fields of a <code>BaseModel</code>, <code>dataclass</code>, or <code>TypedDict</code></li> <li>Using <code>pydantic.types.Strict</code> as a type annotation on a field</li> <li>Pydantic provides some type aliases that are already annotated with <code>Strict</code>, such as <code>pydantic.types.StrictInt</code></li> <li>Using <code>ConfigDict(strict=True)</code></li> </ul>"},{"location":"concepts/strict_mode/#type-coercions-in-strict-mode","title":"Type coercions in strict mode","text":"<p>For most types, when validating data from python in strict mode, only the instances of the exact types are accepted. For example, when validating an <code>int</code> field, only instances of <code>int</code> are accepted; passing instances of <code>float</code> or <code>str</code> will result in raising a <code>ValidationError</code>.</p> <p>Note that we are looser when validating data from JSON in strict mode. For example, when validating a <code>UUID</code> field, instances of <code>str</code> will be accepted when validating from JSON, but not from python:</p> <pre><code>import json\nfrom uuid import UUID\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass MyModel(BaseModel):\n    guid: UUID\n\n\ndata = {'guid': '12345678-1234-1234-1234-123456789012'}\n\nprint(MyModel.model_validate(data))  # OK: lax\n#&gt; guid=UUID('12345678-1234-1234-1234-123456789012')\n\nprint(\n    MyModel.model_validate_json(json.dumps(data), strict=True)\n)  # OK: strict, but from json\n#&gt; guid=UUID('12345678-1234-1234-1234-123456789012')\n\ntry:\n    MyModel.model_validate(data, strict=True)  # Not OK: strict, from python\nexcept ValidationError as exc:\n    print(exc.errors(include_url=False))\n    \"\"\"\n    [\n        {\n            'type': 'is_instance_of',\n            'loc': ('guid',),\n            'msg': 'Input should be an instance of UUID',\n            'input': '12345678-1234-1234-1234-123456789012',\n            'ctx': {'class': 'UUID'},\n        }\n    ]\n    \"\"\"\n</code></pre> <p>For more details about what types are allowed as inputs in strict mode, you can review the Conversion Table.</p>"},{"location":"concepts/strict_mode/#strict-mode-in-method-calls","title":"Strict mode in method calls","text":"<p>All the examples included so far get strict-mode validation through the use of <code>strict=True</code> as a keyword argument to the validation methods. While we have shown this for <code>BaseModel.model_validate</code>, this also works with arbitrary types through the use of <code>TypeAdapter</code>:</p> <pre><code>from pydantic import TypeAdapter, ValidationError\n\nprint(TypeAdapter(bool).validate_python('yes'))  # OK: lax\n#&gt; True\n\ntry:\n    TypeAdapter(bool).validate_python('yes', strict=True)  # Not OK: strict\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for bool\n      Input should be a valid boolean [type=bool_type, input_value='yes', input_type=str]\n    \"\"\"\n</code></pre> <p>Note this also works even when using more \"complex\" types in <code>TypeAdapter</code>: <pre><code>from dataclasses import dataclass\n\nfrom pydantic import TypeAdapter, ValidationError\n\n\n@dataclass\nclass MyDataclass:\n    x: int\n\n\ntry:\n    TypeAdapter(MyDataclass).validate_python({'x': '123'}, strict=True)\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for MyDataclass\n      Input should be an instance of MyDataclass [type=dataclass_exact_type, input_value={'x': '123'}, input_type=dict]\n    \"\"\"\n</code></pre></p> <p>This also works with the <code>TypeAdapter.validate_json</code> and <code>BaseModel.model_validate_json</code> methods:</p> <pre><code>import json\nfrom typing import List\nfrom uuid import UUID\n\nfrom pydantic import BaseModel, TypeAdapter, ValidationError\n\ntry:\n    TypeAdapter(List[int]).validate_json('[\"1\", 2, \"3\"]', strict=True)\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    2 validation errors for list[int]\n    0\n      Input should be a valid integer [type=int_type, input_value='1', input_type=str]\n    2\n      Input should be a valid integer [type=int_type, input_value='3', input_type=str]\n    \"\"\"\n\n\nclass Model(BaseModel):\n    x: int\n    y: UUID\n\n\ndata = {'x': '1', 'y': '12345678-1234-1234-1234-123456789012'}\ntry:\n    Model.model_validate(data, strict=True)\nexcept ValidationError as exc:\n    # Neither x nor y are valid in strict mode from python:\n    print(exc)\n    \"\"\"\n    2 validation errors for Model\n    x\n      Input should be a valid integer [type=int_type, input_value='1', input_type=str]\n    y\n      Input should be an instance of UUID [type=is_instance_of, input_value='12345678-1234-1234-1234-123456789012', input_type=str]\n    \"\"\"\n\njson_data = json.dumps(data)\ntry:\n    Model.model_validate_json(json_data, strict=True)\nexcept ValidationError as exc:\n    # From JSON, x is still not valid in strict mode, but y is:\n    print(exc)\n    \"\"\"\n    1 validation error for Model\n    x\n      Input should be a valid integer [type=int_type, input_value='1', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/strict_mode/#strict-mode-with-field","title":"Strict mode with <code>Field</code>","text":"<p>For individual fields on a model, you can set <code>strict=True</code> on the field. This will cause strict-mode validation to be used for that field, even when the validation methods are called without <code>strict=True</code>.</p> <p>Only the fields for which <code>strict=True</code> is set will be affected:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n    n_pets: int\n\n\nuser = User(name='John', age='42', n_pets='1')\nprint(user)\n#&gt; name='John' age=42 n_pets=1\n\n\nclass AnotherUser(BaseModel):\n    name: str\n    age: int = Field(strict=True)\n    n_pets: int\n\n\ntry:\n    anotheruser = AnotherUser(name='John', age='42', n_pets='1')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for AnotherUser\n    age\n      Input should be a valid integer [type=int_type, input_value='42', input_type=str]\n    \"\"\"\n</code></pre> <p>Note that making fields strict will also affect the validation performed when instantiating the model class:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(strict=True)\n    y: int = Field(strict=False)\n\n\ntry:\n    Model(x='1', y='2')\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for Model\n    x\n      Input should be a valid integer [type=int_type, input_value='1', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/strict_mode/#using-field-as-an-annotation","title":"Using <code>Field</code> as an annotation","text":"<p>Note that <code>Field(strict=True)</code> (or with any other keyword arguments) can be used as an annotation if necessary, e.g., when working with <code>TypedDict</code>:</p> <pre><code>from typing_extensions import Annotated, TypedDict\n\nfrom pydantic import Field, TypeAdapter, ValidationError\n\n\nclass MyDict(TypedDict):\n    x: Annotated[int, Field(strict=True)]\n\n\ntry:\n    TypeAdapter(MyDict).validate_python({'x': '1'})\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for typed-dict\n    x\n      Input should be a valid integer [type=int_type, input_value='1', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/strict_mode/#strict-mode-with-annotated-strict","title":"Strict mode with <code>Annotated[..., Strict()]</code>","text":"API Documentation <p><code>pydantic.types.Strict</code></p> <p>Pydantic also provides the <code>Strict</code> class, which is intended for use as metadata with <code>typing.Annotated</code> class; this annotation indicates that the annotated field should be validated in strict mode:</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Strict, ValidationError\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n    is_active: Annotated[bool, Strict()]\n\n\nUser(name='David', age=33, is_active=True)\ntry:\n    User(name='David', age=33, is_active='True')\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for User\n    is_active\n      Input should be a valid boolean [type=bool_type, input_value='True', input_type=str]\n    \"\"\"\n</code></pre> <p>This is, in fact, the method used to implement some of the strict-out-of-the-box types provided by Pydantic, such as <code>StrictInt</code>.</p>"},{"location":"concepts/strict_mode/#strict-mode-with-configdict","title":"Strict mode with <code>ConfigDict</code>","text":""},{"location":"concepts/strict_mode/#basemodel","title":"<code>BaseModel</code>","text":"<p>If you want to enable strict mode for all fields on a complex input type, you can use <code>ConfigDict(strict=True)</code> in the <code>model_config</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(strict=True)\n\n    name: str\n    age: int\n    is_active: bool\n\n\ntry:\n    User(name='David', age='33', is_active='yes')\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    2 validation errors for User\n    age\n      Input should be a valid integer [type=int_type, input_value='33', input_type=str]\n    is_active\n      Input should be a valid boolean [type=bool_type, input_value='yes', input_type=str]\n    \"\"\"\n</code></pre> <p>Note</p> <p>When using <code>strict=True</code> through a model's <code>model_config</code>, you can still override the strictness of individual fields by setting <code>strict=False</code> on individual fields:</p> <pre><code>from pydantic import BaseModel, ConfigDict, Field\n\n\nclass User(BaseModel):\n    model_config = ConfigDict(strict=True)\n\n    name: str\n    age: int = Field(strict=False)\n</code></pre> <p>Note that strict mode is not recursively applied to nested model fields:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Inner(BaseModel):\n    y: int\n\n\nclass Outer(BaseModel):\n    model_config = ConfigDict(strict=True)\n\n    x: int\n    inner: Inner\n\n\nprint(Outer(x=1, inner=Inner(y='2')))\n#&gt; x=1 inner=Inner(y=2)\n\ntry:\n    Outer(x='1', inner=Inner(y='2'))\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for Outer\n    x\n      Input should be a valid integer [type=int_type, input_value='1', input_type=str]\n    \"\"\"\n</code></pre> <p>(This is also the case for dataclasses and <code>TypedDict</code>.)</p> <p>If this is undesirable, you should make sure that strict mode is enabled for all the types involved. For example, this can be done for model classes by using a shared base class with <code>model_config = ConfigDict(strict=True)</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass MyBaseModel(BaseModel):\n    model_config = ConfigDict(strict=True)\n\n\nclass Inner(MyBaseModel):\n    y: int\n\n\nclass Outer(MyBaseModel):\n    x: int\n    inner: Inner\n\n\ntry:\n    Outer.model_validate({'x': 1, 'inner': {'y': '2'}})\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for Outer\n    inner.y\n      Input should be a valid integer [type=int_type, input_value='2', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/strict_mode/#dataclasses-and-typeddict","title":"Dataclasses and <code>TypedDict</code>","text":"<p>Pydantic dataclasses behave similarly to the examples shown above with <code>BaseModel</code>, just that instead of <code>model_config</code> you should use the <code>config</code> keyword argument to the <code>@pydantic.dataclasses.dataclass</code> decorator.</p> <p>When possible, you can achieve nested strict mode for vanilla dataclasses or <code>TypedDict</code> subclasses by annotating fields with the <code>pydantic.types.Strict</code> annotation.</p> <p>However, if this is not possible (e.g., when working with third-party types), you can set the config that Pydantic should use for the type by setting the <code>__pydantic_config__</code> attribute on the type:</p> <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import ConfigDict, TypeAdapter, ValidationError\n\n\nclass Inner(TypedDict):\n    y: int\n\n\nInner.__pydantic_config__ = ConfigDict(strict=True)\n\n\nclass Outer(TypedDict):\n    x: int\n    inner: Inner\n\n\nadapter = TypeAdapter(Outer)\nprint(adapter.validate_python({'x': '1', 'inner': {'y': 2}}))\n#&gt; {'x': 1, 'inner': {'y': 2}}\n\n\ntry:\n    adapter.validate_python({'x': '1', 'inner': {'y': '2'}})\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for typed-dict\n    inner.y\n      Input should be a valid integer [type=int_type, input_value='2', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/strict_mode/#typeadapter","title":"<code>TypeAdapter</code>","text":"<p>You can also get strict mode through the use of the config keyword argument to the <code>TypeAdapter</code> class:</p> <pre><code>from pydantic import ConfigDict, TypeAdapter, ValidationError\n\nadapter = TypeAdapter(bool, config=ConfigDict(strict=True))\n\ntry:\n    adapter.validate_python('yes')\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for bool\n      Input should be a valid boolean [type=bool_type, input_value='yes', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/strict_mode/#validate_call","title":"<code>@validate_call</code>","text":"<p>Strict mode is also usable with the <code>@validate_call</code> decorator by passing the <code>config</code> keyword argument:</p> <pre><code>from pydantic import ConfigDict, ValidationError, validate_call\n\n\n@validate_call(config=ConfigDict(strict=True))\ndef foo(x: int) -&gt; int:\n    return x\n\n\ntry:\n    foo('1')\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for foo\n    0\n      Input should be a valid integer [type=int_type, input_value='1', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/type_adapter/","title":"Type Adapter","text":"<p>You may have types that are not <code>BaseModel</code>s that you want to validate data against. Or you may want to validate a <code>List[SomeModel]</code>, or dump it to JSON.</p> API Documentation <p><code>pydantic.type_adapter.TypeAdapter</code></p> <p>For use cases like this, Pydantic provides <code>TypeAdapter</code>, which can be used for type validation, serialization, and JSON schema generation without needing to create a <code>BaseModel</code>.</p> <p>A <code>TypeAdapter</code> instance exposes some of the functionality from <code>BaseModel</code> instance methods for types that do not have such methods (such as dataclasses, primitive types, and more):</p> <pre><code>from typing import List\n\nfrom typing_extensions import TypedDict\n\nfrom pydantic import TypeAdapter, ValidationError\n\n\nclass User(TypedDict):\n    name: str\n    id: int\n\n\nuser_list_adapter = TypeAdapter(List[User])\nuser_list = user_list_adapter.validate_python([{'name': 'Fred', 'id': '3'}])\nprint(repr(user_list))\n#&gt; [{'name': 'Fred', 'id': 3}]\n\ntry:\n    user_list_adapter.validate_python(\n        [{'name': 'Fred', 'id': 'wrong', 'other': 'no'}]\n    )\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for list[typed-dict]\n    0.id\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='wrong', input_type=str]\n    \"\"\"\n\nprint(repr(user_list_adapter.dump_json(user_list)))\n#&gt; b'[{\"name\":\"Fred\",\"id\":3}]'\n</code></pre> <p><code>dump_json</code> returns <code>bytes</code></p> <p><code>TypeAdapter</code>'s <code>dump_json</code> methods returns a <code>bytes</code> object, unlike the corresponding method for <code>BaseModel</code>, <code>model_dump_json</code>, which returns a <code>str</code>. The reason for this discrepancy is that in V1, model dumping returned a str type, so this behavior is retained in V2 for backwards compatibility. For the <code>BaseModel</code> case, <code>bytes</code> are coerced to <code>str</code> types, but <code>bytes</code> are often the desired end type. Hence, for the new <code>TypeAdapter</code> class in V2, the return type is simply <code>bytes</code>, which can easily be coerced to a <code>str</code> type if desired.</p> <p>Note</p> <p>Despite some overlap in use cases with <code>RootModel</code>, <code>TypeAdapter</code> should not be used as a type annotation for specifying fields of a <code>BaseModel</code>, etc.</p>"},{"location":"concepts/type_adapter/#parsing-data-into-a-specified-type","title":"Parsing data into a specified type","text":"<p><code>TypeAdapter</code> can be used to apply the parsing logic to populate Pydantic models in a more ad-hoc way. This function behaves similarly to <code>BaseModel.model_validate</code>, but works with arbitrary Pydantic-compatible types.</p> <p>This is especially useful when you want to parse results into a type that is not a direct subclass of <code>BaseModel</code>. For example:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, TypeAdapter\n\n\nclass Item(BaseModel):\n    id: int\n    name: str\n\n\n# `item_data` could come from an API call, eg., via something like:\n# item_data = requests.get('https://my-api.com/items').json()\nitem_data = [{'id': 1, 'name': 'My Item'}]\n\nitems = TypeAdapter(List[Item]).validate_python(item_data)\nprint(items)\n#&gt; [Item(id=1, name='My Item')]\n</code></pre> <p><code>TypeAdapter</code> is capable of parsing data into any of the types Pydantic can handle as fields of a <code>BaseModel</code>.</p> <p>Performance considerations</p> <p>When creating an instance of <code>TypeAdapter</code>, the provided type must be analyzed and converted into a pydantic-core schema. This comes with some non-trivial overhead, so it is recommended to create a <code>TypeAdapter</code> for a given type just once and reuse it in loops or other performance-critical code.</p>"},{"location":"concepts/types/","title":"Types","text":"<p>Where possible Pydantic uses standard library types to define fields, thus smoothing the learning curve. For many useful applications, however, no standard library type exists, so Pydantic implements many commonly used types.</p> <p>There are also more complex types that can be found in the Pydantic Extra Types package.</p> <p>If no existing type suits your purpose you can also implement your own Pydantic-compatible types with custom properties and validation.</p> <p>The following sections describe the types supported by Pydantic.</p> <ul> <li>Standard Library Types \u2014 types from the Python standard library.</li> <li>Strict Types \u2014 types that enable you to prevent coercion from compatible types.</li> <li>Custom Data Types \u2014 create your own custom data types.</li> <li>Field Type Conversions \u2014 strict and lax conversion between different field types.</li> </ul>"},{"location":"concepts/types/#type-conversion","title":"Type conversion","text":"<p>During validation, Pydantic can coerce data into expected types.</p> <p>There are two modes of coercion: strict and lax. See Conversion Table for more details on how Pydantic converts data in both strict and lax modes.</p> <p>See Strict mode and Strict Types for details on enabling strict coercion.</p>"},{"location":"concepts/types/#strict-types","title":"Strict Types","text":"<p>Pydantic provides the following strict types:</p> <ul> <li><code>StrictBool</code></li> <li><code>StrictBytes</code></li> <li><code>StrictFloat</code></li> <li><code>StrictInt</code></li> <li><code>StrictStr</code></li> </ul> <p>These types will only pass validation when the validated value is of the respective type or is a subtype of that type.</p>"},{"location":"concepts/types/#constrained-types","title":"Constrained types","text":"<p>This behavior is also exposed via the <code>strict</code> field of the constrained types and can be combined with a multitude of complex validation rules. See the individual type signatures for supported arguments.</p> <ul> <li><code>conbytes()</code></li> <li><code>condate()</code></li> <li><code>condecimal()</code></li> <li><code>confloat()</code></li> <li><code>confrozenset()</code></li> <li><code>conint()</code></li> <li><code>conlist()</code></li> <li><code>conset()</code></li> <li><code>constr()</code></li> </ul> <p>The following caveats apply:</p> <ul> <li><code>StrictBytes</code> (and the <code>strict</code> option of <code>conbytes()</code>) will accept both <code>bytes</code>,    and <code>bytearray</code> types.</li> <li><code>StrictInt</code> (and the <code>strict</code> option of <code>conint()</code>) will not accept <code>bool</code> types,     even though <code>bool</code> is a subclass of <code>int</code> in Python. Other subclasses will work.</li> <li><code>StrictFloat</code> (and the <code>strict</code> option of <code>confloat()</code>) will not accept <code>int</code>.</li> </ul> <p>Besides the above, you can also have a <code>FiniteFloat</code> type that will only accept finite values (i.e. not <code>inf</code>, <code>-inf</code> or <code>nan</code>).</p>"},{"location":"concepts/types/#custom-types","title":"Custom Types","text":"<p>You can also define your own custom data types. There are several ways to achieve it.</p>"},{"location":"concepts/types/#composing-types-via-annotated","title":"Composing types via <code>Annotated</code>","text":"<p>PEP 593 introduced <code>Annotated</code> as a way to attach runtime metadata to types without changing how type checkers interpret them. Pydantic takes advantage of this to allow you to create types that are identical to the original type as far as type checkers are concerned, but add validation, serialize differently, etc.</p> <p>For example, to create a type representing a positive int:</p> <pre><code># or `from typing import Annotated` for Python 3.9+\nfrom typing_extensions import Annotated\n\nfrom pydantic import Field, TypeAdapter, ValidationError\n\nPositiveInt = Annotated[int, Field(gt=0)]\n\nta = TypeAdapter(PositiveInt)\n\nprint(ta.validate_python(1))\n#&gt; 1\n\ntry:\n    ta.validate_python(-1)\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for constrained-int\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre> <p>Note that you can also use constraints from annotated-types to make this Pydantic-agnostic:</p> <pre><code>from annotated_types import Gt\nfrom typing_extensions import Annotated\n\nfrom pydantic import TypeAdapter, ValidationError\n\nPositiveInt = Annotated[int, Gt(0)]\n\nta = TypeAdapter(PositiveInt)\n\nprint(ta.validate_python(1))\n#&gt; 1\n\ntry:\n    ta.validate_python(-1)\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for constrained-int\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"concepts/types/#adding-validation-and-serialization","title":"Adding validation and serialization","text":"<p>You can add or override validation, serialization, and JSON schemas to an arbitrary type using the markers that Pydantic exports:</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import (\n    AfterValidator,\n    PlainSerializer,\n    TypeAdapter,\n    WithJsonSchema,\n)\n\nTruncatedFloat = Annotated[\n    float,\n    AfterValidator(lambda x: round(x, 1)),\n    PlainSerializer(lambda x: f'{x:.1e}', return_type=str),\n    WithJsonSchema({'type': 'string'}, mode='serialization'),\n]\n\n\nta = TypeAdapter(TruncatedFloat)\n\ninput = 1.02345\nassert input != 1.0\n\nassert ta.validate_python(input) == 1.0\n\nassert ta.dump_json(input) == b'\"1.0e+00\"'\n\nassert ta.json_schema(mode='validation') == {'type': 'number'}\nassert ta.json_schema(mode='serialization') == {'type': 'string'}\n</code></pre>"},{"location":"concepts/types/#generics","title":"Generics","text":"<p>You can use type variables within <code>Annotated</code> to make re-usable modifications to types:</p> <pre><code>from typing import Any, List, Sequence, TypeVar\n\nfrom annotated_types import Gt, Len\nfrom typing_extensions import Annotated\n\nfrom pydantic import ValidationError\nfrom pydantic.type_adapter import TypeAdapter\n\nSequenceType = TypeVar('SequenceType', bound=Sequence[Any])\n\n\nShortSequence = Annotated[SequenceType, Len(max_length=10)]\n\n\nta = TypeAdapter(ShortSequence[List[int]])\n\nv = ta.validate_python([1, 2, 3, 4, 5])\nassert v == [1, 2, 3, 4, 5]\n\ntry:\n    ta.validate_python([1] * 100)\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for list[int]\n      List should have at most 10 items after validation, not 100 [type=too_long, input_value=[1, 1, 1, 1, 1, 1, 1, 1, ... 1, 1, 1, 1, 1, 1, 1, 1], input_type=list]\n    \"\"\"\n\n\nT = TypeVar('T')  # or a bound=SupportGt\n\nPositiveList = List[Annotated[T, Gt(0)]]\n\nta = TypeAdapter(PositiveList[float])\n\nv = ta.validate_python([1])\nassert type(v[0]) is float\n\n\ntry:\n    ta.validate_python([-1])\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for list[constrained-float]\n    0\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"concepts/types/#named-type-aliases","title":"Named type aliases","text":"<p>The above examples make use of implicit type aliases. This means that they will not be able to have a <code>title</code> in JSON schemas and their schema will be copied between fields. You can use PEP 695's <code>TypeAliasType</code> via its typing-extensions backport to make named aliases, allowing you to define a new type without creating subclasses. This new type can be as simple as a name or have complex validation logic attached to it:</p> <pre><code>from typing import List\n\nfrom annotated_types import Gt\nfrom typing_extensions import Annotated, TypeAliasType\n\nfrom pydantic import BaseModel\n\nImplicitAliasPositiveIntList = List[Annotated[int, Gt(0)]]\n\n\nclass Model1(BaseModel):\n    x: ImplicitAliasPositiveIntList\n    y: ImplicitAliasPositiveIntList\n\n\nprint(Model1.model_json_schema())\n\"\"\"\n{\n    'properties': {\n        'x': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'title': 'X',\n            'type': 'array',\n        },\n        'y': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'title': 'Y',\n            'type': 'array',\n        },\n    },\n    'required': ['x', 'y'],\n    'title': 'Model1',\n    'type': 'object',\n}\n\"\"\"\n\nPositiveIntList = TypeAliasType('PositiveIntList', List[Annotated[int, Gt(0)]])\n\n\nclass Model2(BaseModel):\n    x: PositiveIntList\n    y: PositiveIntList\n\n\nprint(Model2.model_json_schema())\n\"\"\"\n{\n    '$defs': {\n        'PositiveIntList': {\n            'items': {'exclusiveMinimum': 0, 'type': 'integer'},\n            'type': 'array',\n        }\n    },\n    'properties': {\n        'x': {'$ref': '#/$defs/PositiveIntList'},\n        'y': {'$ref': '#/$defs/PositiveIntList'},\n    },\n    'required': ['x', 'y'],\n    'title': 'Model2',\n    'type': 'object',\n}\n\"\"\"\n</code></pre> <p>These named type aliases can also be generic:</p> <pre><code>from typing import Generic, List, TypeVar\n\nfrom annotated_types import Gt\nfrom typing_extensions import Annotated, TypeAliasType\n\nfrom pydantic import BaseModel, ValidationError\n\nT = TypeVar('T')  # or a `bound=SupportGt`\n\nPositiveList = TypeAliasType(\n    'PositiveList', List[Annotated[T, Gt(0)]], type_params=(T,)\n)\n\n\nclass Model(BaseModel, Generic[T]):\n    x: PositiveList[T]\n\n\nassert Model[int].model_validate_json('{\"x\": [\"1\"]}').x == [1]\n\ntry:\n    Model[int](x=[-1])\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for Model[int]\n    x.0\n      Input should be greater than 0 [type=greater_than, input_value=-1, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"concepts/types/#named-recursive-types","title":"Named recursive types","text":"<p>You can also use <code>TypeAliasType</code> to create recursive types:</p> <pre><code>from typing import Any, Dict, List, Union\n\nfrom pydantic_core import PydanticCustomError\nfrom typing_extensions import Annotated, TypeAliasType\n\nfrom pydantic import (\n    TypeAdapter,\n    ValidationError,\n    ValidationInfo,\n    ValidatorFunctionWrapHandler,\n    WrapValidator,\n)\n\n\ndef json_custom_error_validator(\n    value: Any, handler: ValidatorFunctionWrapHandler, _info: ValidationInfo\n) -&gt; Any:\n    \"\"\"Simplify the error message to avoid a gross error stemming\n    from exhaustive checking of all union options.\n    \"\"\"\n    try:\n        return handler(value)\n    except ValidationError:\n        raise PydanticCustomError(\n            'invalid_json',\n            'Input is not valid json',\n        )\n\n\nJson = TypeAliasType(\n    'Json',\n    Annotated[\n        Union[Dict[str, 'Json'], List['Json'], str, int, float, bool, None],\n        WrapValidator(json_custom_error_validator),\n    ],\n)\n\n\nta = TypeAdapter(Json)\n\nv = ta.validate_python({'x': [1], 'y': {'z': True}})\nassert v == {'x': [1], 'y': {'z': True}}\n\ntry:\n    ta.validate_python({'x': object()})\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for function-wrap[json_custom_error_validator()]\n      Input is not valid json [type=invalid_json, input_value={'x': &lt;object object at 0x0123456789ab&gt;}, input_type=dict]\n    \"\"\"\n</code></pre>"},{"location":"concepts/types/#customizing-validation-with-__get_pydantic_core_schema__","title":"Customizing validation with <code>__get_pydantic_core_schema__</code>","text":"<p>To do more extensive customization of how Pydantic handles custom classes, and in particular when you have access to the class or can subclass it, you can implement a special <code>__get_pydantic_core_schema__</code> to tell Pydantic how to generate the <code>pydantic-core</code> schema.</p> <p>While <code>pydantic</code> uses <code>pydantic-core</code> internally to handle validation and serialization, it is a new API for Pydantic V2, thus it is one of the areas most likely to be tweaked in the future and you should try to stick to the built-in constructs like those provided by <code>annotated-types</code>, <code>pydantic.Field</code>, or <code>BeforeValidator</code> and so on.</p> <p>You can implement <code>__get_pydantic_core_schema__</code> both on a custom type and on metadata intended to be put in <code>Annotated</code>. In both cases the API is middleware-like and similar to that of \"wrap\" validators: you get a <code>source_type</code> (which isn't necessarily the same as the class, in particular for generics) and a <code>handler</code> that you can call with a type to either call the next metadata in <code>Annotated</code> or call into Pydantic's internal schema generation.</p> <p>The simplest no-op implementation calls the handler with the type you are given, then returns that as the result. You can also choose to modify the type before calling the handler, modify the core schema returned by the handler, or not call the handler at all.</p>"},{"location":"concepts/types/#as-a-method-on-a-custom-type","title":"As a method on a custom type","text":"<p>The following is an example of a type that uses <code>__get_pydantic_core_schema__</code> to customize how it gets validated. This is equivalent to implementing <code>__get_validators__</code> in Pydantic V1.</p> <pre><code>from typing import Any\n\nfrom pydantic_core import CoreSchema, core_schema\n\nfrom pydantic import GetCoreSchemaHandler, TypeAdapter\n\n\nclass Username(str):\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: Any, handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        return core_schema.no_info_after_validator_function(cls, handler(str))\n\n\nta = TypeAdapter(Username)\nres = ta.validate_python('abc')\nassert isinstance(res, Username)\nassert res == 'abc'\n</code></pre> <p>See JSON Schema for more details on how to customize JSON schemas for custom types.</p>"},{"location":"concepts/types/#as-an-annotation","title":"As an annotation","text":"<p>Often you'll want to parametrize your custom type by more than just generic type parameters (which you can do via the type system and will be discussed later). Or you may not actually care (or want to) make an instance of your subclass; you actually want the original type, just with some extra validation done.</p> <p>For example, if you were to implement <code>pydantic.AfterValidator</code> (see Adding validation and serialization) yourself, you'd do something similar to the following:</p> <pre><code>from dataclasses import dataclass\nfrom typing import Any, Callable\n\nfrom pydantic_core import CoreSchema, core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\n\n@dataclass(frozen=True)  # (1)!\nclass MyAfterValidator:\n    func: Callable[[Any], Any]\n\n    def __get_pydantic_core_schema__(\n        self, source_type: Any, handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        return core_schema.no_info_after_validator_function(\n            self.func, handler(source_type)\n        )\n\n\nUsername = Annotated[str, MyAfterValidator(str.lower)]\n\n\nclass Model(BaseModel):\n    name: Username\n\n\nassert Model(name='ABC').name == 'abc'  # (2)!\n</code></pre> <ol> <li>The <code>frozen=True</code> specification makes <code>MyAfterValidator</code> hashable. Without this, a union such as <code>Username | None</code> will raise an error.</li> <li>Notice that type checkers will not complain about assigning <code>'ABC'</code> to <code>Username</code> like they did in the previous example because they do not consider <code>Username</code> to be a distinct type from <code>str</code>.</li> </ol>"},{"location":"concepts/types/#handling-third-party-types","title":"Handling third-party types","text":"<p>Another use case for the pattern in the previous section is to handle third party types.</p> <pre><code>from typing import Any\n\nfrom pydantic_core import core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import (\n    BaseModel,\n    GetCoreSchemaHandler,\n    GetJsonSchemaHandler,\n    ValidationError,\n)\nfrom pydantic.json_schema import JsonSchemaValue\n\n\nclass ThirdPartyType:\n    \"\"\"\n    This is meant to represent a type from a third-party library that wasn't designed with Pydantic\n    integration in mind, and so doesn't have a `pydantic_core.CoreSchema` or anything.\n    \"\"\"\n\n    x: int\n\n    def __init__(self):\n        self.x = 0\n\n\nclass _ThirdPartyTypePydanticAnnotation:\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls,\n        _source_type: Any,\n        _handler: GetCoreSchemaHandler,\n    ) -&gt; core_schema.CoreSchema:\n        \"\"\"\n        We return a pydantic_core.CoreSchema that behaves in the following ways:\n\n        * ints will be parsed as `ThirdPartyType` instances with the int as the x attribute\n        * `ThirdPartyType` instances will be parsed as `ThirdPartyType` instances without any changes\n        * Nothing else will pass validation\n        * Serialization will always return just an int\n        \"\"\"\n\n        def validate_from_int(value: int) -&gt; ThirdPartyType:\n            result = ThirdPartyType()\n            result.x = value\n            return result\n\n        from_int_schema = core_schema.chain_schema(\n            [\n                core_schema.int_schema(),\n                core_schema.no_info_plain_validator_function(validate_from_int),\n            ]\n        )\n\n        return core_schema.json_or_python_schema(\n            json_schema=from_int_schema,\n            python_schema=core_schema.union_schema(\n                [\n                    # check if it's an instance first before doing any further work\n                    core_schema.is_instance_schema(ThirdPartyType),\n                    from_int_schema,\n                ]\n            ),\n            serialization=core_schema.plain_serializer_function_ser_schema(\n                lambda instance: instance.x\n            ),\n        )\n\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, _core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; JsonSchemaValue:\n        # Use the same schema that would be used for `int`\n        return handler(core_schema.int_schema())\n\n\n# We now create an `Annotated` wrapper that we'll use as the annotation for fields on `BaseModel`s, etc.\nPydanticThirdPartyType = Annotated[\n    ThirdPartyType, _ThirdPartyTypePydanticAnnotation\n]\n\n\n# Create a model class that uses this annotation as a field\nclass Model(BaseModel):\n    third_party_type: PydanticThirdPartyType\n\n\n# Demonstrate that this field is handled correctly, that ints are parsed into `ThirdPartyType`, and that\n# these instances are also \"dumped\" directly into ints as expected.\nm_int = Model(third_party_type=1)\nassert isinstance(m_int.third_party_type, ThirdPartyType)\nassert m_int.third_party_type.x == 1\nassert m_int.model_dump() == {'third_party_type': 1}\n\n# Do the same thing where an instance of ThirdPartyType is passed in\ninstance = ThirdPartyType()\nassert instance.x == 0\ninstance.x = 10\n\nm_instance = Model(third_party_type=instance)\nassert isinstance(m_instance.third_party_type, ThirdPartyType)\nassert m_instance.third_party_type.x == 10\nassert m_instance.model_dump() == {'third_party_type': 10}\n\n# Demonstrate that validation errors are raised as expected for invalid inputs\ntry:\n    Model(third_party_type='a')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for Model\n    third_party_type.is-instance[ThirdPartyType]\n      Input should be an instance of ThirdPartyType [type=is_instance_of, input_value='a', input_type=str]\n    third_party_type.chain[int,function-plain[validate_from_int()]]\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    \"\"\"\n\n\nassert Model.model_json_schema() == {\n    'properties': {\n        'third_party_type': {'title': 'Third Party Type', 'type': 'integer'}\n    },\n    'required': ['third_party_type'],\n    'title': 'Model',\n    'type': 'object',\n}\n</code></pre> <p>You can use this approach to e.g. define behavior for Pandas or Numpy types.</p>"},{"location":"concepts/types/#using-getpydanticschema-to-reduce-boilerplate","title":"Using <code>GetPydanticSchema</code> to reduce boilerplate","text":"API Documentation <p><code>pydantic.types.GetPydanticSchema</code></p> <p>You may notice that the above examples where we create a marker class require a good amount of boilerplate. For many simple cases you can greatly minimize this by using <code>pydantic.GetPydanticSchema</code>:</p> <pre><code>from pydantic_core import core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, GetPydanticSchema\n\n\nclass Model(BaseModel):\n    y: Annotated[\n        str,\n        GetPydanticSchema(\n            lambda tp, handler: core_schema.no_info_after_validator_function(\n                lambda x: x * 2, handler(tp)\n            )\n        ),\n    ]\n\n\nassert Model(y='ab').y == 'abab'\n</code></pre>"},{"location":"concepts/types/#summary","title":"Summary","text":"<p>Let's recap:</p> <ol> <li>Pydantic provides high level hooks to customize types via <code>Annotated</code> like <code>AfterValidator</code> and <code>Field</code>. Use these when possible.</li> <li>Under the hood these use <code>pydantic-core</code> to customize validation, and you can hook into that directly using <code>GetPydanticSchema</code> or a marker class with <code>__get_pydantic_core_schema__</code>.</li> <li>If you really want a custom type you can implement <code>__get_pydantic_core_schema__</code> on the type itself.</li> </ol>"},{"location":"concepts/types/#handling-custom-generic-classes","title":"Handling custom generic classes","text":"<p>Warning</p> <p>This is an advanced technique that you might not need in the beginning. In most of the cases you will probably be fine with standard Pydantic models.</p> <p>You can use Generic Classes as field types and perform custom validation based on the \"type parameters\" (or sub-types) with <code>__get_pydantic_core_schema__</code>.</p> <p>If the Generic class that you are using as a sub-type has a classmethod <code>__get_pydantic_core_schema__</code>, you don't need to use <code>arbitrary_types_allowed</code> for it to work.</p> <p>Because the <code>source_type</code> parameter is not the same as the <code>cls</code> parameter, you can use <code>typing.get_args</code> (or <code>typing_extensions.get_args</code>) to extract the generic parameters. Then you can use the <code>handler</code> to generate a schema for them by calling <code>handler.generate_schema</code>. Note that we do not do something like <code>handler(get_args(source_type)[0])</code> because we want to generate an unrelated schema for that generic parameter, not one that is influenced by the current context of <code>Annotated</code> metadata and such. This is less important for custom types, but crucial for annotated metadata that modifies schema building.</p> <pre><code>from dataclasses import dataclass\nfrom typing import Any, Generic, TypeVar\n\nfrom pydantic_core import CoreSchema, core_schema\nfrom typing_extensions import get_args, get_origin\n\nfrom pydantic import (\n    BaseModel,\n    GetCoreSchemaHandler,\n    ValidationError,\n    ValidatorFunctionWrapHandler,\n)\n\nItemType = TypeVar('ItemType')\n\n\n# This is not a pydantic model, it's an arbitrary generic class\n@dataclass\nclass Owner(Generic[ItemType]):\n    name: str\n    item: ItemType\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: Any, handler: GetCoreSchemaHandler\n    ) -&gt; CoreSchema:\n        origin = get_origin(source_type)\n        if origin is None:  # used as `x: Owner` without params\n            origin = source_type\n            item_tp = Any\n        else:\n            item_tp = get_args(source_type)[0]\n        # both calling handler(...) and handler.generate_schema(...)\n        # would work, but prefer the latter for conceptual and consistency reasons\n        item_schema = handler.generate_schema(item_tp)\n\n        def val_item(\n            v: Owner[Any], handler: ValidatorFunctionWrapHandler\n        ) -&gt; Owner[Any]:\n            v.item = handler(v.item)\n            return v\n\n        python_schema = core_schema.chain_schema(\n            # `chain_schema` means do the following steps in order:\n            [\n                # Ensure the value is an instance of Owner\n                core_schema.is_instance_schema(cls),\n                # Use the item_schema to validate `items`\n                core_schema.no_info_wrap_validator_function(\n                    val_item, item_schema\n                ),\n            ]\n        )\n\n        return core_schema.json_or_python_schema(\n            # for JSON accept an object with name and item keys\n            json_schema=core_schema.chain_schema(\n                [\n                    core_schema.typed_dict_schema(\n                        {\n                            'name': core_schema.typed_dict_field(\n                                core_schema.str_schema()\n                            ),\n                            'item': core_schema.typed_dict_field(item_schema),\n                        }\n                    ),\n                    # after validating the json data convert it to python\n                    core_schema.no_info_before_validator_function(\n                        lambda data: Owner(\n                            name=data['name'], item=data['item']\n                        ),\n                        # note that we re-use the same schema here as below\n                        python_schema,\n                    ),\n                ]\n            ),\n            python_schema=python_schema,\n        )\n\n\nclass Car(BaseModel):\n    color: str\n\n\nclass House(BaseModel):\n    rooms: int\n\n\nclass Model(BaseModel):\n    car_owner: Owner[Car]\n    home_owner: Owner[House]\n\n\nmodel = Model(\n    car_owner=Owner(name='John', item=Car(color='black')),\n    home_owner=Owner(name='James', item=House(rooms=3)),\n)\nprint(model)\n\"\"\"\ncar_owner=Owner(name='John', item=Car(color='black')) home_owner=Owner(name='James', item=House(rooms=3))\n\"\"\"\n\ntry:\n    # If the values of the sub-types are invalid, we get an error\n    Model(\n        car_owner=Owner(name='John', item=House(rooms=3)),\n        home_owner=Owner(name='James', item=Car(color='black')),\n    )\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for Model\n    wine\n      Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='Kinda good', input_type=str]\n    cheese\n      Input should be a valid boolean, unable to interpret input [type=bool_parsing, input_value='yeah', input_type=str]\n    \"\"\"\n\n# Similarly with JSON\nmodel = Model.model_validate_json(\n    '{\"car_owner\":{\"name\":\"John\",\"item\":{\"color\":\"black\"}},\"home_owner\":{\"name\":\"James\",\"item\":{\"rooms\":3}}}'\n)\nprint(model)\n\"\"\"\ncar_owner=Owner(name='John', item=Car(color='black')) home_owner=Owner(name='James', item=House(rooms=3))\n\"\"\"\n\ntry:\n    Model.model_validate_json(\n        '{\"car_owner\":{\"name\":\"John\",\"item\":{\"rooms\":3}},\"home_owner\":{\"name\":\"James\",\"item\":{\"color\":\"black\"}}}'\n    )\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for Model\n    car_owner.item.color\n      Field required [type=missing, input_value={'rooms': 3}, input_type=dict]\n    home_owner.item.rooms\n      Field required [type=missing, input_value={'color': 'black'}, input_type=dict]\n    \"\"\"\n</code></pre>"},{"location":"concepts/types/#generic-containers","title":"Generic containers","text":"<p>The same idea can be applied to create generic container types, like a custom <code>Sequence</code> type:</p> <pre><code>from typing import Any, Sequence, TypeVar\n\nfrom pydantic_core import ValidationError, core_schema\nfrom typing_extensions import get_args\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler\n\nT = TypeVar('T')\n\n\nclass MySequence(Sequence[T]):\n    def __init__(self, v: Sequence[T]):\n        self.v = v\n\n    def __getitem__(self, i):\n        return self.v[i]\n\n    def __len__(self):\n        return len(self.v)\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source: Any, handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        instance_schema = core_schema.is_instance_schema(cls)\n\n        args = get_args(source)\n        if args:\n            # replace the type and rely on Pydantic to generate the right schema\n            # for `Sequence`\n            sequence_t_schema = handler.generate_schema(Sequence[args[0]])\n        else:\n            sequence_t_schema = handler.generate_schema(Sequence)\n\n        non_instance_schema = core_schema.no_info_after_validator_function(\n            MySequence, sequence_t_schema\n        )\n        return core_schema.union_schema([instance_schema, non_instance_schema])\n\n\nclass M(BaseModel):\n    model_config = dict(validate_default=True)\n\n    s1: MySequence = [3]\n\n\nm = M()\nprint(m)\n#&gt; s1=&lt;__main__.MySequence object at 0x0123456789ab&gt;\nprint(m.s1.v)\n#&gt; [3]\n\n\nclass M(BaseModel):\n    s1: MySequence[int]\n\n\nM(s1=[1])\ntry:\n    M(s1=['a'])\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    2 validation errors for M\n    s1.is-instance[MySequence]\n      Input should be an instance of MySequence [type=is_instance_of, input_value=['a'], input_type=list]\n    s1.function-after[MySequence(), json-or-python[json=list[int],python=chain[is-instance[Sequence],function-wrap[sequence_validator()]]]].0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/types/#access-to-field-name","title":"Access to field name","text":"<p>Note</p> <p>This was not possible with Pydantic V2 to V2.3, it was re-added in Pydantic V2.4.</p> <p>As of Pydantic V2.4, you can access the field name via the <code>handler.field_name</code> within <code>__get_pydantic_core_schema__</code> and thereby set the field name which will be available from <code>info.field_name</code>.</p> <pre><code>from typing import Any\n\nfrom pydantic_core import core_schema\n\nfrom pydantic import BaseModel, GetCoreSchemaHandler, ValidationInfo\n\n\nclass CustomType:\n    \"\"\"Custom type that stores the field it was used in.\"\"\"\n\n    def __init__(self, value: int, field_name: str):\n        self.value = value\n        self.field_name = field_name\n\n    def __repr__(self):\n        return f'CustomType&lt;{self.value} {self.field_name!r}&gt;'\n\n    @classmethod\n    def validate(cls, value: int, info: ValidationInfo):\n        return cls(value, info.field_name)\n\n    @classmethod\n    def __get_pydantic_core_schema__(\n        cls, source_type: Any, handler: GetCoreSchemaHandler\n    ) -&gt; core_schema.CoreSchema:\n        return core_schema.with_info_after_validator_function(\n            cls.validate, handler(int), field_name=handler.field_name\n        )\n\n\nclass MyModel(BaseModel):\n    my_field: CustomType\n\n\nm = MyModel(my_field=1)\nprint(m.my_field)\n#&gt; CustomType&lt;1 'my_field'&gt;\n</code></pre> <p>You can also access <code>field_name</code> from the markers used with <code>Annotated</code>, like <code>AfterValidator</code>.</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import AfterValidator, BaseModel, ValidationInfo\n\n\ndef my_validators(value: int, info: ValidationInfo):\n    return f'&lt;{value} {info.field_name!r}&gt;'\n\n\nclass MyModel(BaseModel):\n    my_field: Annotated[int, AfterValidator(my_validators)]\n\n\nm = MyModel(my_field=1)\nprint(m.my_field)\n#&gt; &lt;1 'my_field'&gt;\n</code></pre>"},{"location":"concepts/unions/","title":"Unions","text":"<p>Unions are fundamentally different to all other types Pydantic validates - instead of requiring all fields/items/values to be valid, unions require only one member to be valid.</p> <p>This leads to some nuance around how to validate unions:</p> <ul> <li>which member(s) of the union should you validate data against, and in which order?</li> <li>which errors to raise when validation fails?</li> </ul> <p>Validating unions feels like adding another orthogonal dimension to the validation process.</p> <p>To solve these problems, Pydantic supports three fundamental approaches to validating unions:</p> <ol> <li>left to right mode - the simplest approach, each member of the union is tried in order and the first match is returned</li> <li>smart mode - similar to \"left to right mode\" members are tried in order; however, validation will proceed past the first match to attempt to find a better match, this is the default mode for most union validation</li> <li>discriminated unions - only one member of the union is tried, based on a discriminator</li> </ol> <p>Tip</p> <p>In general, we recommend using discriminated unions. They are both more performant and more predictable than untagged unions, as they allow you to control which member of the union to validate against.</p> <p>For complex cases, if you're using untagged unions, it's recommended to use <code>union_mode='left_to_right'</code> if you need guarantees about the order of validation attempts against the union members.</p> <p>If you're looking for incredibly specialized behavior, you can use a custom validator.</p>"},{"location":"concepts/unions/#union-modes","title":"Union Modes","text":""},{"location":"concepts/unions/#left-to-right-mode","title":"Left to Right Mode","text":"<p>Note</p> <p>Because this mode often leads to unexpected validation results, it is not the default in Pydantic &gt;=2, instead <code>union_mode='smart'</code> is the default.</p> <p>With this approach, validation is attempted against each member of the union in their order they're defined, and the first successful validation is accepted as input.</p> <p>If validation fails on all members, the validation error includes the errors from all members of the union.</p> <p><code>union_mode='left_to_right'</code> must be set as a <code>Field</code> parameter on union fields where you want to use it.</p> Union with left to right mode<pre><code>from typing import Union\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass User(BaseModel):\n    id: Union[str, int] = Field(union_mode='left_to_right')\n\n\nprint(User(id=123))\n#&gt; id=123\nprint(User(id='hello'))\n#&gt; id='hello'\n\ntry:\n    User(id=[])\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for User\n    id.str\n      Input should be a valid string [type=string_type, input_value=[], input_type=list]\n    id.int\n      Input should be a valid integer [type=int_type, input_value=[], input_type=list]\n    \"\"\"\n</code></pre> <p>The order of members is very important in this case, as demonstrated by tweak the above example:</p> Union with left to right - unexpected results<pre><code>from typing import Union\n\nfrom pydantic import BaseModel, Field\n\n\nclass User(BaseModel):\n    id: Union[int, str] = Field(union_mode='left_to_right')\n\n\nprint(User(id=123))  # (1)\n#&gt; id=123\nprint(User(id='456'))  # (2)\n#&gt; id=456\n</code></pre> <ol> <li>As expected the input is validated against the <code>int</code> member and the result is as expected.</li> <li>We're in lax mode and the numeric string <code>'123'</code> is valid as input to the first member of the union, <code>int</code>.    Since that is tried first, we get the surprising result of <code>id</code> being an <code>int</code> instead of a <code>str</code>.</li> </ol>"},{"location":"concepts/unions/#smart-mode","title":"Smart Mode","text":"<p>Because of the potentially surprising results of <code>union_mode='left_to_right'</code>, in Pydantic &gt;=2 the default mode for <code>Union</code> validation is <code>union_mode='smart'</code>.</p> <p>In this mode, pydantic attempts to select the best match for the input from the union members. The exact algorithm may change between Pydantic minor releases to allow for improvements in both performance and accuracy.</p> <p>Note</p> <p>We reserve the right to tweak the internal <code>smart</code> matching algorithm in future versions of Pydantic. If you rely on very specific matching behavior, it's recommended to use <code>union_mode='left_to_right'</code> or discriminated unions.</p> Smart Mode Algorithm <p>The smart mode algorithm uses two metrics to determine the best match for the input:</p> <ol> <li>The number of valid fields set (relevant for models, dataclasses, and typed dicts)</li> <li>The exactness of the match (relevant for all types)</li> </ol> <pre><code>from typing import Union\nfrom uuid import UUID\n\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: Union[int, str, UUID]\n    name: str\n\n\nuser_01 = User(id=123, name='John Doe')\nprint(user_01)\n#&gt; id=123 name='John Doe'\nprint(user_01.id)\n#&gt; 123\nuser_02 = User(id='1234', name='John Doe')\nprint(user_02)\n#&gt; id='1234' name='John Doe'\nprint(user_02.id)\n#&gt; 1234\nuser_03_uuid = UUID('cf57432e-809e-4353-adbd-9d5c0d733868')\nuser_03 = User(id=user_03_uuid, name='John Doe')\nprint(user_03)\n#&gt; id=UUID('cf57432e-809e-4353-adbd-9d5c0d733868') name='John Doe'\nprint(user_03.id)\n#&gt; cf57432e-809e-4353-adbd-9d5c0d733868\nprint(user_03_uuid.int)\n#&gt; 275603287559914445491632874575877060712\n</code></pre> <p>Tip</p> <p>The type <code>Optional[x]</code> is a shorthand for <code>Union[x, None]</code>.</p> <p>See more details in Required fields.</p>"},{"location":"concepts/unions/#number-of-valid-fields-set","title":"Number of valid fields set","text":"<p>Note</p> <p>This metric was introduced in Pydantic v2.8.0. Prior to this version, only exactness was used to determine the best match.</p> <p>This metric is currently only relevant for models, dataclasses, and typed dicts.</p> <p>The greater the number of valid fields set, the better the match. The number of fields set on nested models is also taken into account. These counts bubble up to the top-level union, where the union member with the highest count is considered the best match.</p> <p>For data types where this metric is relevant, we prioritize this count over exactness. For all other types, we use solely exactness.</p>"},{"location":"concepts/unions/#exactness","title":"Exactness","text":"<p>For <code>exactness</code>, Pydantic scores a match of a union member into one of the following three groups (from highest score to lowest score):</p> <ul> <li>An exact type match, for example an <code>int</code> input to a <code>float | int</code> union validation is an exact type match for the <code>int</code> member</li> <li>Validation would have succeeded in <code>strict</code> mode</li> <li>Validation would have succeeded in lax mode</li> </ul> <p>The union match which produced the highest exactness score will be considered the best match.</p> <p>In smart mode, the following steps are taken to try to select the best match for the input:</p> <code>BaseModel</code>, <code>dataclass</code>, and <code>TypedDict</code>All other data types <ol> <li>Union members are attempted left to right, with any successful matches scored into one of the three exactness categories described above, with the valid fields set count also tallied.</li> <li>After all members have been evaluated, the member with the highest \"valid fields set\" count is returned.</li> <li>If there's a tie for the highest \"valid fields set\" count, the exactness score is used as a tiebreaker, and the member with the highest exactness score is returned.</li> <li>If validation failed on all the members, return all the errors.</li> </ol> <ol> <li>Union members are attempted left to right, with any successful matches scored into one of the three exactness categories described above.<ul> <li>If validation succeeds with an exact type match, that member is returned immediately and following members will not be attempted.</li> </ul> </li> <li>If validation succeeded on at least one member as a \"strict\" match, the leftmost of those \"strict\" matches is returned.</li> <li>If validation succeeded on at least one member in \"lax\" mode, the leftmost match is returned.</li> <li>Validation failed on all the members, return all the errors.</li> </ol>"},{"location":"concepts/unions/#discriminated-unions","title":"Discriminated Unions","text":"<p>Discriminated unions are sometimes referred to as \"Tagged Unions\".</p> <p>We can use discriminated unions to more efficiently validate <code>Union</code> types, by choosing which member of the union to validate against.</p> <p>This makes validation more efficient and also avoids a proliferation of errors when validation fails.</p> <p>Adding discriminator to unions also means the generated JSON schema implements the associated OpenAPI specification.</p>"},{"location":"concepts/unions/#discriminated-unions-with-str-discriminators","title":"Discriminated Unions with <code>str</code> discriminators","text":"<p>Frequently, in the case of a <code>Union</code> with multiple models, there is a common field to all members of the union that can be used to distinguish which union case the data should be validated against; this is referred to as the \"discriminator\" in OpenAPI.</p> <p>To validate models based on that information you can set the same field - let's call it <code>my_discriminator</code> - in each of the models with a discriminated value, which is one (or many) <code>Literal</code> value(s). For your <code>Union</code>, you can set the discriminator in its value: <code>Field(discriminator='my_discriminator')</code>.</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n    meows: int\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    barks: float\n\n\nclass Lizard(BaseModel):\n    pet_type: Literal['reptile', 'lizard']\n    scales: bool\n\n\nclass Model(BaseModel):\n    pet: Union[Cat, Dog, Lizard] = Field(..., discriminator='pet_type')\n    n: int\n\n\nprint(Model(pet={'pet_type': 'dog', 'barks': 3.14}, n=1))\n#&gt; pet=Dog(pet_type='dog', barks=3.14) n=1\ntry:\n    Model(pet={'pet_type': 'dog'}, n=1)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    pet.dog.barks\n      Field required [type=missing, input_value={'pet_type': 'dog'}, input_type=dict]\n    \"\"\"\n</code></pre>"},{"location":"concepts/unions/#discriminated-unions-with-callable-discriminator","title":"Discriminated Unions with callable <code>Discriminator</code>","text":"API Documentation <p><code>pydantic.types.Discriminator</code></p> <p>In the case of a <code>Union</code> with multiple models, sometimes there isn't a single uniform field across all models that you can use as a discriminator. This is the perfect use case for a callable <code>Discriminator</code>.</p> <pre><code>from typing import Any, Literal, Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Discriminator, Tag\n\n\nclass Pie(BaseModel):\n    time_to_cook: int\n    num_ingredients: int\n\n\nclass ApplePie(Pie):\n    fruit: Literal['apple'] = 'apple'\n\n\nclass PumpkinPie(Pie):\n    filling: Literal['pumpkin'] = 'pumpkin'\n\n\ndef get_discriminator_value(v: Any) -&gt; str:\n    if isinstance(v, dict):\n        return v.get('fruit', v.get('filling'))\n    return getattr(v, 'fruit', getattr(v, 'filling', None))\n\n\nclass ThanksgivingDinner(BaseModel):\n    dessert: Annotated[\n        Union[\n            Annotated[ApplePie, Tag('apple')],\n            Annotated[PumpkinPie, Tag('pumpkin')],\n        ],\n        Discriminator(get_discriminator_value),\n    ]\n\n\napple_variation = ThanksgivingDinner.model_validate(\n    {'dessert': {'fruit': 'apple', 'time_to_cook': 60, 'num_ingredients': 8}}\n)\nprint(repr(apple_variation))\n\"\"\"\nThanksgivingDinner(dessert=ApplePie(time_to_cook=60, num_ingredients=8, fruit='apple'))\n\"\"\"\n\npumpkin_variation = ThanksgivingDinner.model_validate(\n    {\n        'dessert': {\n            'filling': 'pumpkin',\n            'time_to_cook': 40,\n            'num_ingredients': 6,\n        }\n    }\n)\nprint(repr(pumpkin_variation))\n\"\"\"\nThanksgivingDinner(dessert=PumpkinPie(time_to_cook=40, num_ingredients=6, filling='pumpkin'))\n\"\"\"\n</code></pre> <p><code>Discriminator</code>s can also be used to validate <code>Union</code> types with combinations of models and primitive types.</p> <p>For example:</p> <pre><code>from typing import Any, Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Discriminator, Tag, ValidationError\n\n\ndef model_x_discriminator(v: Any) -&gt; str:\n    if isinstance(v, int):\n        return 'int'\n    if isinstance(v, (dict, BaseModel)):\n        return 'model'\n    else:\n        # return None if the discriminator value isn't found\n        return None\n\n\nclass SpecialValue(BaseModel):\n    value: int\n\n\nclass DiscriminatedModel(BaseModel):\n    value: Annotated[\n        Union[\n            Annotated[int, Tag('int')],\n            Annotated['SpecialValue', Tag('model')],\n        ],\n        Discriminator(model_x_discriminator),\n    ]\n\n\nmodel_data = {'value': {'value': 1}}\nm = DiscriminatedModel.model_validate(model_data)\nprint(m)\n#&gt; value=SpecialValue(value=1)\n\nint_data = {'value': 123}\nm = DiscriminatedModel.model_validate(int_data)\nprint(m)\n#&gt; value=123\n\ntry:\n    DiscriminatedModel.model_validate({'value': 'not an int or a model'})\nexcept ValidationError as e:\n    print(e)  # (1)!\n    \"\"\"\n    1 validation error for DiscriminatedModel\n    value\n      Unable to extract tag using discriminator model_x_discriminator() [type=union_tag_not_found, input_value='not an int or a model', input_type=str]\n    \"\"\"\n</code></pre> <ol> <li>Notice the callable discriminator function returns <code>None</code> if a discriminator value is not found.    When <code>None</code> is returned, this <code>union_tag_not_found</code> error is raised.</li> </ol> <p>Note</p> <p>Using the <code>typing.Annotated</code> fields syntax can be handy to regroup the <code>Union</code> and <code>discriminator</code> information. See the next example for more details.</p> <p>There are a few ways to set a discriminator for a field, all varying slightly in syntax.</p> <p>For <code>str</code> discriminators: <pre><code>some_field: Union[...] = Field(discriminator='my_discriminator'\nsome_field: Annotated[Union[...], Field(discriminator='my_discriminator')]\n</code></pre></p> <p>For callable <code>Discriminator</code>s: <pre><code>some_field: Union[...] = Field(discriminator=Discriminator(...))\nsome_field: Annotated[Union[...], Discriminator(...)]\nsome_field: Annotated[Union[...], Field(discriminator=Discriminator(...))]\n</code></pre></p> <p>Warning</p> <p>Discriminated unions cannot be used with only a single variant, such as <code>Union[Cat]</code>.</p> <p>Python changes <code>Union[T]</code> into <code>T</code> at interpretation time, so it is not possible for <code>pydantic</code> to distinguish fields of <code>Union[T]</code> from <code>T</code>.</p>"},{"location":"concepts/unions/#nested-discriminated-unions","title":"Nested Discriminated Unions","text":"<p>Only one discriminator can be set for a field but sometimes you want to combine multiple discriminators. You can do it by creating nested <code>Annotated</code> types, e.g.:</p> <pre><code>from typing import Literal, Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['cat']\n    color: Literal['black']\n    black_name: str\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['cat']\n    color: Literal['white']\n    white_name: str\n\n\nCat = Annotated[Union[BlackCat, WhiteCat], Field(discriminator='color')]\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    name: str\n\n\nPet = Annotated[Union[Cat, Dog], Field(discriminator='pet_type')]\n\n\nclass Model(BaseModel):\n    pet: Pet\n    n: int\n\n\nm = Model(pet={'pet_type': 'cat', 'color': 'black', 'black_name': 'felix'}, n=1)\nprint(m)\n#&gt; pet=BlackCat(pet_type='cat', color='black', black_name='felix') n=1\ntry:\n    Model(pet={'pet_type': 'cat', 'color': 'red'}, n='1')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    pet.cat\n      Input tag 'red' found using 'color' does not match any of the expected tags: 'black', 'white' [type=union_tag_invalid, input_value={'pet_type': 'cat', 'color': 'red'}, input_type=dict]\n    \"\"\"\ntry:\n    Model(pet={'pet_type': 'cat', 'color': 'black'}, n='1')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    pet.cat.black.black_name\n      Field required [type=missing, input_value={'pet_type': 'cat', 'color': 'black'}, input_type=dict]\n    \"\"\"\n</code></pre> <p>Tip</p> <p>If you want to validate data against a union, and solely a union, you can use pydantic's <code>TypeAdapter</code> construct instead of inheriting from the standard <code>BaseModel</code>.</p> <p>In the context of the previous example, we have the following:</p> <pre><code>type_adapter = TypeAdapter(Pet)\n\npet = type_adapter.validate_python(\n    {'pet_type': 'cat', 'color': 'black', 'black_name': 'felix'}\n)\nprint(repr(pet))\n#&gt; BlackCat(pet_type='cat', color='black', black_name='felix')\n</code></pre>"},{"location":"concepts/unions/#union-validation-errors","title":"Union Validation Errors","text":"<p>When <code>Union</code> validation fails, error messages can be quite verbose, as they will produce validation errors for each case in the union. This is especially noticeable when dealing with recursive models, where reasons may be generated at each level of recursion. Discriminated unions help to simplify error messages in this case, as validation errors are only produced for the case with a matching discriminator value.</p> <p>You can also customize the error type, message, and context for a <code>Discriminator</code> by passing these specifications as parameters to the <code>Discriminator</code> constructor, as seen in the example below.</p> <pre><code>from typing import Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Discriminator, Tag, ValidationError\n\n\n# Errors are quite verbose with a normal Union:\nclass Model(BaseModel):\n    x: Union[str, 'Model']\n\n\ntry:\n    Model.model_validate({'x': {'x': {'x': 1}}})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    4 validation errors for Model\n    x.str\n      Input should be a valid string [type=string_type, input_value={'x': {'x': 1}}, input_type=dict]\n    x.Model.x.str\n      Input should be a valid string [type=string_type, input_value={'x': 1}, input_type=dict]\n    x.Model.x.Model.x.str\n      Input should be a valid string [type=string_type, input_value=1, input_type=int]\n    x.Model.x.Model.x.Model\n      Input should be a valid dictionary or instance of Model [type=model_type, input_value=1, input_type=int]\n    \"\"\"\n\ntry:\n    Model.model_validate({'x': {'x': {'x': {}}}})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    4 validation errors for Model\n    x.str\n      Input should be a valid string [type=string_type, input_value={'x': {'x': {}}}, input_type=dict]\n    x.Model.x.str\n      Input should be a valid string [type=string_type, input_value={'x': {}}, input_type=dict]\n    x.Model.x.Model.x.str\n      Input should be a valid string [type=string_type, input_value={}, input_type=dict]\n    x.Model.x.Model.x.Model.x\n      Field required [type=missing, input_value={}, input_type=dict]\n    \"\"\"\n\n\n# Errors are much simpler with a discriminated union:\ndef model_x_discriminator(v):\n    if isinstance(v, str):\n        return 'str'\n    if isinstance(v, (dict, BaseModel)):\n        return 'model'\n\n\nclass DiscriminatedModel(BaseModel):\n    x: Annotated[\n        Union[\n            Annotated[str, Tag('str')],\n            Annotated['DiscriminatedModel', Tag('model')],\n        ],\n        Discriminator(\n            model_x_discriminator,\n            custom_error_type='invalid_union_member',  # (1)!\n            custom_error_message='Invalid union member',  # (2)!\n            custom_error_context={'discriminator': 'str_or_model'},  # (3)!\n        ),\n    ]\n\n\ntry:\n    DiscriminatedModel.model_validate({'x': {'x': {'x': 1}}})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for DiscriminatedModel\n    x.model.x.model.x\n      Invalid union member [type=invalid_union_member, input_value=1, input_type=int]\n    \"\"\"\n\ntry:\n    DiscriminatedModel.model_validate({'x': {'x': {'x': {}}}})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for DiscriminatedModel\n    x.model.x.model.x.model.x\n      Field required [type=missing, input_value={}, input_type=dict]\n    \"\"\"\n\n# The data is still handled properly when valid:\ndata = {'x': {'x': {'x': 'a'}}}\nm = DiscriminatedModel.model_validate(data)\nprint(m.model_dump())\n#&gt; {'x': {'x': {'x': 'a'}}}\n</code></pre> <ol> <li><code>custom_error_type</code> is the <code>type</code> attribute of the <code>ValidationError</code> raised when validation fails.</li> <li><code>custom_error_message</code> is the <code>msg</code> attribute of the <code>ValidationError</code> raised when validation fails.</li> <li><code>custom_error_context</code> is the <code>ctx</code> attribute of the <code>ValidationError</code> raised when validation fails.</li> </ol> <p>You can also simplify error messages by labeling each case with a <code>Tag</code>. This is especially useful when you have complex types like those in this example:</p> <pre><code>from typing import Dict, List, Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import AfterValidator, Tag, TypeAdapter, ValidationError\n\nDoubledList = Annotated[List[int], AfterValidator(lambda x: x * 2)]\nStringsMap = Dict[str, str]\n\n\n# Not using any `Tag`s for each union case, the errors are not so nice to look at\nadapter = TypeAdapter(Union[DoubledList, StringsMap])\n\ntry:\n    adapter.validate_python(['a'])\nexcept ValidationError as exc_info:\n    print(exc_info)\n    \"\"\"\n    2 validation errors for union[function-after[&lt;lambda&gt;(), list[int]],dict[str,str]]\n    function-after[&lt;lambda&gt;(), list[int]].0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    dict[str,str]\n      Input should be a valid dictionary [type=dict_type, input_value=['a'], input_type=list]\n    \"\"\"\n\ntag_adapter = TypeAdapter(\n    Union[\n        Annotated[DoubledList, Tag('DoubledList')],\n        Annotated[StringsMap, Tag('StringsMap')],\n    ]\n)\n\ntry:\n    tag_adapter.validate_python(['a'])\nexcept ValidationError as exc_info:\n    print(exc_info)\n    \"\"\"\n    2 validation errors for union[DoubledList,StringsMap]\n    DoubledList.0\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]\n    StringsMap\n      Input should be a valid dictionary [type=dict_type, input_value=['a'], input_type=list]\n    \"\"\"\n</code></pre>"},{"location":"concepts/validation_decorator/","title":"Validation Decorator","text":"API Documentation <p><code>pydantic.validate_call_decorator.validate_call</code></p> <p>The <code>@validate_call</code> decorator allows the arguments passed to a function to be parsed and validated using the function's annotations before the function is called.</p> <p>While under the hood this uses the same approach of model creation and initialisation (see Validators for more details), it provides an extremely easy way to apply validation to your code with minimal boilerplate.</p> <p>Example of usage:</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef repeat(s: str, count: int, *, separator: bytes = b'') -&gt; bytes:\n    b = s.encode()\n    return separator.join(b for _ in range(count))\n\n\na = repeat('hello', 3)\nprint(a)\n#&gt; b'hellohellohello'\n\nb = repeat('x', '4', separator=b' ')\nprint(b)\n#&gt; b'x x x x'\n\ntry:\n    c = repeat('hello', 'wrong')\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for repeat\n    1\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='wrong', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"concepts/validation_decorator/#argument-types","title":"Argument types","text":"<p>Argument types are inferred from type annotations on the function, arguments without a type decorator are considered as <code>Any</code>. All types listed in types can be validated, including Pydantic models and custom types. As with the rest of Pydantic, types can be coerced by the decorator before they're passed to the actual function:</p> <pre><code># TODO replace find_file with something that isn't affected the filesystem\nimport os\nfrom pathlib import Path\nfrom typing import Optional, Pattern\n\nfrom pydantic import DirectoryPath, validate_call\n\n\n@validate_call\ndef find_file(path: DirectoryPath, regex: Pattern, max=None) -&gt; Optional[Path]:\n    for i, f in enumerate(path.glob('**/*')):\n        if max and i &gt; max:\n            return\n        if f.is_file() and regex.fullmatch(str(f.relative_to(path))):\n            return f\n\n\n# note: this_dir is a string here\nthis_dir = os.path.dirname(__file__)\n\nprint(find_file(this_dir, '^validation.*'))\nprint(find_file(this_dir, '^foobar.*', max=3))\n</code></pre> <p>A few notes:</p> <ul> <li>Though they're passed as strings, <code>path</code> and <code>regex</code> are converted to a <code>Path</code> object and regex respectively     by the decorator.</li> <li><code>max</code> has no type annotation, so will be considered as <code>Any</code> by the decorator.</li> </ul> <p>Type coercion like this can be extremely helpful, but also confusing or not desired. See Coercion and strictness for a discussion of <code>@validate_call</code>'s limitations in this regard.</p>"},{"location":"concepts/validation_decorator/#function-signatures","title":"Function signatures","text":"<p>The <code>@validate_call</code> decorator is designed to work with functions using all possible parameter configurations and all possible combinations of these:</p> <ul> <li>Positional or keyword arguments with or without defaults.</li> <li>Variable positional arguments defined via <code>*</code> (often <code>*args</code>).</li> <li>Variable keyword arguments defined via <code>**</code> (often <code>**kwargs</code>).</li> <li>Keyword-only arguments: arguments after <code>*,</code>.</li> <li>Positional-only arguments: arguments before <code>, /</code> (new in Python 3.8).</li> </ul> <p>To demonstrate all the above parameter types:</p> <pre><code>from pydantic import validate_call\n\n\n@validate_call\ndef pos_or_kw(a: int, b: int = 2) -&gt; str:\n    return f'a={a} b={b}'\n\n\nprint(pos_or_kw(1))\n#&gt; a=1 b=2\nprint(pos_or_kw(a=1))\n#&gt; a=1 b=2\nprint(pos_or_kw(1, 3))\n#&gt; a=1 b=3\nprint(pos_or_kw(a=1, b=3))\n#&gt; a=1 b=3\n\n\n@validate_call\ndef kw_only(*, a: int, b: int = 2) -&gt; str:\n    return f'a={a} b={b}'\n\n\nprint(kw_only(a=1))\n#&gt; a=1 b=2\nprint(kw_only(a=1, b=3))\n#&gt; a=1 b=3\n\n\n@validate_call\ndef pos_only(a: int, b: int = 2, /) -&gt; str:  # python 3.8 only\n    return f'a={a} b={b}'\n\n\nprint(pos_only(1))\n#&gt; a=1 b=2\nprint(pos_only(1, 2))\n#&gt; a=1 b=2\n\n\n@validate_call\ndef var_args(*args: int) -&gt; str:\n    return str(args)\n\n\nprint(var_args(1))\n#&gt; (1,)\nprint(var_args(1, 2))\n#&gt; (1, 2)\nprint(var_args(1, 2, 3))\n#&gt; (1, 2, 3)\n\n\n@validate_call\ndef var_kwargs(**kwargs: int) -&gt; str:\n    return str(kwargs)\n\n\nprint(var_kwargs(a=1))\n#&gt; {'a': 1}\nprint(var_kwargs(a=1, b=2))\n#&gt; {'a': 1, 'b': 2}\n\n\n@validate_call\ndef armageddon(\n    a: int,\n    /,  # python 3.8 only\n    b: int,\n    *c: int,\n    d: int,\n    e: int = None,\n    **f: int,\n) -&gt; str:\n    return f'a={a} b={b} c={c} d={d} e={e} f={f}'\n\n\nprint(armageddon(1, 2, d=3))\n#&gt; a=1 b=2 c=() d=3 e=None f={}\nprint(armageddon(1, 2, 3, 4, 5, 6, d=8, e=9, f=10, spam=11))\n#&gt; a=1 b=2 c=(3, 4, 5, 6) d=8 e=9 f={'f': 10, 'spam': 11}\n</code></pre>"},{"location":"concepts/validation_decorator/#using-field-to-describe-function-arguments","title":"Using Field to describe function arguments","text":"<p>Field can also be used with <code>@validate_call</code> to provide extra information about the field and validations. In general it should be used in a type hint with Annotated, unless <code>default_factory</code> is specified, in which case it should be used as the default value of the field:</p> <pre><code>from datetime import datetime\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import Field, ValidationError, validate_call\n\n\n@validate_call\ndef how_many(num: Annotated[int, Field(gt=10)]):\n    return num\n\n\ntry:\n    how_many(1)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for how_many\n    0\n      Input should be greater than 10 [type=greater_than, input_value=1, input_type=int]\n    \"\"\"\n\n\n@validate_call\ndef when(dt: datetime = Field(default_factory=datetime.now)):\n    return dt\n\n\nprint(type(when()))\n#&gt; &lt;class 'datetime.datetime'&gt;\n</code></pre> <p>The <code>alias</code> can be used with the decorator as normal.</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import Field, validate_call\n\n\n@validate_call\ndef how_many(num: Annotated[int, Field(gt=10, alias='number')]):\n    return num\n\n\nhow_many(number=42)\n</code></pre>"},{"location":"concepts/validation_decorator/#usage-with-mypy","title":"Usage with mypy","text":"<p>The <code>validate_call</code> decorator should work \"out of the box\" with mypy since it's defined to return a function with the same signature as the function it decorates. The only limitation is that since we trick mypy into thinking the function returned by the decorator is the same as the function being decorated; access to the raw function or other attributes will require <code>type: ignore</code>.</p>"},{"location":"concepts/validation_decorator/#raw-function","title":"Raw function","text":"<p>The raw function which was decorated is accessible, this is useful if in some scenarios you trust your input arguments and want to call the function in the most performant way (see notes on performance below):</p> <pre><code>from pydantic import validate_call\n\n\n@validate_call\ndef repeat(s: str, count: int, *, separator: bytes = b'') -&gt; bytes:\n    b = s.encode()\n    return separator.join(b for _ in range(count))\n\n\na = repeat('hello', 3)\nprint(a)\n#&gt; b'hellohellohello'\n\nb = repeat.raw_function('good bye', 2, separator=b', ')\nprint(b)\n#&gt; b'good bye, good bye'\n</code></pre>"},{"location":"concepts/validation_decorator/#async-functions","title":"Async functions","text":"<p><code>@validate_call</code> can also be used on async functions:</p> <pre><code>class Connection:\n    async def execute(self, sql, *args):\n        return 'testing@example.com'\n\n\nconn = Connection()\n# ignore-above\nimport asyncio\n\nfrom pydantic import PositiveInt, ValidationError, validate_call\n\n\n@validate_call\nasync def get_user_email(user_id: PositiveInt):\n    # `conn` is some fictional connection to a database\n    email = await conn.execute('select email from users where id=$1', user_id)\n    if email is None:\n        raise RuntimeError('user not found')\n    else:\n        return email\n\n\nasync def main():\n    email = await get_user_email(123)\n    print(email)\n    #&gt; testing@example.com\n    try:\n        await get_user_email(-4)\n    except ValidationError as exc:\n        print(exc.errors())\n        \"\"\"\n        [\n            {\n                'type': 'greater_than',\n                'loc': (0,),\n                'msg': 'Input should be greater than 0',\n                'input': -4,\n                'ctx': {'gt': 0},\n                'url': 'https://errors.pydantic.dev/2/v/greater_than',\n            }\n        ]\n        \"\"\"\n\n\nasyncio.run(main())\n# requires: `conn.execute()` that will return `'testing@example.com'`\n</code></pre>"},{"location":"concepts/validation_decorator/#custom-config","title":"Custom config","text":"<p>The model behind <code>@validate_call</code> can be customised using a <code>config</code> setting, which is equivalent to setting the <code>ConfigDict</code> sub-class in normal models.</p> <p>Configuration is set using the <code>config</code> keyword argument to the decorator, it may be either a config class or a dict of properties which are converted to a class later.</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\nclass Foobar:\n    def __init__(self, v: str):\n        self.v = v\n\n    def __add__(self, other: 'Foobar') -&gt; str:\n        return f'{self} + {other}'\n\n    def __str__(self) -&gt; str:\n        return f'Foobar({self.v})'\n\n\n@validate_call(config=dict(arbitrary_types_allowed=True))\ndef add_foobars(a: Foobar, b: Foobar):\n    return a + b\n\n\nc = add_foobars(Foobar('a'), Foobar('b'))\nprint(c)\n#&gt; Foobar(a) + Foobar(b)\n\ntry:\n    add_foobars(1, 2)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    2 validation errors for add_foobars\n    0\n      Input should be an instance of Foobar [type=is_instance_of, input_value=1, input_type=int]\n    1\n      Input should be an instance of Foobar [type=is_instance_of, input_value=2, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"concepts/validation_decorator/#extension-validating-arguments-before-calling-a-function","title":"Extension \u2014 validating arguments before calling a function","text":"<p>In some cases, it may be helpful to separate validation of a function's arguments from the function call itself. This might be useful when a particular function is costly / time consuming.</p> <p>Here's an example of a workaround you can use for that pattern:</p> <pre><code>from pydantic import validate_call\n\n\n@validate_call\ndef validate_foo(a: int, b: int):\n    def foo():\n        return a + b\n\n    return foo\n\n\nfoo = validate_foo(a=1, b=2)\nprint(foo())\n#&gt; 3\n</code></pre>"},{"location":"concepts/validation_decorator/#limitations","title":"Limitations","text":""},{"location":"concepts/validation_decorator/#validation-exception","title":"Validation exception","text":"<p>Currently upon validation failure, a standard Pydantic <code>ValidationError</code> is raised. See model error handling for details.</p> <p>This is helpful since its <code>str()</code> method provides useful details of the error which occurred and methods like <code>.errors()</code> and <code>.json()</code> can be useful when exposing the errors to end users. However, <code>ValidationError</code> inherits from <code>ValueError</code> not <code>TypeError</code>, which may be unexpected since Python would raise a <code>TypeError</code> upon invalid or missing arguments. This may be addressed in future by either allowing a custom error or raising a different exception by default, or both.</p>"},{"location":"concepts/validation_decorator/#coercion-and-strictness","title":"Coercion and strictness","text":"<p>Pydantic currently leans on the side of trying to coerce types rather than raise an error if a type is wrong, see model data conversion and <code>@validate_call</code> is no different.</p>"},{"location":"concepts/validation_decorator/#performance","title":"Performance","text":"<p>We've made a big effort to make Pydantic as performant as possible and argument inspect and model creation is only performed once when the function is defined, however there will still be a performance impact to using the <code>@validate_call</code> decorator compared to calling the raw function.</p> <p>In many situations this will have little or no noticeable effect, however be aware that <code>@validate_call</code> is not an equivalent or alternative to function definitions in strongly typed languages; it never will be.</p>"},{"location":"concepts/validation_decorator/#return-value","title":"Return value","text":"<p>The return value of the function may optionally be validated against its return type annotation.</p>"},{"location":"concepts/validators/","title":"Validators","text":""},{"location":"concepts/validators/#annotated-validators","title":"Annotated Validators","text":"API Documentation <p><code>pydantic.functional_validators.WrapValidator</code> <code>pydantic.functional_validators.PlainValidator</code> <code>pydantic.functional_validators.BeforeValidator</code> <code>pydantic.functional_validators.AfterValidator</code></p> <p>Pydantic provides a way to apply validators via use of <code>Annotated</code>. You should use this whenever you want to bind validation to a type instead of model or field.</p> <pre><code>from typing import Any, List\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, ValidationError\nfrom pydantic.functional_validators import AfterValidator\n\n\ndef check_squares(v: int) -&gt; int:\n    assert v**0.5 % 1 == 0, f'{v} is not a square number'\n    return v\n\n\ndef double(v: Any) -&gt; Any:\n    return v * 2\n\n\nMyNumber = Annotated[int, AfterValidator(double), AfterValidator(check_squares)]\n\n\nclass DemoModel(BaseModel):\n    number: List[MyNumber]\n\n\nprint(DemoModel(number=[2, 8]))\n#&gt; number=[4, 16]\ntry:\n    DemoModel(number=[2, 4])\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for DemoModel\n    number.1\n      Assertion failed, 8 is not a square number\n    assert ((8 ** 0.5) % 1) == 0 [type=assertion_error, input_value=4, input_type=int]\n    \"\"\"\n</code></pre> <p>In this example we used some type aliases (<code>MyNumber = Annotated[...]</code>). While this can help with legibility of the code, it is not required, you can use <code>Annotated</code> directly in a model field type hint. These type aliases are also not actual types but you can use a similar approach with <code>TypeAliasType</code> to create actual types. See Custom Types for a more detailed explanation of custom types.</p> <p>It is also worth noting that you can nest <code>Annotated</code> inside other types. In this example we used that to apply validation to the inner items of a list. The same approach can be used for dict keys, etc.</p>"},{"location":"concepts/validators/#before-after-wrap-and-plain-validators","title":"Before, After, Wrap and Plain validators","text":"<p>Pydantic provides multiple types of validator functions:</p> <ul> <li><code>After</code> validators run after Pydantic's internal parsing. They are generally more type safe and thus easier to implement.</li> <li><code>Before</code> validators run before Pydantic's internal parsing and validation (e.g. coercion of a <code>str</code> to an <code>int</code>). These are more flexible than <code>After</code> validators since they can modify the raw input, but they also have to deal with the raw input, which in theory could be any arbitrary object.</li> <li><code>Plain</code> validators are like a <code>mode='before'</code> validator but they terminate validation immediately, no further validators are called and Pydantic does not do any of its internal validation.</li> <li><code>Wrap</code> validators are the most flexible of all. You can run code before or after Pydantic and other validators do their thing or you can terminate validation immediately, both with a successful value or an error.</li> </ul> <p>You can use multiple before, after, or <code>mode='wrap'</code> validators, but only one <code>PlainValidator</code> since a plain validator will not call any inner validators.</p> <p>Here's an example of a <code>mode='wrap'</code> validator:</p> <pre><code>import json\nfrom typing import Any, List\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import (\n    BaseModel,\n    ValidationError,\n    ValidationInfo,\n    ValidatorFunctionWrapHandler,\n)\nfrom pydantic.functional_validators import WrapValidator\n\n\ndef maybe_strip_whitespace(\n    v: Any, handler: ValidatorFunctionWrapHandler, info: ValidationInfo\n) -&gt; int:\n    if info.mode == 'json':\n        assert isinstance(v, str), 'In JSON mode the input must be a string!'\n        # you can call the handler multiple times\n        try:\n            return handler(v)\n        except ValidationError:\n            return handler(v.strip())\n    assert info.mode == 'python'\n    assert isinstance(v, int), 'In Python mode the input must be an int!'\n    # do no further validation\n    return v\n\n\nMyNumber = Annotated[int, WrapValidator(maybe_strip_whitespace)]\n\n\nclass DemoModel(BaseModel):\n    number: List[MyNumber]\n\n\nprint(DemoModel(number=[2, 8]))\n#&gt; number=[2, 8]\nprint(DemoModel.model_validate_json(json.dumps({'number': [' 2 ', '8']})))\n#&gt; number=[2, 8]\ntry:\n    DemoModel(number=['2'])\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for DemoModel\n    number.0\n      Assertion failed, In Python mode the input must be an int!\n    assert False\n     +  where False = isinstance('2', int) [type=assertion_error, input_value='2', input_type=str]\n    \"\"\"\n</code></pre> <p>The same \"modes\" apply to <code>@field_validator</code>, which is discussed in the next section.</p>"},{"location":"concepts/validators/#ordering-of-validators-within-annotated","title":"Ordering of validators within <code>Annotated</code>","text":"<p>Order of validation metadata within <code>Annotated</code> matters. Validation goes from right to left and back. That is, it goes from right to left running all \"before\" validators (or calling into \"wrap\" validators), then left to right back out calling all \"after\" validators.</p> <pre><code>from typing import Any, Callable, List, cast\n\nfrom typing_extensions import Annotated, TypedDict\n\nfrom pydantic import (\n    AfterValidator,\n    BaseModel,\n    BeforeValidator,\n    PlainValidator,\n    ValidationInfo,\n    ValidatorFunctionWrapHandler,\n    WrapValidator,\n)\nfrom pydantic.functional_validators import field_validator\n\n\nclass Context(TypedDict):\n    logs: List[str]\n\n\ndef make_validator(label: str) -&gt; Callable[[Any, ValidationInfo], Any]:\n    def validator(v: Any, info: ValidationInfo) -&gt; Any:\n        context = cast(Context, info.context)\n        context['logs'].append(label)\n        return v\n\n    return validator\n\n\ndef make_wrap_validator(\n    label: str,\n) -&gt; Callable[[Any, ValidatorFunctionWrapHandler, ValidationInfo], Any]:\n    def validator(\n        v: Any, handler: ValidatorFunctionWrapHandler, info: ValidationInfo\n    ) -&gt; Any:\n        context = cast(Context, info.context)\n        context['logs'].append(f'{label}: pre')\n        result = handler(v)\n        context['logs'].append(f'{label}: post')\n        return result\n\n    return validator\n\n\nclass A(BaseModel):\n    x: Annotated[\n        str,\n        BeforeValidator(make_validator('before-1')),\n        AfterValidator(make_validator('after-1')),\n        WrapValidator(make_wrap_validator('wrap-1')),\n        BeforeValidator(make_validator('before-2')),\n        AfterValidator(make_validator('after-2')),\n        WrapValidator(make_wrap_validator('wrap-2')),\n        BeforeValidator(make_validator('before-3')),\n        AfterValidator(make_validator('after-3')),\n        WrapValidator(make_wrap_validator('wrap-3')),\n        BeforeValidator(make_validator('before-4')),\n        AfterValidator(make_validator('after-4')),\n        WrapValidator(make_wrap_validator('wrap-4')),\n    ]\n    y: Annotated[\n        str,\n        BeforeValidator(make_validator('before-1')),\n        AfterValidator(make_validator('after-1')),\n        WrapValidator(make_wrap_validator('wrap-1')),\n        BeforeValidator(make_validator('before-2')),\n        AfterValidator(make_validator('after-2')),\n        WrapValidator(make_wrap_validator('wrap-2')),\n        PlainValidator(make_validator('plain')),\n        BeforeValidator(make_validator('before-3')),\n        AfterValidator(make_validator('after-3')),\n        WrapValidator(make_wrap_validator('wrap-3')),\n        BeforeValidator(make_validator('before-4')),\n        AfterValidator(make_validator('after-4')),\n        WrapValidator(make_wrap_validator('wrap-4')),\n    ]\n\n    val_x_before = field_validator('x', mode='before')(\n        make_validator('val_x before')\n    )\n    val_x_after = field_validator('x', mode='after')(\n        make_validator('val_x after')\n    )\n    val_y_wrap = field_validator('y', mode='wrap')(\n        make_wrap_validator('val_y wrap')\n    )\n\n\ncontext = Context(logs=[])\n\nA.model_validate({'x': 'abc', 'y': 'def'}, context=context)\nprint(context['logs'])\n\"\"\"\n[\n    'val_x before',\n    'wrap-4: pre',\n    'before-4',\n    'wrap-3: pre',\n    'before-3',\n    'wrap-2: pre',\n    'before-2',\n    'wrap-1: pre',\n    'before-1',\n    'after-1',\n    'wrap-1: post',\n    'after-2',\n    'wrap-2: post',\n    'after-3',\n    'wrap-3: post',\n    'after-4',\n    'wrap-4: post',\n    'val_x after',\n    'val_y wrap: pre',\n    'wrap-4: pre',\n    'before-4',\n    'wrap-3: pre',\n    'before-3',\n    'plain',\n    'after-3',\n    'wrap-3: post',\n    'after-4',\n    'wrap-4: post',\n    'val_y wrap: post',\n]\n\"\"\"\n</code></pre>"},{"location":"concepts/validators/#validation-of-default-values","title":"Validation of default values","text":"<p>Validators won't run when the default value is used. This applies both to <code>@field_validator</code> validators and <code>Annotated</code> validators. You can force them to run with <code>Field(validate_default=True)</code>. Setting <code>validate_default</code> to <code>True</code> has the closest behavior to using <code>always=True</code> in <code>validator</code> in Pydantic v1. However, you are generally better off using a <code>@model_validator(mode='before')</code> where the function is called before the inner validator is called.</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field, field_validator\n\n\nclass Model(BaseModel):\n    x: str = 'abc'\n    y: Annotated[str, Field(validate_default=True)] = 'xyz'\n\n    @field_validator('x', 'y')\n    @classmethod\n    def double(cls, v: str) -&gt; str:\n        return v * 2\n\n\nprint(Model())\n#&gt; x='abc' y='xyzxyz'\nprint(Model(x='foo'))\n#&gt; x='foofoo' y='xyzxyz'\nprint(Model(x='abc'))\n#&gt; x='abcabc' y='xyzxyz'\nprint(Model(x='foo', y='bar'))\n#&gt; x='foofoo' y='barbar'\n</code></pre>"},{"location":"concepts/validators/#field-validators","title":"Field validators","text":"API Documentation <p><code>pydantic.functional_validators.field_validator</code></p> <p>If you want to attach a validator to a specific field of a model you can use the <code>@field_validator</code> decorator.</p> <pre><code>from pydantic import (\n    BaseModel,\n    ValidationError,\n    ValidationInfo,\n    field_validator,\n)\n\n\nclass UserModel(BaseModel):\n    name: str\n    id: int\n\n    @field_validator('name')\n    @classmethod\n    def name_must_contain_space(cls, v: str) -&gt; str:\n        if ' ' not in v:\n            raise ValueError('must contain a space')\n        return v.title()\n\n    # you can select multiple fields, or use '*' to select all fields\n    @field_validator('id', 'name')\n    @classmethod\n    def check_alphanumeric(cls, v: str, info: ValidationInfo) -&gt; str:\n        if isinstance(v, str):\n            # info.field_name is the name of the field being validated\n            is_alphanumeric = v.replace(' ', '').isalnum()\n            assert is_alphanumeric, f'{info.field_name} must be alphanumeric'\n        return v\n\n\nprint(UserModel(name='John Doe', id=1))\n#&gt; name='John Doe' id=1\n\ntry:\n    UserModel(name='samuel', id=1)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for UserModel\n    name\n      Value error, must contain a space [type=value_error, input_value='samuel', input_type=str]\n    \"\"\"\n\ntry:\n    UserModel(name='John Doe', id='abc')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for UserModel\n    id\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='abc', input_type=str]\n    \"\"\"\n\ntry:\n    UserModel(name='John Doe!', id=1)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for UserModel\n    name\n      Assertion failed, name must be alphanumeric\n    assert False [type=assertion_error, input_value='John Doe!', input_type=str]\n    \"\"\"\n</code></pre> <p>A few things to note on validators:</p> <ul> <li><code>@field_validator</code>s are \"class methods\", so the first argument value they receive is the <code>UserModel</code> class, not an instance of <code>UserModel</code>. We recommend you use the <code>@classmethod</code> decorator on them below the <code>@field_validator</code> decorator to get proper type checking.</li> <li>the second argument is the field value to validate; it can be named as you please</li> <li>the third argument, if present, is an instance of <code>pydantic.ValidationInfo</code></li> <li>validators should either return the parsed value or raise a <code>ValueError</code> or <code>AssertionError</code> (<code>assert</code> statements may be used).</li> <li>A single validator can be applied to multiple fields by passing it multiple field names.</li> <li>A single validator can also be called on all fields by passing the special value <code>'*'</code>.</li> </ul> <p>Warning</p> <p>If you make use of <code>assert</code> statements, keep in mind that running Python with the <code>-O</code> optimization flag disables <code>assert</code> statements, and validators will stop working.</p> <p>Note</p> <p><code>FieldValidationInfo</code> is deprecated in 2.4, use <code>ValidationInfo</code> instead.</p> <p>If you want to access values from another field inside a <code>@field_validator</code>, this may be possible using <code>ValidationInfo.data</code>, which is a dict of field name to field value. Validation is done in the order fields are defined, so you have to be careful when using <code>ValidationInfo.data</code> to not access a field that has not yet been validated/populated \u2014 in the code above, for example, you would not be able to access <code>info.data['id']</code> from within <code>name_must_contain_space</code>. However, in most cases where you want to perform validation using multiple field values, it is better to use <code>@model_validator</code> which is discussed in the section below.</p>"},{"location":"concepts/validators/#model-validators","title":"Model validators","text":"API Documentation <p><code>pydantic.functional_validators.model_validator</code></p> <p>Validation can also be performed on the entire model's data using <code>@model_validator</code>.</p> <pre><code>from typing import Any\n\nfrom typing_extensions import Self\n\nfrom pydantic import BaseModel, ValidationError, model_validator\n\n\nclass UserModel(BaseModel):\n    username: str\n    password1: str\n    password2: str\n\n    @model_validator(mode='before')\n    @classmethod\n    def check_card_number_omitted(cls, data: Any) -&gt; Any:\n        if isinstance(data, dict):\n            assert (\n                'card_number' not in data\n            ), 'card_number should not be included'\n        return data\n\n    @model_validator(mode='after')\n    def check_passwords_match(self) -&gt; Self:\n        pw1 = self.password1\n        pw2 = self.password2\n        if pw1 is not None and pw2 is not None and pw1 != pw2:\n            raise ValueError('passwords do not match')\n        return self\n\n\nprint(UserModel(username='scolvin', password1='zxcvbn', password2='zxcvbn'))\n#&gt; username='scolvin' password1='zxcvbn' password2='zxcvbn'\ntry:\n    UserModel(username='scolvin', password1='zxcvbn', password2='zxcvbn2')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for UserModel\n      Value error, passwords do not match [type=value_error, input_value={'username': 'scolvin', '... 'password2': 'zxcvbn2'}, input_type=dict]\n    \"\"\"\n\ntry:\n    UserModel(\n        username='scolvin',\n        password1='zxcvbn',\n        password2='zxcvbn',\n        card_number='1234',\n    )\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for UserModel\n      Assertion failed, card_number should not be included\n    assert 'card_number' not in {'card_number': '1234', 'password1': 'zxcvbn', 'password2': 'zxcvbn', 'username': 'scolvin'} [type=assertion_error, input_value={'username': 'scolvin', '..., 'card_number': '1234'}, input_type=dict]\n    \"\"\"\n</code></pre> <p>On return type checking</p> <p>Methods decorated with <code>@model_validator</code> should return the self instance at the end of the method. For type checking purposes, you can use <code>Self</code> from either <code>typing</code> or the <code>typing_extensions</code> backport as the return type of the decorated method. In the context of the above example, you could also use <code>def check_passwords_match(self: 'UserModel') -&gt; 'UserModel'</code> to indicate that the method returns an instance of the model.</p> <p>On not returning <code>self</code></p> <p>If you fail to return <code>self</code> at the end of a <code>@model_validator</code> method (either, returning <code>None</code> or returning something other than <code>self</code>), you may encounter unexpected behavior.</p> <p>Specifically, for nested models, if you return <code>None</code> (or equivalently, don't include a <code>return</code> statement), despite a potentially successful validation, the nested model will be <code>None</code> in the parent model.</p> <p>Returning a value other than <code>self</code> causes unexpected behavior at the top level of validation when validating via <code>__init__</code>. In order to avoid this, we recommend one of: 1. Simply mutate and return <code>self</code> at the end of the method. 2. If you must return a value other than <code>self</code>, use a method like <code>model_validate</code> where you can directly fetch the return value.</p> <p>Here's an example of the unexpected behavior, and the warning you'll receive:</p> <pre><code>from pydantic import BaseModel\nfrom pydantic.functional_validators import model_validator\n\n\nclass Child(BaseModel):\n    name: str\n\n    @model_validator(mode='after')  # type: ignore\n    def validate_model(self) -&gt; 'Child':\n        return Child.model_construct(name='different!')\n\n\nprint(repr(Child(name='foo')))\n\"\"\"\nUserWarning: A custom validator is returning a value other than `self`.\nReturning anything other than `self` from a top level model validator isn't supported when validating via `__init__`.\nSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\n\nChild(name='foo')\n\"\"\"\n</code></pre> <p>On Inheritance</p> <p>A <code>@model_validator</code> defined in a base class will be called during the validation of a subclass instance.</p> <p>Overriding a <code>@model_validator</code> in a subclass will override the base class' <code>@model_validator</code>, and thus only the subclass' version of said <code>@model_validator</code> will be called.</p> <p>Model validators can be <code>mode='before'</code>, <code>mode='after'</code> or <code>mode='wrap'</code>.</p> <p>Before model validators are passed the raw input which is often a <code>dict[str, Any]</code> but could also be an instance of the model itself (e.g. if <code>UserModel.model_validate(UserModel.construct(...))</code> is called) or anything else since you can pass arbitrary objects into <code>model_validate</code>. Because of this <code>mode='before'</code> validators are extremely flexible and powerful but can be cumbersome and error prone to implement. Before model validators should be class methods. The first argument should be <code>cls</code> (and we also recommend you use <code>@classmethod</code> below <code>@model_validator</code> for proper type checking), the second argument will be the input (you should generally type it as <code>Any</code> and use <code>isinstance</code> to narrow the type) and the third argument (if present) will be a <code>pydantic.ValidationInfo</code>.</p> <p><code>mode='after'</code> validators are instance methods and always receive an instance of the model as the first argument. Be sure to return the instance at the end of your validator. You should not use <code>(cls, ModelType)</code> as the signature, instead just use <code>(self)</code> and let type checkers infer the type of <code>self</code> for you. Since these are fully type safe they are often easier to implement than <code>mode='before'</code> validators. If any field fails to validate, <code>mode='after'</code> validators for that field will not be called.</p>"},{"location":"concepts/validators/#handling-errors-in-validators","title":"Handling errors in validators","text":"<p>As mentioned in the previous sections you can raise either a <code>ValueError</code> or <code>AssertionError</code> (including ones generated by <code>assert ...</code> statements) within a validator to indicate validation failed. You can also raise a <code>PydanticCustomError</code> which is a bit more verbose but gives you extra flexibility. Any other errors (including <code>TypeError</code>) are bubbled up and not wrapped in a <code>ValidationError</code>.</p> <pre><code>from pydantic_core import PydanticCustomError\n\nfrom pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    x: int\n\n    @field_validator('x')\n    @classmethod\n    def validate_x(cls, v: int) -&gt; int:\n        if v % 42 == 0:\n            raise PydanticCustomError(\n                'the_answer_error',\n                '{number} is the answer!',\n                {'number': v},\n            )\n        return v\n\n\ntry:\n    Model(x=42 * 2)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    x\n      84 is the answer! [type=the_answer_error, input_value=84, input_type=int]\n    \"\"\"\n</code></pre>"},{"location":"concepts/validators/#special-types","title":"Special Types","text":"<p>Pydantic provides a few special types that can be used to customize validation.</p> <ul> <li><code>InstanceOf</code> is a type that can be used to validate that a value is an instance of a given class.</li> </ul> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, InstanceOf, ValidationError\n\n\nclass Fruit:\n    def __repr__(self):\n        return self.__class__.__name__\n\n\nclass Banana(Fruit): ...\n\n\nclass Apple(Fruit): ...\n\n\nclass Basket(BaseModel):\n    fruits: List[InstanceOf[Fruit]]\n\n\nprint(Basket(fruits=[Banana(), Apple()]))\n#&gt; fruits=[Banana, Apple]\ntry:\n    Basket(fruits=[Banana(), 'Apple'])\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Basket\n    fruits.1\n      Input should be an instance of Fruit [type=is_instance_of, input_value='Apple', input_type=str]\n    \"\"\"\n</code></pre> <ul> <li><code>SkipValidation</code> is a type that can be used to skip validation on a field.</li> </ul> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, SkipValidation\n\n\nclass Model(BaseModel):\n    names: List[SkipValidation[str]]\n\n\nm = Model(names=['foo', 'bar'])\nprint(m)\n#&gt; names=['foo', 'bar']\n\nm = Model(names=['foo', 123])  # (1)!\nprint(m)\n#&gt; names=['foo', 123]\n</code></pre> <ol> <li>Note that the validation of the second item is skipped. If it has the wrong type it will emit a warning during serialization.</li> </ol>"},{"location":"concepts/validators/#field-checks","title":"Field checks","text":"<p>During class creation, validators are checked to confirm that the fields they specify actually exist on the model.</p> <p>This may be undesirable if, for example, you want to define a validator to validate fields that will only be present on subclasses of the model where the validator is defined.</p> <p>If you want to disable these checks during class creation, you can pass <code>check_fields=False</code> as a keyword argument to the validator.</p>"},{"location":"concepts/validators/#dataclass-validators","title":"Dataclass validators","text":"<p>Validators also work with Pydantic dataclasses.</p> <pre><code>from pydantic import field_validator\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass DemoDataclass:\n    product_id: str  # should be a five-digit string, may have leading zeros\n\n    @field_validator('product_id', mode='before')\n    @classmethod\n    def convert_int_serial(cls, v):\n        if isinstance(v, int):\n            v = str(v).zfill(5)\n        return v\n\n\nprint(DemoDataclass(product_id='01234'))\n#&gt; DemoDataclass(product_id='01234')\nprint(DemoDataclass(product_id=2468))\n#&gt; DemoDataclass(product_id='02468')\n</code></pre>"},{"location":"concepts/validators/#validation-context","title":"Validation Context","text":"<p>You can pass a context object to the validation methods which can be accessed from the <code>info</code> argument to decorated validator functions:</p> <pre><code>from pydantic import BaseModel, ValidationInfo, field_validator\n\n\nclass Model(BaseModel):\n    text: str\n\n    @field_validator('text')\n    @classmethod\n    def remove_stopwords(cls, v: str, info: ValidationInfo):\n        context = info.context\n        if context:\n            stopwords = context.get('stopwords', set())\n            v = ' '.join(w for w in v.split() if w.lower() not in stopwords)\n        return v\n\n\ndata = {'text': 'This is an example document'}\nprint(Model.model_validate(data))  # no context\n#&gt; text='This is an example document'\nprint(Model.model_validate(data, context={'stopwords': ['this', 'is', 'an']}))\n#&gt; text='example document'\nprint(Model.model_validate(data, context={'stopwords': ['document']}))\n#&gt; text='This is an example'\n</code></pre> <p>This is useful when you need to dynamically update the validation behavior during runtime. For example, if you wanted a field to have a dynamically controllable set of allowed values, this could be done by passing the allowed values by context, and having a separate mechanism for updating what is allowed:</p> <pre><code>from typing import Any, Dict, List\n\nfrom pydantic import (\n    BaseModel,\n    ValidationError,\n    ValidationInfo,\n    field_validator,\n)\n\n_allowed_choices = ['a', 'b', 'c']\n\n\ndef set_allowed_choices(allowed_choices: List[str]) -&gt; None:\n    global _allowed_choices\n    _allowed_choices = allowed_choices\n\n\ndef get_context() -&gt; Dict[str, Any]:\n    return {'allowed_choices': _allowed_choices}\n\n\nclass Model(BaseModel):\n    choice: str\n\n    @field_validator('choice')\n    @classmethod\n    def validate_choice(cls, v: str, info: ValidationInfo):\n        allowed_choices = info.context.get('allowed_choices')\n        if allowed_choices and v not in allowed_choices:\n            raise ValueError(f'choice must be one of {allowed_choices}')\n        return v\n\n\nprint(Model.model_validate({'choice': 'a'}, context=get_context()))\n#&gt; choice='a'\n\ntry:\n    print(Model.model_validate({'choice': 'd'}, context=get_context()))\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for Model\n    choice\n      Value error, choice must be one of ['a', 'b', 'c'] [type=value_error, input_value='d', input_type=str]\n    \"\"\"\n\nset_allowed_choices(['b', 'c'])\n\ntry:\n    print(Model.model_validate({'choice': 'a'}, context=get_context()))\nexcept ValidationError as exc:\n    print(exc)\n    \"\"\"\n    1 validation error for Model\n    choice\n      Value error, choice must be one of ['b', 'c'] [type=value_error, input_value='a', input_type=str]\n    \"\"\"\n</code></pre> <p>Similarly, you can use a context for serialization.</p>"},{"location":"concepts/validators/#using-validation-context-with-basemodel-initialization","title":"Using validation context with <code>BaseModel</code> initialization","text":"<p>Although there is no way to specify a context in the standard <code>BaseModel</code> initializer, you can work around this through the use of <code>contextvars.ContextVar</code> and a custom <code>__init__</code> method:</p> <pre><code>from contextlib import contextmanager\nfrom contextvars import ContextVar\nfrom typing import Any, Dict, Iterator\n\nfrom pydantic import BaseModel, ValidationInfo, field_validator\n\n_init_context_var = ContextVar('_init_context_var', default=None)\n\n\n@contextmanager\ndef init_context(value: Dict[str, Any]) -&gt; Iterator[None]:\n    token = _init_context_var.set(value)\n    try:\n        yield\n    finally:\n        _init_context_var.reset(token)\n\n\nclass Model(BaseModel):\n    my_number: int\n\n    def __init__(self, /, **data: Any) -&gt; None:\n        self.__pydantic_validator__.validate_python(\n            data,\n            self_instance=self,\n            context=_init_context_var.get(),\n        )\n\n    @field_validator('my_number')\n    @classmethod\n    def multiply_with_context(cls, value: int, info: ValidationInfo) -&gt; int:\n        if info.context:\n            multiplier = info.context.get('multiplier', 1)\n            value = value * multiplier\n        return value\n\n\nprint(Model(my_number=2))\n#&gt; my_number=2\n\nwith init_context({'multiplier': 3}):\n    print(Model(my_number=2))\n    #&gt; my_number=6\n\nprint(Model(my_number=2))\n#&gt; my_number=2\n</code></pre>"},{"location":"concepts/validators/#reusing-validators","title":"Reusing Validators","text":"<p>Occasionally, you will want to use the same validator on multiple fields/models (e.g. to normalize some input data). The \"naive\" approach would be to write a separate function, then call it from multiple decorators. Obviously, this entails a lot of repetition and boiler plate code. The following approach demonstrates how you can reuse a validator so that redundancy is minimized and the models become again almost declarative.</p> <pre><code>from pydantic import BaseModel, field_validator\n\n\ndef normalize(name: str) -&gt; str:\n    return ' '.join((word.capitalize()) for word in name.split(' '))\n\n\nclass Producer(BaseModel):\n    name: str\n\n    _normalize_name = field_validator('name')(normalize)\n\n\nclass Consumer(BaseModel):\n    name: str\n\n    _normalize_name = field_validator('name')(normalize)\n\n\njane_doe = Producer(name='JaNe DOE')\nprint(repr(jane_doe))\n#&gt; Producer(name='Jane Doe')\njohn_doe = Consumer(name='joHN dOe')\nprint(repr(john_doe))\n#&gt; Consumer(name='John Doe')\n</code></pre>"},{"location":"errors/errors/","title":"Error Handling","text":"<p>Pydantic will raise a <code>ValidationError</code> whenever it finds an error in the data it's validating.</p> <p>Note</p> <p>Validation code should not raise <code>ValidationError</code> itself, but rather raise a <code>ValueError</code> or <code>AssertionError</code> (or subclass thereof) which will be caught and used to populate <code>ValidationError</code>.</p> <p>One exception will be raised regardless of the number of errors found, that <code>ValidationError</code> will contain information about all the errors and how they happened.</p> <p>You can access these errors in several ways:</p> Method Description <code>e.errors()</code> Returns a list of errors found in the input data. <code>e.error_count()</code> Returns the number of errors found in <code>errors</code>. <code>e.json()</code> Returns a JSON representation of <code>errors</code>. <code>str(e)</code> Returns a human-readable representation of the errors. <p>Each error object contains:</p> Property Description <code>ctx</code> An optional object which contains values required to render the error message. <code>input</code> The input provided for validation. <code>loc</code> The error's location as a list. <code>msg</code> A human-readable explanation of the error. <code>type</code> A computer-readable identifier of the error type. <code>url</code> The URL to further information about the error. <p>The first item in the <code>loc</code> list will be the field where the error occurred, and if the field is a sub-model, subsequent items will be present to indicate the nested location of the error.</p> <p>As a demonstration:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError, conint\n\n\nclass Location(BaseModel):\n    lat: float = 0.1\n    lng: float = 10.1\n\n\nclass Model(BaseModel):\n    is_required: float\n    gt_int: conint(gt=42)\n    list_of_ints: List[int] = None\n    a_float: float = None\n    recursive_model: Location = None\n\n\ndata = dict(\n    list_of_ints=['1', 2, 'bad'],\n    a_float='not a float',\n    recursive_model={'lat': 4.2, 'lng': 'New York'},\n    gt_int=21,\n)\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    5 validation errors for Model\n    is_required\n      Field required [type=missing, input_value={'list_of_ints': ['1', 2,...ew York'}, 'gt_int': 21}, input_type=dict]\n    gt_int\n      Input should be greater than 42 [type=greater_than, input_value=21, input_type=int]\n    list_of_ints.2\n      Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='bad', input_type=str]\n    a_float\n      Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='not a float', input_type=str]\n    recursive_model.lng\n      Input should be a valid number, unable to parse string as a number [type=float_parsing, input_value='New York', input_type=str]\n    \"\"\"\n\ntry:\n    Model(**data)\nexcept ValidationError as e:\n    print(e.errors())\n    \"\"\"\n    [\n        {\n            'type': 'missing',\n            'loc': ('is_required',),\n            'msg': 'Field required',\n            'input': {\n                'list_of_ints': ['1', 2, 'bad'],\n                'a_float': 'not a float',\n                'recursive_model': {'lat': 4.2, 'lng': 'New York'},\n                'gt_int': 21,\n            },\n            'url': 'https://errors.pydantic.dev/2/v/missing',\n        },\n        {\n            'type': 'greater_than',\n            'loc': ('gt_int',),\n            'msg': 'Input should be greater than 42',\n            'input': 21,\n            'ctx': {'gt': 42},\n            'url': 'https://errors.pydantic.dev/2/v/greater_than',\n        },\n        {\n            'type': 'int_parsing',\n            'loc': ('list_of_ints', 2),\n            'msg': 'Input should be a valid integer, unable to parse string as an integer',\n            'input': 'bad',\n            'url': 'https://errors.pydantic.dev/2/v/int_parsing',\n        },\n        {\n            'type': 'float_parsing',\n            'loc': ('a_float',),\n            'msg': 'Input should be a valid number, unable to parse string as a number',\n            'input': 'not a float',\n            'url': 'https://errors.pydantic.dev/2/v/float_parsing',\n        },\n        {\n            'type': 'float_parsing',\n            'loc': ('recursive_model', 'lng'),\n            'msg': 'Input should be a valid number, unable to parse string as a number',\n            'input': 'New York',\n            'url': 'https://errors.pydantic.dev/2/v/float_parsing',\n        },\n    ]\n    \"\"\"\n</code></pre>"},{"location":"errors/errors/#custom-errors","title":"Custom Errors","text":"<p>In your custom data types or validators you should use <code>ValueError</code> or <code>AssertionError</code> to raise errors.</p> <p>See validators for more details on use of the <code>@validator</code> decorator.</p> <pre><code>from pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    foo: str\n\n    @field_validator('foo')\n    def value_must_equal_bar(cls, v):\n        if v != 'bar':\n            raise ValueError('value must be \"bar\"')\n\n        return v\n\n\ntry:\n    Model(foo='ber')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    foo\n      Value error, value must be \"bar\" [type=value_error, input_value='ber', input_type=str]\n    \"\"\"\n    print(e.errors())\n    \"\"\"\n    [\n        {\n            'type': 'value_error',\n            'loc': ('foo',),\n            'msg': 'Value error, value must be \"bar\"',\n            'input': 'ber',\n            'ctx': {'error': ValueError('value must be \"bar\"')},\n            'url': 'https://errors.pydantic.dev/2/v/value_error',\n        }\n    ]\n    \"\"\"\n</code></pre> <p>You can also use <code>PydanticCustomError</code>, to fully control the error structure:</p> <pre><code>from pydantic_core import PydanticCustomError\n\nfrom pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    foo: str\n\n    @field_validator('foo')\n    def value_must_equal_bar(cls, v):\n        if v != 'bar':\n            raise PydanticCustomError(\n                'not_a_bar',\n                'value is not \"bar\", got \"{wrong_value}\"',\n                dict(wrong_value=v),\n            )\n        return v\n\n\ntry:\n    Model(foo='ber')\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Model\n    foo\n      value is not \"bar\", got \"ber\" [type=not_a_bar, input_value='ber', input_type=str]\n    \"\"\"\n</code></pre>"},{"location":"errors/errors/#error-messages","title":"Error messages","text":"<p>Pydantic attempts to provide useful default error messages for validation and usage errors.</p> <p>We've provided documentation for default error codes in the following sections:</p> <ul> <li>Validation Errors</li> <li>Usage Errors</li> </ul>"},{"location":"errors/errors/#customize-error-messages","title":"Customize error messages","text":"<p>You can customize error messages by creating a custom error handler.</p> <pre><code>from typing import Dict, List\n\nfrom pydantic_core import ErrorDetails\n\nfrom pydantic import BaseModel, HttpUrl, ValidationError\n\nCUSTOM_MESSAGES = {\n    'int_parsing': 'This is not an integer! \ud83e\udd26',\n    'url_scheme': 'Hey, use the right URL scheme! I wanted {expected_schemes}.',\n}\n\n\ndef convert_errors(\n    e: ValidationError, custom_messages: Dict[str, str]\n) -&gt; List[ErrorDetails]:\n    new_errors: List[ErrorDetails] = []\n    for error in e.errors():\n        custom_message = custom_messages.get(error['type'])\n        if custom_message:\n            ctx = error.get('ctx')\n            error['msg'] = (\n                custom_message.format(**ctx) if ctx else custom_message\n            )\n        new_errors.append(error)\n    return new_errors\n\n\nclass Model(BaseModel):\n    a: int\n    b: HttpUrl\n\n\ntry:\n    Model(a='wrong', b='ftp://example.com')\nexcept ValidationError as e:\n    errors = convert_errors(e, CUSTOM_MESSAGES)\n    print(errors)\n    \"\"\"\n    [\n        {\n            'type': 'int_parsing',\n            'loc': ('a',),\n            'msg': 'This is not an integer! \ud83e\udd26',\n            'input': 'wrong',\n            'url': 'https://errors.pydantic.dev/2/v/int_parsing',\n        },\n        {\n            'type': 'url_scheme',\n            'loc': ('b',),\n            'msg': \"Hey, use the right URL scheme! I wanted 'http' or 'https'.\",\n            'input': 'ftp://example.com',\n            'ctx': {'expected_schemes': \"'http' or 'https'\"},\n            'url': 'https://errors.pydantic.dev/2/v/url_scheme',\n        },\n    ]\n    \"\"\"\n</code></pre> <p>A common use case would be to translate error messages. For example, in the above example, we could translate the error messages replacing the <code>CUSTOM_MESSAGES</code> dictionary with a dictionary of translations.</p> <p>Another example is customizing the way that the <code>'loc'</code> value of an error is represented.</p> <pre><code>from typing import Any, Dict, List, Tuple, Union\n\nfrom pydantic import BaseModel, ValidationError\n\n\ndef loc_to_dot_sep(loc: Tuple[Union[str, int], ...]) -&gt; str:\n    path = ''\n    for i, x in enumerate(loc):\n        if isinstance(x, str):\n            if i &gt; 0:\n                path += '.'\n            path += x\n        elif isinstance(x, int):\n            path += f'[{x}]'\n        else:\n            raise TypeError('Unexpected type')\n    return path\n\n\ndef convert_errors(e: ValidationError) -&gt; List[Dict[str, Any]]:\n    new_errors: List[Dict[str, Any]] = e.errors()\n    for error in new_errors:\n        error['loc'] = loc_to_dot_sep(error['loc'])\n    return new_errors\n\n\nclass TestNestedModel(BaseModel):\n    key: str\n    value: str\n\n\nclass TestModel(BaseModel):\n    items: List[TestNestedModel]\n\n\ndata = {'items': [{'key': 'foo', 'value': 'bar'}, {'key': 'baz'}]}\n\ntry:\n    TestModel.model_validate(data)\nexcept ValidationError as e:\n    print(e.errors())  # (1)!\n    \"\"\"\n    [\n        {\n            'type': 'missing',\n            'loc': ('items', 1, 'value'),\n            'msg': 'Field required',\n            'input': {'key': 'baz'},\n            'url': 'https://errors.pydantic.dev/2/v/missing',\n        }\n    ]\n    \"\"\"\n    pretty_errors = convert_errors(e)\n    print(pretty_errors)  # (2)!\n    \"\"\"\n    [\n        {\n            'type': 'missing',\n            'loc': 'items[1].value',\n            'msg': 'Field required',\n            'input': {'key': 'baz'},\n            'url': 'https://errors.pydantic.dev/2/v/missing',\n        }\n    ]\n    \"\"\"\n</code></pre> <ol> <li>By default, <code>e.errors()</code> produces a List of errors with <code>loc</code> values that take the form of tuples.</li> <li>With our custom <code>loc_to_dot_sep</code> function, we've modified the form of the <code>loc</code> representation.</li> </ol>"},{"location":"errors/usage_errors/","title":"Usage Errors","text":"<p>Pydantic attempts to provide useful errors. The following sections provide details on common errors developers may encounter when working with Pydantic, along with suggestions for addressing the error condition.</p>"},{"location":"errors/usage_errors/#class-not-fully-defined","title":"Class not fully defined","text":"<p>This error is raised when a type referenced in an annotation of a pydantic-validated type (such as a subclass of <code>BaseModel</code>, or a pydantic <code>dataclass</code>) is not defined:</p> <pre><code>from typing import ForwardRef\n\nfrom pydantic import BaseModel, PydanticUserError\n\nUndefinedType = ForwardRef('UndefinedType')\n\n\nclass Foobar(BaseModel):\n    a: UndefinedType\n\n\ntry:\n    Foobar(a=1)\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'class-not-fully-defined'\n</code></pre> <p>Or when the type has been defined after usage:</p> <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel, PydanticUserError\n\n\nclass Foo(BaseModel):\n    a: Optional['Bar'] = None\n\n\ntry:\n    # this doesn't work, see raised error\n    foo = Foo(a={'b': {'a': None}})\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'class-not-fully-defined'\n\n\nclass Bar(BaseModel):\n    b: 'Foo'\n\n\n# this works, though\nfoo = Foo(a={'b': {'a': None}})\n</code></pre> <p>For BaseModel subclasses, it can be fixed by defining the type and then calling <code>.model_rebuild()</code>:</p> <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel\n\n\nclass Foo(BaseModel):\n    a: Optional['Bar'] = None\n\n\nclass Bar(BaseModel):\n    b: 'Foo'\n\n\nFoo.model_rebuild()\n\nfoo = Foo(a={'b': {'a': None}})\n</code></pre> <p>In other cases, the error message should indicate how to rebuild the class with the appropriate type defined.</p>"},{"location":"errors/usage_errors/#custom-json-schema","title":"Custom JSON Schema","text":"<p>The <code>__modify_schema__</code> method is no longer supported in V2. You should use the <code>__get_pydantic_json_schema__</code> method instead.</p> <p>The <code>__modify_schema__</code> used to receive a single argument representing the JSON schema. See the example below:</p> Old way<pre><code>from pydantic import BaseModel, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        @classmethod\n        def __modify_schema__(cls, field_schema):\n            field_schema.update(examples=['example'])\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'custom-json-schema'\n</code></pre> <p>The new method <code>__get_pydantic_json_schema__</code> receives two arguments: the first is a dictionary denoted as <code>CoreSchema</code>, and the second a callable <code>handler</code> that receives a <code>CoreSchema</code> as parameter, and returns a JSON schema. See the example below:</p> New way<pre><code>from typing import Any, Dict\n\nfrom pydantic_core import CoreSchema\n\nfrom pydantic import BaseModel, GetJsonSchemaHandler\n\n\nclass Model(BaseModel):\n    @classmethod\n    def __get_pydantic_json_schema__(\n        cls, core_schema: CoreSchema, handler: GetJsonSchemaHandler\n    ) -&gt; Dict[str, Any]:\n        json_schema = super().__get_pydantic_json_schema__(core_schema, handler)\n        json_schema = handler.resolve_ref_schema(json_schema)\n        json_schema.update(examples=['example'])\n        return json_schema\n\n\nprint(Model.model_json_schema())\n\"\"\"\n{'examples': ['example'], 'properties': {}, 'title': 'Model', 'type': 'object'}\n\"\"\"\n</code></pre>"},{"location":"errors/usage_errors/#decorator-missing-field","title":"Decorator on missing field","text":"<p>This error is raised when you define a decorator with a field that is not valid.</p> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: str\n\n        @field_validator('b')\n        def check_b(cls, v: Any):\n            return v\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'decorator-missing-field'\n</code></pre> <p>You can use <code>check_fields=False</code> if you're inheriting from the model and intended this.</p> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel, create_model, field_validator\n\n\nclass Model(BaseModel):\n    @field_validator('a', check_fields=False)\n    def check_a(cls, v: Any):\n        return v\n\n\nmodel = create_model('FooModel', a=(str, 'cake'), __base__=Model)\n</code></pre>"},{"location":"errors/usage_errors/#discriminator-no-field","title":"Discriminator no field","text":"<p>This error is raised when a model in discriminated unions doesn't define a discriminator field.</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-no-field'\n</code></pre>"},{"location":"errors/usage_errors/#discriminator-alias-type","title":"Discriminator alias type","text":"<p>This error is raised when you define a non-string alias on a discriminator field.</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import AliasChoices, BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat'] = Field(\n        validation_alias=AliasChoices('Pet', 'PET')\n    )\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-alias-type'\n</code></pre>"},{"location":"errors/usage_errors/#discriminator-needs-literal","title":"Discriminator needs literal","text":"<p>This error is raised when you define a non-<code>Literal</code> type on a discriminator field.</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: int\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-needs-literal'\n</code></pre>"},{"location":"errors/usage_errors/#discriminator-alias","title":"Discriminator alias","text":"<p>This error is raised when you define different aliases on discriminator fields.</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field, PydanticUserError\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat'] = Field(validation_alias='PET')\n    c: str\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog'] = Field(validation_alias='Pet')\n    d: str\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-alias'\n</code></pre>"},{"location":"errors/usage_errors/#discriminator-validator","title":"Invalid discriminator validator","text":"<p>This error is raised when you use a before, wrap, or plain validator on a discriminator field.</p> <p>This is disallowed because the discriminator field is used to determine the type of the model to use for validation, so you can't use a validator that might change its value.</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field, PydanticUserError, field_validator\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n\n    @field_validator('pet_type', mode='before')\n    @classmethod\n    def validate_pet_type(cls, v):\n        if v == 'kitten':\n            return 'cat'\n        return v\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n\n\ntry:\n\n    class Model(BaseModel):\n        pet: Union[Cat, Dog] = Field(..., discriminator='pet_type')\n        number: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'discriminator-validator'\n</code></pre> <p>This can be worked around by using a standard <code>Union</code>, dropping the discriminator:</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, field_validator\n\n\nclass Cat(BaseModel):\n    pet_type: Literal['cat']\n\n    @field_validator('pet_type', mode='before')\n    @classmethod\n    def validate_pet_type(cls, v):\n        if v == 'kitten':\n            return 'cat'\n        return v\n\n\nclass Dog(BaseModel):\n    pet_type: Literal['dog']\n\n\nclass Model(BaseModel):\n    pet: Union[Cat, Dog]\n\n\nassert Model(pet={'pet_type': 'kitten'}).pet.pet_type == 'cat'\n</code></pre>"},{"location":"errors/usage_errors/#callable-discriminator-no-tag","title":"Callable discriminator case with no tag","text":"<p>This error is raised when a <code>Union</code> that uses a callable <code>Discriminator</code> doesn't have <code>Tag</code> annotations for all cases.</p> <pre><code>from typing import Union\n\nfrom typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Discriminator, PydanticUserError, Tag\n\n\ndef model_x_discriminator(v):\n    if isinstance(v, str):\n        return 'str'\n    if isinstance(v, (dict, BaseModel)):\n        return 'model'\n\n\n# tag missing for both union choices\ntry:\n\n    class DiscriminatedModel(BaseModel):\n        x: Annotated[\n            Union[str, 'DiscriminatedModel'],\n            Discriminator(model_x_discriminator),\n        ]\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'callable-discriminator-no-tag'\n\n# tag missing for `'DiscriminatedModel'` union choice\ntry:\n\n    class DiscriminatedModel(BaseModel):\n        x: Annotated[\n            Union[Annotated[str, Tag('str')], 'DiscriminatedModel'],\n            Discriminator(model_x_discriminator),\n        ]\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'callable-discriminator-no-tag'\n\n# tag missing for `str` union choice\ntry:\n\n    class DiscriminatedModel(BaseModel):\n        x: Annotated[\n            Union[str, Annotated['DiscriminatedModel', Tag('model')]],\n            Discriminator(model_x_discriminator),\n        ]\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'callable-discriminator-no-tag'\n</code></pre>"},{"location":"errors/usage_errors/#typed-dict-version","title":"<code>TypedDict</code> version","text":"<p>This error is raised when you use typing.TypedDict instead of <code>typing_extensions.TypedDict</code> on Python &lt; 3.12.</p>"},{"location":"errors/usage_errors/#model-field-overridden","title":"Model parent field overridden","text":"<p>This error is raised when a field defined on a base class was overridden by a non-annotated attribute.</p> <pre><code>from pydantic import BaseModel, PydanticUserError\n\n\nclass Foo(BaseModel):\n    a: float\n\n\ntry:\n\n    class Bar(Foo):\n        x: float = 12.3\n        a = 123.0\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-field-overridden'\n</code></pre>"},{"location":"errors/usage_errors/#model-field-missing-annotation","title":"Model field missing annotation","text":"<p>This error is raised when a field doesn't have an annotation.</p> <pre><code>from pydantic import BaseModel, Field, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        a = Field('foobar')\n        b = None\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-field-missing-annotation'\n</code></pre> <p>If the field is not meant to be a field, you may be able to resolve the error by annotating it as a <code>ClassVar</code>:</p> <pre><code>from typing import ClassVar\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    a: ClassVar[str]\n</code></pre> <p>Or updating <code>model_config['ignored_types']</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict\n\n\nclass IgnoredType:\n    pass\n\n\nclass MyModel(BaseModel):\n    model_config = ConfigDict(ignored_types=(IgnoredType,))\n\n    _a = IgnoredType()\n    _b: int = IgnoredType()\n    _c: IgnoredType\n    _d: IgnoredType = IgnoredType()\n</code></pre>"},{"location":"errors/usage_errors/#config-both","title":"<code>Config</code> and <code>model_config</code> both defined","text":"<p>This error is raised when <code>class Config</code> and <code>model_config</code> are used together.</p> <pre><code>from pydantic import BaseModel, ConfigDict, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        model_config = ConfigDict(from_attributes=True)\n\n        a: str\n\n        class Config:\n            from_attributes = True\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'config-both'\n</code></pre>"},{"location":"errors/usage_errors/#removed-kwargs","title":"Keyword arguments removed","text":"<p>This error is raised when the keyword arguments are not available in Pydantic V2.</p> <p>For example, <code>regex</code> is removed from Pydantic V2:</p> <pre><code>from pydantic import BaseModel, Field, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        x: str = Field(regex='test')\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'removed-kwargs'\n</code></pre>"},{"location":"errors/usage_errors/#invalid-for-json-schema","title":"JSON schema invalid type","text":"<p>This error is raised when Pydantic fails to generate a JSON schema for some <code>CoreSchema</code>.</p> <pre><code>from pydantic import BaseModel, ImportString, PydanticUserError\n\n\nclass Model(BaseModel):\n    a: ImportString\n\n\ntry:\n    Model.model_json_schema()\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'invalid-for-json-schema'\n</code></pre>"},{"location":"errors/usage_errors/#json-schema-already-used","title":"JSON schema already used","text":"<p>This error is raised when the JSON schema generator has already been used to generate a JSON schema. You must create a new instance to generate a new JSON schema.</p>"},{"location":"errors/usage_errors/#base-model-instantiated","title":"BaseModel instantiated","text":"<p>This error is raised when you instantiate <code>BaseModel</code> directly. Pydantic models should inherit from <code>BaseModel</code>.</p> <pre><code>from pydantic import BaseModel, PydanticUserError\n\ntry:\n    BaseModel()\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'base-model-instantiated'\n</code></pre>"},{"location":"errors/usage_errors/#undefined-annotation","title":"Undefined annotation","text":"<p>This error is raised when handling undefined annotations during <code>CoreSchema</code> generation.</p> <pre><code>from pydantic import BaseModel, PydanticUndefinedAnnotation\n\n\nclass Model(BaseModel):\n    a: 'B'  # noqa F821\n\n\ntry:\n    Model.model_rebuild()\nexcept PydanticUndefinedAnnotation as exc_info:\n    assert exc_info.code == 'undefined-annotation'\n</code></pre>"},{"location":"errors/usage_errors/#schema-for-unknown-type","title":"Schema for unknown type","text":"<p>This error is raised when Pydantic fails to generate a <code>CoreSchema</code> for some type.</p> <pre><code>from pydantic import BaseModel, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        x: 43 = 123\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'schema-for-unknown-type'\n</code></pre>"},{"location":"errors/usage_errors/#import-error","title":"Import error","text":"<p>This error is raised when you try to import an object that was available in Pydantic V1, but has been removed in Pydantic V2.</p> <p>See the Migration Guide for more information.</p>"},{"location":"errors/usage_errors/#create-model-field-definitions","title":"<code>create_model</code> field definitions","text":"<p>This error is raised when you provide field definitions input in <code>create_model</code> that is not valid.</p> <pre><code>from pydantic import PydanticUserError, create_model\n\ntry:\n    create_model('FooModel', foo=(str, 'default value', 'more'))\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'create-model-field-definitions'\n</code></pre> <p>Or when you use <code>typing.Annotated</code> with invalid input</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import PydanticUserError, create_model\n\ntry:\n    create_model('FooModel', foo=Annotated[str, 'NotFieldInfoValue'])\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'create-model-field-definitions'\n</code></pre>"},{"location":"errors/usage_errors/#create-model-config-base","title":"<code>create_model</code> config base","text":"<p>This error is raised when you use both <code>__config__</code> and <code>__base__</code> together in <code>create_model</code>.</p> <pre><code>from pydantic import BaseModel, ConfigDict, PydanticUserError, create_model\n\ntry:\n    config = ConfigDict(frozen=True)\n    model = create_model(\n        'FooModel', foo=(int, ...), __config__=config, __base__=BaseModel\n    )\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'create-model-config-base'\n</code></pre>"},{"location":"errors/usage_errors/#validator-no-fields","title":"Validator with no fields","text":"<p>This error is raised when you use validator bare (with no fields).</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: str\n\n        @field_validator\n        def checker(cls, v):\n            return v\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-no-fields'\n</code></pre> <p>Validators should be used with fields and keyword arguments.</p> <pre><code>from pydantic import BaseModel, field_validator\n\n\nclass Model(BaseModel):\n    a: str\n\n    @field_validator('a')\n    def checker(cls, v):\n        return v\n</code></pre>"},{"location":"errors/usage_errors/#validator-invalid-fields","title":"Invalid validator fields","text":"<p>This error is raised when you use a validator with non-string fields.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: str\n        b: str\n\n        @field_validator(['a', 'b'])\n        def check_fields(cls, v):\n            return v\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-invalid-fields'\n</code></pre> <p>Fields should be passed as separate string arguments:</p> <pre><code>from pydantic import BaseModel, field_validator\n\n\nclass Model(BaseModel):\n    a: str\n    b: str\n\n    @field_validator('a', 'b')\n    def check_fields(cls, v):\n        return v\n</code></pre>"},{"location":"errors/usage_errors/#validator-instance-method","title":"Validator on instance method","text":"<p>This error is raised when you apply a validator on an instance method.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: int = 1\n\n        @field_validator('a')\n        def check_a(self, value):\n            return value\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-instance-method'\n</code></pre>"},{"location":"errors/usage_errors/#validator-input-type","title":"<code>json_schema_input_type</code> used with the wrong mode","text":"<p>This error is raised when you explicitly specify a value for the <code>json_schema_input_type</code> argument and <code>mode</code> isn't set to either <code>'before'</code>, <code>'plain'</code> or <code>'wrap'</code>.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: int = 1\n\n        @field_validator('a', mode='after', json_schema_input_type=int)\n        @classmethod\n        def check_a(self, value):\n            return value\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-input-type'\n</code></pre> <p>Documenting the JSON Schema input type is only possible for validators where the given value can be anything. That is why it isn't available for <code>after</code> validators, where the value is first validated against the type annotation.</p>"},{"location":"errors/usage_errors/#root-validator-pre-skip","title":"Root validator, <code>pre</code>, <code>skip_on_failure</code>","text":"<p>If you use <code>@root_validator</code> with <code>pre=False</code> (the default) you MUST specify <code>skip_on_failure=True</code>. The <code>skip_on_failure=False</code> option is no longer available.</p> <p>If you were not trying to set <code>skip_on_failure=False</code>, you can safely set <code>skip_on_failure=True</code>. If you do, this root validator will no longer be called if validation fails for any of the fields.</p> <p>Please see the Migration Guide for more details.</p>"},{"location":"errors/usage_errors/#model-serializer-instance-method","title":"<code>model_serializer</code> instance methods","text":"<p><code>@model_serializer</code> must be applied to instance methods.</p> <p>This error is raised when you apply <code>model_serializer</code> on an instance method without <code>self</code>:</p> <pre><code>from pydantic import BaseModel, PydanticUserError, model_serializer\n\ntry:\n\n    class MyModel(BaseModel):\n        a: int\n\n        @model_serializer\n        def _serialize(slf, x, y, z):\n            return slf\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-serializer-instance-method'\n</code></pre> <p>Or on a class method:</p> <pre><code>from pydantic import BaseModel, PydanticUserError, model_serializer\n\ntry:\n\n    class MyModel(BaseModel):\n        a: int\n\n        @model_serializer\n        @classmethod\n        def _serialize(self, x, y, z):\n            return self\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-serializer-instance-method'\n</code></pre>"},{"location":"errors/usage_errors/#validator-field-config-info","title":"<code>validator</code>, <code>field</code>, <code>config</code>, and <code>info</code>","text":"<p>The <code>field</code> and <code>config</code> parameters are not available in Pydantic V2. Please use the <code>info</code> parameter instead.</p> <p>You can access the configuration via <code>info.config</code>, but it is a dictionary instead of an object like it was in Pydantic V1.</p> <p>The <code>field</code> argument is no longer available.</p>"},{"location":"errors/usage_errors/#validator-v1-signature","title":"Pydantic V1 validator signature","text":"<p>This error is raised when you use an unsupported signature for Pydantic V1-style validator.</p> <pre><code>import warnings\n\nfrom pydantic import BaseModel, PydanticUserError, validator\n\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\ntry:\n\n    class Model(BaseModel):\n        a: int\n\n        @validator('a')\n        def check_a(cls, value, foo):\n            return value\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-v1-signature'\n</code></pre>"},{"location":"errors/usage_errors/#validator-signature","title":"Unrecognized <code>field_validator</code> signature","text":"<p>This error is raised when a <code>field_validator</code> or <code>model_validator</code> function has the wrong signature.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_validator\n\ntry:\n\n    class Model(BaseModel):\n        a: str\n\n        @field_validator('a')\n        @classmethod\n        def check_a(cls):\n            return 'a'\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'validator-signature'\n</code></pre>"},{"location":"errors/usage_errors/#field-serializer-signature","title":"Unrecognized <code>field_serializer</code> signature","text":"<p>This error is raised when the <code>field_serializer</code> function has the wrong signature.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_serializer\n\ntry:\n\n    class Model(BaseModel):\n        x: int\n\n        @field_serializer('x')\n        def no_args():\n            return 'x'\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'field-serializer-signature'\n</code></pre> <p>Valid field serializer signatures are:</p> <pre><code>from pydantic import FieldSerializationInfo, SerializerFunctionWrapHandler, field_serializer\n\n# an instance method with the default mode or `mode='plain'`\n@field_serializer('x')  # or @field_serializer('x', mode='plain')\ndef ser_x(self, value: Any, info: FieldSerializationInfo): ...\n\n# a static method or function with the default mode or `mode='plain'`\n@field_serializer('x')  # or @field_serializer('x', mode='plain')\n@staticmethod\ndef ser_x(value: Any, info: FieldSerializationInfo): ...\n\n# equivalent to\ndef ser_x(value: Any, info: FieldSerializationInfo): ...\nserializer('x')(ser_x)\n\n# an instance method with `mode='wrap'`\n@field_serializer('x', mode='wrap')\ndef ser_x(self, value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo): ...\n\n# a static method or function with `mode='wrap'`\n@field_serializer('x', mode='wrap')\n@staticmethod\ndef ser_x(value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo): ...\n\n# equivalent to\ndef ser_x(value: Any, nxt: SerializerFunctionWrapHandler, info: FieldSerializationInfo): ...\nserializer('x')(ser_x)\n\n# For all of these, you can also choose to omit the `info` argument, for example:\n@field_serializer('x')\ndef ser_x(self, value: Any): ...\n\n@field_serializer('x', mode='wrap')\ndef ser_x(self, value: Any, handler: SerializerFunctionWrapHandler): ...\n</code></pre>"},{"location":"errors/usage_errors/#model-serializer-signature","title":"Unrecognized <code>model_serializer</code> signature","text":"<p>This error is raised when the <code>model_serializer</code> function has the wrong signature.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, model_serializer\n\ntry:\n\n    class MyModel(BaseModel):\n        a: int\n\n        @model_serializer\n        def _serialize(self, x, y, z):\n            return self\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-serializer-signature'\n</code></pre> <p>Valid model serializer signatures are:</p> <pre><code>from pydantic import SerializerFunctionWrapHandler, SerializationInfo, model_serializer\n\n# an instance method with the default mode or `mode='plain'`\n@model_serializer  # or model_serializer(mode='plain')\ndef mod_ser(self, info: SerializationInfo): ...\n\n# an instance method with `mode='wrap'`\n@model_serializer(mode='wrap')\ndef mod_ser(self, handler: SerializerFunctionWrapHandler, info: SerializationInfo):\n\n# For all of these, you can also choose to omit the `info` argument, for example:\n@model_serializer(mode='plain')\ndef mod_ser(self): ...\n\n@model_serializer(mode='wrap')\ndef mod_ser(self, handler: SerializerFunctionWrapHandler): ...\n</code></pre>"},{"location":"errors/usage_errors/#multiple-field-serializers","title":"Multiple field serializers","text":"<p>This error is raised when multiple <code>model_serializer</code> functions are defined for a field.</p> <pre><code>from pydantic import BaseModel, PydanticUserError, field_serializer\n\ntry:\n\n    class MyModel(BaseModel):\n        x: int\n        y: int\n\n        @field_serializer('x', 'y')\n        def serializer1(v):\n            return f'{v:,}'\n\n        @field_serializer('x')\n        def serializer2(v):\n            return v\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'multiple-field-serializers'\n</code></pre>"},{"location":"errors/usage_errors/#invalid-annotated-type","title":"Invalid annotated type","text":"<p>This error is raised when an annotation cannot annotate a type.</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, FutureDate, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        foo: Annotated[str, FutureDate()]\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'invalid-annotated-type'\n</code></pre>"},{"location":"errors/usage_errors/#type-adapter-config-unused","title":"<code>config</code> is unused with <code>TypeAdapter</code>","text":"<p>You will get this error if you try to pass <code>config</code> to <code>TypeAdapter</code> when the type is a type that has its own config that cannot be overridden (currently this is only <code>BaseModel</code>, <code>TypedDict</code> and <code>dataclass</code>):</p> <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import ConfigDict, PydanticUserError, TypeAdapter\n\n\nclass MyTypedDict(TypedDict):\n    x: int\n\n\ntry:\n    TypeAdapter(MyTypedDict, config=ConfigDict(strict=True))\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'type-adapter-config-unused'\n</code></pre> <p>Instead you'll need to subclass the type and override or set the config on it:</p> <pre><code>from typing_extensions import TypedDict\n\nfrom pydantic import ConfigDict, TypeAdapter\n\n\nclass MyTypedDict(TypedDict):\n    x: int\n\n    # or `model_config = ...` for BaseModel\n    __pydantic_config__ = ConfigDict(strict=True)\n\n\nTypeAdapter(MyTypedDict)  # ok\n</code></pre>"},{"location":"errors/usage_errors/#root-model-extra","title":"Cannot specify <code>model_config['extra']</code> with <code>RootModel</code>","text":"<p>Because <code>RootModel</code> is not capable of storing or even accepting extra fields during initialization, we raise an error if you try to specify a value for the config setting <code>'extra'</code> when creating a subclass of <code>RootModel</code>:</p> <pre><code>from pydantic import PydanticUserError, RootModel\n\ntry:\n\n    class MyRootModel(RootModel):\n        model_config = {'extra': 'allow'}\n        root: int\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'root-model-extra'\n</code></pre>"},{"location":"errors/usage_errors/#unevaluable-type-annotation","title":"Cannot evaluate type annotation","text":"<p>Because type annotations are evaluated after assignments, you might get unexpected results when using a type annotation name that clashes with one of your fields. We raise an error in the following case:</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, Field\n\n\nclass Model(BaseModel):\n    date: date = Field(description='A date')\n</code></pre> <p>As a workaround, you can either use an alias or change your import:</p> <pre><code>import datetime\n# Or `from datetime import date as _date`\n\nfrom pydantic import BaseModel, Field\n\n\nclass Model(BaseModel):\n    date: datetime.date = Field(description='A date')\n</code></pre>"},{"location":"errors/usage_errors/#dataclass-init-false-extra-allow","title":"Incompatible <code>dataclass</code> <code>init</code> and <code>extra</code> settings","text":"<p>Pydantic does not allow the specification of the <code>extra='allow'</code> setting on a dataclass while any of the fields have <code>init=False</code> set.</p> <p>Thus, you may not do something like the following:</p> <pre><code>from pydantic import ConfigDict, Field\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass(config=ConfigDict(extra='allow'))\nclass A:\n    a: int = Field(init=False, default=1)\n</code></pre> <p>The above snippet results in the following error during schema building for the <code>A</code> dataclass:</p> <pre><code>pydantic.errors.PydanticUserError: Field a has `init=False` and dataclass has config setting `extra=\"allow\"`.\nThis combination is not allowed.\n</code></pre>"},{"location":"errors/usage_errors/#clashing-init-and-init-var","title":"Incompatible <code>init</code> and <code>init_var</code> settings on <code>dataclass</code> field","text":"<p>The <code>init=False</code> and <code>init_var=True</code> settings are mutually exclusive. Doing so results in the <code>PydanticUserError</code> shown in the example below.</p> <pre><code>from pydantic import Field\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass\nclass Foo:\n    bar: str = Field(..., init=False, init_var=True)\n\n\n\"\"\"\npydantic.errors.PydanticUserError: Dataclass field bar has init=False and init_var=True, but these are mutually exclusive.\n\"\"\"\n</code></pre>"},{"location":"errors/usage_errors/#model-config-invalid-field-name","title":"<code>model_config</code> is used as a model field","text":"<p>This error is raised when <code>model_config</code> is used as the name of a field. <pre><code>from pydantic import BaseModel, PydanticUserError\n\ntry:\n\n    class Model(BaseModel):\n        model_config: str\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'model-config-invalid-field-name'\n</code></pre></p>"},{"location":"errors/usage_errors/#with-config-on-model","title":"<code>with_config</code> is used on a <code>BaseModel</code> subclass","text":"<p>This error is raised when the <code>with_config</code>  decorator is used on a class which is already a Pydantic model (use the <code>model_config</code> attribute instead).</p> <pre><code>from pydantic import BaseModel, PydanticUserError, with_config\n\ntry:\n\n    @with_config({'allow_inf_nan': True})\n    class Model(BaseModel):\n        bar: str\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'with-config-on-model'\n</code></pre>"},{"location":"errors/usage_errors/#dataclass-on-model","title":"<code>dataclass</code> is used on a <code>BaseModel</code> subclass","text":"<p>This error is raised when the Pydantic <code>dataclass</code> decorator is used on a class which is already a Pydantic model.</p> <pre><code>from pydantic import BaseModel, PydanticUserError\nfrom pydantic.dataclasses import dataclass\n\ntry:\n\n    @dataclass\n    class Model(BaseModel):\n        bar: str\n\nexcept PydanticUserError as exc_info:\n    assert exc_info.code == 'dataclass-on-model'\n</code></pre>"},{"location":"errors/validation_errors/","title":"Validation Errors","text":"<p>Pydantic attempts to provide useful validation errors. Below are details on common validation errors users may encounter when working with pydantic, together with some suggestions on how to fix them.</p>"},{"location":"errors/validation_errors/#arguments_type","title":"<code>arguments_type</code>","text":"<p>This error is raised when an object that would be passed as arguments to a function during validation is not a <code>tuple</code>, <code>list</code>, or <code>dict</code>. Because <code>NamedTuple</code> uses function calls in its implementation, that is one way to produce this error:</p> <pre><code>from typing import NamedTuple\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass MyNamedTuple(NamedTuple):\n    x: int\n\n\nclass MyModel(BaseModel):\n    field: MyNamedTuple\n\n\ntry:\n    MyModel.model_validate({'field': 'invalid'})\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'arguments_type'\n</code></pre>"},{"location":"errors/validation_errors/#assertion_error","title":"<code>assertion_error</code>","text":"<p>This error is raised when a failing <code>assert</code> statement is encountered during validation:</p> <pre><code>from pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    x: int\n\n    @field_validator('x')\n    @classmethod\n    def force_x_positive(cls, v):\n        assert v &gt; 0\n        return v\n\n\ntry:\n    Model(x=-1)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'assertion_error'\n</code></pre>"},{"location":"errors/validation_errors/#bool_parsing","title":"<code>bool_parsing</code>","text":"<p>This error is raised when the input value is a string that is not valid for coercion to a boolean:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: bool\n\n\nModel(x='true')  # OK\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'bool_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#bool_type","title":"<code>bool_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>bool</code> field:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: bool\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'bool_type'\n</code></pre>"},{"location":"errors/validation_errors/#bytes_invalid_encoding","title":"<code>bytes_invalid_encoding</code>","text":"<p>This error is raised when a <code>bytes</code> value is invalid under the configured encoding. In the following example, <code>b'a'</code> is invalid hex (odd number of digits).</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: bytes\n    model_config = {'val_json_bytes': 'hex'}\n\n\ntry:\n    Model(x=b'a')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'bytes_invalid_encoding'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>bool</code>.</p>"},{"location":"errors/validation_errors/#bytes_too_long","title":"<code>bytes_too_long</code>","text":"<p>This error is raised when the length of a <code>bytes</code> value is greater than the field's <code>max_length</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: bytes = Field(max_length=3)\n\n\ntry:\n    Model(x=b'test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'bytes_too_long'\n</code></pre>"},{"location":"errors/validation_errors/#bytes_too_short","title":"<code>bytes_too_short</code>","text":"<p>This error is raised when the length of a <code>bytes</code> value is less than the field's <code>min_length</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: bytes = Field(min_length=3)\n\n\ntry:\n    Model(x=b't')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'bytes_too_short'\n</code></pre>"},{"location":"errors/validation_errors/#bytes_type","title":"<code>bytes_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>bytes</code> field:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: bytes\n\n\ntry:\n    Model(x=123)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'bytes_type'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>bytes</code>.</p>"},{"location":"errors/validation_errors/#callable_type","title":"<code>callable_type</code>","text":"<p>This error is raised when the input value is not valid as a <code>Callable</code>:</p> <pre><code>from typing import Any, Callable\n\nfrom pydantic import BaseModel, ImportString, ValidationError\n\n\nclass Model(BaseModel):\n    x: ImportString[Callable[[Any], Any]]\n\n\nModel(x='math:cos')  # OK\n\ntry:\n    Model(x='os.path')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'callable_type'\n</code></pre>"},{"location":"errors/validation_errors/#complex_str_parsing","title":"<code>complex_str_parsing</code>","text":"<p>This error is raised when the input value is a string but cannot be parsed as a complex number because it does not follow the rule in Python:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    num: complex\n\n\ntry:\n    # Complex numbers in json are expected to be valid complex strings.\n    # This value `abc` is not a valid complex string.\n    Model.model_validate_json('{\"num\": \"abc\"}')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'complex_str_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#complex_type","title":"<code>complex_type</code>","text":"<p>This error is raised when the input value cannot be interpreted as a complex number:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    num: complex\n\n\ntry:\n    Model(num=False)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'complex_type'\n</code></pre>"},{"location":"errors/validation_errors/#dataclass_exact_type","title":"<code>dataclass_exact_type</code>","text":"<p>This error is raised when validating a dataclass with <code>strict=True</code> and the input is not an instance of the dataclass:</p> <pre><code>import pydantic.dataclasses\nfrom pydantic import TypeAdapter, ValidationError\n\n\n@pydantic.dataclasses.dataclass\nclass MyDataclass:\n    x: str\n\n\nadapter = TypeAdapter(MyDataclass)\n\nprint(adapter.validate_python(MyDataclass(x='test'), strict=True))\n#&gt; MyDataclass(x='test')\nprint(adapter.validate_python({'x': 'test'}))\n#&gt; MyDataclass(x='test')\n\ntry:\n    adapter.validate_python({'x': 'test'}, strict=True)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'dataclass_exact_type'\n</code></pre>"},{"location":"errors/validation_errors/#dataclass_type","title":"<code>dataclass_type</code>","text":"<p>This error is raised when the input value is not valid for a <code>dataclass</code> field:</p> <pre><code>from pydantic import ValidationError, dataclasses\n\n\n@dataclasses.dataclass\nclass Inner:\n    x: int\n\n\n@dataclasses.dataclass\nclass Outer:\n    y: Inner\n\n\nOuter(y=Inner(x=1))  # OK\n\ntry:\n    Outer(y=1)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'dataclass_type'\n</code></pre>"},{"location":"errors/validation_errors/#date_from_datetime_inexact","title":"<code>date_from_datetime_inexact</code>","text":"<p>This error is raised when the input <code>datetime</code> value provided for a <code>date</code> field has a nonzero time component. For a timestamp to parse into a field of type <code>date</code>, the time components must all be zero:</p> <pre><code>from datetime import date, datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: date\n\n\nModel(x='2023-01-01')  # OK\nModel(x=datetime(2023, 1, 1))  # OK\n\ntry:\n    Model(x=datetime(2023, 1, 1, 12))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'date_from_datetime_inexact'\n</code></pre>"},{"location":"errors/validation_errors/#date_from_datetime_parsing","title":"<code>date_from_datetime_parsing</code>","text":"<p>This error is raised when the input value is a string that cannot be parsed for a <code>date</code> field:</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: date\n\n\ntry:\n    Model(x='XX1494012000')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'date_from_datetime_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#date_future","title":"<code>date_future</code>","text":"<p>This error is raised when the input value provided for a <code>FutureDate</code> field is not in the future:</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, FutureDate, ValidationError\n\n\nclass Model(BaseModel):\n    x: FutureDate\n\n\ntry:\n    Model(x=date(2000, 1, 1))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'date_future'\n</code></pre>"},{"location":"errors/validation_errors/#date_parsing","title":"<code>date_parsing</code>","text":"<p>This error is raised when validating JSON where the input value is string that cannot be parsed for a <code>date</code> field:</p> <pre><code>import json\nfrom datetime import date\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: date = Field(strict=True)\n\n\ntry:\n    Model.model_validate_json(json.dumps({'x': '1'}))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'date_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#date_past","title":"<code>date_past</code>","text":"<p>This error is raised when the value provided for a <code>PastDate</code> field is not in the past:</p> <pre><code>from datetime import date, timedelta\n\nfrom pydantic import BaseModel, PastDate, ValidationError\n\n\nclass Model(BaseModel):\n    x: PastDate\n\n\ntry:\n    Model(x=date.today() + timedelta(1))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'date_past'\n</code></pre>"},{"location":"errors/validation_errors/#date_type","title":"<code>date_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>date</code> field:</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: date\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'date_type'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>date</code>.</p>"},{"location":"errors/validation_errors/#datetime_from_date_parsing","title":"<code>datetime_from_date_parsing</code>","text":"<p>Note</p> <p>Support for this error, along with support for parsing datetimes from <code>yyyy-MM-DD</code> dates will be added in <code>v2.6.0</code></p> <p>This error is raised when the input value is a string that cannot be parsed for a <code>datetime</code> field:</p> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: datetime\n\n\ntry:\n    # there is no 13th month\n    Model(x='2023-13-01')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'datetime_from_date_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#datetime_future","title":"<code>datetime_future</code>","text":"<p>This error is raised when the value provided for a <code>FutureDatetime</code> field is not in the future:</p> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, FutureDatetime, ValidationError\n\n\nclass Model(BaseModel):\n    x: FutureDatetime\n\n\ntry:\n    Model(x=datetime(2000, 1, 1))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'datetime_future'\n</code></pre>"},{"location":"errors/validation_errors/#datetime_object_invalid","title":"<code>datetime_object_invalid</code>","text":"<p>This error is raised when something about the <code>datetime</code> object is not valid:</p> <pre><code>from datetime import datetime, tzinfo\n\nfrom pydantic import AwareDatetime, BaseModel, ValidationError\n\n\nclass CustomTz(tzinfo):\n    # utcoffset is not implemented!\n\n    def tzname(self, _dt):\n        return 'CustomTZ'\n\n\nclass Model(BaseModel):\n    x: AwareDatetime\n\n\ntry:\n    Model(x=datetime(2023, 1, 1, tzinfo=CustomTz()))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'datetime_object_invalid'\n</code></pre>"},{"location":"errors/validation_errors/#datetime_parsing","title":"<code>datetime_parsing</code>","text":"<p>This error is raised when the value is a string that cannot be parsed for a <code>datetime</code> field:</p> <pre><code>import json\nfrom datetime import datetime\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: datetime = Field(strict=True)\n\n\ntry:\n    Model.model_validate_json(json.dumps({'x': 'not a datetime'}))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'datetime_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#datetime_past","title":"<code>datetime_past</code>","text":"<p>This error is raised when the value provided for a <code>PastDatetime</code> field is not in the past:</p> <pre><code>from datetime import datetime, timedelta\n\nfrom pydantic import BaseModel, PastDatetime, ValidationError\n\n\nclass Model(BaseModel):\n    x: PastDatetime\n\n\ntry:\n    Model(x=datetime.now() + timedelta(100))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'datetime_past'\n</code></pre>"},{"location":"errors/validation_errors/#datetime_type","title":"<code>datetime_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>datetime</code> field:</p> <pre><code>from datetime import datetime\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: datetime\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'datetime_type'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>datetime</code>.</p>"},{"location":"errors/validation_errors/#decimal_max_digits","title":"<code>decimal_max_digits</code>","text":"<p>This error is raised when the value provided for a <code>Decimal</code> has too many digits:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: Decimal = Field(max_digits=3)\n\n\ntry:\n    Model(x='42.1234')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'decimal_max_digits'\n</code></pre>"},{"location":"errors/validation_errors/#decimal_max_places","title":"<code>decimal_max_places</code>","text":"<p>This error is raised when the value provided for a <code>Decimal</code> has too many digits after the decimal point:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: Decimal = Field(decimal_places=3)\n\n\ntry:\n    Model(x='42.1234')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'decimal_max_places'\n</code></pre>"},{"location":"errors/validation_errors/#decimal_parsing","title":"<code>decimal_parsing</code>","text":"<p>This error is raised when the value provided for a <code>Decimal</code> could not be parsed as a decimal number:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: Decimal = Field(decimal_places=3)\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'decimal_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#decimal_type","title":"<code>decimal_type</code>","text":"<p>This error is raised when the value provided for a <code>Decimal</code> is of the wrong type:</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: Decimal = Field(decimal_places=3)\n\n\ntry:\n    Model(x=[1, 2, 3])\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'decimal_type'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>Decimal</code>.</p>"},{"location":"errors/validation_errors/#decimal_whole_digits","title":"<code>decimal_whole_digits</code>","text":"<p>This error is raised when the value provided for a <code>Decimal</code> has more digits before the decimal point than <code>max_digits</code> - <code>decimal_places</code> (as long as both are specified):</p> <pre><code>from decimal import Decimal\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: Decimal = Field(max_digits=6, decimal_places=3)\n\n\ntry:\n    Model(x='12345.6')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'decimal_whole_digits'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>Decimal</code>.</p>"},{"location":"errors/validation_errors/#dict_type","title":"<code>dict_type</code>","text":"<p>This error is raised when the input value's type is not <code>dict</code> for a <code>dict</code> field:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: dict\n\n\ntry:\n    Model(x=['1', '2'])\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'dict_type'\n</code></pre>"},{"location":"errors/validation_errors/#enum","title":"<code>enum</code>","text":"<p>This error is raised when the input value does not exist in an <code>enum</code> field members:</p> <pre><code>from enum import Enum\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass MyEnum(str, Enum):\n    option = 'option'\n\n\nclass Model(BaseModel):\n    x: MyEnum\n\n\ntry:\n    Model(x='other_option')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'enum'\n</code></pre>"},{"location":"errors/validation_errors/#extra_forbidden","title":"<code>extra_forbidden</code>","text":"<p>This error is raised when the input value contains extra fields, but <code>model_config['extra'] == 'forbid'</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n    model_config = ConfigDict(extra='forbid')\n\n\ntry:\n    Model(x='test', y='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'extra_forbidden'\n</code></pre> <p>You can read more about the <code>extra</code> configuration in the Extra Attributes section.</p>"},{"location":"errors/validation_errors/#finite_number","title":"<code>finite_number</code>","text":"<p>This error is raised when the value is infinite, or too large to be represented as a 64-bit floating point number during validation:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\ntry:\n    Model(x=2.2250738585072011e308)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'finite_number'\n</code></pre>"},{"location":"errors/validation_errors/#float_parsing","title":"<code>float_parsing</code>","text":"<p>This error is raised when the value is a string that can't be parsed as a <code>float</code>:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: float\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'float_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#float_type","title":"<code>float_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>float</code> field:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: float\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'float_type'\n</code></pre>"},{"location":"errors/validation_errors/#frozen_field","title":"<code>frozen_field</code>","text":"<p>This error is raised when you attempt to assign a value to a field with <code>frozen=True</code>, or to delete such a field:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: str = Field('test', frozen=True)\n\n\nmodel = Model()\n\ntry:\n    model.x = 'test1'\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'frozen_field'\n\ntry:\n    del model.x\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'frozen_field'\n</code></pre>"},{"location":"errors/validation_errors/#frozen_instance","title":"<code>frozen_instance</code>","text":"<p>This error is raised when <code>model_config['frozen] == True</code> and you attempt to delete or assign a new value to any of the fields:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n    model_config = ConfigDict(frozen=True)\n\n\nm = Model(x=1)\n\ntry:\n    m.x = 2\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'frozen_instance'\n\ntry:\n    del m.x\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'frozen_instance'\n</code></pre>"},{"location":"errors/validation_errors/#frozen_set_type","title":"<code>frozen_set_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>frozenset</code> field:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: frozenset\n\n\ntry:\n    model = Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'frozen_set_type'\n</code></pre>"},{"location":"errors/validation_errors/#get_attribute_error","title":"<code>get_attribute_error</code>","text":"<p>This error is raised when <code>model_config['from_attributes'] == True</code> and an error is raised while reading the attributes:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Foobar:\n    def __init__(self):\n        self.x = 1\n\n    @property\n    def y(self):\n        raise RuntimeError('intentional error')\n\n\nclass Model(BaseModel):\n    x: int\n    y: str\n\n    model_config = ConfigDict(from_attributes=True)\n\n\ntry:\n    Model.model_validate(Foobar())\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'get_attribute_error'\n</code></pre>"},{"location":"errors/validation_errors/#greater_than","title":"<code>greater_than</code>","text":"<p>This error is raised when the value is not greater than the field's <code>gt</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(gt=10)\n\n\ntry:\n    Model(x=10)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'greater_than'\n</code></pre>"},{"location":"errors/validation_errors/#greater_than_equal","title":"<code>greater_than_equal</code>","text":"<p>This error is raised when the value is not greater than or equal to the field's <code>ge</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(ge=10)\n\n\ntry:\n    Model(x=9)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'greater_than_equal'\n</code></pre>"},{"location":"errors/validation_errors/#int_from_float","title":"<code>int_from_float</code>","text":"<p>This error is raised when you provide a <code>float</code> value for an <code>int</code> field:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\ntry:\n    Model(x=0.5)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'int_from_float'\n</code></pre>"},{"location":"errors/validation_errors/#int_parsing","title":"<code>int_parsing</code>","text":"<p>This error is raised when the value can't be parsed as <code>int</code>:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'int_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#int_parsing_size","title":"<code>int_parsing_size</code>","text":"<p>This error is raised when attempting to parse a python or JSON value from a string outside the maximum range that Python <code>str</code> to <code>int</code> parsing permits:</p> <pre><code>import json\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\n# from Python\nassert Model(x='1' * 4_300).x == int('1' * 4_300)  # OK\n\ntoo_long = '1' * 4_301\ntry:\n    Model(x=too_long)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'int_parsing_size'\n\n# from JSON\ntry:\n    Model.model_validate_json(json.dumps({'x': too_long}))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'int_parsing_size'\n</code></pre>"},{"location":"errors/validation_errors/#int_type","title":"<code>int_type</code>","text":"<p>This error is raised when the input value's type is not valid for an <code>int</code> field:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'int_type'\n</code></pre>"},{"location":"errors/validation_errors/#invalid_key","title":"<code>invalid_key</code>","text":"<p>This error is raised when attempting to validate a <code>dict</code> that has a key that is not an instance of <code>str</code>:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Model(BaseModel):\n    x: int\n\n    model_config = ConfigDict(extra='allow')\n\n\ntry:\n    Model.model_validate({'x': 1, b'y': 2})\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'invalid_key'\n</code></pre>"},{"location":"errors/validation_errors/#is_instance_of","title":"<code>is_instance_of</code>","text":"<p>This error is raised when the input value is not an instance of the expected type:</p> <pre><code>from pydantic import BaseModel, ConfigDict, ValidationError\n\n\nclass Nested:\n    x: str\n\n\nclass Model(BaseModel):\n    y: Nested\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n\n\ntry:\n    Model(y='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'is_instance_of'\n</code></pre>"},{"location":"errors/validation_errors/#is_subclass_of","title":"<code>is_subclass_of</code>","text":"<p>This error is raised when the input value is not a subclass of the expected type:</p> <pre><code>from typing import Type\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Nested:\n    x: str\n\n\nclass Model(BaseModel):\n    y: Type[Nested]\n\n\ntry:\n    Model(y='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'is_subclass_of'\n</code></pre>"},{"location":"errors/validation_errors/#iterable_type","title":"<code>iterable_type</code>","text":"<p>This error is raised when the input value is not valid as an <code>Iterable</code>:</p> <pre><code>from typing import Iterable\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    y: Iterable\n\n\ntry:\n    Model(y=123)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'iterable_type'\n</code></pre>"},{"location":"errors/validation_errors/#iteration_error","title":"<code>iteration_error</code>","text":"<p>This error is raised when an error occurs during iteration:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\ndef gen():\n    yield 1\n    raise RuntimeError('error')\n\n\nclass Model(BaseModel):\n    x: List[int]\n\n\ntry:\n    Model(x=gen())\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'iteration_error'\n</code></pre>"},{"location":"errors/validation_errors/#json_invalid","title":"<code>json_invalid</code>","text":"<p>This error is raised when the input value is not a valid JSON string:</p> <pre><code>from pydantic import BaseModel, Json, ValidationError\n\n\nclass Model(BaseModel):\n    x: Json\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'json_invalid'\n</code></pre>"},{"location":"errors/validation_errors/#json_type","title":"<code>json_type</code>","text":"<p>This error is raised when the input value is of a type that cannot be parsed as JSON:</p> <pre><code>from pydantic import BaseModel, Json, ValidationError\n\n\nclass Model(BaseModel):\n    x: Json\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'json_type'\n</code></pre>"},{"location":"errors/validation_errors/#less_than","title":"<code>less_than</code>","text":"<p>This error is raised when the input value is not less than the field's <code>lt</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(lt=10)\n\n\ntry:\n    Model(x=10)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'less_than'\n</code></pre>"},{"location":"errors/validation_errors/#less_than_equal","title":"<code>less_than_equal</code>","text":"<p>This error is raised when the input value is not less than or equal to the field's <code>le</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(le=10)\n\n\ntry:\n    Model(x=11)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'less_than_equal'\n</code></pre>"},{"location":"errors/validation_errors/#list_type","title":"<code>list_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>list</code> field:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: List[int]\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'list_type'\n</code></pre>"},{"location":"errors/validation_errors/#literal_error","title":"<code>literal_error</code>","text":"<p>This error is raised when the input value is not one of the expected literal values:</p> <pre><code>from typing import Literal\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: Literal['a', 'b']\n\n\nModel(x='a')  # OK\n\ntry:\n    Model(x='c')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'literal_error'\n</code></pre>"},{"location":"errors/validation_errors/#mapping_type","title":"<code>mapping_type</code>","text":"<p>This error is raised when a problem occurs during validation due to a failure in a call to the methods from the <code>Mapping</code> protocol, such as <code>.items()</code>:</p> <pre><code>from collections.abc import Mapping\nfrom typing import Dict\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass BadMapping(Mapping):\n    def items(self):\n        raise ValueError()\n\n    def __iter__(self):\n        raise ValueError()\n\n    def __getitem__(self, key):\n        raise ValueError()\n\n    def __len__(self):\n        return 1\n\n\nclass Model(BaseModel):\n    x: Dict[str, str]\n\n\ntry:\n    Model(x=BadMapping())\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'mapping_type'\n</code></pre>"},{"location":"errors/validation_errors/#missing","title":"<code>missing</code>","text":"<p>This error is raised when there are required fields missing from the input value:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n\ntry:\n    Model()\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'missing'\n</code></pre>"},{"location":"errors/validation_errors/#missing_argument","title":"<code>missing_argument</code>","text":"<p>This error is raised when a required positional-or-keyword argument is not passed to a function decorated with <code>validate_call</code>:</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(a: int):\n    return a\n\n\ntry:\n    foo()\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'missing_argument'\n</code></pre>"},{"location":"errors/validation_errors/#missing_keyword_only_argument","title":"<code>missing_keyword_only_argument</code>","text":"<p>This error is raised when a required keyword-only argument is not passed to a function decorated with <code>validate_call</code>:</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(*, a: int):\n    return a\n\n\ntry:\n    foo()\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'missing_keyword_only_argument'\n</code></pre>"},{"location":"errors/validation_errors/#missing_positional_only_argument","title":"<code>missing_positional_only_argument</code>","text":"<p>This error is raised when a required positional-only argument is not passed to a function decorated with <code>validate_call</code>:</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(a: int, /):\n    return a\n\n\ntry:\n    foo()\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'missing_positional_only_argument'\n</code></pre>"},{"location":"errors/validation_errors/#model_attributes_type","title":"<code>model_attributes_type</code>","text":"<p>This error is raised when the input value is not a valid dictionary, model instance, or instance that fields can be extracted from:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    a: int\n    b: int\n\n\n# simply validating a dict\nprint(Model.model_validate({'a': 1, 'b': 2}))\n#&gt; a=1 b=2\n\n\nclass CustomObj:\n    def __init__(self, a, b):\n        self.a = a\n        self.b = b\n\n\n# using from attributes to extract fields from an objects\nprint(Model.model_validate(CustomObj(3, 4), from_attributes=True))\n#&gt; a=3 b=4\n\ntry:\n    Model.model_validate('not an object', from_attributes=True)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'model_attributes_type'\n</code></pre>"},{"location":"errors/validation_errors/#model_type","title":"<code>model_type</code>","text":"<p>This error is raised when the input to a model is not an instance of the model or dict:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    a: int\n    b: int\n\n\n# simply validating a dict\nm = Model.model_validate({'a': 1, 'b': 2})\nprint(m)\n#&gt; a=1 b=2\n\n# validating an existing model instance\nprint(Model.model_validate(m))\n#&gt; a=1 b=2\n\ntry:\n    Model.model_validate('not an object')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'model_type'\n</code></pre>"},{"location":"errors/validation_errors/#multiple_argument_values","title":"<code>multiple_argument_values</code>","text":"<p>This error is raised when you provide multiple values for a single argument while calling a function decorated with <code>validate_call</code>:</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(a: int):\n    return a\n\n\ntry:\n    foo(1, a=2)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'multiple_argument_values'\n</code></pre>"},{"location":"errors/validation_errors/#multiple_of","title":"<code>multiple_of</code>","text":"<p>This error is raised when the input is not a multiple of a field's <code>multiple_of</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: int = Field(multiple_of=5)\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'multiple_of'\n</code></pre>"},{"location":"errors/validation_errors/#no_such_attribute","title":"<code>no_such_attribute</code>","text":"<p>This error is raised when <code>validate_assignment=True</code> in the config, and you attempt to assign a value to an attribute that is not an existing field:</p> <pre><code>from pydantic import ConfigDict, ValidationError, dataclasses\n\n\n@dataclasses.dataclass(config=ConfigDict(validate_assignment=True))\nclass MyDataclass:\n    x: int\n\n\nm = MyDataclass(x=1)\ntry:\n    m.y = 10\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'no_such_attribute'\n</code></pre>"},{"location":"errors/validation_errors/#none_required","title":"<code>none_required</code>","text":"<p>This error is raised when the input value is not <code>None</code> for a field that requires <code>None</code>:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: None\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'none_required'\n</code></pre> <p>Note</p> <p>You may encounter this error when there is a naming collision in your model between a field name and its type. More specifically, this error is likely to be thrown when the default value of that field is <code>None</code>.</p> <p>For example, the following would yield the <code>none_required</code> validation error since the field <code>int</code> is set to a default value of <code>None</code> and has the exact same name as its type, which causes problems with validation. <pre><code>from typing import Optional\n\nfrom pydantic import BaseModel\n\n\nclass M1(BaseModel):\n    int: Optional[int] = None\n\n\nm = M1(int=123)  # errors\n</code></pre></p>"},{"location":"errors/validation_errors/#recursion_loop","title":"<code>recursion_loop</code>","text":"<p>This error is raised when a cyclic reference is detected:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: List['Model']\n\n\nd = {'x': []}\nd['x'].append(d)\ntry:\n    Model(**d)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'recursion_loop'\n</code></pre>"},{"location":"errors/validation_errors/#set_type","title":"<code>set_type</code>","text":"<p>This error is raised when the value type is not valid for a <code>set</code> field:</p> <pre><code>from typing import Set\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: Set[int]\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'set_type'\n</code></pre>"},{"location":"errors/validation_errors/#string_pattern_mismatch","title":"<code>string_pattern_mismatch</code>","text":"<p>This error is raised when the input value doesn't match the field's <code>pattern</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: str = Field(pattern='test')\n\n\ntry:\n    Model(x='1')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'string_pattern_mismatch'\n</code></pre>"},{"location":"errors/validation_errors/#string_sub_type","title":"<code>string_sub_type</code>","text":"<p>This error is raised when the value is an instance of a strict subtype of <code>str</code> when the field is strict:</p> <pre><code>from enum import Enum\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass MyEnum(str, Enum):\n    foo = 'foo'\n\n\nclass Model(BaseModel):\n    x: str = Field(strict=True)\n\n\ntry:\n    Model(x=MyEnum.foo)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'string_sub_type'\n</code></pre>"},{"location":"errors/validation_errors/#string_too_long","title":"<code>string_too_long</code>","text":"<p>This error is raised when the input value is a string whose length is greater than the field's <code>max_length</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: str = Field(max_length=3)\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'string_too_long'\n</code></pre>"},{"location":"errors/validation_errors/#string_too_short","title":"<code>string_too_short</code>","text":"<p>This error is raised when the input value is a string whose length is less than the field's <code>min_length</code> constraint:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: str = Field(min_length=3)\n\n\ntry:\n    Model(x='t')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'string_too_short'\n</code></pre>"},{"location":"errors/validation_errors/#string_type","title":"<code>string_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>str</code> field:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n\ntry:\n    Model(x=1)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'string_type'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>str</code>.</p>"},{"location":"errors/validation_errors/#string_unicode","title":"<code>string_unicode</code>","text":"<p>This error is raised when the value cannot be parsed as a Unicode string:</p> <pre><code>from pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: str\n\n\ntry:\n    Model(x=b'\\x81')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'string_unicode'\n</code></pre>"},{"location":"errors/validation_errors/#time_delta_parsing","title":"<code>time_delta_parsing</code>","text":"<p>This error is raised when the input value is a string that cannot be parsed for a <code>timedelta</code> field:</p> <pre><code>from datetime import timedelta\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: timedelta\n\n\ntry:\n    Model(x='t')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'time_delta_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#time_delta_type","title":"<code>time_delta_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>timedelta</code> field:</p> <pre><code>from datetime import timedelta\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: timedelta\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'time_delta_type'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>timedelta</code>.</p>"},{"location":"errors/validation_errors/#time_parsing","title":"<code>time_parsing</code>","text":"<p>This error is raised when the input value is a string that cannot be parsed for a <code>time</code> field:</p> <pre><code>from datetime import time\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: time\n\n\ntry:\n    Model(x='25:20:30.400')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'time_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#time_type","title":"<code>time_type</code>","text":"<p>This error is raised when the value type is not valid for a <code>time</code> field:</p> <pre><code>from datetime import time\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: time\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'time_type'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>time</code>.</p>"},{"location":"errors/validation_errors/#timezone_aware","title":"<code>timezone_aware</code>","text":"<p>This error is raised when the <code>datetime</code> value provided for a timezone-aware <code>datetime</code> field doesn't have timezone information:</p> <pre><code>from datetime import datetime\n\nfrom pydantic import AwareDatetime, BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: AwareDatetime\n\n\ntry:\n    Model(x=datetime.now())\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'timezone_aware'\n</code></pre>"},{"location":"errors/validation_errors/#timezone_naive","title":"<code>timezone_naive</code>","text":"<p>This error is raised when the <code>datetime</code> value provided for a timezone-naive <code>datetime</code> field has timezone info:</p> <pre><code>from datetime import datetime, timezone\n\nfrom pydantic import BaseModel, NaiveDatetime, ValidationError\n\n\nclass Model(BaseModel):\n    x: NaiveDatetime\n\n\ntry:\n    Model(x=datetime.now(tz=timezone.utc))\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'timezone_naive'\n</code></pre>"},{"location":"errors/validation_errors/#too_long","title":"<code>too_long</code>","text":"<p>This error is raised when the input value's length is greater than the field's <code>max_length</code> constraint:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: List[int] = Field(max_length=3)\n\n\ntry:\n    Model(x=[1, 2, 3, 4])\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'too_long'\n</code></pre>"},{"location":"errors/validation_errors/#too_short","title":"<code>too_short</code>","text":"<p>This error is raised when the value length is less than the field's <code>min_length</code> constraint:</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass Model(BaseModel):\n    x: List[int] = Field(min_length=3)\n\n\ntry:\n    Model(x=[1, 2])\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'too_short'\n</code></pre>"},{"location":"errors/validation_errors/#tuple_type","title":"<code>tuple_type</code>","text":"<p>This error is raised when the input value's type is not valid for a <code>tuple</code> field:</p> <pre><code>from typing import Tuple\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: Tuple[int]\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'tuple_type'\n</code></pre> <p>This error is also raised for strict fields when the input value is not an instance of <code>tuple</code>.</p>"},{"location":"errors/validation_errors/#unexpected_keyword_argument","title":"<code>unexpected_keyword_argument</code>","text":"<p>This error is raised when you provide a value by keyword for a positional-only argument while calling a function decorated with <code>validate_call</code>:</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(a: int, /):\n    return a\n\n\ntry:\n    foo(a=2)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[1]['type']))\n    #&gt; 'unexpected_keyword_argument'\n</code></pre> <p>It is also raised when using pydantic.dataclasses and <code>extra=forbid</code>:</p> <pre><code>from pydantic import TypeAdapter, ValidationError\nfrom pydantic.dataclasses import dataclass\n\n\n@dataclass(config={'extra': 'forbid'})\nclass Foo:\n    bar: int\n\n\ntry:\n    TypeAdapter(Foo).validate_python({'bar': 1, 'foobar': 2})\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'unexpected_keyword_argument'\n</code></pre>"},{"location":"errors/validation_errors/#unexpected_positional_argument","title":"<code>unexpected_positional_argument</code>","text":"<p>This error is raised when you provide a positional value for a keyword-only argument while calling a function decorated with <code>validate_call</code>:</p> <pre><code>from pydantic import ValidationError, validate_call\n\n\n@validate_call\ndef foo(*, a: int):\n    return a\n\n\ntry:\n    foo(2)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[1]['type']))\n    #&gt; 'unexpected_positional_argument'\n</code></pre>"},{"location":"errors/validation_errors/#union_tag_invalid","title":"<code>union_tag_invalid</code>","text":"<p>This error is raised when the input's discriminator is not one of the expected values:</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['blackcat']\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['whitecat']\n\n\nclass Model(BaseModel):\n    cat: Union[BlackCat, WhiteCat] = Field(..., discriminator='pet_type')\n\n\ntry:\n    Model(cat={'pet_type': 'dog'})\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'union_tag_invalid'\n</code></pre>"},{"location":"errors/validation_errors/#union_tag_not_found","title":"<code>union_tag_not_found</code>","text":"<p>This error is raised when it is not possible to extract a discriminator value from the input:</p> <pre><code>from typing import Literal, Union\n\nfrom pydantic import BaseModel, Field, ValidationError\n\n\nclass BlackCat(BaseModel):\n    pet_type: Literal['blackcat']\n\n\nclass WhiteCat(BaseModel):\n    pet_type: Literal['whitecat']\n\n\nclass Model(BaseModel):\n    cat: Union[BlackCat, WhiteCat] = Field(..., discriminator='pet_type')\n\n\ntry:\n    Model(cat={'name': 'blackcat'})\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'union_tag_not_found'\n</code></pre>"},{"location":"errors/validation_errors/#url_parsing","title":"<code>url_parsing</code>","text":"<p>This error is raised when the input value cannot be parsed as a URL:</p> <pre><code>from pydantic import AnyUrl, BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    x: AnyUrl\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'url_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#url_scheme","title":"<code>url_scheme</code>","text":"<p>This error is raised when the URL scheme is not valid for the URL type of the field:</p> <pre><code>from pydantic import BaseModel, HttpUrl, ValidationError\n\n\nclass Model(BaseModel):\n    x: HttpUrl\n\n\ntry:\n    Model(x='ftp://example.com')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'url_scheme'\n</code></pre>"},{"location":"errors/validation_errors/#url_syntax_violation","title":"<code>url_syntax_violation</code>","text":"<p>This error is raised when the URL syntax is not valid:</p> <pre><code>from pydantic import BaseModel, Field, HttpUrl, ValidationError\n\n\nclass Model(BaseModel):\n    x: HttpUrl = Field(strict=True)\n\n\ntry:\n    Model(x='http:////example.com')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'url_syntax_violation'\n</code></pre>"},{"location":"errors/validation_errors/#url_too_long","title":"<code>url_too_long</code>","text":"<p>This error is raised when the URL length is greater than 2083:</p> <pre><code>from pydantic import BaseModel, HttpUrl, ValidationError\n\n\nclass Model(BaseModel):\n    x: HttpUrl\n\n\ntry:\n    Model(x='x' * 2084)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'url_too_long'\n</code></pre>"},{"location":"errors/validation_errors/#url_type","title":"<code>url_type</code>","text":"<p>This error is raised when the input value's type is not valid for a URL field:</p> <pre><code>from pydantic import BaseModel, HttpUrl, ValidationError\n\n\nclass Model(BaseModel):\n    x: HttpUrl\n\n\ntry:\n    Model(x=None)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'url_type'\n</code></pre>"},{"location":"errors/validation_errors/#uuid_parsing","title":"<code>uuid_parsing</code>","text":"<p>This error is raised when the input value's type is not valid for a UUID field:</p> <pre><code>from uuid import UUID\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    u: UUID\n\n\ntry:\n    Model(u='12345678-124-1234-1234-567812345678')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'uuid_parsing'\n</code></pre>"},{"location":"errors/validation_errors/#uuid_type","title":"<code>uuid_type</code>","text":"<p>This error is raised when the input value's type is not valid instance for a UUID field (str, bytes or UUID):</p> <pre><code>from uuid import UUID\n\nfrom pydantic import BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    u: UUID\n\n\ntry:\n    Model(u=1234567812412341234567812345678)\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'uuid_type'\n</code></pre>"},{"location":"errors/validation_errors/#uuid_version","title":"<code>uuid_version</code>","text":"<p>This error is raised when the input value's type is not match UUID version:</p> <pre><code>from pydantic import UUID5, BaseModel, ValidationError\n\n\nclass Model(BaseModel):\n    u: UUID5\n\n\ntry:\n    Model(u='a6cc5730-2261-11ee-9c43-2eb5a363657c')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'uuid_version'\n</code></pre>"},{"location":"errors/validation_errors/#value_error","title":"<code>value_error</code>","text":"<p>This error is raised when a <code>ValueError</code> is raised during validation:</p> <pre><code>from pydantic import BaseModel, ValidationError, field_validator\n\n\nclass Model(BaseModel):\n    x: str\n\n    @field_validator('x')\n    @classmethod\n    def repeat_b(cls, v):\n        raise ValueError()\n\n\ntry:\n    Model(x='test')\nexcept ValidationError as exc:\n    print(repr(exc.errors()[0]['type']))\n    #&gt; 'value_error'\n</code></pre>"},{"location":"examples/secrets/","title":"Secrets","text":"<p>\ud83d\udea7 Work in Progress</p> <p>This page is a work in progress.</p>"},{"location":"examples/secrets/#serialize-secretstr-and-secretbytes-as-plain-text","title":"Serialize <code>SecretStr</code> and <code>SecretBytes</code> as plain-text","text":"<p>By default, <code>SecretStr</code> and <code>SecretBytes</code> will be serialized as <code>**********</code> when serializing to json.</p> <p>You can use the <code>field_serializer</code> to dump the secret as plain-text when serializing to json.</p> <pre><code>from pydantic import BaseModel, SecretBytes, SecretStr, field_serializer\n\n\nclass Model(BaseModel):\n    password: SecretStr\n    password_bytes: SecretBytes\n\n    @field_serializer('password', 'password_bytes', when_used='json')\n    def dump_secret(self, v):\n        return v.get_secret_value()\n\n\nmodel = Model(password='IAmSensitive', password_bytes=b'IAmSensitiveBytes')\nprint(model)\n#&gt; password=SecretStr('**********') password_bytes=SecretBytes(b'**********')\nprint(model.password)\n#&gt; **********\nprint(model.model_dump())\n\"\"\"\n{\n    'password': SecretStr('**********'),\n    'password_bytes': SecretBytes(b'**********'),\n}\n\"\"\"\nprint(model.model_dump_json())\n#&gt; {\"password\":\"IAmSensitive\",\"password_bytes\":\"IAmSensitiveBytes\"}\n</code></pre>"},{"location":"examples/secrets/#create-your-own-secret-field","title":"Create your own Secret field","text":"<p>Pydantic provides the generic <code>Secret</code> class as a mechanism for creating custom secret types.</p> API Documentation <p><code>pydantic.types.Secret</code></p> <p>Pydantic provides the generic <code>Secret</code> class as a mechanism for creating custom secret types. You can either directly parametrize <code>Secret</code>, or subclass from a parametrized <code>Secret</code> to customize the <code>str()</code> and <code>repr()</code> of a secret type.</p> <pre><code>from datetime import date\n\nfrom pydantic import BaseModel, Secret\n\n# Using the default representation\nSecretDate = Secret[date]\n\n\n# Overwriting the representation\nclass SecretSalary(Secret[float]):\n    def _display(self) -&gt; str:\n        return '$****.**'\n\n\nclass Employee(BaseModel):\n    date_of_birth: SecretDate\n    salary: SecretSalary\n\n\nemployee = Employee(date_of_birth='1990-01-01', salary=42)\n\nprint(employee)\n#&gt; date_of_birth=Secret('**********') salary=SecretSalary('$****.**')\n\nprint(employee.salary)\n#&gt; $****.**\n\nprint(employee.salary.get_secret_value())\n#&gt; 42.0\n\nprint(employee.date_of_birth)\n#&gt; **********\n\nprint(employee.date_of_birth.get_secret_value())\n#&gt; 1990-01-01\n</code></pre> <p>You can enforce constraints on the underlying type through annotations: For example:</p> <pre><code>from typing_extensions import Annotated\n\nfrom pydantic import BaseModel, Field, Secret, ValidationError\n\nSecretPosInt = Secret[Annotated[int, Field(gt=0, strict=True)]]\n\n\nclass Model(BaseModel):\n    sensitive_int: SecretPosInt\n\n\nm = Model(sensitive_int=42)\nprint(m.model_dump())\n#&gt; {'sensitive_int': Secret('**********')}\n\ntry:\n    m = Model(sensitive_int=-42)  # (1)!\nexcept ValidationError as exc_info:\n    print(exc_info.errors(include_url=False, include_input=False))\n    \"\"\"\n    [\n        {\n            'type': 'greater_than',\n            'loc': ('sensitive_int',),\n            'msg': 'Input should be greater than 0',\n            'ctx': {'gt': 0},\n        }\n    ]\n    \"\"\"\n\ntry:\n    m = Model(sensitive_int='42')  # (2)!\nexcept ValidationError as exc_info:\n    print(exc_info.errors(include_url=False, include_input=False))\n    \"\"\"\n    [\n        {\n            'type': 'int_type',\n            'loc': ('sensitive_int',),\n            'msg': 'Input should be a valid integer',\n        }\n    ]\n    \"\"\"\n</code></pre> <ol> <li>The input value is not greater than 0, so it raises a validation error.</li> <li>The input value is not an integer, so it raises a validation error because the <code>SecretPosInt</code> type has strict mode enabled.</li> </ol>"},{"location":"examples/validators/","title":"Validators","text":"<p>\ud83d\udea7 Work in Progress</p> <p>This page is a work in progress.</p> <p>This page provides example snippets for creating more complex, custom validators in Pydantic.</p>"},{"location":"examples/validators/#using-custom-validators-with-annotated-metadata","title":"Using Custom Validators with <code>Annotated</code> Metadata","text":"<p>In this example, we'll construct a custom validator, attached to an <code>Annotated</code> type, that ensures a <code>datetime</code> object adheres to a given timezone constraint.</p> <p>The custom validator supports string specification of the timezone, and will raise an error if the <code>datetime</code> object does not have the correct timezone.</p> <p>We use <code>__get_pydantic_core_schema__</code> in the validator to customize the schema of the annotated type (in this case, <code>datetime</code>), which allows us to add custom validation logic. Notably, we use a <code>wrap</code> validator function so that we can perform operations both before and after the default <code>pydantic</code> validation of a <code>datetime</code>.</p> Python 3.8 and abovePython 3.9 and abovePython 3.10 and above <pre><code>import datetime as dt\nfrom dataclasses import dataclass\nfrom pprint import pprint\nfrom typing import Any, Callable, Optional\n\nimport pytz\nfrom pydantic_core import CoreSchema, core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import (\n    GetCoreSchemaHandler,\n    PydanticUserError,\n    TypeAdapter,\n    ValidationError,\n)\n\n\n@dataclass(frozen=True)\nclass MyDatetimeValidator:\n    tz_constraint: Optional[str] = None\n\n    def tz_constraint_validator(\n        self,\n        value: dt.datetime,\n        handler: Callable,  # (1)!\n    ):\n        \"\"\"Validate tz_constraint and tz_info.\"\"\"\n        # handle naive datetimes\n        if self.tz_constraint is None:\n            assert (\n                value.tzinfo is None\n            ), 'tz_constraint is None, but provided value is tz-aware.'\n            return handler(value)\n\n        # validate tz_constraint and tz-aware tzinfo\n        if self.tz_constraint not in pytz.all_timezones:\n            raise PydanticUserError(\n                f'Invalid tz_constraint: {self.tz_constraint}',\n                code='unevaluable-type-annotation',\n            )\n        result = handler(value)  # (2)!\n        assert self.tz_constraint == str(\n            result.tzinfo\n        ), f'Invalid tzinfo: {str(result.tzinfo)}, expected: {self.tz_constraint}'\n\n        return result\n\n    def __get_pydantic_core_schema__(\n        self,\n        source_type: Any,\n        handler: GetCoreSchemaHandler,\n    ) -&gt; CoreSchema:\n        return core_schema.no_info_wrap_validator_function(\n            self.tz_constraint_validator,\n            handler(source_type),\n        )\n\n\nLA = 'America/Los_Angeles'\nta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(LA)])\nprint(\n    ta.validate_python(dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LA)))\n)\n#&gt; 2023-01-01 00:00:00-07:53\n\nLONDON = 'Europe/London'\ntry:\n    ta.validate_python(\n        dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LONDON))\n    )\nexcept ValidationError as ve:\n    pprint(ve.errors(), width=100)\n    \"\"\"\n    [{'ctx': {'error': AssertionError('Invalid tzinfo: Europe/London, expected: America/Los_Angeles')},\n    'input': datetime.datetime(2023, 1, 1, 0, 0, tzinfo=&lt;DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD&gt;),\n    'loc': (),\n    'msg': 'Assertion failed, Invalid tzinfo: Europe/London, expected: America/Los_Angeles',\n    'type': 'assertion_error',\n    'url': 'https://errors.pydantic.dev/2.8/v/assertion_error'}]\n    \"\"\"\n</code></pre> <ol> <li>The <code>handler</code> function is what we call to validate the input with standard <code>pydantic</code> validation</li> <li>We call the <code>handler</code> function to validate the input with standard <code>pydantic</code> validation in this wrap validator</li> </ol> <pre><code>import datetime as dt\nfrom dataclasses import dataclass\nfrom pprint import pprint\nfrom typing import Any, Callable, Optional\n\nimport pytz\nfrom pydantic_core import CoreSchema, core_schema\nfrom typing import Annotated\n\nfrom pydantic import (\n    GetCoreSchemaHandler,\n    PydanticUserError,\n    TypeAdapter,\n    ValidationError,\n)\n\n\n@dataclass(frozen=True)\nclass MyDatetimeValidator:\n    tz_constraint: Optional[str] = None\n\n    def tz_constraint_validator(\n        self,\n        value: dt.datetime,\n        handler: Callable,  # (1)!\n    ):\n        \"\"\"Validate tz_constraint and tz_info.\"\"\"\n        # handle naive datetimes\n        if self.tz_constraint is None:\n            assert (\n                value.tzinfo is None\n            ), 'tz_constraint is None, but provided value is tz-aware.'\n            return handler(value)\n\n        # validate tz_constraint and tz-aware tzinfo\n        if self.tz_constraint not in pytz.all_timezones:\n            raise PydanticUserError(\n                f'Invalid tz_constraint: {self.tz_constraint}',\n                code='unevaluable-type-annotation',\n            )\n        result = handler(value)  # (2)!\n        assert self.tz_constraint == str(\n            result.tzinfo\n        ), f'Invalid tzinfo: {str(result.tzinfo)}, expected: {self.tz_constraint}'\n\n        return result\n\n    def __get_pydantic_core_schema__(\n        self,\n        source_type: Any,\n        handler: GetCoreSchemaHandler,\n    ) -&gt; CoreSchema:\n        return core_schema.no_info_wrap_validator_function(\n            self.tz_constraint_validator,\n            handler(source_type),\n        )\n\n\nLA = 'America/Los_Angeles'\nta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(LA)])\nprint(\n    ta.validate_python(dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LA)))\n)\n#&gt; 2023-01-01 00:00:00-07:53\n\nLONDON = 'Europe/London'\ntry:\n    ta.validate_python(\n        dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LONDON))\n    )\nexcept ValidationError as ve:\n    pprint(ve.errors(), width=100)\n    \"\"\"\n    [{'ctx': {'error': AssertionError('Invalid tzinfo: Europe/London, expected: America/Los_Angeles')},\n    'input': datetime.datetime(2023, 1, 1, 0, 0, tzinfo=&lt;DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD&gt;),\n    'loc': (),\n    'msg': 'Assertion failed, Invalid tzinfo: Europe/London, expected: America/Los_Angeles',\n    'type': 'assertion_error',\n    'url': 'https://errors.pydantic.dev/2.8/v/assertion_error'}]\n    \"\"\"\n</code></pre> <ol> <li>The <code>handler</code> function is what we call to validate the input with standard <code>pydantic</code> validation</li> <li>We call the <code>handler</code> function to validate the input with standard <code>pydantic</code> validation in this wrap validator</li> </ol> <pre><code>import datetime as dt\nfrom dataclasses import dataclass\nfrom pprint import pprint\nfrom typing import Any\nfrom collections.abc import Callable\n\nimport pytz\nfrom pydantic_core import CoreSchema, core_schema\nfrom typing import Annotated\n\nfrom pydantic import (\n    GetCoreSchemaHandler,\n    PydanticUserError,\n    TypeAdapter,\n    ValidationError,\n)\n\n\n@dataclass(frozen=True)\nclass MyDatetimeValidator:\n    tz_constraint: str | None = None\n\n    def tz_constraint_validator(\n        self,\n        value: dt.datetime,\n        handler: Callable,  # (1)!\n    ):\n        \"\"\"Validate tz_constraint and tz_info.\"\"\"\n        # handle naive datetimes\n        if self.tz_constraint is None:\n            assert (\n                value.tzinfo is None\n            ), 'tz_constraint is None, but provided value is tz-aware.'\n            return handler(value)\n\n        # validate tz_constraint and tz-aware tzinfo\n        if self.tz_constraint not in pytz.all_timezones:\n            raise PydanticUserError(\n                f'Invalid tz_constraint: {self.tz_constraint}',\n                code='unevaluable-type-annotation',\n            )\n        result = handler(value)  # (2)!\n        assert self.tz_constraint == str(\n            result.tzinfo\n        ), f'Invalid tzinfo: {str(result.tzinfo)}, expected: {self.tz_constraint}'\n\n        return result\n\n    def __get_pydantic_core_schema__(\n        self,\n        source_type: Any,\n        handler: GetCoreSchemaHandler,\n    ) -&gt; CoreSchema:\n        return core_schema.no_info_wrap_validator_function(\n            self.tz_constraint_validator,\n            handler(source_type),\n        )\n\n\nLA = 'America/Los_Angeles'\nta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(LA)])\nprint(\n    ta.validate_python(dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LA)))\n)\n#&gt; 2023-01-01 00:00:00-07:53\n\nLONDON = 'Europe/London'\ntry:\n    ta.validate_python(\n        dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LONDON))\n    )\nexcept ValidationError as ve:\n    pprint(ve.errors(), width=100)\n    \"\"\"\n    [{'ctx': {'error': AssertionError('Invalid tzinfo: Europe/London, expected: America/Los_Angeles')},\n    'input': datetime.datetime(2023, 1, 1, 0, 0, tzinfo=&lt;DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD&gt;),\n    'loc': (),\n    'msg': 'Assertion failed, Invalid tzinfo: Europe/London, expected: America/Los_Angeles',\n    'type': 'assertion_error',\n    'url': 'https://errors.pydantic.dev/2.8/v/assertion_error'}]\n    \"\"\"\n</code></pre> <ol> <li>The <code>handler</code> function is what we call to validate the input with standard <code>pydantic</code> validation</li> <li>We call the <code>handler</code> function to validate the input with standard <code>pydantic</code> validation in this wrap validator</li> </ol> <p>We can also enforce UTC offset constraints in a similar way.  Assuming we have a <code>lower_bound</code> and an <code>upper_bound</code>, we can create a custom validator to ensure our <code>datetime</code> has a UTC offset that is inclusive within the boundary we define:</p> <pre><code>import datetime as dt\nfrom dataclasses import dataclass\nfrom pprint import pprint\nfrom typing import Any, Callable\n\nimport pytz\nfrom pydantic_core import CoreSchema, core_schema\nfrom typing_extensions import Annotated\n\nfrom pydantic import GetCoreSchemaHandler, TypeAdapter, ValidationError\n\n\n@dataclass(frozen=True)\nclass MyDatetimeValidator:\n    lower_bound: int\n    upper_bound: int\n\n    def validate_tz_bounds(self, value: dt.datetime, handler: Callable):\n        \"\"\"Validate and test bounds\"\"\"\n        assert value.utcoffset() is not None, 'UTC offset must exist'\n        assert self.lower_bound &lt;= self.upper_bound, 'Invalid bounds'\n\n        result = handler(value)\n\n        hours_offset = value.utcoffset().total_seconds() / 3600\n        assert (\n            self.lower_bound &lt;= hours_offset &lt;= self.upper_bound\n        ), 'Value out of bounds'\n\n        return result\n\n    def __get_pydantic_core_schema__(\n        self,\n        source_type: Any,\n        handler: GetCoreSchemaHandler,\n    ) -&gt; CoreSchema:\n        return core_schema.no_info_wrap_validator_function(\n            self.validate_tz_bounds,\n            handler(source_type),\n        )\n\n\nLA = 'America/Los_Angeles'  # UTC-7 or UTC-8\nta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(-10, -5)])\nprint(\n    ta.validate_python(dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LA)))\n)\n#&gt; 2023-01-01 00:00:00-07:53\n\nLONDON = 'Europe/London'\ntry:\n    print(\n        ta.validate_python(\n            dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LONDON))\n        )\n    )\nexcept ValidationError as e:\n    pprint(e.errors(), width=100)\n    \"\"\"\n    [{'ctx': {'error': AssertionError('Value out of bounds')},\n    'input': datetime.datetime(2023, 1, 1, 0, 0, tzinfo=&lt;DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD&gt;),\n    'loc': (),\n    'msg': 'Assertion failed, Value out of bounds',\n    'type': 'assertion_error',\n    'url': 'https://errors.pydantic.dev/2.8/v/assertion_error'}]\n    \"\"\"\n</code></pre>"},{"location":"examples/validators/#validating-nested-model-fields","title":"Validating Nested Model Fields","text":"<p>Here, we demonstrate two ways to validate a field of a nested model, where the validator utilizes data from the parent model.</p> <p>In this example, we construct a validator that checks that each user's password is not in a list of forbidden passwords specified by the parent model.</p> <p>One way to do this is to place a custom validator on the outer model:</p> <pre><code>from typing import List\n\nfrom typing_extensions import Self\n\nfrom pydantic import BaseModel, ValidationError, model_validator\n\n\nclass User(BaseModel):\n    username: str\n    password: str\n\n\nclass Organization(BaseModel):\n    forbidden_passwords: List[str]\n    users: List[User]\n\n    @model_validator(mode='after')\n    def validate_user_passwords(self) -&gt; Self:\n        \"\"\"Check that user password is not in forbidden list. Raise a validation error if a forbidden password is encountered.\"\"\"\n        for user in self.users:\n            current_pw = user.password\n            if current_pw in self.forbidden_passwords:\n                raise ValueError(\n                    f'Password {current_pw} is forbidden. Please choose another password for user {user.username}.'\n                )\n        return self\n\n\ndata = {\n    'forbidden_passwords': ['123'],\n    'users': [\n        {'username': 'Spartacat', 'password': '123'},\n        {'username': 'Iceburgh', 'password': '87'},\n    ],\n}\ntry:\n    org = Organization(**data)\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Organization\n      Value error, Password 123 is forbidden. Please choose another password for user Spartacat. [type=value_error, input_value={'forbidden_passwords': [...gh', 'password': '87'}]}, input_type=dict]\n    \"\"\"\n</code></pre> <p>Alternatively, a custom validator can be used in the nested model class (<code>User</code>), with the forbidden passwords data from the parent model being passed in via validation context.</p> <p>Warning</p> <p>The ability to mutate the context within a validator adds a lot of power to nested validation, but can also lead to confusing or hard-to-debug code. Use this approach at your own risk!</p> <pre><code>from typing import List\n\nfrom pydantic import BaseModel, ValidationError, ValidationInfo, field_validator\n\n\nclass User(BaseModel):\n    username: str\n    password: str\n\n    @field_validator('password', mode='after')\n    @classmethod\n    def validate_user_passwords(\n        cls, password: str, info: ValidationInfo\n    ) -&gt; str:\n        \"\"\"Check that user password is not in forbidden list.\"\"\"\n        forbidden_passwords = (\n            info.context.get('forbidden_passwords', []) if info.context else []\n        )\n        if password in forbidden_passwords:\n            raise ValueError(f'Password {password} is forbidden.')\n        return password\n\n\nclass Organization(BaseModel):\n    forbidden_passwords: List[str]\n    users: List[User]\n\n    @field_validator('forbidden_passwords', mode='after')\n    @classmethod\n    def add_context(cls, v: List[str], info: ValidationInfo) -&gt; List[str]:\n        if info.context is not None:\n            info.context.update({'forbidden_passwords': v})\n        return v\n\n\ndata = {\n    'forbidden_passwords': ['123'],\n    'users': [\n        {'username': 'Spartacat', 'password': '123'},\n        {'username': 'Iceburgh', 'password': '87'},\n    ],\n}\n\ntry:\n    org = Organization.model_validate(data, context={})\nexcept ValidationError as e:\n    print(e)\n    \"\"\"\n    1 validation error for Organization\n    users.0.password\n      Value error, Password 123 is forbidden. [type=value_error, input_value='123', input_type=str]\n    \"\"\"\n</code></pre> <p>Note that if the context property is not included in <code>model_validate</code>, then <code>info.context</code> will be <code>None</code> and the forbidden passwords list will not get added to the context in the above implementation. As such, <code>validate_user_passwords</code> would not carry out the desired password validation.</p> <p>More details about validation context can be found here.</p>"},{"location":"integrations/aws_lambda/","title":"AWS Lambda","text":"<p><code>pydantic</code> integrates well with AWS Lambda functions. In this guide, we'll discuss how to setup <code>pydantic</code> for an AWS Lambda function.</p>"},{"location":"integrations/aws_lambda/#installing-python-libraries-for-aws-lambda-functions","title":"Installing Python libraries for AWS Lambda functions","text":"<p>There are many ways to utilize Python libraries in AWS Lambda functions. As outlined in the AWS Lambda documentation, the most common approaches include:</p> <ul> <li>Using a <code>.zip</code> file archive to package your code and dependencies</li> <li>Using AWS Lambda Layers to share libraries across multiple functions</li> <li>Using a container image to package your code and dependencies</li> </ul> <p>All of these approaches can be used with <code>pydantic</code>. The best approach for you will depend on your specific requirements and constraints. We'll cover the first two cases more in-depth here, as dependency management with a container image is more straightforward. If you're using a container image, you might find this comment helpful for installing <code>pydantic</code>.</p> <p>Tip</p> <p>If you use <code>pydantic</code> across multiple functions, you may want to consider AWS Lambda Layers, which support seamless sharing of libraries across multiple functions.</p> <p>Regardless of the dependencies management approach you choose, it's beneficial to adhere to these guidelines to ensure a smooth dependency management process.</p>"},{"location":"integrations/aws_lambda/#installing-pydantic-for-aws-lambda-functions","title":"Installing <code>pydantic</code> for AWS Lambda functions","text":"<p>When you're building your <code>.zip</code> file archive with your code and dependencies or organizing your <code>.zip</code> file for a Lambda Layer, you'll likely use a local virtual environment to install and manage your dependencies. This can be a bit tricky if you're using <code>pip</code> because <code>pip</code> installs wheels compiled for your local platform, which may not be compatible with the Lambda environment.</p> <p>Thus, we suggest you use a command similar to the following:</p> <pre><code>pip install \\\n    --platform manylinux2014_x86_64 \\  # (1)!\n    --target=&lt;your_package_dir&gt; \\  # (2)!\n    --implementation cp \\  # (3)!\n    --python-version 3.10 \\  # (4)!\n    --only-binary=:all: \\  # (5)!\n    --upgrade pydantic  # (6)!\n</code></pre> <ol> <li>Use the platform corresponding to your Lambda runtime.</li> <li>Specify the directory where you want to install the package (often <code>python</code> for Lambda Layers).</li> <li>Use the CPython implementation.</li> <li>The Python version must be compatible with the Lambda runtime.</li> <li>This flag ensures that the package is installed pre-built binary wheels.</li> <li>The latest version of <code>pydantic</code> will be installed.</li> </ol>"},{"location":"integrations/aws_lambda/#troubleshooting","title":"Troubleshooting","text":""},{"location":"integrations/aws_lambda/#no-module-named-pydantic_core_pydantic_core","title":"<code>no module named 'pydantic_core._pydantic_core'</code>","text":"<p>The <pre><code>no module named `pydantic_core._pydantic_core`\n</code></pre></p> <p>error is a common issue that indicates you have installed <code>pydantic</code> incorrectly. To debug this issue, you can try the following steps (before the failing import):</p> <ol> <li>Check the contents of the installed <code>pydantic-core</code> package. Are the compiled library and its type stubs both present?</li> </ol> <pre><code>from importlib.metadata import files\nprint([file for file in files('pydantic-core') if file.name.startswith('_pydantic_core')])\n\"\"\"\n[PackagePath('pydantic_core/_pydantic_core.pyi'), PackagePath('pydantic_core/_pydantic_core.cpython-312-x86_64-linux-gnu.so')]\n\"\"\"\n</code></pre> <p>You should expect to see two files like those printed above. The compile library file will be a .so or .pyd with a name that varies according to the OS and Python version.</p> <ol> <li>Check that your lambda's Python version is compatible with the compiled library version found above.</li> </ol> <pre><code>import sysconfig\nprint(sysconfig.get_config_var(\"EXT_SUFFIX\"))\n#&gt; '.cpython-312-x86_64-linux-gnu.so'\n</code></pre> <p>You should expect to see the same suffix here as the compiled library, for example here we see this suffix <code>.cpython-312-x86_64-linux-gnu.so</code> indeed matches <code>_pydantic_core.cpython-312-x86_64-linux-gnu.so</code>.</p> <p>If these two checks do not match, your build steps have not installed the correct native code for your lambda's target platform. You should adjust your build steps to change the version of the installed library which gets installed.</p> <p>Most likely errors:</p> <ul> <li> <p>Your OS or CPU architecture is mismatched (e.g. darwin vs x86_64-linux-gnu). Try passing correct <code>--platform</code> argument to <code>pip install</code> when installing your lambda dependencies, or build inside a linux docker container for the correct platform. Possible platforms at the moment include <code>--platform manylinux2014_x86_64</code> or <code>--platform manylinux2014_aarch64</code>, but these may change with a future Pydantic major release.</p> </li> <li> <p>Your Python version is mismatched (e.g. <code>cpython-310</code> vs <code>cpython-312</code>). Try passing correct <code>--python-version</code> argument to <code>pip install</code>, or otherwise change the Python version used on your build.</p> </li> </ul>"},{"location":"integrations/aws_lambda/#no-package-metadata-was-found-for-email-validator","title":"No package metadata was found for <code>email-validator</code>","text":"<p>Pydantic uses <code>version</code> from <code>importlib.metadata</code> to check what version of <code>email-validator</code> is installed. This package versioning mechanism is somewhat incompatible with AWS Lambda, even though it's the industry standard for versioning packages in Python. There are a few ways to fix this issue:</p> <p>If you're deploying your lambda with the serverless framework, it's likely that the appropriate metadata for the <code>email-validator</code> package is not being included in your deployment package. Tools like <code>serverless-python-requirements</code> remove metadata to reduce package size. You can fix this issue by setting the <code>slim</code> setting to false in your <code>serverless.yml</code> file:</p> <pre><code>pythonRequirements:\n    dockerizePip: non-linux\n    slim: false\n    fileName: requirements.txt\n</code></pre> <p>You can read more about this fix, and other <code>slim</code> settings that might be relevant here.</p> <p>If you're using a <code>.zip</code> archive for your code and/or dependencies, make sure that your package contains the required version metadata. To do this, make sure you include the <code>dist-info</code> directory in your <code>.zip</code> archive for the <code>email-validator</code> package.</p> <p>This issue has been reported for other popular python libraries like <code>jsonschema</code>, so you can read more about the issue and potential fixes there as well.</p>"},{"location":"integrations/aws_lambda/#extra-resources","title":"Extra Resources","text":""},{"location":"integrations/aws_lambda/#more-debugging-tips","title":"More Debugging Tips","text":"<p>If you're still struggling with installing <code>pydantic</code> for your AWS Lambda, you might consult with this issue, which covers a variety of problems and solutions encountered by other developers.</p>"},{"location":"integrations/aws_lambda/#validating-event-and-context-data","title":"Validating <code>event</code> and <code>context</code> data","text":"<p>Check out our blog post to learn more about how to use <code>pydantic</code> to validate <code>event</code> and <code>context</code> data in AWS Lambda functions.</p>"},{"location":"integrations/datamodel_code_generator/","title":"Code Generation with datamodel-code-generator","text":"<p>The datamodel-code-generator project is a library and command-line utility to generate pydantic models from just about any data source, including:</p> <ul> <li>OpenAPI 3 (YAML/JSON)</li> <li>JSON Schema</li> <li>JSON/YAML/CSV Data (which will be converted to JSON Schema)</li> <li>Python dictionary (which will be converted to JSON Schema)</li> <li>GraphQL schema</li> </ul> <p>Whenever you find yourself with any data convertible JSON but without pydantic models, this tool will allow you to generate type-safe model hierarchies on demand.</p>"},{"location":"integrations/datamodel_code_generator/#installation","title":"Installation","text":"<pre><code>pip install datamodel-code-generator\n</code></pre>"},{"location":"integrations/datamodel_code_generator/#example","title":"Example","text":"<p>In this case, datamodel-code-generator creates pydantic models from a JSON Schema file. <pre><code>datamodel-codegen  --input person.json --input-file-type jsonschema --output model.py\n</code></pre></p> <p>person.json: <pre><code>{\n  \"$id\": \"person.json\",\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"title\": \"Person\",\n  \"type\": \"object\",\n  \"properties\": {\n    \"first_name\": {\n      \"type\": \"string\",\n      \"description\": \"The person's first name.\"\n    },\n    \"last_name\": {\n      \"type\": \"string\",\n      \"description\": \"The person's last name.\"\n    },\n    \"age\": {\n      \"description\": \"Age in years.\",\n      \"type\": \"integer\",\n      \"minimum\": 0\n    },\n    \"pets\": {\n      \"type\": \"array\",\n      \"items\": [\n        {\n          \"$ref\": \"#/definitions/Pet\"\n        }\n      ]\n    },\n    \"comment\": {\n      \"type\": \"null\"\n    }\n  },\n  \"required\": [\n      \"first_name\",\n      \"last_name\"\n  ],\n  \"definitions\": {\n    \"Pet\": {\n      \"properties\": {\n        \"name\": {\n          \"type\": \"string\"\n        },\n        \"age\": {\n          \"type\": \"integer\"\n        }\n      }\n    }\n  }\n}\n</code></pre></p> <p>model.py: <pre><code># generated by datamodel-codegen:\n#   filename:  person.json\n#   timestamp: 2020-05-19T15:07:31+00:00\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom pydantic import BaseModel, Field, conint\n\n\nclass Pet(BaseModel):\n    name: str | None = None\n    age: int | None = None\n\n\nclass Person(BaseModel):\n    first_name: str = Field(..., description=\"The person's first name.\")\n    last_name: str = Field(..., description=\"The person's last name.\")\n    age: conint(ge=0) | None = Field(None, description='Age in years.')\n    pets: list[Pet] | None = None\n    comment: Any | None = None\n</code></pre></p> <p>More information can be found on the official documentation</p>"},{"location":"integrations/devtools/","title":"devtools","text":"<p>Note</p> <p>Admission: I (the primary developer of Pydantic) also develop python-devtools.</p> <p>python-devtools (<code>pip install devtools</code>) provides a number of tools which are useful during Python development, including <code>debug()</code> an alternative to <code>print()</code> which formats output in a way which should be easier to read than <code>print</code> as well as giving information about which file/line the print statement is on and what value was printed.</p> <p>Pydantic integrates with devtools by implementing the <code>__pretty__</code> method on most public classes.</p> <p>In particular <code>debug()</code> is useful when inspecting models:</p> <pre><code>from datetime import datetime\nfrom typing import List\n\nfrom devtools import debug\n\nfrom pydantic import BaseModel\n\n\nclass Address(BaseModel):\n    street: str\n    country: str\n    lat: float\n    lng: float\n\n\nclass User(BaseModel):\n    id: int\n    name: str\n    signup_ts: datetime\n    friends: List[int]\n    address: Address\n\n\nuser = User(\n    id='123',\n    name='John Doe',\n    signup_ts='2019-06-01 12:22',\n    friends=[1234, 4567, 7890],\n    address=dict(street='Testing', country='uk', lat=51.5, lng=0),\n)\ndebug(user)\nprint('\\nshould be much easier read than:\\n')\nprint('user:', user)\n</code></pre> <p>Will output in your terminal:</p> <pre><code>\ndevtools_example.py:31 &lt;module&gt;\n    user: User(\n        id=123,\n        name='John Doe',\n        signup_ts=datetime.datetime(2019, 6, 1, 12, 22),\n        friends=[\n            1234,\n            4567,\n            7890,\n        ],\n        address=Address(\n            street='Testing',\n            country='uk',\n            lat=51.5,\n            lng=0.0,\n        ),\n    ) (User)\n\nshould be much easier read than:\n\nuser: id=123 name='John Doe' signup_ts=datetime.datetime(2019, 6, 1, 12, 22) friends=[1234, 4567, 7890] address=Address(street='Testing', country='uk', lat=51.5, lng=0.0)</code></pre> <p>Note</p> <p><code>python-devtools</code> doesn't yet support Python 3.13.</p>"},{"location":"integrations/hypothesis/","title":"Hypothesis","text":"<p>Hypothesis is the Python library for property-based testing. Hypothesis can infer how to construct type-annotated classes, and supports builtin types, many standard library types, and generic types from the <code>typing</code> and <code>typing_extensions</code> modules by default.</p> <p>Pydantic v2.0 drops built-in support for Hypothesis and no more ships with the integrated Hypothesis plugin.</p> <p>Warning</p> <p>We are temporarily removing the Hypothesis plugin in favor of studying a different mechanism. For more information, see the issue annotated-types/annotated-types#37.</p> <p>The Hypothesis plugin may be back in a future release. Subscribe to pydantic/pydantic#4682 for updates.</p>"},{"location":"integrations/linting/","title":"Linting","text":""},{"location":"integrations/linting/#flake8-plugin","title":"Flake8 plugin","text":"<p>If using Flake8 in your project, a plugin is available and can be installed using the following:</p> <pre><code>pip install flake8-pydantic\n</code></pre> <p>The lint errors provided by this plugin are namespaced under the <code>PYDXXX</code> code. To ignore some unwanted rules, the Flake8 configuration can be adapted:</p> <pre><code>[flake8]\nextend-ignore = PYD001,PYD002\n</code></pre>"},{"location":"integrations/mypy/","title":"Mypy","text":"<p>Pydantic works well with mypy right out of the box.</p> <p>However, Pydantic also ships with a mypy plugin that adds a number of important pydantic-specific features to mypy that improve its ability to type-check your code.</p> <p>For example, consider the following script:</p> <pre><code>from datetime import datetime\nfrom typing import List, Optional\n\nfrom pydantic import BaseModel\n\n\nclass Model(BaseModel):\n    age: int\n    first_name = 'John'\n    last_name: Optional[str] = None\n    signup_ts: Optional[datetime] = None\n    list_of_ints: List[int]\n\n\nm = Model(age=42, list_of_ints=[1, '2', b'3'])\nprint(m.middle_name)  # not a model field!\nModel()  # will raise a validation error for age and list_of_ints\n</code></pre> <p>Without any special configuration, mypy does not catch the missing model field annotation and warns about the <code>list_of_ints</code> argument which Pydantic parses correctly:</p> <pre><code>test.py:15: error: List item 1 has incompatible type \"str\"; expected \"int\"  [list-item]\ntest.py:15: error: List item 2 has incompatible type \"bytes\"; expected \"int\"  [list-item]\ntest.py:16: error: \"Model\" has no attribute \"middle_name\"  [attr-defined]\ntest.py:17: error: Missing named argument \"age\" for \"Model\"  [call-arg]\ntest.py:17: error: Missing named argument \"list_of_ints\" for \"Model\"  [call-arg]\n</code></pre> <p>But with the plugin enabled, it gives the correct error: <pre><code>9: error: Untyped fields disallowed  [pydantic-field]\n16: error: \"Model\" has no attribute \"middle_name\"  [attr-defined]\n17: error: Missing named argument \"age\" for \"Model\"  [call-arg]\n17: error: Missing named argument \"list_of_ints\" for \"Model\"  [call-arg]\n</code></pre></p> <p>With the pydantic mypy plugin, you can fearlessly refactor your models knowing mypy will catch any mistakes if your field names or types change.</p> <p>There are other benefits too! See below for more details.</p>"},{"location":"integrations/mypy/#using-mypy-without-the-plugin","title":"Using mypy without the plugin","text":"<p>You can run your code through mypy with:</p> <pre><code>mypy \\\n  --ignore-missing-imports \\\n  --follow-imports=skip \\\n  --strict-optional \\\n  pydantic_mypy_test.py\n</code></pre>"},{"location":"integrations/mypy/#strict-optional","title":"Strict Optional","text":"<p>For your code to pass with <code>--strict-optional</code>, you need to use <code>Optional[]</code> or an alias of <code>Optional[]</code> for all fields with <code>None</code> as the default. (This is standard with mypy.)</p>"},{"location":"integrations/mypy/#other-pydantic-interfaces","title":"Other Pydantic interfaces","text":"<p>Pydantic dataclasses and the <code>validate_call</code> decorator should also work well with mypy.</p>"},{"location":"integrations/mypy/#mypy-plugin-capabilities","title":"Mypy Plugin Capabilities","text":""},{"location":"integrations/mypy/#generate-a-signature-for-model__init__","title":"Generate a signature for <code>Model.__init__</code>","text":"<ul> <li>Any required fields that don't have dynamically-determined aliases will be included as required   keyword arguments.</li> <li>If <code>Config.populate_by_name=True</code>, the generated signature will use the field names,   rather than aliases.</li> <li>If <code>Config.extra='forbid'</code> and you don't make use of dynamically-determined aliases, the generated signature   will not allow unexpected inputs.</li> <li>Optional: If the <code>init_forbid_extra</code> plugin setting is set to <code>True</code>, unexpected inputs to   <code>__init__</code> will raise errors even if <code>Config.extra</code> is not <code>'forbid'</code>.</li> <li>Optional: If the <code>init_typed</code> plugin setting is set to <code>True</code>, the generated signature   will use the types of the model fields (otherwise they will be annotated as <code>Any</code> to allow parsing).</li> </ul>"},{"location":"integrations/mypy/#generate-a-typed-signature-for-modelmodel_construct","title":"Generate a typed signature for <code>Model.model_construct</code>","text":"<ul> <li>The <code>model_construct</code> method is an alternative to <code>__init__</code>   when input data is known to be valid and should not be parsed. Because this method performs no runtime validation,   static checking is important to detect errors.</li> </ul>"},{"location":"integrations/mypy/#respect-configfrozen","title":"Respect <code>Config.frozen</code>","text":"<ul> <li>If <code>Config.frozen</code> is <code>True</code>, you'll get a mypy error if you try to change   the value of a model field; cf. faux immutability.</li> </ul>"},{"location":"integrations/mypy/#generate-a-signature-for-dataclasses","title":"Generate a signature for <code>dataclasses</code>","text":"<ul> <li>classes decorated with <code>@pydantic.dataclasses.dataclass</code> are type checked the same as standard Python dataclasses</li> <li>The <code>@pydantic.dataclasses.dataclass</code> decorator accepts a <code>config</code> keyword argument which has the same meaning as the <code>Config</code> sub-class.</li> </ul>"},{"location":"integrations/mypy/#respect-the-type-of-the-fields-default-and-default_factory","title":"Respect the type of the <code>Field</code>'s <code>default</code> and <code>default_factory</code>","text":"<ul> <li>Field with both a <code>default</code> and a <code>default_factory</code> will result in an error during static checking.</li> <li>The type of the <code>default</code> and <code>default_factory</code> value must be compatible with the one of the field.</li> </ul>"},{"location":"integrations/mypy/#warn-about-the-use-of-untyped-fields","title":"Warn about the use of untyped fields","text":"<ul> <li>You'll get a mypy error any time you assign a public attribute on a model without annotating its type</li> <li>If your goal is to set a ClassVar, you should explicitly annotate the field using typing.ClassVar</li> </ul>"},{"location":"integrations/mypy/#optional-capabilities","title":"Optional Capabilities:","text":""},{"location":"integrations/mypy/#prevent-the-use-of-required-dynamic-aliases","title":"Prevent the use of required dynamic aliases","text":"<ul> <li>If the <code>warn_required_dynamic_aliases</code> plugin setting is set to <code>True</code>, you'll get a mypy   error any time you use a dynamically-determined alias or alias generator on a model with   <code>Config.populate_by_name=False</code>.</li> <li>This is important because if such aliases are present, mypy cannot properly type check calls to <code>__init__</code>.   In this case, it will default to treating all arguments as optional.</li> </ul>"},{"location":"integrations/mypy/#enabling-the-plugin","title":"Enabling the Plugin","text":"<p>To enable the plugin, just add <code>pydantic.mypy</code> to the list of plugins in your mypy config file (this could be <code>mypy.ini</code>, <code>pyproject.toml</code>, or <code>setup.cfg</code>).</p> <p>To get started, all you need to do is create a <code>mypy.ini</code> file with following contents: <pre><code>[mypy]\nplugins = pydantic.mypy\n</code></pre></p> <p>Note</p> <p>If you're using <code>pydantic.v1</code> models, you'll need to add <code>pydantic.v1.mypy</code> to your list of plugins.</p> <p>The plugin is compatible with mypy versions <code>&gt;=0.930</code>.</p> <p>See the plugin configuration docs for more details.</p>"},{"location":"integrations/mypy/#configuring-the-plugin","title":"Configuring the Plugin","text":"<p>To change the values of the plugin settings, create a section in your mypy config file called <code>[pydantic-mypy]</code>, and add any key-value pairs for settings you want to override.</p> <p>A <code>mypy.ini</code> file with all plugin strictness flags enabled (and some other mypy strictness flags, too) might look like:</p> <pre><code>[mypy]\nplugins = pydantic.mypy\n\nfollow_imports = silent\nwarn_redundant_casts = True\nwarn_unused_ignores = True\ndisallow_any_generics = True\ncheck_untyped_defs = True\nno_implicit_reexport = True\n\n# for strict mypy: (this is the tricky one :-))\ndisallow_untyped_defs = True\n\n[pydantic-mypy]\ninit_forbid_extra = True\ninit_typed = True\nwarn_required_dynamic_aliases = True\n</code></pre> <p>As of <code>mypy&gt;=0.900</code>, mypy config may also be included in the <code>pyproject.toml</code> file rather than <code>mypy.ini</code>. The same configuration as above would be:</p> <pre><code>[tool.mypy]\nplugins = [\n  \"pydantic.mypy\"\n]\n\nfollow_imports = \"silent\"\nwarn_redundant_casts = true\nwarn_unused_ignores = true\ndisallow_any_generics = true\ncheck_untyped_defs = true\nno_implicit_reexport = true\n\n# for strict mypy: (this is the tricky one :-))\ndisallow_untyped_defs = true\n\n[tool.pydantic-mypy]\ninit_forbid_extra = true\ninit_typed = true\nwarn_required_dynamic_aliases = true\n</code></pre>"},{"location":"integrations/mypy/#note-on-disallow-any-explicit","title":"Note on <code>--disallow-any-explicit</code>","text":"<p>If you're using the <code>--disallow-any-explicit</code> mypy config setting (or other settings that ban <code>Any</code>), you may encounter <code>no-any-explicit</code> errors when extending <code>BaseModel</code>. This is because by default, Pydantic's <code>mypy</code> plugin adds an <code>__init__</code> method with a signature like <code>def __init__(self, field_1: Any, field_2: Any, **kwargs: Any):</code></p> <p>Why the extra signature?</p> <p>The Pydantic <code>mypy</code> plugin adds an <code>__init__</code> method with a signature like <code>def __init__(self, field_1: Any, field_2: Any, **kwargs: Any):</code> in order to avoid type errors when initializing models with types that don't match the field annotations. For example <code>Model(date='2024-01-01')</code> would raise a type error without this <code>Any</code> signature, but Pydantic has the ability to parse the string <code>'2024-01-01'</code> into a <code>datetime.date</code> type.</p> <p>To resolve this issue, you need to enable strict mode settings for the Pydantic mypy plugin. Specifically, add these options to your <code>[pydantic-mypy]</code> section:</p> <pre><code>[tool.pydantic-mypy]\ninit_forbid_extra = true\ninit_typed = true\n</code></pre> <p>With <code>init_forbid_extra = True</code>, the <code>**kwargs</code> are removed from the generated <code>__init__</code> signature. With <code>init_typed = True</code>, the <code>Any</code> types for fields are replaced with their actual type hints.</p> <p>This configuration allows you to use <code>--disallow-any-explicit</code> without getting errors on your Pydantic models. However, be aware that this stricter checking might flag some valid Pydantic use cases (like passing a string for a datetime field) as type errors.</p>"},{"location":"integrations/pycharm/","title":"PyCharm","text":"<p>While pydantic will work well with any IDE out of the box, a PyCharm plugin offering improved pydantic integration is available on the JetBrains Plugins Repository for PyCharm. You can install the plugin for free from the plugin marketplace (PyCharm's Preferences -&gt; Plugin -&gt; Marketplace -&gt; search \"pydantic\").</p> <p>The plugin currently supports the following features:</p> <ul> <li>For <code>pydantic.BaseModel.__init__</code>:</li> <li>Inspection</li> <li>Autocompletion</li> <li> <p>Type-checking</p> </li> <li> <p>For fields of <code>pydantic.BaseModel</code>:</p> </li> <li>Refactor-renaming fields updates <code>__init__</code> calls, and affects sub- and super-classes</li> <li>Refactor-renaming <code>__init__</code> keyword arguments updates field names, and affects sub- and super-classes</li> </ul> <p>More information can be found on the official plugin page and Github repository.</p>"},{"location":"integrations/rich/","title":"Rich","text":"<p>Pydantic models may be printed with the Rich library which will add additional formatting and color to the output. Here's an example:</p> <p></p> <p>See the Rich documentation on pretty printing for more information.</p>"},{"location":"integrations/visual_studio_code/","title":"Visual Studio Code","text":"<p>Pydantic works well with any editor or IDE out of the box because it's made on top of standard Python type annotations.</p> <p>When using Visual Studio Code (VS Code), there are some additional editor features supported, comparable to the ones provided by the PyCharm plugin.</p> <p>This means that you will have autocompletion (or \"IntelliSense\") and error checks for types and required arguments even while creating new Pydantic model instances.</p> <p></p>"},{"location":"integrations/visual_studio_code/#configure-vs-code","title":"Configure VS Code","text":"<p>To take advantage of these features, you need to make sure you configure VS Code correctly, using the recommended settings.</p> <p>In case you have a different configuration, here's a short overview of the steps.</p>"},{"location":"integrations/visual_studio_code/#install-pylance","title":"Install Pylance","text":"<p>You should use the Pylance extension for VS Code. It is the recommended, next-generation, official VS Code plug-in for Python.</p> <p>Pylance is installed as part of the Python Extension for VS Code by default, so it should probably just work. Otherwise, you can double check it's installed and enabled in your editor.</p>"},{"location":"integrations/visual_studio_code/#configure-your-environment","title":"Configure your environment","text":"<p>Then you need to make sure your editor knows the Python environment (probably a virtual environment) for your Python project.</p> <p>This would be the environment in where you installed Pydantic.</p>"},{"location":"integrations/visual_studio_code/#configure-pylance","title":"Configure Pylance","text":"<p>With the default configurations, you will get support for autocompletion, but Pylance might not check for type errors.</p> <p>You can enable type error checks from Pylance with these steps:</p> <ul> <li>Open the \"User Settings\"</li> <li>Search for <code>Type Checking Mode</code></li> <li>You will find an option under <code>Python \u203a Analysis: Type Checking Mode</code></li> <li>Set it to <code>basic</code> or <code>strict</code> (by default it's <code>off</code>)</li> </ul> <p></p> <p>Now you will not only get autocompletion when creating new Pydantic model instances but also error checks for required arguments.</p> <p></p> <p>And you will also get error checks for invalid data types.</p> <p></p> <p>Technical Details</p> <p>Pylance is the VS Code extension, it's closed source, but free to use. Underneath, Pylance uses an open source tool (also from Microsoft) called Pyright that does all the heavy lifting.</p> <p>You can read more about it in the Pylance Frequently Asked Questions.</p>"},{"location":"integrations/visual_studio_code/#configure-mypy","title":"Configure mypy","text":"<p>You might also want to configure mypy in VS Code to get mypy error checks inline in your editor (alternatively/additionally to Pylance).</p> <p>This would include the errors detected by the Pydantic mypy plugin, if you configured it.</p> <p>To enable mypy in VS Code, do the following:</p> <ul> <li>Open the \"User Settings\"</li> <li>Search for <code>Mypy Enabled</code></li> <li>You will find an option under <code>Python \u203a Linting: Mypy Enabled</code></li> <li>Check the box (by default it's unchecked)</li> </ul> <p></p>"},{"location":"integrations/visual_studio_code/#tips-and-tricks","title":"Tips and tricks","text":"<p>Here are some additional tips and tricks to improve your developer experience when using VS Code with Pydantic.</p>"},{"location":"integrations/visual_studio_code/#strict-errors","title":"Strict errors","text":"<p>The way this additional editor support works is that Pylance will treat your Pydantic models as if they were Python's pure <code>dataclasses</code>.</p> <p>And it will show strict type error checks about the data types passed in arguments when creating a new Pydantic model instance.</p> <p>In this example you can see that it shows that a <code>str</code> of <code>'23'</code> is not a valid <code>int</code> for the argument <code>age</code>.</p> <p></p> <p>It would expect <code>age=23</code> instead of <code>age='23'</code>.</p> <p>Nevertheless, the design, and one of the main features of Pydantic, is that it is very lenient with data types.</p> <p>It will actually accept the <code>str</code> with value <code>'23'</code> and will convert it to an <code>int</code> with value <code>23</code>.</p> <p>These strict error checks are very useful most of the time and can help you detect many bugs early. But there are cases, like with <code>age='23'</code>, where they could be inconvenient by reporting a \"false positive\" error.</p> <p>This example above with <code>age='23'</code> is intentionally simple, to show the error and the differences in types.</p> <p>But more common cases where these strict errors would be inconvenient would be when using more sophisticated data types, like <code>int</code> values for <code>datetime</code> fields, or <code>dict</code> values for Pydantic sub-models.</p> <p>For example, this is valid for Pydantic:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nclass Quest(BaseModel):\n    title: str\n    knight: Knight\n\n\nquest = Quest(\n    title='To seek the Holy Grail', knight={'title': 'Sir Lancelot', 'age': 23}\n)\n</code></pre> <p>The type of the field <code>knight</code> is declared with the class <code>Knight</code> (a Pydantic model) and the code is passing a literal <code>dict</code> instead. This is still valid for Pydantic, and the <code>dict</code> would be automatically converted to a <code>Knight</code> instance.</p> <p>Nevertheless, it would be detected as a type error:</p> <p></p> <p>In those cases, there are several ways to disable or ignore strict errors in very specific places, while still preserving them in the rest of the code.</p> <p>Below are several techniques to achieve it.</p>"},{"location":"integrations/visual_studio_code/#disable-type-checks-in-a-line","title":"Disable type checks in a line","text":"<p>You can disable the errors for a specific line using a comment of:</p> <pre><code># type: ignore\n</code></pre> <p>or (to be specific to pylance/pyright):</p> <pre><code># pyright: ignore\n</code></pre> <p>(pyright is the language server used by Pylance.).</p> <p>coming back to the example with <code>age='23'</code>, it would be:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nlancelot = Knight(title='Sir Lancelot', age='23')  # pyright: ignore\n</code></pre> <p>that way Pylance and mypy will ignore errors in that line.</p> <p>Pros: it's a simple change in that line to remove errors there.</p> <p>Cons: any other error in that line will also be omitted, including type checks, misspelled arguments, required arguments not provided, etc.</p>"},{"location":"integrations/visual_studio_code/#override-the-type-of-a-variable","title":"Override the type of a variable","text":"<p>You can also create a variable with the value you want to use and declare its type explicitly with <code>Any</code>.</p> <pre><code>from typing import Any\n\nfrom pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nage_str: Any = '23'\nlancelot = Knight(title='Sir Lancelot', age=age_str)\n</code></pre> <p>that way Pylance and mypy will interpret the variable <code>age_str</code> as if they didn't know its type, instead of knowing it has a type of <code>str</code> when an <code>int</code> was expected (and then showing the corresponding error).</p> <p>Pros: errors will be ignored only for a specific value, and you will still see any additional errors for the other arguments.</p> <p>Cons: it requires importing <code>Any</code> and a new variable in a new line for each argument that needs ignoring errors.</p>"},{"location":"integrations/visual_studio_code/#override-the-type-of-a-value-with-cast","title":"Override the type of a value with <code>cast</code>","text":"<p>The same idea from the previous example can be put on the same line with the help of <code>cast()</code>.</p> <p>This way, the type declaration of the value is overridden inline, without requiring another variable.</p> <pre><code>from typing import Any, cast\n\nfrom pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nlancelot = Knight(title='Sir Lancelot', age=cast(Any, '23'))\n</code></pre> <p><code>cast(Any, '23')</code> doesn't affect the value, it's still just <code>'23'</code>, but now Pylance and mypy will assume it is of type <code>Any</code>, which means, they will act as if they didn't know the type of the value.</p> <p>So, this is the equivalent of the previous example, without the additional variable.</p> <p>Pros: errors will be ignored only for a specific value, and you will still see any additional errors for the other arguments. There's no need for additional variables.</p> <p>Cons: it requires importing <code>Any</code> and <code>cast</code>, and if you are not used to using <code>cast()</code>, it could seem strange at first.</p>"},{"location":"integrations/visual_studio_code/#config-in-class-arguments","title":"Config in class arguments","text":"<p>Pydantic has a rich set of Model Configurations available.</p> <p>These configurations can be set in an internal <code>class Config</code> on each model:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    model_config = dict(frozen=True)\n    title: str\n    age: int\n    color: str = 'blue'\n</code></pre> <p>or passed as keyword arguments when defining the model class:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel, frozen=True):\n    title: str\n    age: int\n    color: str = 'blue'\n</code></pre> <p>The specific configuration <code>frozen</code> (in beta) has a special meaning.</p> <p>It prevents other code from changing a model instance once it's created, keeping it \"frozen\".</p> <p>When using the second version to declare <code>frozen=True</code> (with keyword arguments in the class definition), Pylance can use it to help you check in your code and detect errors when something is trying to set values in a model that is \"frozen\".</p> <p></p>"},{"location":"integrations/visual_studio_code/#adding-a-default-with-field","title":"Adding a default with <code>Field</code>","text":"<p>Pylance/pyright requires <code>default</code> to be a keyword argument to <code>Field</code> in order to infer that the field is optional.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Knight(BaseModel):\n    title: str = Field(default='Sir Lancelot')  # this is okay\n    age: int = Field(\n        23\n    )  # this works fine at runtime but will case an error for pyright\n\n\nlance = Knight()  # error: Argument missing for parameter \"age\"\n</code></pre> <p>This is a limitation of dataclass transforms and cannot be fixed in pydantic.</p>"},{"location":"integrations/visual_studio_code/#technical-details","title":"Technical Details","text":"<p>Warning</p> <p>As a Pydantic user, you don't need the details below. Feel free to skip the rest of this section.</p> <p>These details are only useful for other library authors, etc.</p> <p>This additional editor support works by implementing the proposed draft standard for Dataclass Transform (PEP 681).</p> <p>The proposed draft standard is written by Eric Traut, from the Microsoft team, the same author of the open source package Pyright (used by Pylance to provide Python support in VS Code).</p> <p>The intention of the standard is to provide a way for libraries like Pydantic and others to tell editors and tools that they (the editors) should treat these libraries (e.g. Pydantic) as if they were <code>dataclasses</code>, providing autocompletion, type checks, etc.</p> <p>The draft standard also includes an Alternate Form for early adopters, like Pydantic, to add support for it right away, even before the new draft standard is finished and approved.</p> <p>This new draft standard, with the Alternate Form, is already supported by Pyright, so it can be used via Pylance in VS Code.</p> <p>As it is being proposed as an official standard for Python, other editors can also easily add support for it.</p> <p>And authors of other libraries similar to Pydantic can also easily adopt the standard right away (using the \"Alternate Form\") and get the benefits of these additional editor features.</p>"}]}