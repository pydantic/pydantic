{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>Data validation and settings management using Python type annotations.</p> <p>pydantic enforces type hints at runtime, and provides user friendly errors when data is invalid.</p> <p>Define how data should be in pure, canonical Python; validate it with pydantic.</p>"},{"location":"#sponsors","title":"Sponsors","text":"<p>Development of pydantic is made possible by the following sponsors:</p> Salesforce FastAPI AWS Explosion TutorCruncher ExoFlare Robusta SendCloud Jina AI <p>And many more who kindly sponsor Samuel Colvin on GitHub Sponsors.</p>"},{"location":"#example","title":"Example","text":"<p>What's going on here:</p> <ul> <li><code>id</code> is of type int; the annotation-only declaration tells pydantic that this field is required. Strings,   bytes or floats will be coerced to ints if possible; otherwise an exception will be raised.</li> <li><code>name</code> is inferred as a string from the provided default; because it has a default, it is not required.</li> <li><code>signup_ts</code> is a datetime field which is not required (and takes the value <code>None</code> if it's not supplied).   pydantic will process either a unix timestamp int (e.g. <code>1496498400</code>) or a string representing the date &amp; time.</li> <li><code>friends</code> uses Python's typing system, and requires a list of integers. As with <code>id</code>, integer-like objects   will be converted to integers.</li> </ul> <p>If validation fails pydantic will raise an error with a breakdown of what was wrong:</p>"},{"location":"#rationale","title":"Rationale","text":"<p>So pydantic uses some cool new language features, but why should I actually go and use it?</p> plays nicely with your IDE/linter/brain There's no new schema definition micro-language to learn. If you know how to use Python type hints,  you know how to use pydantic. Data structures are just instances of classes you define with type annotations,  so auto-completion, linting, mypy, IDEs (especially PyCharm),  and your intuition should all work properly with your validated data. dual use pydantic's BaseSettings class allows pydantic to be used in both a \"validate this request data\" context and in a \"load my system settings\" context. The main differences are that system settings can be read from environment variables, and more complex objects like DSNs and Python objects are often required. fast pydantic has always taken performance seriously, most of the library is compiled with cython giving a ~50% speedup, it's generally as fast or faster than most similar libraries. validate complex structures use of recursive pydantic models, <code>typing</code>'s  standard types (e.g. <code>List</code>, <code>Tuple</code>, <code>Dict</code> etc.) and  validators allow complex data schemas to be clearly and easily defined, validated, and parsed. extensible pydantic allows custom data types to be defined or you can extend validation  with methods on a model decorated with the <code>validator</code> decorator. dataclasses integration As well as <code>BaseModel</code>, pydantic provides a <code>dataclass</code> decorator which creates (almost) vanilla Python dataclasses with input data parsing and validation."},{"location":"#using-pydantic","title":"Using Pydantic","text":"<p>Hundreds of organisations and packages are using pydantic, including:</p> FastAPI a high performance API framework, easy to learn, fast to code and ready for production, based on pydantic and Starlette. Project Jupyter developers of the Jupyter notebook are using pydantic for subprojects, through the FastAPI-based Jupyter server Jupyverse, and for FPS's configuration management. Microsoft are using pydantic (via FastAPI) for  numerous services, some of which are  \"getting integrated into the core Windows product and some Office products.\" Amazon Web Services are using pydantic in gluon-ts, an open-source probabilistic time series modeling library. The NSA are using pydantic in WALKOFF, an open-source automation framework. Uber are using pydantic in Ludwig, an open-source TensorFlow wrapper. Cuenca are a Mexican neobank that uses pydantic for several internal tools (including API validation) and for open source projects like stpmex, which is used to process real-time, 24/7, inter-bank transfers in Mexico. The Molecular Sciences Software Institute are using pydantic in QCFractal, a massively distributed compute framework for quantum chemistry. Reach trusts pydantic (via FastAPI) and arq (Samuel's excellent asynchronous task queue) to reliably power multiple mission-critical microservices. Robusta.dev are using pydantic to automate Kubernetes troubleshooting and maintenance. For example, their open source tools to debug and profile Python applications on Kubernetes use pydantic models. <p>For a more comprehensive list of open-source projects using pydantic see the  list of dependents on github.</p>"},{"location":"#discussion-of-pydantic","title":"Discussion of Pydantic","text":"<p>Podcasts and videos discussing pydantic.</p> Talk Python To Me Michael Kennedy and Samuel Colvin, the creator of pydantic, dive into the history of pydantic and its many uses and benefits. Podcast.__init__ Discussion about where pydantic came from and ideas for where it might go next with  Samuel Colvin the creator of pydantic. Python Bytes Podcast \"This is a sweet simple framework that solves some really nice problems... Data validations and settings management  using Python type annotations, and it's the Python type annotations that makes me really extra happy... It works  automatically with all the IDE's you already have.\" --Michael Kennedy Python pydantic Introduction \u2013 Give your data classes super powers a talk by Alexander Hultn\u00e9r originally for the Python Pizza Conference introducing new users to pydantic and walking  through the core features of pydantic."},{"location":"contributing/","title":"Contributing to pydantic","text":"<p>We'd love you to contribute to pydantic!</p>"},{"location":"contributing/#issues","title":"Issues","text":"<p>Questions, feature requests and bug reports are all welcome as discussions or issues. However, to report a security vulnerability, please see our security policy.</p> <p>To make it as simple as possible for us to help you, please include the output of the following call in your issue:</p> <p><pre><code>python -c \"import pydantic.utils; print(pydantic.utils.version_info())\"\n</code></pre> If you're using pydantic prior to v1.3 (when <code>version_info()</code> was added), please manually include OS, Python version and pydantic version.</p> <p>Please try to always include the above unless you're unable to install pydantic or know it's not relevant to your question or feature request.</p>"},{"location":"contributing/#pull-requests","title":"Pull Requests","text":"<p>It should be extremely simple to get started and create a Pull Request. pydantic is released regularly so you should see your improvements release in a matter of days or weeks.</p> <p>Note</p> <p>Unless your change is trivial (typo, docs tweak etc.), please create an issue to discuss the change before creating a pull request.</p> <p>If you're looking for something to get your teeth into, check out the \"help wanted\" label on github.</p> <p>To make contributing as easy and fast as possible, you'll want to run tests and linting locally. Luckily, pydantic has few dependencies, doesn't require compiling and tests don't need access to databases, etc. Because of this, setting up and running the tests should be very simple.</p> <p>You'll need to have a version between Python 3.7 and 3.11, virtualenv, git, and make installed.</p> <pre><code># 1. clone your fork and cd into the repo directory\ngit clone git@github.com:&lt;your username&gt;/pydantic.git\ncd pydantic\n\n# 2. Set up a virtualenv for running tests\nvirtualenv -p `which python3.8` env\nsource env/bin/activate\n# Building docs requires 3.8. If you don't need to build docs you can use\n# whichever version; 3.7 will work too.\n\n# 3. Install pydantic, dependencies, test dependencies and doc dependencies\nmake install\n\n# 4. Checkout a new branch and make your changes\ngit checkout -b my-new-feature-branch\n# make your changes...\n\n# 5. Fix formatting and imports\nmake format\n# Pydantic uses black to enforce formatting and isort to fix imports\n# (https://github.com/ambv/black, https://github.com/timothycrosley/isort)\n\n# 6. Run tests and linting\nmake\n# there are a few sub-commands in Makefile like `test`, `testcov` and `lint`\n# which you might want to use, but generally just `make` should be all you need\n\n# 7. Build documentation\nmake docs\n# if you have changed the documentation make sure it builds successfully\n# you can also use `make docs-serve` to serve the documentation at localhost:8000\n\n# ... commit, push, and create your pull request\n</code></pre> <p>tl;dr: use <code>make format</code> to fix formatting, <code>make</code> to run tests and linting &amp; <code>make docs</code> to build the docs.</p>"},{"location":"datamodel_code_generator/","title":"Code Generation","text":"<p>The datamodel-code-generator project is a library and command-line utility to generate pydantic models from just about any data source, including:</p> <ul> <li>OpenAPI 3 (YAML/JSON)</li> <li>JSON Schema</li> <li>JSON/YAML Data (which will converted to JSON Schema)</li> </ul> <p>Whenever you find yourself with any data convertible JSON but without pydantic models, this tool will allow you to generate type-safe model hierarchies on demand.</p>"},{"location":"datamodel_code_generator/#installation","title":"Installation","text":"<pre><code>pip install datamodel-code-generator\n</code></pre>"},{"location":"datamodel_code_generator/#example","title":"Example","text":"<p>In this case, datamodel-code-generator creates pydantic models from a JSON Schema file. <pre><code>datamodel-codegen  --input person.json --input-file-type jsonschema --output model.py\n</code></pre></p> <p>person.json: <pre><code>{\n\"$id\": \"person.json\",\n\"$schema\": \"http://json-schema.org/draft-07/schema#\",\n\"title\": \"Person\",\n\"type\": \"object\",\n\"properties\": {\n\"first_name\": {\n\"type\": \"string\",\n\"description\": \"The person's first name.\"\n},\n\"last_name\": {\n\"type\": \"string\",\n\"description\": \"The person's last name.\"\n},\n\"age\": {\n\"description\": \"Age in years.\",\n\"type\": \"integer\",\n\"minimum\": 0\n},\n\"pets\": {\n\"type\": \"array\",\n\"items\": [\n{\n\"$ref\": \"#/definitions/Pet\"\n}\n]\n},\n\"comment\": {\n\"type\": \"null\"\n}\n},\n\"required\": [\n\"first_name\",\n\"last_name\"\n],\n\"definitions\": {\n\"Pet\": {\n\"properties\": {\n\"name\": {\n\"type\": \"string\"\n},\n\"age\": {\n\"type\": \"integer\"\n}\n}\n}\n}\n}\n</code></pre></p> <p>model.py:</p> <p>More information can be found on the official documentation</p>"},{"location":"hypothesis_plugin/","title":"Hypothesis plugin","text":"<p>Hypothesis is the Python library for property-based testing. Hypothesis can infer how to construct type-annotated classes, and supports builtin types, many standard library types, and generic types from the <code>typing</code> and <code>typing_extensions</code> modules by default.</p> <p>From Pydantic v1.8 and Hypothesis v5.29.0, Hypothesis will automatically load support for custom types like <code>PaymentCardNumber</code> and <code>PositiveFloat</code>, so that the <code>st.builds()</code> and <code>st.from_type()</code> strategies support them without any user configuration.</p> <p>Warning</p> <p>Please note, while the plugin supports these types, hypothesis will(currently) generate values outside  of given args for the constrained function types.</p>"},{"location":"hypothesis_plugin/#example-tests","title":"Example tests","text":""},{"location":"hypothesis_plugin/#use-with-json-schemas","title":"Use with JSON Schemas","text":"<p>To test client-side code, you can use <code>Model.schema()</code> with the <code>hypothesis-jsonschema</code> package to generate arbitrary JSON instances matching the schema. For web API testing, Schemathesis provides a higher-level wrapper and can detect both errors and security vulnerabilities.</p>"},{"location":"install/","title":"Install","text":"<p>Installation is as simple as:</p> <pre><code>pip install pydantic\n</code></pre> <p>pydantic has no required dependencies except Python 3.7, 3.8, 3.9, 3.10 or 3.11 and <code>typing-extensions</code>. If you've got Python 3.7+ and <code>pip</code> installed, you're good to go.</p> <p>Pydantic is also available on conda under the conda-forge channel:</p> <pre><code>conda install pydantic -c conda-forge\n</code></pre>"},{"location":"install/#compiled-with-cython","title":"Compiled with Cython","text":"<p>pydantic can optionally be compiled with cython which should give a 30-50% performance improvement. </p> <p>By default <code>pip install</code> provides optimized binaries via PyPI for Linux, MacOS and 64bit Windows.</p> <p>If you're installing manually, install <code>cython</code> before installing pydantic and compilation should happen automatically.</p> <p>To test if pydantic is compiled run:</p> <pre><code>import pydantic\nprint('compiled:', pydantic.compiled)\n</code></pre>"},{"location":"install/#performance-vs-package-size-trade-off","title":"Performance vs package size trade-off","text":"<p>Compiled binaries can increase the size of your Python environment. If for some reason you want to reduce the size of your pydantic installation you can avoid installing any binaries using the <code>pip --no-binary</code> option. Make sure <code>Cython</code> is not in your environment, or that you have the <code>SKIP_CYTHON</code> environment variable set to avoid re-compiling pydantic libraries:</p> <pre><code>SKIP_CYTHON=1 pip install --no-binary pydantic pydantic\n</code></pre> <p>Note</p> <p><code>pydantic</code> is repeated here intentionally, <code>--no-binary pydantic</code> tells <code>pip</code> you want no binaries for pydantic, the next <code>pydantic</code> tells <code>pip</code> which package to install.</p> <p>Alternatively, you can re-compile pydantic with custom build options, this would require having the <code>Cython</code> package installed before re-compiling pydantic with: <pre><code>CFLAGS=\"-Os -g0 -s\" pip install \\\n--no-binary pydantic \\\n--global-option=build_ext \\\npydantic\n</code></pre></p>"},{"location":"install/#optional-dependencies","title":"Optional dependencies","text":"<p>pydantic has two optional dependencies:</p> <ul> <li>If you require email validation you can add email-validator</li> <li>dotenv file support with <code>Settings</code> requires   python-dotenv</li> </ul> <p>To install these along with pydantic: <pre><code>pip install pydantic[email]\n# or\npip install pydantic[dotenv]\n# or just\npip install pydantic[email,dotenv]\n</code></pre></p> <p>Of course, you can also install these requirements manually with <code>pip install email-validator</code> and/or <code>pip install python-dotenv</code>.</p>"},{"location":"install/#install-from-repository","title":"Install from repository","text":"<p>And if you prefer to install pydantic directly from the repository: <pre><code>pip install git+git://github.com/pydantic/pydantic@main#egg=pydantic\n# or with extras\npip install git+git://github.com/pydantic/pydantic@main#egg=pydantic[email,dotenv]\n</code></pre></p>"},{"location":"mypy_plugin/","title":"Mypy plugin","text":"<p>Pydantic works well with mypy right out of the box.</p> <p>However, Pydantic also ships with a mypy plugin that adds a number of important pydantic-specific features to mypy that improve its ability to type-check your code.</p> <p>For example, consider the following script:</p> <p>Without any special configuration, mypy catches one of the errors (see here for usage instructions): <pre><code>13: error: \"Model\" has no attribute \"middle_name\"\n</code></pre></p> <p>But with the plugin enabled, it catches both: <pre><code>13: error: \"Model\" has no attribute \"middle_name\"\n16: error: Missing named argument \"age\" for \"Model\"\n16: error: Missing named argument \"list_of_ints\" for \"Model\"\n</code></pre></p> <p>With the pydantic mypy plugin, you can fearlessly refactor your models knowing mypy will catch any mistakes if your field names or types change.</p> <p>There are other benefits too! See below for more details.</p>"},{"location":"mypy_plugin/#plugin-capabilities","title":"Plugin Capabilities","text":""},{"location":"mypy_plugin/#generate-a-signature-for-model__init__","title":"Generate a signature for <code>Model.__init__</code>","text":"<ul> <li>Any required fields that don't have dynamically-determined aliases will be included as required   keyword arguments.</li> <li>If <code>Config.allow_population_by_field_name=True</code>, the generated signature will use the field names,   rather than aliases.</li> <li>For subclasses of <code>BaseSettings</code>, all fields are treated as optional since they may be   read from the environment.</li> <li>If <code>Config.extra=\"forbid\"</code> and you don't make use of dynamically-determined aliases, the generated signature   will not allow unexpected inputs.</li> <li>Optional: If the <code>init_forbid_extra</code> plugin setting is set to <code>True</code>, unexpected inputs to   <code>__init__</code> will raise errors even if <code>Config.extra</code> is not <code>\"forbid\"</code>.</li> <li>Optional: If the <code>init_typed</code> plugin setting is set to <code>True</code>, the generated signature   will use the types of the model fields (otherwise they will be annotated as <code>Any</code> to allow parsing).</li> </ul>"},{"location":"mypy_plugin/#generate-a-typed-signature-for-modelconstruct","title":"Generate a typed signature for <code>Model.construct</code>","text":"<ul> <li>The <code>construct</code> method is a faster alternative to <code>__init__</code>   when input data is known to be valid and does not need to be parsed. But because this method performs no runtime   validation, static checking is important to detect errors.</li> </ul>"},{"location":"mypy_plugin/#respect-configallow_mutation","title":"Respect <code>Config.allow_mutation</code>","text":"<ul> <li>If <code>Config.allow_mutation</code> is <code>False</code>, you'll get a mypy error if you try to change   the value of a model field; cf. faux immutability.</li> </ul>"},{"location":"mypy_plugin/#respect-configorm_mode","title":"Respect <code>Config.orm_mode</code>","text":"<ul> <li>If <code>Config.orm_mode</code> is <code>False</code>, you'll get a mypy error if you try to call <code>.from_orm()</code>;   cf. ORM mode</li> </ul>"},{"location":"mypy_plugin/#generate-a-signature-for-dataclasses","title":"Generate a signature for <code>dataclasses</code>","text":"<ul> <li>classes decorated with <code>@pydantic.dataclasses.dataclass</code> are type checked the same as standard Python dataclasses</li> <li>The <code>@pydantic.dataclasses.dataclass</code> decorator accepts a <code>config</code> keyword argument which has the same meaning as the <code>Config</code> sub-class.</li> </ul>"},{"location":"mypy_plugin/#respect-the-type-of-the-fields-default-and-default_factory","title":"Respect the type of the <code>Field</code>'s <code>default</code> and <code>default_factory</code>","text":"<ul> <li>Field with both a <code>default</code> and a <code>default_factory</code> will result in an error during static checking.</li> <li>The type of the <code>default</code> and <code>default_factory</code> value must be compatible with the one of the field.</li> </ul>"},{"location":"mypy_plugin/#optional-capabilities","title":"Optional Capabilities:","text":""},{"location":"mypy_plugin/#prevent-the-use-of-required-dynamic-aliases","title":"Prevent the use of required dynamic aliases","text":"<ul> <li>If the <code>warn_required_dynamic_aliases</code> plugin setting is set to <code>True</code>, you'll get a mypy   error any time you use a dynamically-determined alias or alias generator on a model with   <code>Config.allow_population_by_field_name=False</code>.</li> <li>This is important because if such aliases are present, mypy cannot properly type check calls to <code>__init__</code>.   In this case, it will default to treating all arguments as optional.</li> </ul>"},{"location":"mypy_plugin/#prevent-the-use-of-untyped-fields","title":"Prevent the use of untyped fields","text":"<ul> <li>If the <code>warn_untyped_fields</code> plugin setting is set to <code>True</code>, you'll get a mypy error   any time you create a field on a model without annotating its type.</li> <li>This is important because non-annotated fields may result in   validators being applied in a surprising order.</li> <li>In addition, mypy may not be able to correctly infer the type of the field, and may miss   checks or raise spurious errors.</li> </ul>"},{"location":"mypy_plugin/#enabling-the-plugin","title":"Enabling the Plugin","text":"<p>To enable the plugin, just add <code>pydantic.mypy</code> to the list of plugins in your mypy config file (this could be <code>mypy.ini</code> or <code>setup.cfg</code>).</p> <p>To get started, all you need to do is create a <code>mypy.ini</code> file with following contents: <pre><code>[mypy]\nplugins = pydantic.mypy\n</code></pre></p> <p>The plugin is compatible with mypy versions <code>&gt;=0.910</code>.</p> <p>See the mypy usage and plugin configuration docs for more details.</p>"},{"location":"mypy_plugin/#plugin-settings","title":"Plugin Settings","text":"<p>The plugin offers a few optional strictness flags if you want even stronger checks:</p> <ul> <li><code>init_forbid_extra</code><p>If enabled, disallow extra arguments to the <code>__init__</code> call even when <code>Config.extra</code> is not <code>\"forbid\"</code>.</p> </li> </ul> <ul> <li><code>init_typed</code><p>If enabled, include the field types as type hints in the generated signature for the <code>__init__</code> method.   This means that you'll get mypy errors if you pass an argument that is not already the right type to   <code>__init__</code>, even if parsing could safely convert the type.</p> </li> </ul> <ul> <li><code>warn_required_dynamic_aliases</code><p>If enabled, raise a mypy error whenever a model is created for which   calls to its <code>__init__</code> or <code>construct</code> methods require the use of aliases that cannot be statically determined.   This is the case, for example, if <code>allow_population_by_field_name=False</code> and the model uses an alias generator.</p> </li> </ul> <ul> <li><code>warn_untyped_fields</code><p>If enabled, raise a mypy error whenever a field is declared on a model without explicitly specifying its type.</p> </li> </ul>"},{"location":"mypy_plugin/#configuring-the-plugin","title":"Configuring the Plugin","text":"<p>To change the values of the plugin settings, create a section in your mypy config file called <code>[pydantic-mypy]</code>, and add any key-value pairs for settings you want to override.</p> <p>A <code>mypy.ini</code> file with all plugin strictness flags enabled (and some other mypy strictness flags, too) might look like: <pre><code>[mypy]\nplugins = pydantic.mypy\n\nfollow_imports = silent\nwarn_redundant_casts = True\nwarn_unused_ignores = True\ndisallow_any_generics = True\ncheck_untyped_defs = True\nno_implicit_reexport = True\n\n# for strict mypy: (this is the tricky one :-))\ndisallow_untyped_defs = True\n\n[pydantic-mypy]\ninit_forbid_extra = True\ninit_typed = True\nwarn_required_dynamic_aliases = True\nwarn_untyped_fields = True\n</code></pre></p> <p>As of <code>mypy&gt;=0.900</code>, mypy config may also be included in the <code>pyproject.toml</code> file rather than <code>mypy.ini</code>. The same configuration as above would be: <pre><code>[tool.mypy]\nplugins = [\n\"pydantic.mypy\"\n]\n\nfollow_imports = \"silent\"\nwarn_redundant_casts = true\nwarn_unused_ignores = true\ndisallow_any_generics = true\ncheck_untyped_defs = true\nno_implicit_reexport = true\n\n# for strict mypy: (this is the tricky one :-))\ndisallow_untyped_defs = true\n\n[tool.pydantic-mypy]\ninit_forbid_extra = true\ninit_typed = true\nwarn_required_dynamic_aliases = true\nwarn_untyped_fields = true\n</code></pre></p>"},{"location":"pycharm_plugin/","title":"PyCharm plugin","text":"<p>While pydantic will work well with any IDE out of the box, a  PyCharm plugin offering improved pydantic integration is available on the JetBrains Plugins Repository for PyCharm. You can install the plugin for free from the plugin marketplace (PyCharm's Preferences -&gt; Plugin -&gt; Marketplace -&gt; search \"pydantic\").</p> <p>The plugin currently supports the following features:</p> <ul> <li>For <code>pydantic.BaseModel.__init__</code>:<ul> <li>Inspection</li> <li>Autocompletion</li> <li>Type-checking</li> </ul> </li> </ul> <ul> <li>For fields of <code>pydantic.BaseModel</code>:<ul> <li>Refactor-renaming fields updates <code>__init__</code> calls, and affects sub- and super-classes</li> <li>Refactor-renaming <code>__init__</code> keyword arguments updates field names, and affects sub- and super-classes</li> </ul> </li> </ul> <p>More information can be found on the official plugin page and Github repository.</p>"},{"location":"visual_studio_code/","title":"Visual Studio Code","text":"<p>pydantic works well with any editor or IDE out of the box because it's made on top of standard Python type annotations.</p> <p>When using Visual Studio Code (VS Code), there are some additional editor features supported, comparable to the ones provided by the PyCharm plugin.</p> <p>This means that you will have autocompletion (or \"IntelliSense\") and error checks for types and required arguments even while creating new pydantic model instances.</p> <p></p>"},{"location":"visual_studio_code/#configure-vs-code","title":"Configure VS Code","text":"<p>To take advantage of these features, you need to make sure you configure VS Code correctly, using the recommended settings.</p> <p>In case you have a different configuration, here's a short overview of the steps.</p>"},{"location":"visual_studio_code/#install-pylance","title":"Install Pylance","text":"<p>You should use the Pylance extension for VS Code. It is the recommended, next-generation, official VS Code plug-in for Python.</p> <p>Pylance is installed as part of the Python Extension for VS Code by default, so it should probably just work. Otherwise, you can double check it's installed and enabled in your editor.</p>"},{"location":"visual_studio_code/#configure-your-environment","title":"Configure your environment","text":"<p>Then you need to make sure your editor knows the Python environment (probably a virtual environment) for your Python project.</p> <p>This would be the environment in where you installed pydantic.</p>"},{"location":"visual_studio_code/#configure-pylance","title":"Configure Pylance","text":"<p>With the default configurations, you will get support for autocompletion, but Pylance might not check for type errors.</p> <p>You can enable type error checks from Pylance with these steps:</p> <ul> <li>Open the \"User Settings\"</li> <li>Search for <code>Type Checking Mode</code></li> <li>You will find an option under <code>Python \u203a Analysis: Type Checking Mode</code></li> <li>Set it to <code>basic</code> or <code>strict</code> (by default it's <code>off</code>)</li> </ul> <p></p> <p>Now you will not only get autocompletion when creating new pydantic model instances but also error checks for required arguments.</p> <p></p> <p>And you will also get error checks for invalid data types.</p> <p></p> <p>Technical Details</p> <p>Pylance is the VS Code extension, it's closed source, but free to use. Underneath, Pylance uses an open source tool (also from Microsoft) called Pyright that does all the heavy lifting.</p> <p>You can read more about it in the Pylance Frequently Asked Questions.</p>"},{"location":"visual_studio_code/#configure-mypy","title":"Configure mypy","text":"<p>You might also want to configure mypy in VS Code to get mypy error checks inline in your editor (alternatively/additionally to Pylance).</p> <p>This would include the errors detected by the pydantic mypy plugin, if you configured it.</p> <p>To enable mypy in VS Code, do the following:</p> <ul> <li>Open the \"User Settings\"</li> <li>Search for <code>Mypy Enabled</code></li> <li>You will find an option under <code>Python \u203a Linting: Mypy Enabled</code></li> <li>Check the box (by default it's unchecked)</li> </ul> <p></p>"},{"location":"visual_studio_code/#tips-and-tricks","title":"Tips and tricks","text":"<p>Here are some additional tips and tricks to improve your developer experience when using VS Code with pydantic.</p>"},{"location":"visual_studio_code/#strict-errors","title":"Strict errors","text":"<p>The way this additional editor support works is that Pylance will treat your pydantic models as if they were Python's pure <code>dataclasses</code>.</p> <p>And it will show strict type error checks about the data types passed in arguments when creating a new pydantic model instance.</p> <p>In this example you can see that it shows that a <code>str</code> of <code>'23'</code> is not a valid <code>int</code> for the argument <code>age</code>.</p> <p></p> <p>It would expect <code>age=23</code> instead of <code>age='23'</code>.</p> <p>Nevertheless, the design, and one of the main features of pydantic, is that it is very lenient with data types.</p> <p>It will actually accept the <code>str</code> with value <code>'23'</code> and will convert it to an <code>int</code> with value <code>23</code>.</p> <p>These strict error checks are very useful most of the time and can help you detect many bugs early. But there are cases, like with <code>age='23'</code>, where they could be inconvenient by reporting a \"false positive\" error.</p> <p>This example above with <code>age='23'</code> is intentionally simple, to show the error and the differences in types.</p> <p>But more common cases where these strict errors would be inconvenient would be when using more sophisticated data types, like <code>int</code> values for <code>datetime</code> fields, or <code>dict</code> values for pydantic sub-models.</p> <p>For example, this is valid for pydantic:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nclass Quest(BaseModel):\n    title: str\nknight: Knight\nquest = Quest(\n    title='To seek the Holy Grail',\nknight={'title': 'Sir Lancelot', 'age': 23}\n)\n</code></pre> <p>The type of the field <code>knight</code> is declared with the class <code>Knight</code> (a pydantic model) and the code is passing a literal <code>dict</code> instead. This is still valid for pydantic, and the <code>dict</code> would be automatically converted to a <code>Knight</code> instance.</p> <p>Nevertheless, it would be detected as a type error:</p> <p></p> <p>In those cases, there are several ways to disable or ignore strict errors in very specific places, while still preserving them in the rest of the code.</p> <p>Below are several techniques to achieve it.</p>"},{"location":"visual_studio_code/#disable-type-checks-in-a-line","title":"Disable type checks in a line","text":"<p>You can disable the errors for a specific line using a comment of:</p> <pre><code># type: ignore\n</code></pre> <p>or (to be specific to pylance/pyright):</p> <pre><code># pyright: ignore\n</code></pre> <p>(pyright is the language server used by Pylance.).</p> <p>coming back to the example with <code>age='23'</code>, it would be:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nlancelot = Knight(title='Sir Lancelot', age='23')  # pyright: ignore\n</code></pre> <p>that way Pylance and mypy will ignore errors in that line.</p> <p>Pros: it's a simple change in that line to remove errors there.</p> <p>Cons: any other error in that line will also be omitted, including type checks, misspelled arguments, required arguments not provided, etc.</p>"},{"location":"visual_studio_code/#override-the-type-of-a-variable","title":"Override the type of a variable","text":"<p>You can also create a variable with the value you want to use and declare it's type explicitly with <code>Any</code>.</p> <pre><code>from typing import Any\nfrom pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nage_str: Any = '23'\nlancelot = Knight(title='Sir Lancelot', age=age_str)\n</code></pre> <p>that way Pylance and mypy will interpret the variable <code>age_str</code> as if they didn't know its type, instead of knowing it has a type of <code>str</code> when an <code>int</code> was expected (and then showing the corresponding error).</p> <p>Pros: errors will be ignored only for a specific value, and you will still see any additional errors for the other arguments.</p> <p>Cons: it requires importing <code>Any</code> and a new variable in a new line for each argument that needs ignoring errors.</p>"},{"location":"visual_studio_code/#override-the-type-of-a-value-with-cast","title":"Override the type of a value with <code>cast</code>","text":"<p>The same idea from the previous example can be put on the same line with the help of <code>cast()</code>.</p> <p>This way, the type declaration of the value is overridden inline, without requiring another variable.</p> <pre><code>from typing import Any, cast\nfrom pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\n\nlancelot = Knight(title='Sir Lancelot', age=cast(Any, '23'))\n</code></pre> <p><code>cast(Any, '23')</code> doesn't affect the value, it's still just <code>'23'</code>, but now Pylance and mypy will assume it is of type <code>Any</code>, which means, they will act as if they didn't know the type of the value.</p> <p>So, this is the equivalent of the previous example, without the additional variable.</p> <p>Pros: errors will be ignored only for a specific value, and you will still see any additional errors for the other arguments. There's no need for additional variables.</p> <p>Cons: it requires importing <code>Any</code> and <code>cast</code>, and if you are not used to using <code>cast()</code>, it could seem strange at first.</p>"},{"location":"visual_studio_code/#config-in-class-arguments","title":"Config in class arguments","text":"<p>pydantic has a rich set of Model Configurations available.</p> <p>These configurations can be set in an internal <code>class Config</code> on each model:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel):\n    title: str\n    age: int\n    color: str = 'blue'\n\nclass Config:\nfrozen = True\n</code></pre> <p>or passed as keyword arguments when defining the model class:</p> <pre><code>from pydantic import BaseModel\n\n\nclass Knight(BaseModel, frozen=True):\ntitle: str\n    age: int\n    color: str = 'blue'\n</code></pre> <p>The specific configuration <code>frozen</code> (in beta) has a special meaning.</p> <p>It prevents other code from changing a model instance once it's created, keeping it \"frozen\".</p> <p>When using the second version to declare <code>frozen=True</code> (with keyword arguments in the class definition),  Pylance can use it to help you check in your code and detect errors when something is trying to set values  in a model that is \"frozen\".</p> <p></p>"},{"location":"visual_studio_code/#basesettings-and-ignoring-pylancepyright-errors","title":"BaseSettings and ignoring Pylance/pyright errors","text":"<p>Pylance/pyright does not work well with <code>BaseSettings</code> - fields in settings classes can be  configured via environment variables and therefore \"required\" fields do not have to be explicitly set when initialising a settings instance. However, pyright considers these fields as \"required\" and will therefore show an error when they're not set.</p> <p>See #3753 for an explanation of the reasons behind this, and why we can't avoid the problem.</p> <p>There are two potential workarounds:</p> <ul> <li>use an ignore comment (<code># pyright: ignore</code>) when initialising <code>settings</code></li> <li>or, use <code>settings.parse_obj({})</code> to avoid the warning</li> </ul>"},{"location":"visual_studio_code/#adding-a-default-with-field","title":"Adding a default with <code>Field</code>","text":"<p>Pylance/pyright requires <code>default</code> to be a keyword argument to <code>Field</code> in order to infer that the field is optional.</p> <pre><code>from pydantic import BaseModel, Field\n\n\nclass Knight(BaseModel):\n    title: str = Field(default='Sir Lancelot')  # this is okay\n    age: int = Field(23)  # this works fine at runtime but will case an error for pyright\n\nlance = Knight()  # error: Argument missing for parameter \"age\" \n</code></pre> <p>Like the issue with <code>BaseSettings</code>, this is a limitation of dataclass transforms and cannot be fixed in pydantic.</p>"},{"location":"visual_studio_code/#technical-details","title":"Technical Details","text":"<p>Warning</p> <p>As a pydantic user, you don't need the details below. Feel free to skip the rest of this section.</p> <p>These details are only useful for other library authors, etc.</p> <p>This additional editor support works by implementing the proposed draft standard for Dataclass Transform.</p> <p>The proposed draft standard is written by Eric Traut, from the Microsoft team, the same author of the open source package Pyright (used by Pylance to provide Python support in VS Code).</p> <p>The intention of the standard is to provide a way for libraries like pydantic and others to tell editors and tools that they (the editors) should treat these libraries (e.g. pydantic) as if they were <code>dataclasses</code>, providing autocompletion, type checks, etc.</p> <p>The draft standard also includes an Alternate Form for early adopters, like pydantic, to add support for it right away, even before the new draft standard is finished and approved.</p> <p>This new draft standard, with the Alternate Form, is already supported by Pyright, so it can be used via Pylance in VS Code.</p> <p>As it is being proposed as an official standard for Python, other editors can also easily add support for it.</p> <p>And authors of other libraries similar to pydantic can also easily adopt the standard right away (using the \"Alternate Form\") and get the benefits of these additional editor features.</p>"},{"location":"blog/pydantic-v2-alpha/","title":"Pydantic V2 Pre Release","text":"<p>Terrence Dorsey &amp; Samuel Colvin \u2022\u00a0    \u2022\u00a0    \u2022\u00a0    April 3, 2023 \u2022\u00a0    8 min read</p> <p>We're excited to announce the first alpha release of Pydantic V2!</p> <p>This first Pydantic V2 alpha is no April Fool's joke \u2014 for a start we missed our April 1st target date . After a year's work, we invite you to explore the improvements we've made and give us your feedback.  We look forward to hearing your thoughts and working together to improve the library.</p> <p>For many of you, Pydantic is already a key part of your Python toolkit and needs no introduction \u2014  we hope you'll find the improvements and additions in Pydantic V2 useful.</p> <p>If you're new to Pydantic: Pydantic is an open-source Python library that provides powerful data parsing and validation \u2014  including type coercion and useful error messages when typing issues arise \u2014 and settings management capabilities. See the docs for examples of Pydantic at work.</p>"},{"location":"blog/pydantic-v2-alpha/#getting-started-with-the-pydantic-v2-alpha","title":"Getting started with the Pydantic V2 alpha","text":"<p>Your feedback will be a critical part of ensuring that we have made the right tradeoffs with the API changes in V2.</p> <p>To get started with the Pydantic V2 alpha, install it from PyPI.  We recommend using a virtual environment to isolate your testing environment:</p> <pre><code>pip install --pre -U \"pydantic&gt;=2.0a1\"\n</code></pre> <p>Note that there are still some rough edges and incomplete features, and while trying out the Pydantic V2 alpha releases you may experience errors.  We encourage you to try out the alpha releases in a test environment and not in production.  Some features are still in development, and we will continue to make changes to the API.</p> <p>If you do encounter any issues, please create an issue in GitHub using the <code>bug V2</code> label.  This will help us to actively monitor and track errors, and to continue to improve the library\u2019s performance.</p> <p>This will be the first of several upcoming alpha releases. As you evaluate our changes and enhancements,  we encourage you to share your feedback with us.</p> <p>Please let us know:</p> <ul> <li>If you don't like the changes, so we can make sure Pydantic remains a library you enjoy using.</li> <li>If this breaks your usage of Pydantic so we can fix it, or at least describe a migration path.</li> </ul> <p>Thank you for your support, and we look forward to your feedback.</p>"},{"location":"blog/pydantic-v2-alpha/#headlines","title":"Headlines","text":"<p>Here are some of the most interesting new features in the current Pydantic V2 alpha release.  For background on plans behind these features, see the earlier Pydantic V2 Plan blog post.</p> <p>The biggest change to Pydantic V2 is <code>pydantic-core</code> \u2014 all validation logic has been rewritten in Rust and moved to a separate package, <code>pydantic-core</code>. This has a number of big advantages:</p> <ul> <li>Performance - Pydantic V2 is 5-50x faster than Pydantic V1.</li> <li>Safety &amp; maintainability - We've made changes to the architecture that we think will help us maintain Pydantic V2 with far fewer bugs in the long term.</li> </ul> <p>With the use of <code>pydantic-core</code>, the majority of the logic in the Pydantic library is dedicated to generating \"pydantic core schema\" \u2014 the schema used define the behaviour of the new, high-performance <code>pydantic-core</code> validators and serializers.  </p>"},{"location":"blog/pydantic-v2-alpha/#ready-for-experimentation","title":"Ready for experimentation","text":"<ul> <li>BaseModel - the core of validation in Pydantic V1 remains, albeit with new method names.</li> <li>Dataclasses - Pydantic dataclasses are improved and ready to test.</li> <li>Serialization - dumping/serialization/marshalling is significantly more flexible, and ready to test.</li> <li>Strict mode - one of the biggest additions in Pydantic V2 is strict mode, which is ready to test.</li> <li>JSON Schema - generation of JSON Schema is much improved and ready to test.</li> <li>Generic Models - are much improved and ready to test.</li> <li>Recursive Models - and validation of recursive data structures is much improved and ready to test.</li> <li>Custom Types - custom types have a new interface and are ready to test.</li> <li>Custom Field Modifiers - used via <code>Annotated[]</code> are working and in use in Pydantic itself.</li> <li>Validation without a BaseModel - the new <code>AnalyzedType</code> class allows validation without the need for a <code>BaseModel</code> class, and it's ready to test.</li> <li>TypedDict - we now have full support for <code>TypedDict</code> via <code>AnalyzedType</code>, it's ready to test.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#still-under-construction","title":"Still under construction","text":"<ul> <li>Documentation - we're working hard on full documentation for V2, but it's not ready yet.</li> <li>Conversion Table - a big addition to the documentation will be a conversion table showing how types are coerced, this is a WIP.</li> <li>BaseSettings - <code>BaseSettings</code> will move to a separate <code>pydantic-settings</code> package, it's not yet ready to test.    Notice: since <code>pydantic-settings</code> is not yet ready to release, there's no support for <code>BaseSettings</code> in the first alpha release.</li> <li>validate_arguments - the <code>validate_arguments</code> decorator remains and is working, but hasn't been updated yet.</li> <li>Hypothesis Plugin - the Hypothesis plugin is yet to be updated.</li> <li>computed fields - we know a lot of people are waiting for this, we will include it in Pydantic V2.</li> <li>Error messages - could use some love, and links to docs in error messages are still to be added.</li> <li>Migration Guide - we have some pointers below, but this needs completing.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#migration-guide","title":"Migration Guide","text":"<p>Please note: this is just the beginning of a migration guide. We'll work hard up to the final release to prepare a full migration guide, but for now the following pointers should be some help while experimenting with V2.</p>"},{"location":"blog/pydantic-v2-alpha/#changes-to-basemodel","title":"Changes to BaseModel","text":"<ul> <li>Various method names have been changed; <code>BaseModel</code> methods all start with <code>model_</code> now.    Where possible, we have retained the old method names to help ease migration, but calling them will result in <code>DeprecationWarning</code>s.<ul> <li>Some of the built-in data loading functionality has been slated for removal.    In particular, <code>parse_raw</code> and <code>parse_file</code> are now deprecated. You should load the data and then pass it to <code>model_validate</code>.</li> </ul> </li> <li>The <code>from_orm</code> method has been removed; you can now just use <code>model_validate</code> (equivalent to <code>parse_obj</code> from Pydantic V1) to achieve something similar,    as long as you've set <code>from_attributes=True</code> in the model config.</li> <li>The <code>__eq__</code> method has changed for models; models are no longer considered equal to the dicts.</li> <li>Custom <code>__init__</code> overrides won't be called. This should be replaced with a <code>@root_validator</code>.</li> <li>Due to inconsistency with the rest of the library, we have removed the special behavior of models   using the <code>__root__</code> field, and have disallowed the use of an attribute with this name to prevent confusion.   However, you can achieve equivalent behavior with a \"standard\" field name through the use of <code>@root_validator</code>,   <code>@model_serializer</code>, and <code>__pydantic_modify_json_schema__</code>. You can see an example of this   here.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-pydantic-dataclasses","title":"Changes to Pydantic Dataclasses","text":"<ul> <li>The <code>__post_init__</code> in Pydantic dataclasses will now be called after validation, rather than before.</li> <li>We no longer support <code>extra='allow'</code> for Pydantic dataclasses, where extra attributes passed to the initializer would be    stored as extra fields on the dataclass. <code>extra='ignore'</code> is still supported for the purposes of allowing extra fields while parsing data; they just aren't stored.</li> <li><code>__post_init_post_parse__</code> has been removed.</li> <li>Nested dataclasses no longer accept tuples as input, only dict.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-config","title":"Changes to Config","text":"<ul> <li>To specify config on a model, it is now deprecated to create a class called <code>Config</code> in the namespace of the parent <code>BaseModel</code> subclass.    Instead, you just need to set a class attribute called <code>model_config</code> to be a dict with the key/value pairs you want to be used as the config.</li> </ul> <p>The following config settings have been removed:</p> <ul> <li><code>allow_mutation</code>.</li> <li><code>error_msg_templates</code>.</li> <li><code>fields</code> \u2014 this was the source of various bugs, so has been removed. You should be able to use <code>Annotated</code> on fields to modify them as desired.</li> <li><code>getter_dict</code> \u2014 <code>orm_mode</code> has been removed, and this implementation detail is no longer necessary.</li> <li><code>schema_extra</code> \u2014 you should now use the <code>json_schema_extra</code> keyword argument to <code>pydantic.Field</code>.</li> <li><code>smart_union</code>.</li> <li><code>underscore_attrs_are_private</code> \u2014 the Pydantic V2 behavior is now the same as if this was always set to <code>True</code> in Pydantic V1.</li> </ul> <p>The following config settings have been renamed:</p> <ul> <li><code>allow_population_by_field_name</code> \u2192 <code>populate_by_name</code></li> <li><code>anystr_lower</code> \u2192 <code>str_to_lower</code></li> <li><code>anystr_strip_whitespace</code> \u2192 <code>str_strip_whitespace</code></li> <li><code>anystr_upper</code> \u2192 <code>str_to_upper</code></li> <li><code>keep_untouched</code> \u2192 <code>ignored_types</code></li> <li><code>max_anystr_length</code> \u2192 <code>str_max_length</code></li> <li><code>min_anystr_length</code> \u2192 <code>str_min_length</code></li> <li><code>orm_mode</code> \u2192 <code>from_attributes</code></li> <li><code>validate_all</code> \u2192 <code>validate_default</code></li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-validators","title":"Changes to Validators","text":"<ul> <li>Raising a <code>TypeError</code> inside a validator no longer produces a <code>ValidationError</code>, but just raises the <code>TypeError</code> directly.    This was necessary to prevent certain common bugs (such as calling functions with invalid signatures) from    being unintentionally converted into <code>ValidationError</code> and displayed to users.    If you really want <code>TypeError</code> to be converted to a <code>ValidationError</code> you should use a <code>try: except:</code> block that will catch it and do the conversion.</li> <li><code>each_item</code> validators are deprecated and should be replaced with a type annotation using <code>Annotated</code> to apply a validator    or with a validator that operates on all items at the top level.</li> <li>Changes to <code>@validator</code>-decorated function signatures.</li> <li>The <code>stricturl</code> type has been removed.</li> <li>Root validators can no longer be run with <code>skip_on_failure=False</code>.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-validation-of-specific-types","title":"Changes to Validation of specific types","text":"<ul> <li>Integers outside the valid range of 64 bit integers will cause <code>ValidationError</code>s during parsing.    To work around this, use an <code>IsInstance</code> validator (more details to come).</li> <li>Subclasses of built-ins won't validate into their subclass types; you'll need to use an <code>IsInstance</code> validator to validate these types.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#changes-to-generic-models","title":"Changes to Generic models","text":"<ul> <li>While it does not raise an error at runtime yet, subclass checks for parametrized generics should no longer be used.    These will result in <code>TypeError</code>s and we can't promise they will work forever. However, it will be okay to do subclass checks against non-parametrized generic models</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#other-changes","title":"Other changes","text":"<ul> <li><code>GetterDict</code> has been removed, as it was just an implementation detail for <code>orm_mode</code>, which has been removed.</li> </ul>"},{"location":"blog/pydantic-v2-alpha/#analyzedtype","title":"AnalyzedType","text":"<p>Pydantic V1 didn't have good support for validation or serializing non-<code>BaseModel</code>. To work with them you had to create a \"root\" model or use the utility functions in <code>pydantic.tools</code> (<code>parse_obj_as</code> and <code>schema_of</code>). In Pydantic V2 this is a lot easier: the <code>AnalyzedType</code> class lets you build an object that behaves almost like a <code>BaseModel</code> class which you can use for a lot of the use cases of root models and as a complete replacement for <code>parse_obj_as</code> and <code>schema_of</code>.</p> <pre><code>from typing import List\nfrom pydantic import AnalyzedType\n\nvalidator = AnalyzedType(List[int])\nassert validator.validate_python(['1', '2', '3']) == [1, 2, 3]\nprint(validator.json_schema())\n# {'type': 'array', 'items': {'type': 'integer'}}\n</code></pre> <p>Note that this API is provisional and may change before the final release of Pydantic V2.</p>"},{"location":"blog/pydantic-v2/","title":"Pydantic V2 Plan","text":"<p>Samuel Colvin \u2022\u00a0    \u2022\u00a0    \u2022\u00a0    Jul 10, 2022 \u2022\u00a0    25 min read</p> <p>Updated late 10 Jul 2022, see pydantic#4226.</p> <p>Update 30 Dec 2022: The new release deadline for Pydantic V2 is the end of Q1 2023,  see pydantic#4887 for more details, further updates will be posted on that issue.</p> <p>I've spoken to quite a few people about pydantic V2, and mention it in passing even more.</p> <p>I owe people a proper explanation of the plan for V2:</p> <ul> <li>What we will add</li> <li>What we will remove</li> <li>What we will change</li> <li>How I'm intending to go about completing it and getting it released</li> <li>Some idea of timeframe </li> </ul> <p>Here goes...</p> <p>Enormous thanks to Eric Jolibois, Laurence Watson,  Sebasti\u00e1n Ram\u00edrez, Adrian Garcia Badaracco,  Tom Hamilton Stubber, Zac Hatfield-Dodds,  Tom &amp; Hasan Ramezani for reviewing this blog post, putting up with (and correcting) my horrible typos and making great suggestions that have made this post and Pydantic V2 materially better.</p>"},{"location":"blog/pydantic-v2/#plan-timeframe","title":"Plan &amp; Timeframe","text":"<p>I'm currently taking a kind of sabbatical after leaving my last job to get pydantic V2 released. Why? I ask myself that question quite often. I'm very proud of how much pydantic is used, but I'm less proud of its internals. Since it's something people seem to care about and use quite a lot (26m downloads a month, used by 72k public repos, 10k stars). I want it to be as good as possible.</p> <p>While I'm on the subject of why, how and my odd sabbatical: if you work for a large company who use pydantic a lot, you might encourage the company to sponsor me a meaningful amount, like Salesforce did (if your organisation is not open to donations, I can also offer consulting services). This is not charity, recruitment or marketing - the argument should be about how much the company will save if pydantic is 10x faster, more stable and more powerful - it would be worth paying me 10% of that to make it happen.</p> <p>Before pydantic V2 can be released, we need to release pydantic V1.10 - there are lots of changes in the main branch of pydantic contributed by the community, it's only fair to provide a release including those changes, many of them will remain unchanged for V2, the rest will act as a requirement to make sure pydantic V2 includes the capabilities they implemented.</p> <p>The basic road map for me is as follows:</p> <ol> <li>Implement a few more features in pydantic-core, and release a first version, see below</li> <li>Work on getting pydantic V1.10 out - basically merge all open PRs that are finished</li> <li>Release pydantic V1.10</li> <li>Delete all stale PRs which didn't make it into V1.10, apologise profusely to their authors who put their valuable    time into pydantic only to have their PRs closed     (and explain when and how they can rebase and recreate the PR)</li> <li>Rename <code>master</code> to <code>main</code>, seems like a good time to do this</li> <li>Change the main branch of pydantic to target V2</li> <li>Start tearing pydantic code apart and see how many existing tests can be made to pass</li> <li>Rinse, repeat</li> <li>Release pydantic V2 </li> </ol> <p>Plan is to have all this done by the end of October, definitely by the end of the year.</p>"},{"location":"blog/pydantic-v2/#breaking-changes-compatibility","title":"Breaking Changes &amp; Compatibility","text":"<p>While we'll do our best to avoid breaking changes, some things will break.</p> <p>As per the greatest pun in modern TV history.</p> <p>You can't make a Tomelette without breaking some Greggs.</p> <p>Where possible, if breaking changes are unavoidable, we'll try to provide warnings or errors to make sure those changes are obvious to developers.</p>"},{"location":"blog/pydantic-v2/#motivation-pydantic-core","title":"Motivation &amp; <code>pydantic-core</code>","text":"<p>Since pydantic's initial release, with the help of wonderful contributors Eric Jolibois, Sebasti\u00e1n Ram\u00edrez, David Montague and many others, the package and its usage have grown enormously. The core logic however has remained mostly unchanged since the initial experiment. It's old, it smells, it needs to be rebuilt.</p> <p>The release of version 2 is an opportunity to rebuild pydantic and correct many things that don't make sense - to make pydantic amazing .</p> <p>The core validation logic of pydantic V2 will be performed by a separate package pydantic-core which I've been building over the last few months. pydantic-core is written in Rust using the excellent pyo3 library which provides rust bindings for python.</p> <p>The motivation for building pydantic-core in Rust is as follows:</p> <ol> <li>Performance, see below</li> <li>Recursion and code separation - with no stack and little-to-no overhead for extra function calls,    Rust allows pydantic-core to be implemented as a tree of small validators which call each other,    making code easier to understand and extend without harming performance</li> <li>Safety and complexity - pydantic-core is a fairly complex piece of code which has to draw distinctions    between many different errors, Rust is great in situations like this,    it should minimise bugs () and allow the codebase to be extended for a long time to come</li> </ol> <p>Note</p> <p>The python interface to pydantic shouldn't change as a result of using pydantic-core, instead pydantic will use type annotations to build a schema for pydantic-core to use.</p> <p>pydantic-core is usable now, albeit with an unintuitive API, if you're interested, please give it a try.</p> <p>pydantic-core provides validators for common data types, see a list here. Other, less commonly used data types will be supported via validator functions implemented in pydantic, in Python.</p> <p>See pydantic-core#153 for a summary of what needs to be completed before its first release.</p>"},{"location":"blog/pydantic-v2/#headlines","title":"Headlines","text":"<p>Here are some of the biggest changes expected in V2.</p>"},{"location":"blog/pydantic-v2/#performance","title":"Performance","text":"<p>As a result of the move to Rust for the validation logic (and significant improvements in how validation objects are structured) pydantic V2 will be significantly faster than pydantic V1.</p> <p>Looking at the pydantic-core benchmarks today, pydantic V2 is between 4x and 50x faster than pydantic V1.9.1.</p> <p>In general, pydantic V2 is about 17x faster than V1 when validating a model containing a range of common fields.</p>"},{"location":"blog/pydantic-v2/#strict-mode","title":"Strict Mode","text":"<p>People have long complained about pydantic for coercing data instead of throwing an error. E.g. input to an <code>int</code> field could be <code>123</code> or the string <code>\"123\"</code> which would be converted to <code>123</code> While this is very useful in many scenarios (think: URL parameters, environment variables, user input), there are some situations where it's not desirable.</p> <p>pydantic-core comes with \"strict mode\" built in. With this, only the exact data type is allowed, e.g. passing <code>\"123\"</code> to an <code>int</code> field would result in a validation error.</p> <p>This will allow pydantic V2 to offer a <code>strict</code> switch which can be set on either a model or a field.</p>"},{"location":"blog/pydantic-v2/#formalised-conversion-table","title":"Formalised Conversion Table","text":"<p>As well as complaints about coercion, another legitimate complaint was inconsistency around data conversion.</p> <p>In pydantic V2, the following principle will govern when data should be converted in \"lax mode\" (<code>strict=False</code>):</p> <p>If the input data has a SINGLE and INTUITIVE representation, in the field's type, AND no data is lost during the conversion, then the data will be converted; otherwise a validation error is raised. There is one exception to this rule: string fields - virtually all data has an intuitive representation as a string (e.g. <code>repr()</code> and <code>str()</code>), therefore a custom rule is required: only <code>str</code>, <code>bytes</code> and <code>bytearray</code> are valid as inputs to string fields.</p> <p>Some examples of what that means in practice:</p> Field Type Input Single &amp; Intuitive R. All Data Preserved Result <code>int</code> <code>\"123\"</code> Convert <code>int</code> <code>123.0</code> Convert <code>int</code> <code>123.1</code> Error <code>date</code> <code>\"2020-01-01\"</code> Convert <code>date</code> <code>\"2020-01-01T00:00:00\"</code> Convert <code>date</code> <code>\"2020-01-01T12:00:00\"</code> Error <code>int</code> <code>b\"1\"</code> Error <p>(For the last case converting <code>bytes</code> to an <code>int</code> could reasonably mean <code>int(bytes_data.decode())</code> or <code>int.from_bytes(b'1', 'big/little')</code>, hence an error)</p> <p>In addition to the general rule, we'll provide a conversion table which defines exactly what data will be allowed to which field types. See the table below for a start on this.</p>"},{"location":"blog/pydantic-v2/#built-in-json-support","title":"Built in JSON support","text":"<p>pydantic-core can parse JSON directly into a model or output type, this both improves performance and avoids issue with strictness - e.g. if you have a strict model with a <code>datetime</code> field, the input must be a <code>datetime</code> object, but clearly that makes no sense when parsing JSON which has no <code>datatime</code> type. Same with <code>bytes</code> and many other types.</p> <p>Pydantic V2 will therefore allow some conversion when validating JSON directly, even in strict mode (e.g. <code>ISO8601 string -&gt; datetime</code>, <code>str -&gt; bytes</code>) even though this would not be allowed when validating a python object.</p> <p>In future direct validation of JSON will also allow:</p> <ul> <li>parsing in a separate thread while starting validation in the main thread</li> <li>line numbers from JSON to be included in the validation errors</li> </ul> <p>(These features will not be included in V2, but instead will hopefully be added later.)</p> <p>Note</p> <p>Pydantic has always had special support for JSON, that is not going to change.</p> <p>While in theory other formats could be specifically supported, the overheads and development time are  significant and I don't think there's another format that's used widely enough to be worth specific logic. Other formats can be parsed to python then validated, similarly when serialising, data can be exported to a python object, then serialised, see below.</p>"},{"location":"blog/pydantic-v2/#validation-without-a-model","title":"Validation without a Model","text":"<p>In pydantic V1 the core of all validation was a pydantic model, this led to a significant performance penalty  and extra complexity when the output data type was not a model.</p> <p>pydantic-core operates on a tree of validators with no \"model\" type required at the base of that tree. It can therefore validate a single <code>string</code> or <code>datetime</code> value, a <code>TypedDict</code> or a <code>Model</code> equally easily.</p> <p>This feature will provide significant addition performance improvements in scenarios like:</p> <ul> <li>Adding validation to <code>dataclasses</code></li> <li>Validating URL arguments, query strings, headers, etc. in FastAPI</li> <li>Adding validation to <code>TypedDict</code></li> <li>Function argument validation</li> <li>Adding validation to your custom classes, decorators...</li> </ul> <p>In effect - anywhere where you don't care about a traditional model class instance.</p> <p>We'll need to add standalone methods for generating JSON Schema and dumping these objects to JSON, etc.</p>"},{"location":"blog/pydantic-v2/#required-vs-nullable-cleanup","title":"Required vs. Nullable Cleanup","text":"<p>Pydantic previously had a somewhat confused idea about \"required\" vs. \"nullable\". This mostly resulted from my misgivings about marking a field as <code>Optional[int]</code> but requiring a value to be provided but allowing it to be <code>None</code> - I didn't like using the word \"optional\" in relation to a field which was not optional.</p> <p>In pydantic V2, pydantic will move to match dataclasses, thus:</p> Required vs. Nullable<pre><code>from pydantic import BaseModel\n\nclass Foo(BaseModel):\n    f1: str  # required, cannot be None\n    f2: str | None  # required, can be None - same as Optional[str] / Union[str, None]\n    f3: str | None = None  # not required, can be None\n    f4: str = 'Foobar'  # not required, but cannot be None\n</code></pre>"},{"location":"blog/pydantic-v2/#validator-function-improvements","title":"Validator Function Improvements","text":"<p>This is one of the changes in pydantic V2 that I'm most excited about, I've been talking about something like this for a long time, see pydantic#1984, but couldn't find a way to do this until now.</p> <p>Fields which use a function for validation can be any of the following types:</p> <ul> <li>function before mode - where the function is called before the inner validator is called</li> <li>function after mode - where the function is called after the inner validator is called</li> <li>plain mode - where there's no inner validator</li> <li>wrap mode - where the function takes a reference to a function which calls the inner validator,   and can therefore modify the input before inner validation, modify the output after inner validation, conditionally   not call the inner validator or catch errors from the inner validator and return a default value, or change the error</li> </ul> <p>An example how a wrap validator might look:</p> Wrap mode validator function<pre><code>from datetime import datetime\nfrom pydantic import BaseModel, ValidationError, validator\n\nclass MyModel(BaseModel):\n    timestamp: datetime\n\n    @validator('timestamp', mode='wrap')\n    def validate_timestamp(cls, v, handler):\n        if v == 'now':\n            # we don't want to bother with further validation, \n            # just return the new value\n            return datetime.now()\n        try:\n            return handler(v)\n        except ValidationError:\n            # validation failed, in this case we want to \n            # return a default value\n            return datetime(2000, 1, 1)\n</code></pre> <p>As well as being powerful, this provides a great \"escape hatch\" when pydantic validation doesn't do what you need.</p>"},{"location":"blog/pydantic-v2/#more-powerful-aliases","title":"More powerful alias(es)","text":"<p>pydantic-core can support alias \"paths\" as well as simple string aliases to flatten data as it's validated.</p> <p>Best demonstrated with an example:</p> Alias paths<pre><code>from pydantic import BaseModel, Field\n\n\nclass Foo(BaseModel):\n    bar: str = Field(aliases=[['baz', 2, 'qux']])\n\n\ndata = {\n    'baz': [\n        {'qux': 'a'},\n        {'qux': 'b'},\n        {'qux': 'c'},\n        {'qux': 'd'},\n    ]\n}\n\nfoo = Foo(**data)\nassert foo.bar == 'c'\n</code></pre> <p><code>aliases</code> is a list of lists because multiple paths can be provided, if so they're tried in turn until a value is found.</p> <p>Tagged unions will use the same logic as <code>aliases</code> meaning nested attributes can be used to select a schema to validate against.</p>"},{"location":"blog/pydantic-v2/#improvements-to-dumpingserializationexport","title":"Improvements to Dumping/Serialization/Export","text":"<p>(I haven't worked on this yet, so these ideas are only provisional)</p> <p>There has long been a debate about how to handle converting data when extracting it from a model. One of the features people have long requested is the ability to convert data to JSON compliant types while converting a model to a dict.</p> <p>My plan is to move data export into pydantic-core, with that, one implementation can support all export modes without compromising (and hopefully significantly improving) performance.</p> <p>I see four different export/serialisation scenarios:</p> <ol> <li>Extracting the field values of a model with no conversion, effectively <code>model.__dict__</code> but with the current filtering    logic provided by <code>.dict()</code></li> <li>Extracting the field values of a model recursively (effectively what <code>.dict()</code> does now) - sub-models are converted to    dicts, but other fields remain unchanged.</li> <li>Extracting data and converting at the same time (e.g. to JSON compliant types)</li> <li>Serialising data straight to JSON</li> </ol> <p>I think all 4 modes can be supported in a single implementation, with a kind of \"3.5\" mode where a python function is used to convert the data as the user wishes.</p> <p>The current <code>include</code> and <code>exclude</code> logic is extremely complicated, but hopefully it won't be too hard to translate it to Rust.</p> <p>We should also add support for <code>validate_alias</code> and <code>dump_alias</code> as well as the standard <code>alias</code> to allow for customising field keys.</p>"},{"location":"blog/pydantic-v2/#validation-context","title":"Validation Context","text":"<p>Pydantic V2 will add a new optional <code>context</code> argument to <code>model_validate</code> and <code>model_validate_json</code> which will allow you to pass information not available when creating a model to validators. See pydantic#1549 for motivation.</p> <p>Here's an example of <code>context</code> might be used:</p> Context during Validation<pre><code>from pydantic import BaseModel, EmailStr, validator\n\nclass User(BaseModel):\n    email: EmailStr\n    home_country: str\n\n    @validator('home_country')\n    def check_home_country(cls, v, context):\n        if v not in context['countries']:\n            raise ValueError('invalid country choice')\n        return v\n\nasync def add_user(post_data: bytes):\n    countries = set(await db_connection.fetch_all('select code from country'))\n    user = User.model_validate_json(post_data, context={'countries': countries})\n    ...\n</code></pre> <p>Note</p> <p>We (actually mostly Sebasti\u00e1n ) will have to make some changes to FastAPI to fully leverage <code>context</code> as we'd need some kind of dependency injection to build context before validation so models can still be passed as arguments to views. I'm sure he'll be game.</p> <p>Warning</p> <p>Although this will make it slightly easier to run synchronous IO (HTTP requests, DB. queries, etc.) from within validators, I strongly advise you keep IO separate from validation - do it before and use context, do it afterwards, avoid where possible making queries inside validation.</p>"},{"location":"blog/pydantic-v2/#model-namespace-cleanup","title":"Model Namespace Cleanup","text":"<p>For years I've wanted to clean up the model namespace, see pydantic#1001. This would avoid confusing gotchas when field names clash with methods on a model, it would also make it safer to add more methods to a model without risking new clashes.</p> <p>After much deliberation (and even giving a lightning talk at the python language submit about alternatives, see this discussion). I've decided to go with the simplest and clearest approach, at the expense of a bit more typing:</p> <p>All methods on models will start with <code>model_</code>, fields' names will not be allowed to start with <code>\"model\"</code> (aliases can be used if required).</p> <p>This will mean <code>BaseModel</code> will have roughly the following signature.</p> New BaseModel methods<pre><code>class BaseModel:\n    model_fields: List[FieldInfo]\n\"\"\"previously `__fields__`, although the format will change a lot\"\"\"\n    @classmethod\n    def model_validate(cls, data: Any, *, context=None) -&gt; Self:  # (1)\n\"\"\"\n        previously `parse_obj()`, validate data\n        \"\"\"\n    @classmethod\n    def model_validate_json(\n        cls,\n        data: str | bytes | bytearray,\n        *,\n        context=None\n    ) -&gt; Self:\n\"\"\"\n        previously `parse_raw(..., content_type='application/json')`\n        validate data from JSON\n        \"\"\"\n    @classmethod\n    def model_is_instance(cls, data: Any, *, context=None) -&gt; bool: # (2)\n\"\"\"\n        new, check if data is value for the model\n        \"\"\"\n    @classmethod\n    def model_is_instance_json(\n        cls,\n        data: str | bytes | bytearray,\n        *,\n        context=None\n    ) -&gt; bool:\n\"\"\"\n        Same as `model_is_instance`, but from JSON\n        \"\"\"\n    def model_dump(\n        self,\n        include: ... = None,\n        exclude: ... = None,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        mode: Literal['unchanged', 'dicts', 'json-compliant'] = 'unchanged',\n        converter: Callable[[Any], Any] | None = None\n    ) -&gt; Any:\n\"\"\"\n        previously `dict()`, as before\n        with new `mode` argument\n        \"\"\"\n    def model_dump_json(self, ...) -&gt; str:\n\"\"\"\n        previously `json()`, arguments as above\n        effectively equivalent to `json.dump(self.model_dump(..., mode='json'))`,\n        but more performant\n        \"\"\"\n    def model_json_schema(self, ...) -&gt; dict[str, Any]:\n\"\"\"\n        previously `schema()`, arguments roughly as before\n        JSON schema as a dict\n        \"\"\"\n    def model_update_forward_refs(self) -&gt; None:\n\"\"\"\n        previously `update_forward_refs()`, update forward references\n        \"\"\"\n    @classmethod\n    def model_construct(\n        self,\n        _fields_set: set[str] | None = None,\n        **values: Any\n    ) -&gt; Self:\n\"\"\"\n        previously `construct()`, arguments roughly as before\n        construct a model with no validation\n        \"\"\"\n    @classmethod\n    def model_customize_schema(cls, schema: dict[str, Any]) -&gt; dict[str, Any]:\n\"\"\"\n        new, way to customize validation,\n        e.g. if you wanted to alter how the model validates certain types,\n        or add validation for a specific type without custom types or\n        decorated validators\n        \"\"\"\n    class ModelConfig:\n\"\"\"\n        previously `Config`, configuration class for models\n        \"\"\"\n</code></pre> <ol> <li>see Validation Context for more information on <code>context</code></li> <li>see <code>is_instance</code> checks</li> </ol> <p>The following methods will be removed:</p> <ul> <li><code>.parse_file()</code> - was a mistake, should never have been in pydantic</li> <li><code>.parse_raw()</code> - partially replaced by <code>.model_validate_json()</code>, the other functionality was a mistake</li> <li><code>.from_orm()</code> - the functionality has been moved to config, see other improvements below</li> <li><code>.schema_json()</code> - mostly since it causes confusion between pydantic validation schema and JSON schema,   and can be replaced with just <code>json.dumps(m.model_json_schema())</code></li> <li><code>.copy()</code> instead we'll implement <code>__copy__</code> and let people use the <code>copy</code> module   (this removes some functionality) from <code>copy()</code> but there are bugs and ambiguities with the functionality anyway</li> </ul>"},{"location":"blog/pydantic-v2/#strict-api-api-documentation","title":"Strict API &amp; API documentation","text":"<p>When preparing for pydantic V2, we'll make a strict distinction between the public API and private functions &amp; classes. Private objects will be clearly identified as private via a <code>_internal</code> sub package to discourage use.</p> <p>The public API will have API documentation. I've recently been working with the wonderful mkdocstrings package for both dirty-equals and watchfiles documentation. I intend to use <code>mkdocstrings</code> to generate complete API documentation for V2.</p> <p>This wouldn't replace the current example-based somewhat informal documentation style but instead will augment it.</p>"},{"location":"blog/pydantic-v2/#error-descriptions","title":"Error descriptions","text":"<p>The way line errors (the individual errors within a <code>ValidationError</code>) are built has become much more sophisticated in pydantic-core.</p> <p>There's a well-defined set of error codes and messages.</p> <p>More will be added when other types are validated via pure python validators in pydantic.</p> <p>I would like to add a dedicated section to the documentation with extra information for each type of error.</p> <p>This would be another key in a line error: <code>documentation</code>, which would link to the appropriate section in the docs.</p> <p>Thus, errors might look like:</p> Line Errors Example<pre><code>[\n    {\n        'kind': 'greater_than_equal',\n        'loc': ['age'],\n        'message': 'Value must be greater than or equal to 18',\n        'input_value': 11,\n        'context': {'ge': 18},\n        'documentation': 'https://pydantic.dev/errors/#greater_than_equal',\n    },\n    {\n        'kind': 'bool_parsing',\n        'loc': ['is_developer'],\n        'message': 'Value must be a valid boolean, unable to interpret input',\n        'input_value': 'foobar',\n        'documentation': 'https://pydantic.dev/errors/#bool_parsing',\n    },\n]\n</code></pre> <p>I own the <code>pydantic.dev</code> domain and will use it for at least these errors so that even if the docs URL changes, the error will still link to the correct documentation. If developers don't want to show these errors to users, they can always process the errors list and filter out items from each error they don't need or want.</p>"},{"location":"blog/pydantic-v2/#no-pure-python-implementation","title":"No pure python implementation","text":"<p>Since pydantic-core is written in Rust, and I have absolutely no intention of rewriting it in python, pydantic V2 will only work where a binary package can be installed.</p> <p>pydantic-core will provide binaries in PyPI for (at least):</p> <ul> <li>Linux: <code>x86_64</code>, <code>aarch64</code>, <code>i686</code>, <code>armv7l</code>, <code>musl-x86_64</code> &amp; <code>musl-aarch64</code></li> <li>MacOS: <code>x86_64</code> &amp; <code>arm64</code> (except python 3.7)</li> <li>Windows: <code>amd64</code> &amp; <code>win32</code></li> <li>Web Assembly: <code>wasm32</code>   (pydantic-core is already   compiled for wasm32 using emscripten and unit tests pass, except where cpython itself has   problems)</li> </ul> <p>Binaries for pypy are a work in progress and will be added if possible, see pydantic-core#154.</p> <p>Other binaries can be added provided they can be (cross-)compiled on github actions. If no binary is available from PyPI, pydantic-core can be compiled from source if Rust stable is available.</p> <p>The only place where I know this will cause problems is Raspberry Pi, which is a mess when it comes to packages written in Rust for Python. Effectively, until that's fixed you'll likely have to install pydantic with <code>pip install -i https://pypi.org/simple/ pydantic</code>.</p>"},{"location":"blog/pydantic-v2/#pydantic-becomes-a-pure-python-package","title":"Pydantic becomes a pure python package","text":"<p>Pydantic V1.X is a pure python code base but is compiled with cython to provide some performance improvements. Since the \"hot\" code is moved to pydantic-core, pydantic itself can go back to being a pure python package.</p> <p>This should significantly reduce the size of the pydantic package and make unit tests of pydantic much faster. In addition:</p> <ul> <li>some constraints on pydantic code can be removed once it no-longer has to be compilable with cython</li> <li>debugging will be easier as you'll be able to drop straight into the pydantic codebase as you can with other,   pure python packages</li> </ul> <p>Some pieces of edge logic could get a little slower as they're no longer compiled.</p>"},{"location":"blog/pydantic-v2/#is_instance-like-checks","title":"<code>is_instance</code> like checks","text":"<p>Strict mode also means it makes sense to provide an <code>is_instance</code> method on models which effectively run validation then throws away the result while avoiding the (admittedly small) overhead of creating and raising an error or returning the validation result.</p> <p>To be clear, this isn't a real <code>isinstance</code> call, rather it is equivalent to</p> is_instance<pre><code>class BaseModel:\n    ...\n    @classmethod\n    def model_is_instance(cls, data: Any) -&gt; bool:\n        try:\n            cls(**data)\n        except ValidationError:\n            return False\n        else:\n            return True\n</code></pre>"},{"location":"blog/pydantic-v2/#im-dropping-the-word-parse-and-just-using-validate","title":"I'm dropping the word \"parse\" and just using \"validate\"","text":"<p>Partly due to the issues with the lack of strict mode, I've gone back and forth between using the terms \"parse\" and \"validate\" for what pydantic does.</p> <p>While pydantic is not simply a validation library (and I'm sure some would argue validation is not strictly what it does), most people use the word \"validation\".</p> <p>It's time to stop fighting that, and use consistent names.</p> <p>The word \"parse\" will no longer be used except when talking about JSON parsing, see model methods above.</p>"},{"location":"blog/pydantic-v2/#changes-to-custom-field-types","title":"Changes to custom field types","text":"<p>Since the core structure of validators has changed from \"a list of validators to call one after another\" to \"a tree of validators which call each other\", the <code>__get_validators__</code> way of defining custom field types no longer makes sense.</p> <p>Instead, we'll look for the attribute <code>__pydantic_validation_schema__</code> which must be a pydantic-core compliant schema for validating data to this field type (the <code>function</code> item can be a string, if so a function of that name will be taken from the class, see <code>'validate'</code> below).</p> <p>Here's an example of how a custom field type could be defined:</p> New custom field types<pre><code>from pydantic import ValidationSchema\n\nclass Foobar:\n    def __init__(self, value: str):\n        self.value = value\n\n    __pydantic_validation_schema__: ValidationSchema = {\n        'type': 'function',\n        'mode': 'after',\n        'function': 'validate',\n        'schema': {'type': 'str'}\n    }\n\n    @classmethod\n    def validate(cls, value):\n        if 'foobar' in value:\n            return Foobar(value)\n        else:\n            raise ValueError('expected foobar')\n</code></pre> <p>What's going on here: <code>__pydantic_validation_schema__</code> defines a schema which effectively says:</p> <p>Validate input data as a string, then call the <code>validate</code> function with that string, use the returned value as the final result of validation.</p> <p><code>ValidationSchema</code> is just an alias to <code>pydantic_core.Schema</code> which is a type defining the schema for validation schemas.</p> <p>Note</p> <p>pydantic-core schema has full type definitions although since the type is recursive, mypy can't provide static type analysis, pyright however can.</p> <p>We can probably provide one or more helper functions to make <code>__pydantic_validation_schema__</code> easier to generate.</p>"},{"location":"blog/pydantic-v2/#other-improvements","title":"Other Improvements","text":"<p>Some other things which will also change, IMHO for the better:</p> <ol> <li>Recursive models with cyclic references - although recursive models were supported by pydantic V1,    data with cyclic references caused recursion errors, in pydantic-core cyclic references are correctly detected    and a validation error is raised</li> <li>The reason I've been so keen to get pydantic-core to compile and run with wasm is that I want all examples    in the docs of pydantic V2 to be editable and runnable in the browser</li> <li>Full support for <code>TypedDict</code>, including <code>total=False</code> - e.g. omitted keys,    providing validation schema to a <code>TypedDict</code> field/item will use <code>Annotated</code>, e.g. <code>Annotated[str, Field(strict=True)]</code></li> <li><code>from_orm</code> has become <code>from_attributes</code> and is now defined at schema generation time    (either via model config or field config)</li> <li><code>input_value</code> has been added to each line error in a <code>ValidationError</code>, making errors easier to understand,    and more comprehensive details of errors to be provided to end users,    pydantic#784</li> <li><code>on_error</code> logic in a schema which allows either a default value to be used in the event of an error,    or that value to be omitted (in the case of a <code>total=False</code> <code>TypedDict</code>),    pydantic-core#151</li> <li><code>datetime</code>, <code>date</code>, <code>time</code> &amp; <code>timedelta</code> validation is improved, see the    speedate Rust library I built specifically for this purpose for more details</li> <li>Powerful \"priority\" system for optionally merging or overriding config in sub-models for nested schemas</li> <li>Pydantic will support annotated-types,    so you can do stuff like <code>Annotated[set[int], Len(0, 10)]</code> or <code>Name = Annotated[str, Len(1, 1024)]</code></li> <li>A single decorator for general usage - we should add a <code>validate</code> decorator which can be used:<ul> <li>on functions (replacing <code>validate_arguments</code>)</li> <li>on dataclasses, <code>pydantic.dataclasses.dataclass</code> will become an alias of this</li> <li>on <code>TypedDict</code>s</li> <li>On any supported type, e.g. <code>Union[...]</code>, <code>Dict[str, Thing]</code></li> <li>On Custom field types - e.g. anything with a <code>__pydantic_schema__</code> attribute</li> </ul> </li> <li>Easier validation error creation, I've often found myself wanting to raise <code>ValidationError</code>s outside     models, particularly in FastAPI     (here     is one method I've used), we should provide utilities to generate these errors</li> <li>Improve the performance of <code>__eq__</code> on models</li> <li>Computed fields, these having been an idea for a long time in pydantic - we should get them right</li> <li>Model validation that avoids instances of subclasses leaking data (particularly important for FastAPI),     see pydantic-core#155</li> <li>We'll now follow semvar properly and avoid breaking changes between minor versions,     as a result, major versions will become more common</li> <li>Improve generics to use <code>M(Basemodel, Generic[T])</code> instead of <code>M(GenericModel, Generic[T])</code> - e.g. <code>GenericModel</code>     can be removed; this results from no-longer needing to compile pydantic code with cython</li> </ol>"},{"location":"blog/pydantic-v2/#removed-features-limitations","title":"Removed Features &amp; Limitations","text":"<p>The emoji here is just for variation, I'm not frowning about any of this, these changes are either good IMHO (will make pydantic cleaner, easier to learn and easier to maintain) or irrelevant to 99.9+% of users.</p> <ol> <li><code>__root__</code> custom root models are no longer necessary since validation on any supported data type is allowed    without a model</li> <li><code>.parse_file()</code> and <code>.parse_raw()</code>, partially replaced with <code>.model_validate_json()</code>,     see model methods</li> <li><code>.schema_json()</code> &amp; <code>.copy()</code>, see model methods</li> <li><code>TypeError</code> are no longer considered as validation errors, but rather as internal errors, this is to better    catch errors in argument names in function validators.</li> <li>Subclasses of builtin types like <code>str</code>, <code>bytes</code> and <code>int</code> are coerced to their parent builtin type,    this is a limitation of how pydantic-core converts these types to Rust types during validation, if you have a    specific need to keep the type, you can use wrap validators or custom type validation as described above</li> <li>integers are represented in rust code as <code>i64</code>, meaning if you want to use ints where <code>abs(v) &gt; 2^63 \u2212 1</code>    (9,223,372,036,854,775,807), you'll need to use a wrap validator and your own logic</li> <li>Settings Management ??? - I definitely don't want to    remove the functionality, but it's something of a historical curiosity that it lives within pydantic,    perhaps it should move to a separate package, perhaps installable alongside pydantic with    <code>pip install pydantic[settings]</code>?</li> <li>The following <code>Config</code> properties will be removed:<ul> <li><code>fields</code> - it's very old (it pre-dates <code>Field</code>), can be removed</li> <li><code>allow_mutation</code> will be removed, instead <code>frozen</code> will be used</li> <li><code>error_msg_templates</code>, it's not properly documented anyway, error messages can be customized with external logic if required</li> <li><code>getter_dict</code> - pydantic-core has hardcoded <code>from_attributes</code> logic</li> <li><code>json_loads</code> - again this is hard coded in pydantic-core</li> <li><code>json_dumps</code> - possibly</li> <li><code>json_encoders</code> - see the export \"mode\" discussion above</li> <li><code>underscore_attrs_are_private</code> we should just choose a sensible default</li> <li><code>smart_union</code> - all unions are now \"smart\"</li> </ul> </li> <li><code>dict(model)</code> functionality should be removed, there's a much clearer distinction now that in 2017 when I     implemented this between a model and a dict</li> </ol>"},{"location":"blog/pydantic-v2/#features-remaining","title":"Features Remaining","text":"<p>The following features will remain (mostly) unchanged:</p> <ul> <li>JSONSchema, internally this will need to change a lot, but hopefully the external interface will remain unchanged</li> <li><code>dataclass</code> support, again internals might change, but not the external interface</li> <li><code>validate_arguments</code>, might be renamed, but otherwise remain</li> <li>hypothesis plugin, might be able to improve this as part of the general cleanup</li> </ul>"},{"location":"blog/pydantic-v2/#questions","title":"Questions","text":"<p>I hope the explanation above is useful. I'm sure people will have questions and feedback; I'm aware I've skipped over some features with limited detail (this post is already fairly long ).</p> <p>To allow feedback without being overwhelmed, I've created a \"Pydantic V2\" category for discussions on github - please feel free to create a discussion if you have any questions or suggestions. We will endeavour to read and respond to everyone.</p>"},{"location":"blog/pydantic-v2/#implementation-details","title":"Implementation Details","text":"<p>(This is yet to be built, so these are nascent ideas which might change)</p> <p>At the center of pydantic v2 will be a <code>PydanticValidator</code> class which looks roughly like this (note: this is just pseudo-code, it's not even valid python and is only supposed to be used to demonstrate the idea):</p> PydanticValidator<pre><code># type identifying data which has been validated,\n# as per pydantic-core, this can include \"fields_set\" data\nValidData = ...\n\n# any type we can perform validation for\nAnyOutputType = ...\n\nclass PydanticValidator:\n    def __init__(self, output_type: AnyOutputType, config: Config):\n        ...\n    def validate(self, input_data: Any) -&gt; ValidData:\n        ...\n    def validate_json(self, input_data: str | bytes | bytearray) -&gt; ValidData:\n        ...\n    def is_instance(self, input_data: Any) -&gt; bool:\n        ...\n    def is_instance_json(self, input_data: str | bytes | bytearray) -&gt; bool:\n        ...\n    def json_schema(self) -&gt; dict:\n        ...\n    def dump(\n        self,\n        data: ValidData,\n        include: ... = None,\n        exclude: ... = None,\n        by_alias: bool = False,\n        exclude_unset: bool = False,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        mode: Literal['unchanged', 'dicts', 'json-compliant'] = 'unchanged',\n        converter: Callable[[Any], Any] | None = None\n    ) -&gt; Any:\n        ...\n    def dump_json(self, ...) -&gt; str:\n        ...\n</code></pre> <p>This could be used directly, but more commonly will be used by the following:</p> <ul> <li><code>BaseModel</code></li> <li>the <code>validate</code> decorator described above</li> <li><code>pydantic.dataclasses.dataclass</code> (which might be an alias of <code>validate</code>)</li> <li>generics</li> </ul> <p>The aim will be to get pydantic V2 to a place were the vast majority of tests continue to pass unchanged.</p> <p>Thereby guaranteeing (as much as possible) that the external interface to pydantic and its behaviour are unchanged.</p>"},{"location":"blog/pydantic-v2/#conversion-table","title":"Conversion Table","text":"<p>The table below provisionally defines what input value types are allowed to which field types.</p> <p>An updated and complete version of this table will be included in the docs for V2.</p> <p>Note</p> <p>Some type conversion shown here is a significant departure from existing behavior, we may have to provide a config flag for backwards compatibility for a few of them, however pydantic V2 cannot be entirely backward compatible, see pydantic-core#152.</p> Field Type Input Mode Input Source Conditions <code>str</code> <code>str</code> both python, JSON - <code>str</code> <code>bytes</code> lax python assumes UTF-8, error on unicode decoding error <code>str</code> <code>bytearray</code> lax python assumes UTF-8, error on unicode decoding error <code>bytes</code> <code>bytes</code> both python - <code>bytes</code> <code>str</code> both JSON - <code>bytes</code> <code>str</code> lax python - <code>bytes</code> <code>bytearray</code> lax python - <code>int</code> <code>int</code> strict python, JSON max abs value 2^64 - <code>i64</code> is used internally, <code>bool</code> explicitly forbidden <code>int</code> <code>int</code> lax python, JSON <code>i64</code> <code>int</code> <code>float</code> lax python, JSON <code>i64</code>, must be exact int, e.g. <code>f % 1 == 0</code>, <code>nan</code>, <code>inf</code> raise errors <code>int</code> <code>Decimal</code> lax python, JSON <code>i64</code>, must be exact int, e.g. <code>f % 1 == 0</code> <code>int</code> <code>bool</code> lax python, JSON - <code>int</code> <code>str</code> lax python, JSON <code>i64</code>, must be numeric only, e.g. <code>[0-9]+</code> <code>float</code> <code>float</code> strict python, JSON <code>bool</code> explicitly forbidden <code>float</code> <code>float</code> lax python, JSON - <code>float</code> <code>int</code> lax python, JSON - <code>float</code> <code>str</code> lax python, JSON must match <code>[0-9]+(\\.[0-9]+)?</code> <code>float</code> <code>Decimal</code> lax python - <code>float</code> <code>bool</code> lax python, JSON - <code>bool</code> <code>bool</code> both python, JSON - <code>bool</code> <code>int</code> lax python, JSON allowed: <code>0, 1</code> <code>bool</code> <code>float</code> lax python, JSON allowed: <code>0, 1</code> <code>bool</code> <code>Decimal</code> lax python, JSON allowed: <code>0, 1</code> <code>bool</code> <code>str</code> lax python, JSON allowed: <code>'f', 'n', 'no', 'off', 'false', 't', 'y', 'on', 'yes', 'true'</code> <code>None</code> <code>None</code> both python, JSON - <code>date</code> <code>date</code> both python - <code>date</code> <code>datetime</code> lax python must be exact date, eg. no H, M, S, f <code>date</code> <code>str</code> both JSON format <code>YYYY-MM-DD</code> <code>date</code> <code>str</code> lax python format <code>YYYY-MM-DD</code> <code>date</code> <code>bytes</code> lax python format <code>YYYY-MM-DD</code> (UTF-8) <code>date</code> <code>int</code> lax python, JSON interpreted as seconds or ms from epoch, see speedate, must be exact date <code>date</code> <code>float</code> lax python, JSON interpreted as seconds or ms from epoch, see speedate, must be exact date <code>datetime</code> <code>datetime</code> both python - <code>datetime</code> <code>date</code> lax python - <code>datetime</code> <code>str</code> both JSON format <code>YYYY-MM-DDTHH:MM:SS.f</code> etc. see speedate <code>datetime</code> <code>str</code> lax python format <code>YYYY-MM-DDTHH:MM:SS.f</code> etc. see speedate <code>datetime</code> <code>bytes</code> lax python format <code>YYYY-MM-DDTHH:MM:SS.f</code> etc. see speedate, (UTF-8) <code>datetime</code> <code>int</code> lax python, JSON interpreted as seconds or ms from epoch, see speedate <code>datetime</code> <code>float</code> lax python, JSON interpreted as seconds or ms from epoch, see speedate <code>time</code> <code>time</code> both python - <code>time</code> <code>str</code> both JSON format <code>HH:MM:SS.FFFFFF</code> etc. see speedate <code>time</code> <code>str</code> lax python format <code>HH:MM:SS.FFFFFF</code> etc. see speedate <code>time</code> <code>bytes</code> lax python format <code>HH:MM:SS.FFFFFF</code> etc. see speedate, (UTF-8) <code>time</code> <code>int</code> lax python, JSON interpreted as seconds, range 0 - 86399 <code>time</code> <code>float</code> lax python, JSON interpreted as seconds, range 0 - 86399.9* <code>time</code> <code>Decimal</code> lax python, JSON interpreted as seconds, range 0 - 86399.9* <code>timedelta</code> <code>timedelta</code> both python - <code>timedelta</code> <code>str</code> both JSON format ISO8601 etc. see speedate <code>timedelta</code> <code>str</code> lax python format ISO8601 etc. see speedate <code>timedelta</code> <code>bytes</code> lax python format ISO8601 etc. see speedate, (UTF-8) <code>timedelta</code> <code>int</code> lax python, JSON interpreted as seconds <code>timedelta</code> <code>float</code> lax python, JSON interpreted as seconds <code>timedelta</code> <code>Decimal</code> lax python, JSON interpreted as seconds <code>dict</code> <code>dict</code> both python - <code>dict</code> <code>Object</code> both JSON - <code>dict</code> <code>mapping</code> lax python must implement the mapping interface and have an <code>items()</code> method <code>TypedDict</code> <code>dict</code> both python - <code>TypedDict</code> <code>Object</code> both JSON - <code>TypedDict</code> <code>Any</code> both python builtins not allowed, uses <code>getattr</code>, requires <code>from_attributes=True</code> <code>TypedDict</code> <code>mapping</code> lax python must implement the mapping interface and have an <code>items()</code> method <code>list</code> <code>list</code> both python - <code>list</code> <code>Array</code> both JSON - <code>list</code> <code>tuple</code> lax python - <code>list</code> <code>set</code> lax python - <code>list</code> <code>frozenset</code> lax python - <code>list</code> <code>dict_keys</code> lax python - <code>tuple</code> <code>tuple</code> both python - <code>tuple</code> <code>Array</code> both JSON - <code>tuple</code> <code>list</code> lax python - <code>tuple</code> <code>set</code> lax python - <code>tuple</code> <code>frozenset</code> lax python - <code>tuple</code> <code>dict_keys</code> lax python - <code>set</code> <code>set</code> both python - <code>set</code> <code>Array</code> both JSON - <code>set</code> <code>list</code> lax python - <code>set</code> <code>tuple</code> lax python - <code>set</code> <code>frozenset</code> lax python - <code>set</code> <code>dict_keys</code> lax python - <code>frozenset</code> <code>frozenset</code> both python - <code>frozenset</code> <code>Array</code> both JSON - <code>frozenset</code> <code>list</code> lax python - <code>frozenset</code> <code>tuple</code> lax python - <code>frozenset</code> <code>set</code> lax python - <code>frozenset</code> <code>dict_keys</code> lax python - <code>is_instance</code> <code>Any</code> both python <code>isinstance()</code> check returns <code>True</code> <code>is_instance</code> - both JSON never valid <code>callable</code> <code>Any</code> both python <code>callable()</code> check returns <code>True</code> <code>callable</code> - both JSON never valid <p>The <code>ModelClass</code> validator (use to create instances of a class) uses the <code>TypedDict</code> validator, then creates an instance with <code>__dict__</code> and <code>__fields_set__</code> set, so same rules apply as <code>TypedDict</code>.</p>"},{"location":"usage/dataclasses/","title":"Dataclasses","text":"<p>If you don't want to use pydantic's <code>BaseModel</code> you can instead get the same data validation on standard dataclasses (introduced in Python 3.7).</p> <p>Note</p> <p>Keep in mind that <code>pydantic.dataclasses.dataclass</code> is a drop-in replacement for <code>dataclasses.dataclass</code> with validation, not a replacement for <code>pydantic.BaseModel</code> (with a small difference in how initialization hooks work). There are cases where subclassing <code>pydantic.BaseModel</code> is the better choice.</p> <p>For more information and discussion see pydantic/pydantic#710.</p> <p>You can use all the standard pydantic field types, and the resulting dataclass will be identical to the one created by the standard library <code>dataclass</code> decorator.</p> <p>The underlying model and its schema can be accessed through <code>__pydantic_model__</code>. Also, fields that require a <code>default_factory</code> can be specified by either a <code>pydantic.Field</code> or a <code>dataclasses.field</code>.</p> <p><code>pydantic.dataclasses.dataclass</code>'s arguments are the same as the standard decorator, except one extra keyword argument <code>config</code> which has the same meaning as Config.</p> <p>Warning</p> <p>After v1.2, The Mypy plugin must be installed to type check pydantic dataclasses.</p> <p>For more information about combining validators with dataclasses, see dataclass validators.</p>"},{"location":"usage/dataclasses/#dataclass-config","title":"Dataclass Config","text":"<p>If you want to modify the <code>Config</code> like you would with a <code>BaseModel</code>, you have three options:</p> <p>Warning</p> <p>After v1.10, pydantic dataclasses support <code>Config.extra</code> but some default behaviour of stdlib dataclasses may prevail. For example, when <code>print</code>ing a pydantic dataclass with allowed extra fields, it will still use the <code>__str__</code> method of stdlib dataclass and show only the required fields. This may be improved further in the future.</p>"},{"location":"usage/dataclasses/#nested-dataclasses","title":"Nested dataclasses","text":"<p>Nested dataclasses are supported both in dataclasses and normal models.</p> <p>Dataclasses attributes can be populated by tuples, dictionaries or instances of the dataclass itself.</p>"},{"location":"usage/dataclasses/#stdlib-dataclasses-and-pydantic-dataclasses","title":"Stdlib dataclasses and pydantic dataclasses","text":""},{"location":"usage/dataclasses/#convert-stdlib-dataclasses-into-pydantic-dataclasses","title":"Convert stdlib dataclasses into pydantic dataclasses","text":"<p>Stdlib dataclasses (nested or not) can be easily converted into pydantic dataclasses by just decorating them with <code>pydantic.dataclasses.dataclass</code>. Pydantic will enhance the given stdlib dataclass but won't alter the default behaviour (i.e. without validation). It will instead create a wrapper around it to trigger validation that will act like a plain proxy. The stdlib dataclass can still be accessed via the <code>__dataclass__</code> attribute (see example below).</p>"},{"location":"usage/dataclasses/#choose-when-to-trigger-validation","title":"Choose when to trigger validation","text":"<p>As soon as your stdlib dataclass has been decorated with pydantic dataclass decorator, magic methods have been added to validate input data. If you want, you can still keep using your dataclass and choose when to trigger it.</p>"},{"location":"usage/dataclasses/#inherit-from-stdlib-dataclasses","title":"Inherit from stdlib dataclasses","text":"<p>Stdlib dataclasses (nested or not) can also be inherited and pydantic will automatically validate all the inherited fields.</p>"},{"location":"usage/dataclasses/#use-of-stdlib-dataclasses-with-basemodel","title":"Use of stdlib dataclasses with <code>BaseModel</code>","text":"<p>Bear in mind that stdlib dataclasses (nested or not) are automatically converted into pydantic dataclasses when mixed with <code>BaseModel</code>! Furthermore the generated pydantic dataclass will have the exact same configuration (<code>order</code>, <code>frozen</code>, ...) as the original one.</p>"},{"location":"usage/dataclasses/#use-custom-types","title":"Use custom types","text":"<p>Since stdlib dataclasses are automatically converted to add validation using custom types may cause some unexpected behaviour. In this case you can simply add <code>arbitrary_types_allowed</code> in the config!</p>"},{"location":"usage/dataclasses/#initialize-hooks","title":"Initialize hooks","text":"<p>When you initialize a dataclass, it is possible to execute code after validation with the help of <code>__post_init_post_parse__</code>. This is not the same as <code>__post_init__</code>, which executes code before validation.</p> <p>Tip</p> <p>If you use a stdlib <code>dataclass</code>, you may only have <code>__post_init__</code> available and wish the validation to be done before. In this case you can set <code>Config.post_init_call = 'after_validation'</code></p> <p>Since version v1.0, any fields annotated with <code>dataclasses.InitVar</code> are passed to both <code>__post_init__</code> and <code>__post_init_post_parse__</code>.</p>"},{"location":"usage/dataclasses/#difference-with-stdlib-dataclasses","title":"Difference with stdlib dataclasses","text":"<p>Note that the <code>dataclasses.dataclass</code> from Python stdlib implements only the <code>__post_init__</code> method since it doesn't run a validation step.</p> <p>When substituting usage of <code>dataclasses.dataclass</code> with <code>pydantic.dataclasses.dataclass</code>, it is recommended to move the code executed in the <code>__post_init__</code> method to the <code>__post_init_post_parse__</code> method, and only leave behind part of code which needs to be executed before validation.</p>"},{"location":"usage/dataclasses/#json-dumping","title":"JSON Dumping","text":"<p>Pydantic dataclasses do not feature a <code>.json()</code> function. To dump them as JSON, you will need to make use of the <code>pydantic_encoder</code> as follows:</p>"},{"location":"usage/devtools/","title":"Usage with devtools","text":"<p>Note</p> <p>Admission: I (the primary developer of pydantic) also develop python-devtools.</p> <p>python-devtools (<code>pip install devtools</code>) provides a number of tools which are useful during Python development, including <code>debug()</code> an alternative to <code>print()</code> which formats output in a way which should be easier to read than <code>print</code> as well as giving information about which file/line the print statement  is on and what value was printed.</p> <p>pydantic integrates with devtools by implementing the <code>__pretty__</code> method on most public classes.</p> <p>In particular <code>debug()</code> is useful when inspecting models:</p> <p>Will output in your terminal:</p>"},{"location":"usage/exporting_models/","title":"Exporting models","text":"<p>As well as accessing model attributes directly via their names (e.g. <code>model.foobar</code>), models can be converted and exported in a number of ways:</p>"},{"location":"usage/exporting_models/#modeldict","title":"<code>model.dict(...)</code>","text":"<p>This is the primary way of converting a model to a dictionary. Sub-models will be recursively converted to dictionaries.</p> <p>Arguments:</p> <ul> <li><code>include</code>: fields to include in the returned dictionary; see below</li> <li><code>exclude</code>: fields to exclude from the returned dictionary; see below</li> <li><code>by_alias</code>: whether field aliases should be used as keys in the returned dictionary; default <code>False</code></li> <li><code>exclude_unset</code>: whether fields which were not explicitly set when creating the model should   be excluded from the returned dictionary; default <code>False</code>.   Prior to v1.0, <code>exclude_unset</code> was known as <code>skip_defaults</code>; use of <code>skip_defaults</code> is now deprecated</li> <li><code>exclude_defaults</code>: whether fields which are equal to their default values (whether set or otherwise) should   be excluded from the returned dictionary; default <code>False</code></li> <li><code>exclude_none</code>: whether fields which are equal to <code>None</code> should be excluded from the returned dictionary; default   <code>False</code></li> </ul> <p>Example:</p>"},{"location":"usage/exporting_models/#dictmodel-and-iteration","title":"<code>dict(model)</code> and iteration","text":"<p>pydantic models can also be converted to dictionaries using <code>dict(model)</code>, and you can also iterate over a model's field using <code>for field_name, value in model:</code>. With this approach the raw field values are returned, so sub-models will not be converted to dictionaries.</p> <p>Example:</p>"},{"location":"usage/exporting_models/#modelcopy","title":"<code>model.copy(...)</code>","text":"<p><code>copy()</code> allows models to be duplicated, which is particularly useful for immutable models.</p> <p>Arguments:</p> <ul> <li><code>include</code>: fields to include in the returned dictionary; see below</li> <li><code>exclude</code>: fields to exclude from the returned dictionary; see below</li> <li><code>update</code>: a dictionary of values to change when creating the copied model</li> <li><code>deep</code>: whether to make a deep copy of the new model; default <code>False</code></li> </ul> <p>Example:</p>"},{"location":"usage/exporting_models/#modeljson","title":"<code>model.json(...)</code>","text":"<p>The <code>.json()</code> method will serialise a model to JSON. (For models with a custom root type, only the value for the <code>__root__</code> key is serialised)</p> <p>Arguments:</p> <ul> <li><code>include</code>: fields to include in the returned dictionary; see below</li> <li><code>exclude</code>: fields to exclude from the returned dictionary; see below</li> <li><code>by_alias</code>: whether field aliases should be used as keys in the returned dictionary; default <code>False</code></li> <li><code>exclude_unset</code>: whether fields which were not set when creating the model and have their default values should   be excluded from the returned dictionary; default <code>False</code>.   Prior to v1.0, <code>exclude_unset</code> was known as <code>skip_defaults</code>; use of <code>skip_defaults</code> is now deprecated</li> <li><code>exclude_defaults</code>: whether fields which are equal to their default values (whether set or otherwise) should   be excluded from the returned dictionary; default <code>False</code></li> <li><code>exclude_none</code>: whether fields which are equal to <code>None</code> should be excluded from the returned dictionary; default   <code>False</code></li> <li><code>encoder</code>: a custom encoder function passed to the <code>default</code> argument of <code>json.dumps()</code>; defaults to a custom   encoder designed to take care of all common types</li> <li><code>**dumps_kwargs</code>: any other keyword arguments are passed to <code>json.dumps()</code>, e.g. <code>indent</code>.</li> </ul> <p>pydantic can serialise many commonly used types to JSON (e.g. <code>datetime</code>, <code>date</code> or <code>UUID</code>) which would normally fail with a simple <code>json.dumps(foobar)</code>.</p>"},{"location":"usage/exporting_models/#json_encoders","title":"<code>json_encoders</code>","text":"<p>Serialisation can be customised on a model using the <code>json_encoders</code> config property; the keys should be types (or names of types for forward references), and the values should be functions which serialise that type (see the example below):</p> <p>By default, <code>timedelta</code> is encoded as a simple float of total seconds. The <code>timedelta_isoformat</code> is provided as an optional alternative which implements ISO 8601 time diff encoding.</p> <p>The <code>json_encoders</code> are also merged during the models inheritance with the child encoders taking precedence over the parent one.</p>"},{"location":"usage/exporting_models/#serialising-self-reference-or-other-models","title":"Serialising self-reference or other models","text":"<p>By default, models are serialised as dictionaries. If you want to serialise them differently, you can add <code>models_as_dict=False</code> when calling <code>json()</code> method and add the classes of the model in <code>json_encoders</code>. In case of forward references, you can use a string with the class name instead of the class itself</p>"},{"location":"usage/exporting_models/#serialising-subclasses","title":"Serialising subclasses","text":"<p>Note</p> <p>New in version v1.5.</p> <p>Subclasses of common types were not automatically serialised to JSON before v1.5.</p> <p>Subclasses of common types are automatically encoded like their super-classes:</p>"},{"location":"usage/exporting_models/#custom-json-deserialisation","title":"Custom JSON (de)serialisation","text":"<p>To improve the performance of encoding and decoding JSON, alternative JSON implementations (e.g. ujson) can be used via the <code>json_loads</code> and <code>json_dumps</code> properties of <code>Config</code>.</p> <p><code>ujson</code> generally cannot be used to dump JSON since it doesn't support encoding of objects like datetimes and does not accept a <code>default</code> fallback function argument. To do this, you may use another library like orjson.</p> <p>Note that <code>orjson</code> takes care of <code>datetime</code> encoding natively, making it faster than <code>json.dumps</code> but meaning you cannot always customise the encoding using <code>Config.json_encoders</code>.</p>"},{"location":"usage/exporting_models/#pickledumpsmodel","title":"<code>pickle.dumps(model)</code>","text":"<p>Using the same plumbing as <code>copy()</code>, pydantic models support efficient pickling and unpickling.</p>"},{"location":"usage/exporting_models/#advanced-include-and-exclude","title":"Advanced include and exclude","text":"<p>The <code>dict</code>, <code>json</code>, and <code>copy</code> methods support <code>include</code> and <code>exclude</code> arguments which can either be sets or dictionaries. This allows nested selection of which fields to export:</p> <p>The <code>True</code> indicates that we want to exclude or include an entire key, just as if we included it in a set. Of course, the same can be done at any depth level.</p> <p>Special care must be taken when including or excluding fields from a list or tuple of submodels or dictionaries.  In this scenario, <code>dict</code> and related methods expect integer keys for element-wise inclusion or exclusion. To exclude a field from every member of a list or tuple, the dictionary key <code>'__all__'</code> can be used as follows:</p> <p>The same holds for the <code>json</code> and <code>copy</code> methods.</p>"},{"location":"usage/exporting_models/#model-and-field-level-include-and-exclude","title":"Model and field level include and exclude","text":"<p>In addition to the explicit arguments <code>exclude</code> and <code>include</code> passed to <code>dict</code>, <code>json</code> and <code>copy</code> methods, we can also pass the <code>include</code>/<code>exclude</code> arguments directly to the <code>Field</code> constructor or the equivalent <code>field</code> entry in the models <code>Config</code> class:</p> <p>In the case where multiple strategies are used, <code>exclude</code>/<code>include</code> fields are merged according to the following rules:</p> <ul> <li>First, model config level settings (via <code>\"fields\"</code> entry) are merged per field with the field constructor settings (i.e. <code>Field(..., exclude=True)</code>), with the field constructor taking priority.</li> <li>The resulting settings are merged per class with the explicit settings on <code>dict</code>, <code>json</code>, <code>copy</code> calls with the explicit settings taking priority.</li> </ul> <p>Note that while merging settings, <code>exclude</code> entries are merged by computing the \"union\" of keys, while <code>include</code> entries are merged by computing the \"intersection\" of keys.</p> <p>The resulting merged exclude settings:</p> <p>are the same as using merged include settings as follows:</p>"},{"location":"usage/model_config/","title":"Model Config","text":"<p>Behaviour of pydantic can be controlled via the <code>Config</code> class on a model or a pydantic dataclass.</p> <p>Also, you can specify config options as model class kwargs:</p> <p>Similarly, if using the <code>@dataclass</code> decorator:</p>"},{"location":"usage/model_config/#options","title":"Options","text":"<code>title</code> the title for the generated JSON Schema <code>anystr_strip_whitespace</code> whether to strip leading and trailing whitespace for str &amp; byte types (default: <code>False</code>) <code>anystr_upper</code> whether to make all characters uppercase for str &amp; byte types (default: <code>False</code>) <code>anystr_lower</code> whether to make all characters lowercase for str &amp; byte types (default: <code>False</code>) <code>min_anystr_length</code> the min length for str &amp; byte types (default: <code>0</code>) <code>max_anystr_length</code> the max length for str &amp; byte types (default: <code>None</code>) <code>validate_all</code> whether to validate field defaults (default: <code>False</code>) <code>extra</code> whether to ignore, allow, or forbid extra attributes during model initialization. Accepts the string values of <code>'ignore'</code>, <code>'allow'</code>, or <code>'forbid'</code>, or values of the <code>Extra</code> enum (default: <code>Extra.ignore</code>). <code>'forbid'</code> will cause validation to fail if extra attributes are included, <code>'ignore'</code> will silently ignore any extra attributes, and <code>'allow'</code> will assign the attributes to the model. <code>allow_mutation</code> whether or not models are faux-immutable, i.e. whether <code>__setattr__</code> is allowed (default: <code>True</code>) <p><code>frozen</code></p> <p>Warning</p> <p>This parameter is in beta</p> setting <code>frozen=True</code> does everything that <code>allow_mutation=False</code> does, and also generates a <code>__hash__()</code> method for the model. This makes instances of the model potentially hashable if all the attributes are hashable. (default: <code>False</code>) <code>use_enum_values</code> whether to populate models with the <code>value</code> property of enums, rather than the raw enum. This may be useful if you want to serialise <code>model.dict()</code> later (default: <code>False</code>) <code>fields</code> a <code>dict</code> containing schema information for each field; this is equivalent to using the <code>Field</code> class, except when a field is already defined through annotation or the Field class, in which case only <code>alias</code>, <code>include</code>, <code>exclude</code>, <code>min_length</code>, <code>max_length</code>, <code>regex</code>, <code>gt</code>, <code>lt</code>, <code>gt</code>, <code>le</code>, <code>multiple_of</code>, <code>max_digits</code>, <code>decimal_places</code>, <code>min_items</code>, <code>max_items</code>, <code>unique_items</code> and allow_mutation can be set (for example you cannot set default of default_factory)  (default: <code>None</code>) <code>validate_assignment</code> whether to perform validation on assignment to attributes (default: <code>False</code>) <code>allow_population_by_field_name</code> whether an aliased field may be populated by its name as given by the model attribute, as well as the alias (default: <code>False</code>) <p>Note</p> <p>The name of this configuration setting was changed in v1.0 from <code>allow_population_by_alias</code> to <code>allow_population_by_field_name</code>.</p> <code>error_msg_templates</code> a <code>dict</code> used to override the default error message templates. Pass in a dictionary with keys matching the error messages you want to override (default: <code>{}</code>) <code>arbitrary_types_allowed</code> whether to allow arbitrary user types for fields (they are validated simply by checking if the value is an instance of the type). If <code>False</code>, <code>RuntimeError</code> will be raised on model declaration (default: <code>False</code>). See an example in Field Types. <code>orm_mode</code> whether to allow usage of ORM mode <code>getter_dict</code> a custom class (which should inherit from <code>GetterDict</code>) to use when decomposing arbitrary classes for validation, for use with <code>orm_mode</code>; see Data binding. <code>alias_generator</code> a callable that takes a field name and returns an alias for it; see the dedicated section <code>keep_untouched</code> a tuple of types (e.g. descriptors) for a model's default values that should not be changed during model creation and will not be included in the model schemas. Note: this means that attributes on the model with defaults of this type, not annotations of this type, will be left alone. <code>schema_extra</code> a <code>dict</code> used to extend/update the generated JSON Schema, or a callable to post-process it; see schema customization <code>json_loads</code> a custom function for decoding JSON; see custom JSON (de)serialisation <code>json_dumps</code> a custom function for encoding JSON; see custom JSON (de)serialisation <code>json_encoders</code> a <code>dict</code> used to customise the way types are encoded to JSON; see JSON Serialisation <code>underscore_attrs_are_private</code> whether to treat any underscore non-class var attrs as private, or leave them as is; see Private model attributes <code>copy_on_model_validation</code> string literal to control how models instances are processed during validation,  with the following means (see #4093 for a full discussion of the changes to this field): <ul> <li><code>'none'</code> - models are not copied on validation, they're simply kept \"untouched\"</li> <li><code>'shallow'</code> - models are shallow copied, this is the default</li> <li><code>'deep'</code> - models are deep copied </li> </ul> <code>smart_union</code> whether pydantic should try to check all types inside <code>Union</code> to prevent undesired coercion; see the dedicated section <code>post_init_call</code> whether stdlib dataclasses <code>__post_init__</code> should be run before (default behaviour with value <code>'before_validation'</code>) or after (value <code>'after_validation'</code>) parsing and validation when they are converted. <code>allow_inf_nan</code> whether to allow infinity (<code>+inf</code> an <code>-inf</code>) and NaN values to float fields, defaults to <code>True</code>, set to <code>False</code> for compatibility with <code>JSON</code>, see #3994 for more details, added in V1.10"},{"location":"usage/model_config/#change-behaviour-globally","title":"Change behaviour globally","text":"<p>If you wish to change the behaviour of pydantic globally, you can create your own custom <code>BaseModel</code> with custom <code>Config</code> since the config is inherited</p>"},{"location":"usage/model_config/#alias-generator","title":"Alias Generator","text":"<p>If data source field names do not match your code style (e. g. CamelCase fields), you can automatically generate aliases using <code>alias_generator</code>:</p> <p>Here camel case refers to \"upper camel case\" aka pascal case e.g. <code>CamelCase</code>. If you'd like instead to use lower camel case e.g. <code>camelCase</code>, instead use the <code>to_lower_camel</code> function.</p>"},{"location":"usage/model_config/#alias-precedence","title":"Alias Precedence","text":"<p>Warning</p> <p>Alias priority logic changed in v1.4 to resolve buggy and unexpected behaviour in previous versions. In some circumstances this may represent a breaking change, see #1178 and the precedence order below for details.</p> <p>In the case where a field's alias may be defined in multiple places, the selected value is determined as follows (in descending order of priority):</p> <ol> <li>Set via <code>Field(..., alias=&lt;alias&gt;)</code>, directly on the model</li> <li>Defined in <code>Config.fields</code>, directly on the model</li> <li>Set via <code>Field(..., alias=&lt;alias&gt;)</code>, on a parent model</li> <li>Defined in <code>Config.fields</code>, on a parent model</li> <li>Generated by <code>alias_generator</code>, regardless of whether it's on the model or a parent</li> </ol> <p>Note</p> <p>This means an <code>alias_generator</code> defined on a child model does not take priority over an alias defined on a field in a parent model.</p> <p>For example:</p>"},{"location":"usage/model_config/#smart-union","title":"Smart Union","text":"<p>By default, as explained here, pydantic tries to validate (and coerce if it can) in the order of the <code>Union</code>. So sometimes you may have unexpected coerced data.</p> <p>To prevent this, you can enable <code>Config.smart_union</code>. Pydantic will then check all allowed types before even trying to coerce. Know that this is of course slower, especially if your <code>Union</code> is quite big.</p> <p>Warning</p> <p>Note that this option does not support compound types yet (e.g. differentiate <code>List[int]</code> and <code>List[str]</code>). This option will be improved further once a strict mode is added in pydantic and will probably be the default behaviour in v2!</p>"},{"location":"usage/models/","title":"Models","text":"<p>The primary means of defining objects in pydantic is via models  (models are simply classes which inherit from <code>BaseModel</code>).</p> <p>You can think of models as similar to types in strictly typed languages, or as the requirements of a single endpoint in an API.</p> <p>Untrusted data can be passed to a model, and after parsing and validation pydantic guarantees that the fields of the resultant model instance will conform to the field types defined on the model.</p> <p>Note</p> <p>pydantic is primarily a parsing library, not a validation library. Validation is a means to an end: building a model which conforms to the types and constraints provided.</p> <p>In other words, pydantic guarantees the types and constraints of the output model, not the input data.</p> <p>This might sound like an esoteric distinction, but it is not. If you're unsure what this means or how it might affect your usage you should read the section about Data Conversion below.</p> <p>Although validation is not the main purpose of pydantic, you can use this library for custom validation.</p>"},{"location":"usage/models/#basic-model-usage","title":"Basic model usage","text":"<p><pre><code>from pydantic import BaseModel\n\nclass User(BaseModel):\n    id: int\n    name = 'Jane Doe'\n</code></pre> <code>User</code> here is a model with two fields <code>id</code> which is an integer and is required,  and <code>name</code> which is a string and is not required (it has a default value). The type of <code>name</code> is inferred from the default value, and so a type annotation is not required (however note this warning about field  order when some fields do not have type annotations). <pre><code>user = User(id='123')\nuser_x = User(id='123.45')\n</code></pre> <code>user</code> here is an instance of <code>User</code>. Initialisation of the object will perform all parsing and validation, if no <code>ValidationError</code> is raised, you know the resulting model instance is valid. <pre><code>assert user.id == 123\nassert user_x.id == 123\nassert isinstance(user_x.id, int)  # Note that 123.45 was casted to an int and its value is 123\n</code></pre> More details on the casting in the case of <code>user_x</code> can be found in Data Conversion. Fields of a model can be accessed as normal attributes of the user object. The string '123' has been cast to an int as per the field type <pre><code>assert user.name == 'Jane Doe'\n</code></pre> <code>name</code> wasn't set when user was initialised, so it has the default value <pre><code>assert user.__fields_set__ == {'id'}\n</code></pre> The fields which were supplied when user was initialised. <pre><code>assert user.dict() == dict(user) == {'id': 123, 'name': 'Jane Doe'}\n</code></pre> Either <code>.dict()</code> or <code>dict(user)</code> will provide a dict of fields, but <code>.dict()</code> can take numerous other arguments. <pre><code>user.id = 321\nassert user.id == 321\n</code></pre> This model is mutable so field values can be changed.</p>"},{"location":"usage/models/#model-properties","title":"Model properties","text":"<p>The example above only shows the tip of the iceberg of what models can do.  Models possess the following methods and attributes:</p> <code>dict()</code> returns a dictionary of the model's fields and values;  cf. exporting models <code>json()</code> returns a JSON string representation <code>dict()</code>;  cf. exporting models <code>copy()</code> returns a copy (by default, shallow copy) of the model; cf. exporting models <code>parse_obj()</code> a utility for loading any object into a model with error handling if the object is not a dictionary; cf. helper functions <code>parse_raw()</code> a utility for loading strings of numerous formats; cf. helper functions <code>parse_file()</code> like <code>parse_raw()</code> but for file paths; cf. helper functions <code>from_orm()</code> loads data into a model from an arbitrary class; cf. ORM mode <code>schema()</code> returns a dictionary representing the model as JSON Schema; cf. schema <code>schema_json()</code> returns a JSON string representation of <code>schema()</code>; cf. schema <code>construct()</code> a class method for creating models without running validation;  cf. Creating models without validation <code>__fields_set__</code> Set of names of fields which were set when the model instance was initialised <code>__fields__</code> a dictionary of the model's fields <code>__config__</code> the configuration class for the model, cf. model config"},{"location":"usage/models/#recursive-models","title":"Recursive Models","text":"<p>More complex hierarchical data structures can be defined using models themselves as types in annotations.</p> <p>For self-referencing models, see postponed annotations.</p>"},{"location":"usage/models/#orm-mode-aka-arbitrary-class-instances","title":"ORM Mode (aka Arbitrary Class Instances)","text":"<p>Pydantic models can be created from arbitrary class instances to support models that map to ORM objects.</p> <p>To do this:</p> <ol> <li>The Config property <code>orm_mode</code> must be set to <code>True</code>.</li> <li>The special constructor <code>from_orm</code> must be used to create the model instance.</li> </ol> <p>The example here uses SQLAlchemy, but the same approach should work for any ORM.</p>"},{"location":"usage/models/#reserved-names","title":"Reserved names","text":"<p>You may want to name a Column after a reserved SQLAlchemy field. In that case, Field aliases will be convenient:</p> <p>Note</p> <p>The example above works because aliases have priority over field names for field population. Accessing <code>SQLModel</code>'s <code>metadata</code> attribute would lead to a <code>ValidationError</code>.</p>"},{"location":"usage/models/#recursive-orm-models","title":"Recursive ORM models","text":"<p>ORM instances will be parsed with <code>from_orm</code> recursively as well as at the top level.</p> <p>Here a vanilla class is used to demonstrate the principle, but any ORM class could be used instead.</p>"},{"location":"usage/models/#data-binding","title":"Data binding","text":"<p>Arbitrary classes are processed by pydantic using the <code>GetterDict</code> class (see utils.py), which attempts to provide a dictionary-like interface to any class. You can customise how this works by setting your own sub-class of <code>GetterDict</code> as the value of <code>Config.getter_dict</code> (see config).</p> <p>You can also customise class validation using root_validators with <code>pre=True</code>.  In this case your validator function will be passed a <code>GetterDict</code> instance which you may copy and modify.</p> <p>The <code>GetterDict</code> instance will be called for each field with a sentinel as a fallback (if no other default value is set). Returning this sentinel means that the field is missing. Any other value will be interpreted as the value of the field.</p>"},{"location":"usage/models/#error-handling","title":"Error Handling","text":"<p>pydantic will raise <code>ValidationError</code> whenever it finds an error in the data it's validating.</p> <p>Note</p> <p>Validation code should not raise <code>ValidationError</code> itself, but rather raise <code>ValueError</code>, <code>TypeError</code> or <code>AssertionError</code> (or subclasses of <code>ValueError</code> or <code>TypeError</code>) which will be caught and used to populate <code>ValidationError</code>.</p> <p>One exception will be raised regardless of the number of errors found, that <code>ValidationError</code> will contain information about all the errors and how they happened.</p> <p>You can access these errors in several ways:</p> <code>e.errors()</code> method will return list of errors found in the input data. <code>e.json()</code> method will return a JSON representation of <code>errors</code>. <code>str(e)</code> method will return a human readable representation of the errors. <p>Each error object contains:</p> <code>loc</code> the error's location as a list. The first item in the list will be the field where the error occurred, and if the field is a sub-model, subsequent items will be present to indicate the nested location of the error. <code>type</code> a computer-readable identifier of the error type. <code>msg</code> a human readable explanation of the error. <code>ctx</code> an optional object which contains values required to render the error message. <p>As a demonstration:</p>"},{"location":"usage/models/#custom-errors","title":"Custom Errors","text":"<p>In your custom data types or validators you should use <code>ValueError</code>, <code>TypeError</code> or <code>AssertionError</code> to raise errors.</p> <p>See validators for more details on use of the <code>@validator</code> decorator.</p> <p>You can also define your own error classes, which can specify a custom error code, message template, and context:</p>"},{"location":"usage/models/#helper-functions","title":"Helper Functions","text":"<p>Pydantic provides three <code>classmethod</code> helper functions on models for parsing data:</p> <ul> <li><code>parse_obj</code>: this is very similar to the <code>__init__</code> method of the model, except it takes a dict   rather than keyword arguments. If the object passed is not a dict a <code>ValidationError</code> will be raised.</li> <li><code>parse_raw</code>: this takes a str or bytes and parses it as json, then passes the result to <code>parse_obj</code>.   Parsing pickle data is also supported by setting the <code>content_type</code> argument appropriately.</li> <li><code>parse_file</code>: this takes in a file path, reads the file and passes the contents to <code>parse_raw</code>. If <code>content_type</code> is omitted,   it is inferred from the file's extension.</li> </ul> <p>Warning</p> <p>To quote the official <code>pickle</code> docs, \"The pickle module is not secure against erroneous or maliciously constructed data. Never unpickle data received from an untrusted or unauthenticated source.\" </p> <p>Info</p> <p>Because it can result in arbitrary code execution, as a security measure, you need to explicitly pass <code>allow_pickle</code> to the parsing function in order to load <code>pickle</code> data.</p>"},{"location":"usage/models/#creating-models-without-validation","title":"Creating models without validation","text":"<p>pydantic also provides the <code>construct()</code> method which allows models to be created without validation this can be useful when data has already been validated or comes from a trusted source and you want to create a model as efficiently as possible (<code>construct()</code> is generally around 30x faster than creating a model with full validation).</p> <p>Warning</p> <p><code>construct()</code> does not do any validation, meaning it can create models which are invalid. You should only ever use the <code>construct()</code> method with data which has already been validated, or you trust.</p> <p>The <code>_fields_set</code> keyword argument to <code>construct()</code> is optional, but allows you to be more precise about  which fields were originally set and which weren't. If it's omitted <code>__fields_set__</code> will just be the keys of the data provided. </p> <p>For example, in the example above, if <code>_fields_set</code> was not provided,  <code>new_user.__fields_set__</code> would be <code>{'id', 'age', 'name'}</code>.</p>"},{"location":"usage/models/#generic-models","title":"Generic Models","text":"<p>Pydantic supports the creation of generic models to make it easier to reuse a common model structure.</p> <p>In order to declare a generic model, you perform the following steps:</p> <ul> <li>Declare one or more <code>typing.TypeVar</code> instances to use to parameterize your model.</li> <li>Declare a pydantic model that inherits from <code>pydantic.generics.GenericModel</code> and <code>typing.Generic</code>,   where you pass the <code>TypeVar</code> instances as parameters to <code>typing.Generic</code>.</li> <li>Use the <code>TypeVar</code> instances as annotations where you will want to replace them with other types or   pydantic models.</li> </ul> <p>Here is an example using <code>GenericModel</code> to create an easily-reused HTTP response payload wrapper:</p> <p>If you set <code>Config</code> or make use of <code>validator</code> in your generic model definition, it is applied to concrete subclasses in the same way as when inheriting from <code>BaseModel</code>. Any methods defined on your generic class will also be inherited.</p> <p>Pydantic's generics also integrate properly with mypy, so you get all the type checking you would expect mypy to provide if you were to declare the type without using <code>GenericModel</code>.</p> <p>Note</p> <p>Internally, pydantic uses <code>create_model</code> to generate a (cached) concrete <code>BaseModel</code> at runtime, so there is essentially zero overhead introduced by making use of <code>GenericModel</code>.</p> <p>To inherit from a GenericModel without replacing the <code>TypeVar</code> instance, a class must also inherit from  <code>typing.Generic</code>:</p> <p>You can also create a generic subclass of a <code>GenericModel</code> that partially or fully replaces the type  parameters in the superclass.</p> <p>If the name of the concrete subclasses is important, you can also override the default behavior:</p> <p>Using the same TypeVar in nested models allows you to enforce typing relationships at different points in your model:</p> <p>Pydantic also treats <code>GenericModel</code> similarly to how it treats built-in generic types like <code>List</code> and <code>Dict</code> when it comes to leaving them unparameterized, or using bounded <code>TypeVar</code> instances:    </p> <ul> <li>If you don't specify parameters before instantiating the generic model, they will be treated as <code>Any</code></li> <li>You can parametrize models with one or more bounded parameters to add subclass checks</li> </ul> <p>Also, like <code>List</code> and <code>Dict</code>, any parameters specified using a <code>TypeVar</code> can later be substituted with concrete types.</p>"},{"location":"usage/models/#dynamic-model-creation","title":"Dynamic model creation","text":"<p>There are some occasions where the shape of a model is not known until runtime. For this pydantic provides the <code>create_model</code> method to allow models to be created on the fly.</p> <p>Here <code>StaticFoobarModel</code> and <code>DynamicFoobarModel</code> are identical.</p> <p>Warning</p> <p>See the note in Required Optional Fields for the distinction between an ellipsis as a field default and annotation-only fields.  See pydantic/pydantic#1047 for more details.</p> <p>Fields are defined by either a tuple of the form <code>(&lt;type&gt;, &lt;default value&gt;)</code> or just a default value. The special key word arguments <code>__config__</code> and <code>__base__</code> can be used to customise the new model. This includes extending a base model with extra fields.</p> <p>You can also add validators by passing a dict to the <code>__validators__</code> argument.</p>"},{"location":"usage/models/#model-creation-from-namedtuple-or-typeddict","title":"Model creation from <code>NamedTuple</code> or <code>TypedDict</code>","text":"<p>Sometimes you already use in your application classes that inherit from <code>NamedTuple</code> or <code>TypedDict</code> and you don't want to duplicate all your information to have a <code>BaseModel</code>. For this pydantic provides <code>create_model_from_namedtuple</code> and <code>create_model_from_typeddict</code> methods. Those methods have the exact same keyword arguments as <code>create_model</code>.</p>"},{"location":"usage/models/#custom-root-types","title":"Custom Root Types","text":"<p>Pydantic models can be defined with a custom root type by declaring the <code>__root__</code> field. </p> <p>The root type can be any type supported by pydantic, and is specified by the type hint on the <code>__root__</code> field. The root value can be passed to the model <code>__init__</code> via the <code>__root__</code> keyword argument, or as the first and only argument to <code>parse_obj</code>.</p> <p>If you call the <code>parse_obj</code> method for a model with a custom root type with a dict as the first argument, the following logic is used:</p> <ul> <li>If the custom root type is a mapping type (eg., <code>Dict</code> or <code>Mapping</code>),   the argument itself is always validated against the custom root type.</li> <li>For other custom root types, if the dict has precisely one key with the value <code>__root__</code>,   the corresponding value will be validated against the custom root type.</li> <li>Otherwise, the dict itself is validated against the custom root type.    </li> </ul> <p>This is demonstrated in the following example:</p> <p>Warning</p> <p>Calling the <code>parse_obj</code> method on a dict with the single key <code>\"__root__\"</code> for non-mapping custom root types is currently supported for backwards compatibility, but is not recommended and may be dropped in a future version.</p> <p>If you want to access items in the <code>__root__</code> field directly or to iterate over the items, you can implement custom <code>__iter__</code> and <code>__getitem__</code> functions, as shown in the following example.</p>"},{"location":"usage/models/#faux-immutability","title":"Faux Immutability","text":"<p>Models can be configured to be immutable via <code>allow_mutation = False</code>. When this is set, attempting to change the values of instance attributes will raise errors. See model config for more details on <code>Config</code>.</p> <p>Warning</p> <p>Immutability in Python is never strict. If developers are determined/stupid they can always modify a so-called \"immutable\" object.</p> <p>Trying to change <code>a</code> caused an error, and <code>a</code> remains unchanged. However, the dict <code>b</code> is mutable, and the immutability of <code>foobar</code> doesn't stop <code>b</code> from being changed.</p>"},{"location":"usage/models/#abstract-base-classes","title":"Abstract Base Classes","text":"<p>Pydantic models can be used alongside Python's Abstract Base Classes (ABCs).</p>"},{"location":"usage/models/#field-ordering","title":"Field Ordering","text":"<p>Field order is important in models for the following reasons:</p> <ul> <li>validation is performed in the order fields are defined; fields validators    can access the values of earlier fields, but not later ones</li> <li>field order is preserved in the model schema</li> <li>field order is preserved in validation errors</li> <li>field order is preserved by <code>.dict()</code> and <code>.json()</code> etc.</li> </ul> <p>As of v1.0 all fields with annotations (whether annotation-only or with a default value) will precede all fields without an annotation. Within their respective groups, fields remain in the order they were defined.</p> <p>Warning</p> <p>As demonstrated by the example above, combining the use of annotated and non-annotated fields in the same model can result in surprising field orderings. (This is due to limitations of Python)</p> <p>Therefore, we recommend adding type annotations to all fields, even when a default value would determine the type by itself to guarantee field order is preserved.</p>"},{"location":"usage/models/#required-fields","title":"Required fields","text":"<p>To declare a field as required, you may declare it using just an annotation, or you may use an ellipsis (<code>...</code>)  as the value:</p> <p>Where <code>Field</code> refers to the field function.</p> <p>Here <code>a</code>, <code>b</code> and <code>c</code> are all required. However, use of the ellipses in <code>b</code> will not work well with mypy, and as of v1.0 should be avoided in most cases.</p>"},{"location":"usage/models/#required-optional-fields","title":"Required Optional fields","text":"<p>Warning</p> <p>Since version v1.2 annotation only nullable (<code>Optional[...]</code>, <code>Union[None, ...]</code> and <code>Any</code>) fields and nullable fields with an ellipsis (<code>...</code>) as the default value, no longer mean the same thing.</p> <p>In some situations this may cause v1.2 to not be entirely backwards compatible with earlier v1.* releases.</p> <p>If you want to specify a field that can take a <code>None</code> value while still being required, you can use <code>Optional</code> with <code>...</code>:</p> <p>In this model, <code>a</code>, <code>b</code>, and <code>c</code> can take <code>None</code> as a value. But <code>a</code> is optional, while <code>b</code> and <code>c</code> are required. <code>b</code> and <code>c</code> require a value, even if the value is <code>None</code>.</p>"},{"location":"usage/models/#field-with-dynamic-default-value","title":"Field with dynamic default value","text":"<p>When declaring a field with a default value, you may want it to be dynamic (i.e. different for each model). To do this, you may want to use a <code>default_factory</code>.</p> <p>In Beta</p> <p>The <code>default_factory</code> argument is in beta, it has been added to pydantic in v1.5 on a provisional basis. It may change significantly in future releases and its signature or behaviour will not be concrete until v2. Feedback from the community while it's still provisional would be extremely useful; either comment on #866 or create a new issue.</p> <p>Example of usage:</p> <p>Where <code>Field</code> refers to the field function.</p> <p>Warning</p> <p>The <code>default_factory</code> expects the field type to be set.</p>"},{"location":"usage/models/#automatically-excluded-attributes","title":"Automatically excluded attributes","text":"<p>Class variables which begin with an underscore and attributes annotated with <code>typing.ClassVar</code> will be automatically excluded from the model.</p>"},{"location":"usage/models/#private-model-attributes","title":"Private model attributes","text":"<p>If you need to vary or manipulate internal attributes on instances of the model, you can declare them using <code>PrivateAttr</code>:</p> <p>Private attribute names must start with underscore to prevent conflicts with model fields: both <code>_attr</code> and <code>__attr__</code>  are supported.</p> <p>If <code>Config.underscore_attrs_are_private</code> is <code>True</code>, any non-ClassVar underscore attribute will be treated as private:</p> <p>Upon class creation pydantic constructs <code>__slots__</code> filled with private attributes.</p>"},{"location":"usage/models/#parsing-data-into-a-specified-type","title":"Parsing data into a specified type","text":"<p>Pydantic includes a standalone utility function <code>parse_obj_as</code> that can be used to apply the parsing logic used to populate pydantic models in a more ad-hoc way. This function behaves similarly to <code>BaseModel.parse_obj</code>, but works with arbitrary pydantic-compatible types.</p> <p>This is especially useful when you want to parse results into a type that is not a direct subclass of <code>BaseModel</code>. For example: </p> <p>This function is capable of parsing data into any of the types pydantic can handle as fields of a <code>BaseModel</code>.</p> <p>Pydantic also includes two similar standalone functions called <code>parse_file_as</code> and <code>parse_raw_as</code>, which are analogous to <code>BaseModel.parse_file</code> and <code>BaseModel.parse_raw</code>.</p>"},{"location":"usage/models/#data-conversion","title":"Data Conversion","text":"<p>pydantic may cast input data to force it to conform to model field types, and in some cases this may result in a loss of information. For example:</p> <p>This is a deliberate decision of pydantic, and in general it's the most useful approach. See  here for a longer discussion on the subject.</p> <p>Nevertheless, strict type checking is partially supported.</p>"},{"location":"usage/models/#model-signature","title":"Model signature","text":"<p>All pydantic models will have their signature generated based on their fields:</p> <p>An accurate signature is useful for introspection purposes and libraries like <code>FastAPI</code> or <code>hypothesis</code>.</p> <p>The generated signature will also respect custom <code>__init__</code> functions:</p> <p>To be included in the signature, a field's alias or name must be a valid Python identifier.  pydantic prefers aliases over names, but may use field names if the alias is not a valid Python identifier. </p> <p>If a field's alias and name are both invalid identifiers, a <code>**data</code> argument will be added. In addition, the <code>**data</code> argument will always be present in the signature if <code>Config.extra</code> is <code>Extra.allow</code>.</p> <p>Note</p> <p>Types in the model signature are the same as declared in model annotations,  not necessarily all the types that can actually be provided to that field. This may be fixed one day once #1055 is solved.</p>"},{"location":"usage/models/#structural-pattern-matching","title":"Structural pattern matching","text":"<p>pydantic supports structural pattern matching for models, as introduced by PEP 636 in Python 3.10.</p> <p>Note</p> <p>A match-case statement may seem as if it creates a new model, but don't be fooled; it is just syntactic sugar for getting an attribute and either comparing it or declaring and initializing it.</p>"},{"location":"usage/mypy/","title":"Usage with mypy","text":"<p>pydantic models work with mypy provided you use the annotation-only version of required fields:</p> <p>You can run your code through mypy with:</p> <pre><code>mypy \\\n--ignore-missing-imports \\\n--follow-imports=skip \\\n--strict-optional \\\npydantic_mypy_test.py\n</code></pre> <p>If you call mypy on the example code above, you should see mypy detect the attribute access error: <pre><code>13: error: \"Model\" has no attribute \"middle_name\"\n</code></pre></p>"},{"location":"usage/mypy/#strict-optional","title":"Strict Optional","text":"<p>For your code to pass with <code>--strict-optional</code>, you need to to use <code>Optional[]</code> or an alias of <code>Optional[]</code> for all fields with <code>None</code> as the default. (This is standard with mypy.)</p> <p>Pydantic provides a few useful optional or union types:</p> <ul> <li><code>NoneStr</code> aka. <code>Optional[str]</code></li> <li><code>NoneBytes</code> aka. <code>Optional[bytes]</code></li> <li><code>StrBytes</code> aka. <code>Union[str, bytes]</code></li> <li><code>NoneStrBytes</code> aka. <code>Optional[StrBytes]</code></li> </ul> <p>If these aren't sufficient you can of course define your own.</p>"},{"location":"usage/mypy/#mypy-plugin","title":"Mypy Plugin","text":"<p>Pydantic ships with a mypy plugin that adds a number of important pydantic-specific features to mypy that improve its ability to type-check your code.</p> <p>See the pydantic mypy plugin docs for more details.</p>"},{"location":"usage/mypy/#other-pydantic-interfaces","title":"Other pydantic interfaces","text":"<p>Pydantic dataclasses and the <code>validate_arguments</code> decorator should also work well with mypy.</p>"},{"location":"usage/postponed_annotations/","title":"Postponed annotations","text":"<p>Note</p> <p>Both postponed annotations via the future import and <code>ForwardRef</code> require Python 3.7+.</p> <p>Postponed annotations (as described in PEP563) \"just work\".</p> <p>Internally, pydantic  will call a method similar to <code>typing.get_type_hints</code> to resolve annotations.</p> <p>In cases where the referenced type is not yet defined, <code>ForwardRef</code> can be used (although referencing the type directly or by its string is a simpler solution in the case of self-referencing models).</p> <p>In some cases, a <code>ForwardRef</code> won't be able to be resolved during model creation. For example, this happens whenever a model references itself as a field type. When this happens, you'll need to call <code>update_forward_refs</code> after the model has been created before it can be used:</p> <p>Warning</p> <p>To resolve strings (type names) into annotations (types), pydantic needs a namespace dict in which to perform the lookup. For this it uses <code>module.__dict__</code>, just like <code>get_type_hints</code>. This means pydantic may not play well with types not defined in the global scope of a module.</p> <p>For example, this works fine:</p> <p>While this will break:</p> <p>Resolving this is beyond the call for pydantic: either remove the future import or declare the types globally.</p>"},{"location":"usage/postponed_annotations/#self-referencing-models","title":"Self-referencing Models","text":"<p>Data structures with self-referencing models are also supported. Self-referencing fields will be automatically resolved after model creation.</p> <p>Within the model, you can refer to the not-yet-constructed model using a string:</p> <p>Since Python 3.7, you can also refer it by its type, provided you import <code>annotations</code> (see above for support depending on Python and pydantic versions).</p>"},{"location":"usage/rich/","title":"Usage with rich","text":"<p>Pydantic models may be printed with the Rich library which will add additional formatting and color to the output. Here's an example:</p> <p></p> <p>See the Rich documentation on pretty printing for more information.</p>"},{"location":"usage/schema/","title":"Schema","text":"<p>Pydantic allows auto creation of JSON Schemas from models:</p> <p>The generated schemas are compliant with the specifications: JSON Schema Core, JSON Schema Validation and OpenAPI.</p> <p><code>BaseModel.schema</code> will return a dict of the schema, while <code>BaseModel.schema_json</code> will return a JSON string representation of that dict.</p> <p>Sub-models used are added to the <code>definitions</code> JSON attribute and referenced, as per the spec.</p> <p>All sub-models' (and their sub-models') schemas are put directly in a top-level <code>definitions</code> JSON key for easy re-use and reference.</p> <p>\"Sub-models\" with modifications (via the <code>Field</code> class) like a custom title, description or default value, are recursively included instead of referenced.</p> <p>The <code>description</code> for models is taken from either the docstring of the class or the argument <code>description</code> to the <code>Field</code> class.</p> <p>The schema is generated by default using aliases as keys, but it can be generated using model property names instead by calling <code>MainModel.schema/schema_json(by_alias=False)</code>.</p> <p>The format of <code>$ref</code>s (<code>\"#/definitions/FooBar\"</code> above) can be altered by calling <code>schema()</code> or <code>schema_json()</code> with the <code>ref_template</code> keyword argument, e.g. <code>ApplePie.schema(ref_template='/schemas/{model}.json#/')</code>, here <code>{model}</code> will be replaced with the model naming using <code>str.format()</code>.</p>"},{"location":"usage/schema/#getting-schema-of-a-specified-type","title":"Getting schema of a specified type","text":"<p>Pydantic includes two standalone utility functions <code>schema_of</code> and <code>schema_json_of</code> that can be used to apply the schema generation logic used for pydantic models in a more ad-hoc way. These functions behave similarly to <code>BaseModel.schema</code> and <code>BaseModel.schema_json</code>, but work with arbitrary pydantic-compatible types.</p>"},{"location":"usage/schema/#field-customization","title":"Field customization","text":"<p>Optionally, the <code>Field</code> function can be used to provide extra information about the field and validations. It has the following arguments:</p> <ul> <li><code>default</code>: (a positional argument) the default value of the field.     Since the <code>Field</code> replaces the field's default, this first argument can be used to set the default.     Use ellipsis (<code>...</code>) to indicate the field is required.</li> <li><code>default_factory</code>: a zero-argument callable that will be called when a default value is needed for this field.     Among other purposes, this can be used to set dynamic default values.     It is forbidden to set both <code>default</code> and <code>default_factory</code>.</li> <li><code>alias</code>: the public name of the field</li> <li><code>title</code>: if omitted, <code>field_name.title()</code> is used</li> <li><code>description</code>: if omitted and the annotation is a sub-model,     the docstring of the sub-model will be used</li> <li><code>exclude</code>: exclude this field when dumping (<code>.dict</code> and <code>.json</code>) the instance. The exact syntax and configuration options are described in details in the exporting models section.</li> <li><code>include</code>: include (only) this field when dumping (<code>.dict</code> and <code>.json</code>) the instance. The exact syntax and configuration options are described in details in the exporting models section.</li> <li><code>const</code>: this argument must be the same as the field's default value if present.</li> <li><code>gt</code>: for numeric values (<code>int</code>, <code>float</code>, <code>Decimal</code>), adds a validation of \"greater than\" and an annotation   of <code>exclusiveMinimum</code> to the JSON Schema</li> <li><code>ge</code>: for numeric values, this adds a validation of \"greater than or equal\" and an annotation of <code>minimum</code> to the   JSON Schema</li> <li><code>lt</code>: for numeric values, this adds a validation of \"less than\" and an annotation of <code>exclusiveMaximum</code> to the   JSON Schema</li> <li><code>le</code>: for numeric values, this adds a validation of \"less than or equal\" and an annotation of <code>maximum</code> to the   JSON Schema</li> <li><code>multiple_of</code>: for numeric values, this adds a validation of \"a multiple of\" and an annotation of <code>multipleOf</code> to the   JSON Schema</li> <li><code>max_digits</code>: for <code>Decimal</code> values, this adds a validation to have a maximum number of digits within the decimal. It   does not include a zero before the decimal point or trailing decimal zeroes.</li> <li><code>decimal_places</code>: for <code>Decimal</code> values, this adds a validation to have at most a number of decimal places allowed. It   does not include trailing decimal zeroes.</li> <li><code>min_items</code>: for list values, this adds a corresponding validation and an annotation of <code>minItems</code> to the   JSON Schema</li> <li><code>max_items</code>: for list values, this adds a corresponding validation and an annotation of <code>maxItems</code> to the   JSON Schema</li> <li><code>unique_items</code>: for list values, this adds a corresponding validation and an annotation of <code>uniqueItems</code> to the   JSON Schema</li> <li><code>min_length</code>: for string values, this adds a corresponding validation and an annotation of <code>minLength</code> to the   JSON Schema</li> <li><code>max_length</code>: for string values, this adds a corresponding validation and an annotation of <code>maxLength</code> to the   JSON Schema</li> <li><code>allow_mutation</code>: a boolean which defaults to <code>True</code>. When False, the field raises a <code>TypeError</code> if the field is   assigned on an instance.  The model config must set <code>validate_assignment</code> to <code>True</code> for this check to be performed.</li> <li> <p><code>regex</code>: for string values, this adds a Regular Expression validation generated from the passed string and an   annotation of <code>pattern</code> to the JSON Schema</p> <p>Note</p> <p>pydantic validates strings using <code>re.match</code>, which treats regular expressions as implicitly anchored at the beginning. On the contrary, JSON Schema validators treat the <code>pattern</code> keyword as implicitly unanchored, more like what <code>re.search</code> does.</p> <p>For interoperability, depending on your desired behavior, either explicitly anchor your regular expressions with <code>^</code> (e.g. <code>^foo</code> to match any string starting with <code>foo</code>), or explicitly allow an arbitrary prefix with <code>.*?</code> (e.g. <code>.*?foo</code> to match any string containing the substring <code>foo</code>).</p> <p>See #1631 for a discussion of possible changes to pydantic behavior in v2.</p> </li> </ul> <ul> <li><code>repr</code>: a boolean which defaults to <code>True</code>. When False, the field shall be hidden from the object representation.</li> <li><code>**</code> any other keyword arguments (e.g. <code>examples</code>) will be added verbatim to the field's schema</li> </ul> <p>Instead of using <code>Field</code>, the <code>fields</code> property of the Config class can be used to set all of the arguments above except <code>default</code>.</p>"},{"location":"usage/schema/#unenforced-field-constraints","title":"Unenforced Field constraints","text":"<p>If pydantic finds constraints which are not being enforced, an error will be raised. If you want to force the constraint to appear in the schema, even though it's not being checked upon parsing, you can use variadic arguments to <code>Field()</code> with the raw schema attribute name:</p>"},{"location":"usage/schema/#typingannotated-fields","title":"typing.Annotated Fields","text":"<p>Rather than assigning a <code>Field</code> value, it can be specified in the type hint with <code>typing.Annotated</code>:</p> <p><code>Field</code> can only be supplied once per field - an error will be raised if used in <code>Annotated</code> and as the assigned value. Defaults can be set outside <code>Annotated</code> as the assigned value or with <code>Field.default_factory</code> inside <code>Annotated</code> - the <code>Field.default</code> argument is not supported inside <code>Annotated</code>.</p> <p>For versions of Python prior to 3.9, <code>typing_extensions.Annotated</code> can be used.</p>"},{"location":"usage/schema/#modifying-schema-in-custom-fields","title":"Modifying schema in custom fields","text":"<p>Custom field types can customise the schema generated for them using the <code>__modify_schema__</code> class method; see Custom Data Types for more details.</p> <p><code>__modify_schema__</code> can also take a <code>field</code> argument which will have type <code>Optional[ModelField]</code>. pydantic will inspect the signature of <code>__modify_schema__</code> to determine whether the <code>field</code> argument should be included.</p>"},{"location":"usage/schema/#json-schema-types","title":"JSON Schema Types","text":"<p>Types, custom field types, and constraints (like <code>max_length</code>) are mapped to the corresponding spec formats in the following priority order (when there is an equivalent available):</p> <ol> <li>JSON Schema Core</li> <li>JSON Schema Validation</li> <li>OpenAPI Data Types</li> <li>The standard <code>format</code> JSON field is used to define pydantic extensions for more complex <code>string</code> sub-types.</li> </ol> <p>The field schema mapping from Python / pydantic to JSON Schema is done as follows:</p>"},{"location":"usage/schema/#top-level-schema-generation","title":"Top-level schema generation","text":"<p>You can also generate a top-level JSON Schema that only includes a list of models and related sub-models in its <code>definitions</code>:</p>"},{"location":"usage/schema/#schema-customization","title":"Schema customization","text":"<p>You can customize the generated <code>$ref</code> JSON location: the definitions are always stored under the key <code>definitions</code>, but a specified prefix can be used for the references.</p> <p>This is useful if you need to extend or modify the JSON Schema default definitions location. E.g. with OpenAPI:</p> <p>It's also possible to extend/override the generated JSON schema in a model.</p> <p>To do it, use the <code>Config</code> sub-class attribute <code>schema_extra</code>.</p> <p>For example, you could add <code>examples</code> to the JSON Schema:</p> <p>For more fine-grained control, you can alternatively set <code>schema_extra</code> to a callable and post-process the generated schema. The callable can have one or two positional arguments. The first will be the schema dictionary. The second, if accepted, will be the model class. The callable is expected to mutate the schema dictionary in-place; the return value is not used.</p> <p>For example, the <code>title</code> key can be removed from the model's <code>properties</code>:</p>"},{"location":"usage/settings/","title":"Settings management","text":"<p>One of pydantic's most useful applications is settings management.</p> <p>If you create a model that inherits from <code>BaseSettings</code>, the model initialiser will attempt to determine the values of any fields not passed as keyword arguments by reading from the environment. (Default values will still be used if the matching environment variable is not set.)</p> <p>This makes it easy to:</p> <ul> <li>Create a clearly-defined, type-hinted application configuration class</li> <li>Automatically read modifications to the configuration from environment variables</li> <li>Manually override specific settings in the initialiser where desired (e.g. in unit tests)</li> </ul> <p>For example:</p>"},{"location":"usage/settings/#environment-variable-names","title":"Environment variable names","text":"<p>The following rules are used to determine which environment variable(s) are read for a given field:</p> <ul> <li> <p>By default, the environment variable name is built by concatenating the prefix and field name.</p> <ul> <li>For example, to override <code>special_function</code> above, you could use:<pre><code>  export my_prefix_special_function='foo.bar'\n</code></pre> </li> </ul> <ul> <li>Note 1: The default prefix is an empty string.</li> <li>Note 2: Field aliases are ignored when building the environment variable name.</li> </ul> </li> </ul> <ul> <li>Custom environment variable names can be set in two ways:<ul> <li><code>Config.fields['field_name']['env']</code> (see <code>auth_key</code> and <code>redis_dsn</code> above)</li> <li><code>Field(..., env=...)</code> (see <code>api_key</code> above)</li> </ul> </li> <li>When specifying custom environment variable names, either a string or a list of strings may be provided.<ul> <li>When specifying a list of strings, order matters: the first detected value is used.</li> <li>For example, for <code>redis_dsn</code> above, <code>service_redis_dsn</code> would take precedence over <code>redis_url</code>.</li> </ul> </li> </ul> <p>Warning</p> <p>Since v1.0 pydantic does not consider field aliases when finding environment variables to populate settings models, use <code>env</code> instead as described above.</p> <p>To aid the transition from aliases to <code>env</code>, a warning will be raised when aliases are used on settings models without a custom env var name. If you really mean to use aliases, either ignore the warning or set <code>env</code> to suppress it.</p> <p>Case-sensitivity can be turned on through the <code>Config</code>:</p> <p>When <code>case_sensitive</code> is <code>True</code>, the environment variable names must match field names (optionally with a prefix), so in this example <code>redis_host</code> could only be modified via <code>export redis_host</code>. If you want to name environment variables all upper-case, you should name attribute all upper-case too. You can still name environment variables anything you like through <code>Field(..., env=...)</code>.</p> <p>In Pydantic v1 <code>case_sensitive</code> is <code>False</code> by default and all variable names are converted to lower-case internally. If you want to define upper-case variable names on nested models like <code>SubModel</code> you have to set <code>case_sensitive=True</code> to disable this behaviour.</p> <p>Note</p> <p>On Windows, Python's <code>os</code> module always treats environment variables as case-insensitive, so the <code>case_sensitive</code> config setting will have no effect - settings will always be updated ignoring case.</p>"},{"location":"usage/settings/#parsing-environment-variable-values","title":"Parsing environment variable values","text":"<p>For most simple field types (such as <code>int</code>, <code>float</code>, <code>str</code>, etc.), the environment variable value is parsed the same way it would be if passed directly to the initialiser (as a string).</p> <p>Complex types like <code>list</code>, <code>set</code>, <code>dict</code>, and sub-models are populated from the environment by treating the environment variable's value as a JSON-encoded string.</p> <p>Another way to populate nested complex variables is to configure your model with the <code>env_nested_delimiter</code> config setting, then use an env variable with a name pointing to the nested module fields. What it does is simply explodes your variable into nested models or dicts. So if you define a variable <code>FOO__BAR__BAZ=123</code> it will convert it into <code>FOO={'BAR': {'BAZ': 123}}</code> If you have multiple variables with the same structure they will be merged.</p> <p>With the following environment variables: <pre><code># your environment\nexport V0=0\nexport SUB_MODEL='{\"v1\": \"json-1\", \"v2\": \"json-2\"}'\nexport SUB_MODEL__V2=nested-2\nexport SUB_MODEL__V3=3\nexport SUB_MODEL__DEEP__V4=v4\n</code></pre></p> <p>You could load a settings module thus:</p> <p><code>env_nested_delimiter</code> can be configured via the <code>Config</code> class as shown above, or via the <code>_env_nested_delimiter</code> keyword argument on instantiation.</p> <p>JSON is only parsed in top-level fields, if you need to parse JSON in sub-models, you will need to implement validators on those models.</p> <p>Nested environment variables take precedence over the top-level environment variable JSON (e.g. in the example above, <code>SUB_MODEL__V2</code> trumps <code>SUB_MODEL</code>).</p> <p>You may also populate a complex type by providing your own parsing function to the <code>parse_env_var</code> classmethod in the Config object.</p>"},{"location":"usage/settings/#dotenv-env-support","title":"Dotenv (.env) support","text":"<p>Note</p> <p>dotenv file parsing requires python-dotenv to be installed. This can be done with either <code>pip install python-dotenv</code> or <code>pip install pydantic[dotenv]</code>.</p> <p>Dotenv files (generally named <code>.env</code>) are a common pattern that make it easy to use environment variables in a platform-independent manner.</p> <p>A dotenv file follows the same general principles of all environment variables, and looks something like:</p> <pre><code># ignore comment\nENVIRONMENT=\"production\"\nREDIS_ADDRESS=localhost:6379\nMEANING_OF_LIFE=42\nMY_VAR='Hello world'\n</code></pre> <p>Once you have your <code>.env</code> file filled with variables, pydantic supports loading it in two ways:</p> <p>1. setting <code>env_file</code> (and <code>env_file_encoding</code> if you don't want the default encoding of your OS) on <code>Config</code> in a <code>BaseSettings</code> class:</p> <pre><code>class Settings(BaseSettings):\n    ...\n\n    class Config:\n        env_file = '.env'\n        env_file_encoding = 'utf-8'\n</code></pre> <p>2. instantiating a <code>BaseSettings</code> derived class with the <code>_env_file</code> keyword argument (and the <code>_env_file_encoding</code> if needed):</p> <pre><code>settings = Settings(_env_file='prod.env', _env_file_encoding='utf-8')\n</code></pre> <p>In either case, the value of the passed argument can be any valid path or filename, either absolute or relative to the current working directory. From there, pydantic will handle everything for you by loading in your variables and validating them.</p> <p>Note</p> <p>If a filename is specified for <code>env_file</code>, Pydantic will only check the current working directory and won't check any parent directories for the <code>.env</code> file.</p> <p>Even when using a dotenv file, pydantic will still read environment variables as well as the dotenv file, environment variables will always take priority over values loaded from a dotenv file.</p> <p>Passing a file path via the <code>_env_file</code> keyword argument on instantiation (method 2) will override the value (if any) set on the <code>Config</code> class. If the above snippets were used in conjunction, <code>prod.env</code> would be loaded while <code>.env</code> would be ignored.</p> <p>If you need to load multiple dotenv files, you can pass the file paths as a <code>list</code> or <code>tuple</code>.</p> <p>Later files in the list/tuple will take priority over earlier files.</p> <pre><code>from pydantic import BaseSettings\n\nclass Settings(BaseSettings):\n    ...\n\n    class Config:\n        # `.env.prod` takes priority over `.env`\n        env_file = '.env', '.env.prod'\n</code></pre> <p>You can also use the keyword argument override to tell Pydantic not to load any file at all (even if one is set in the <code>Config</code> class) by passing <code>None</code> as the instantiation keyword argument, e.g. <code>settings = Settings(_env_file=None)</code>.</p> <p>Because python-dotenv is used to parse the file, bash-like semantics such as <code>export</code> can be used which (depending on your OS and environment) may allow your dotenv file to also be used with <code>source</code>, see python-dotenv's documentation for more details.</p>"},{"location":"usage/settings/#secret-support","title":"Secret Support","text":"<p>Placing secret values in files is a common pattern to provide sensitive configuration to an application.</p> <p>A secret file follows the same principal as a dotenv file except it only contains a single value and the file name is used as the key. A secret file will look like the following:</p> <p><code>/var/run/database_password</code>: <pre><code>super_secret_database_password\n</code></pre></p> <p>Once you have your secret files, pydantic supports loading it in two ways:</p> <p>1. setting <code>secrets_dir</code> on <code>Config</code> in a <code>BaseSettings</code> class to the directory where your secret files are stored:</p> <pre><code>class Settings(BaseSettings):\n    ...\n    database_password: str\n\n    class Config:\n        secrets_dir = '/var/run'\n</code></pre> <p>2. instantiating a <code>BaseSettings</code> derived class with the <code>_secrets_dir</code> keyword argument:</p> <pre><code>settings = Settings(_secrets_dir='/var/run')\n</code></pre> <p>In either case, the value of the passed argument can be any valid directory, either absolute or relative to the current working directory. Note that a non existent directory will only generate a warning. From there, pydantic will handle everything for you by loading in your variables and validating them.</p> <p>Even when using a secrets directory, pydantic will still read environment variables from a dotenv file or the environment, a dotenv file and environment variables will always take priority over values loaded from the secrets directory.</p> <p>Passing a file path via the <code>_secrets_dir</code> keyword argument on instantiation (method 2) will override the value (if any) set on the <code>Config</code> class.</p>"},{"location":"usage/settings/#use-case-docker-secrets","title":"Use Case: Docker Secrets","text":"<p>Docker Secrets can be used to provide sensitive configuration to an application running in a Docker container. To use these secrets in a pydantic application the process is simple. More information regarding creating, managing and using secrets in Docker see the official Docker documentation.</p> <p>First, define your Settings <pre><code>class Settings(BaseSettings):\n    my_secret_data: str\n\n    class Config:\n        secrets_dir = '/run/secrets'\n</code></pre></p> <p>Note</p> <p>By default Docker uses <code>/run/secrets</code> as the target mount point. If you want to use a different location, change <code>Config.secrets_dir</code> accordingly.</p> <p>Then, create your secret via the Docker CLI <pre><code>printf \"This is a secret\" | docker secret create my_secret_data -\n</code></pre></p> <p>Last, run your application inside a Docker container and supply your newly created secret <pre><code>docker service create --name pydantic-with-secrets --secret my_secret_data pydantic-app:latest\n</code></pre></p>"},{"location":"usage/settings/#field-value-priority","title":"Field value priority","text":"<p>In the case where a value is specified for the same <code>Settings</code> field in multiple ways, the selected value is determined as follows (in descending order of priority):</p> <ol> <li>Arguments passed to the <code>Settings</code> class initialiser.</li> <li>Environment variables, e.g. <code>my_prefix_special_function</code> as described above.</li> <li>Variables loaded from a dotenv (<code>.env</code>) file.</li> <li>Variables loaded from the secrets directory.</li> <li>The default field values for the <code>Settings</code> model.</li> </ol>"},{"location":"usage/settings/#customise-settings-sources","title":"Customise settings sources","text":"<p>If the default order of priority doesn't match your needs, it's possible to change it by overriding the <code>customise_sources</code> method on the <code>Config</code> class of your <code>Settings</code> .</p> <p><code>customise_sources</code> takes three callables as arguments and returns any number of callables as a tuple. In turn these callables are called to build the inputs to the fields of the settings class.</p> <p>Each callable should take an instance of the settings class as its sole argument and return a <code>dict</code>.</p>"},{"location":"usage/settings/#changing-priority","title":"Changing Priority","text":"<p>The order of the returned callables decides the priority of inputs; first item is the highest priority.</p> <p>By flipping <code>env_settings</code> and <code>init_settings</code>, environment variables now have precedence over <code>__init__</code> kwargs.</p>"},{"location":"usage/settings/#adding-sources","title":"Adding sources","text":"<p>As explained earlier, pydantic ships with multiples built-in settings sources. However, you may occasionally need to add your own custom sources, <code>customise_sources</code> makes this very easy:</p>"},{"location":"usage/settings/#removing-sources","title":"Removing sources","text":"<p>You might also want to disable a source:</p>"},{"location":"usage/types/","title":"Field Types","text":"<p>Where possible pydantic uses standard library types to define fields, thus smoothing the learning curve. For many useful applications, however, no standard library type exists, so pydantic implements many commonly used types.</p> <p>If no existing type suits your purpose you can also implement your own pydantic-compatible types with custom properties and validation.</p>"},{"location":"usage/types/#standard-library-types","title":"Standard Library Types","text":"<p>pydantic supports many common types from the Python standard library. If you need stricter processing see Strict Types; if you need to constrain the values allowed (e.g. to require a positive int) see Constrained Types.</p> <code>None</code>, <code>type(None)</code> or <code>Literal[None]</code> (equivalent according to PEP 484) allows only <code>None</code> value <code>bool</code> see Booleans below for details on how bools are validated and what values are permitted <code>int</code> pydantic uses <code>int(v)</code> to coerce types to an <code>int</code>; see this warning on loss of information during data conversion <code>float</code> similarly, <code>float(v)</code> is used to coerce values to floats <code>str</code> strings are accepted as-is, <code>int</code> <code>float</code> and <code>Decimal</code> are coerced using <code>str(v)</code>, <code>bytes</code> and <code>bytearray</code> are converted using <code>v.decode()</code>, enums inheriting from <code>str</code> are converted using <code>v.value</code>, and all other types cause an error <code>bytes</code> <code>bytes</code> are accepted as-is, <code>bytearray</code> is converted using <code>bytes(v)</code>, <code>str</code> are converted using <code>v.encode()</code>, and <code>int</code>, <code>float</code>, and <code>Decimal</code> are coerced using <code>str(v).encode()</code> <code>list</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a list; see <code>typing.List</code> below for sub-type constraints <code>tuple</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a tuple; see <code>typing.Tuple</code> below for sub-type constraints <code>dict</code> <code>dict(v)</code> is used to attempt to convert a dictionary; see <code>typing.Dict</code> below for sub-type constraints <code>set</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a set; see <code>typing.Set</code> below for sub-type constraints <code>frozenset</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a frozen set; see <code>typing.FrozenSet</code> below for sub-type constraints <code>deque</code> allows <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>, <code>deque</code>, or generators and casts to a deque; see <code>typing.Deque</code> below for sub-type constraints <code>datetime.date</code> see Datetime Types below for more detail on parsing and validation <code>datetime.time</code> see Datetime Types below for more detail on parsing and validation <code>datetime.datetime</code> see Datetime Types below for more detail on parsing and validation <code>datetime.timedelta</code> see Datetime Types below for more detail on parsing and validation <code>typing.Any</code> allows any value including <code>None</code>, thus an <code>Any</code> field is optional <code>typing.Annotated</code> allows wrapping another type with arbitrary metadata, as per PEP-593. The <code>Annotated</code> hint may contain a single call to the <code>Field</code> function, but otherwise the additional metadata is ignored and the root type is used. <code>typing.TypeVar</code> constrains the values allowed based on <code>constraints</code> or <code>bound</code>, see TypeVar <code>typing.Union</code> see Unions below for more detail on parsing and validation <code>typing.Optional</code> <code>Optional[x]</code> is simply short hand for <code>Union[x, None]</code>; see Unions below for more detail on parsing and validation and Required Fields for details about required fields that can receive <code>None</code> as a value. <code>typing.List</code> see Typing Iterables below for more detail on parsing and validation <code>typing.Tuple</code> see Typing Iterables below for more detail on parsing and validation <code>subclass of typing.NamedTuple</code> Same as <code>tuple</code> but instantiates with the given namedtuple and validates fields since they are annotated. See Annotated Types below for more detail on parsing and validation <code>subclass of collections.namedtuple</code> Same as <code>subclass of typing.NamedTuple</code> but all fields will have type <code>Any</code> since they are not annotated <code>typing.Dict</code> see Typing Iterables below for more detail on parsing and validation <code>subclass of typing.TypedDict</code> Same as <code>dict</code> but pydantic will validate the dictionary since keys are annotated. See Annotated Types below for more detail on parsing and validation <code>typing.Set</code> see Typing Iterables below for more detail on parsing and validation <code>typing.FrozenSet</code> see Typing Iterables below for more detail on parsing and validation <code>typing.Deque</code> see Typing Iterables below for more detail on parsing and validation <code>typing.Sequence</code> see Typing Iterables below for more detail on parsing and validation <code>typing.Iterable</code> this is reserved for iterables that shouldn't be consumed. See Infinite Generators below for more detail on parsing and validation <code>typing.Type</code> see Type below for more detail on parsing and validation <code>typing.Callable</code> see Callable below for more detail on parsing and validation <code>typing.Pattern</code> will cause the input value to be passed to <code>re.compile(v)</code> to create a regex pattern <code>ipaddress.IPv4Address</code> simply uses the type itself for validation by passing the value to <code>IPv4Address(v)</code>; see Pydantic Types for other custom IP address types <code>ipaddress.IPv4Interface</code> simply uses the type itself for validation by passing the value to <code>IPv4Address(v)</code>; see Pydantic Types for other custom IP address types <code>ipaddress.IPv4Network</code> simply uses the type itself for validation by passing the value to <code>IPv4Network(v)</code>; see Pydantic Types for other custom IP address types <code>ipaddress.IPv6Address</code> simply uses the type itself for validation by passing the value to <code>IPv6Address(v)</code>; see Pydantic Types for other custom IP address types <code>ipaddress.IPv6Interface</code> simply uses the type itself for validation by passing the value to <code>IPv6Interface(v)</code>; see Pydantic Types for other custom IP address types <code>ipaddress.IPv6Network</code> simply uses the type itself for validation by passing the value to <code>IPv6Network(v)</code>; see Pydantic Types for other custom IP address types <code>enum.Enum</code> checks that the value is a valid Enum instance <code>subclass of enum.Enum</code> checks that the value is a valid member of the enum; see Enums and Choices for more details <code>enum.IntEnum</code> checks that the value is a valid IntEnum instance <code>subclass of enum.IntEnum</code> checks that the value is a valid member of the integer enum; see Enums and Choices for more details <code>decimal.Decimal</code> pydantic attempts to convert the value to a string, then passes the string to <code>Decimal(v)</code> <code>pathlib.Path</code> simply uses the type itself for validation by passing the value to <code>Path(v)</code>; see Pydantic Types for other more strict path types <code>uuid.UUID</code> strings and bytes (converted to strings) are passed to <code>UUID(v)</code>, with a fallback to <code>UUID(bytes=v)</code> for <code>bytes</code> and <code>bytearray</code>; see Pydantic Types for other stricter UUID types <code>ByteSize</code> converts a bytes string with units to bytes"},{"location":"usage/types/#typing-iterables","title":"Typing Iterables","text":"<p>pydantic uses standard library <code>typing</code> types as defined in PEP 484 to define complex objects.</p>"},{"location":"usage/types/#infinite-generators","title":"Infinite Generators","text":"<p>If you have a generator you can use <code>Sequence</code> as described above. In that case, the generator will be consumed and stored on the model as a list and its values will be validated with the sub-type of <code>Sequence</code> (e.g. <code>int</code> in <code>Sequence[int]</code>).</p> <p>But if you have a generator that you don't want to be consumed, e.g. an infinite generator or a remote data loader, you can define its type with <code>Iterable</code>:</p> <p>Warning</p> <p><code>Iterable</code> fields only perform a simple check that the argument is iterable and won't be consumed.</p> <p>No validation of their values is performed as it cannot be done without consuming the iterable.</p> <p>Tip</p> <p>If you want to validate the values of an infinite generator you can create a separate model and use it while consuming the generator, reporting the validation errors as appropriate.</p> <p>pydantic can't validate the values automatically for you because it would require consuming the infinite generator.</p>"},{"location":"usage/types/#validating-the-first-value","title":"Validating the first value","text":"<p>You can create a validator to validate the first value in an infinite generator and still not consume it entirely.</p>"},{"location":"usage/types/#unions","title":"Unions","text":"<p>The <code>Union</code> type allows a model attribute to accept different types, e.g.:</p> <p>Info</p> <p>You may get unexpected coercion with <code>Union</code>; see below. Know that you can also make the check slower but stricter by using Smart Union</p> <p>However, as can be seen above, pydantic will attempt to 'match' any of the types defined under <code>Union</code> and will use the first one that matches. In the above example the <code>id</code> of <code>user_03</code> was defined as a <code>uuid.UUID</code> class (which is defined under the attribute's <code>Union</code> annotation) but as the <code>uuid.UUID</code> can be marshalled into an <code>int</code> it chose to match against the <code>int</code> type and disregarded the other types.</p> <p>Warning</p> <p><code>typing.Union</code> also ignores order when defined, so <code>Union[int, float] == Union[float, int]</code> which can lead to unexpected behaviour when combined with matching based on the <code>Union</code> type order inside other type definitions, such as <code>List</code> and <code>Dict</code> types (because Python treats these definitions as singletons). For example, <code>Dict[str, Union[int, float]] == Dict[str, Union[float, int]]</code> with the order based on the first time it was defined. Please note that this can also be affected by third party libraries and their internal type definitions and the import orders.</p> <p>As such, it is recommended that, when defining <code>Union</code> annotations, the most specific type is included first and followed by less specific types.</p> <p>In the above example, the <code>UUID</code> class should precede the <code>int</code> and <code>str</code> classes to preclude the unexpected representation as such:</p> <p>Tip</p> <p>The type <code>Optional[x]</code> is a shorthand for <code>Union[x, None]</code>.</p> <p><code>Optional[x]</code> can also be used to specify a required field that can take <code>None</code> as a value.</p> <p>See more details in Required Fields.</p>"},{"location":"usage/types/#discriminated-unions-aka-tagged-unions","title":"Discriminated Unions (a.k.a. Tagged Unions)","text":"<p>When <code>Union</code> is used with multiple submodels, you sometimes know exactly which submodel needs to be checked and validated and want to enforce this. To do that you can set the same field - let's call it <code>my_discriminator</code> - in each of the submodels with a discriminated value, which is one (or many) <code>Literal</code> value(s). For your <code>Union</code>, you can set the discriminator in its value: <code>Field(discriminator='my_discriminator')</code>.</p> <p>Setting a discriminated union has many benefits:</p> <ul> <li>validation is faster since it is only attempted against one model</li> <li>only one explicit error is raised in case of failure</li> <li>the generated JSON schema implements the associated OpenAPI specification</li> </ul> <p>Note</p> <p>Using the Annotated Fields syntax can be handy to regroup the <code>Union</code> and <code>discriminator</code> information. See below for an example!</p> <p>Warning</p> <p>Discriminated unions cannot be used with only a single variant, such as <code>Union[Cat]</code>.</p> <p>Python changes <code>Union[T]</code> into <code>T</code> at interpretation time, so it is not possible for <code>pydantic</code> to distinguish fields of <code>Union[T]</code> from <code>T</code>.</p>"},{"location":"usage/types/#nested-discriminated-unions","title":"Nested Discriminated Unions","text":"<p>Only one discriminator can be set for a field but sometimes you want to combine multiple discriminators. In this case you can always create \"intermediate\" models with <code>__root__</code> and add your discriminator.</p>"},{"location":"usage/types/#enums-and-choices","title":"Enums and Choices","text":"<p>pydantic uses Python's standard <code>enum</code> classes to define choices.</p>"},{"location":"usage/types/#datetime-types","title":"Datetime Types","text":"<p>Pydantic supports the following datetime types:</p> <ul> <li> <p><code>datetime</code> fields can be:</p> <ul> <li><code>datetime</code>, existing <code>datetime</code> object</li> <li><code>int</code> or <code>float</code>, assumed as Unix time, i.e. seconds (if &gt;= <code>-2e10</code> or &lt;= <code>2e10</code>) or milliseconds (if &lt; <code>-2e10</code>or &gt; <code>2e10</code>) since 1 January 1970</li> <li> <p><code>str</code>, following formats work:</p> <ul> <li><code>YYYY-MM-DD[T]HH:MM[:SS[.ffffff]][Z or [\u00b1]HH[:]MM]</code></li> <li><code>int</code> or <code>float</code> as a string (assumed as Unix time)</li> </ul> </li> </ul> </li> </ul> <ul> <li> <p><code>date</code> fields can be:</p> <ul> <li><code>date</code>, existing <code>date</code> object</li> <li><code>int</code> or <code>float</code>, see <code>datetime</code></li> <li> <p><code>str</code>, following formats work:</p> <ul> <li><code>YYYY-MM-DD</code></li> <li><code>int</code> or <code>float</code>, see <code>datetime</code></li> </ul> </li> </ul> </li> </ul> <ul> <li> <p><code>time</code> fields can be:</p> <ul> <li><code>time</code>, existing <code>time</code> object</li> <li> <p><code>str</code>, following formats work:</p> <ul> <li><code>HH:MM[:SS[.ffffff]][Z or [\u00b1]HH[:]MM]</code></li> </ul> </li> </ul> </li> </ul> <ul> <li> <p><code>timedelta</code> fields can be:</p> <ul> <li><code>timedelta</code>, existing <code>timedelta</code> object</li> <li><code>int</code> or <code>float</code>, assumed as seconds</li> <li> <p><code>str</code>, following formats work:</p> <ul> <li><code>[-][DD ][HH:MM]SS[.ffffff]</code></li> <li><code>[\u00b1]P[DD]DT[HH]H[MM]M[SS]S</code> (ISO 8601 format for timedelta)</li> </ul> </li> </ul> </li> </ul>"},{"location":"usage/types/#booleans","title":"Booleans","text":"<p>Warning</p> <p>The logic for parsing <code>bool</code> fields has changed as of version v1.0.</p> <p>Prior to v1.0, <code>bool</code> parsing never failed, leading to some unexpected results. The new logic is described below.</p> <p>A standard <code>bool</code> field will raise a <code>ValidationError</code> if the value is not one of the following:</p> <ul> <li>A valid boolean (i.e. <code>True</code> or <code>False</code>),</li> <li>The integers <code>0</code> or <code>1</code>,</li> <li>a <code>str</code> which when converted to lower case is one of   <code>'0', 'off', 'f', 'false', 'n', 'no', '1', 'on', 't', 'true', 'y', 'yes'</code></li> <li>a <code>bytes</code> which is valid (per the previous rule) when decoded to <code>str</code></li> </ul> <p>Note</p> <p>If you want stricter boolean logic (e.g. a field which only permits <code>True</code> and <code>False</code>) you can use <code>StrictBool</code>.</p> <p>Here is a script demonstrating some of these behaviors:</p>"},{"location":"usage/types/#callable","title":"Callable","text":"<p>Fields can also be of type <code>Callable</code>:</p> <p>Warning</p> <p>Callable fields only perform a simple check that the argument is callable; no validation of arguments, their types, or the return type is performed.</p>"},{"location":"usage/types/#type","title":"Type","text":"<p>pydantic supports the use of <code>Type[T]</code> to specify that a field may only accept classes (not instances) that are subclasses of <code>T</code>.</p> <p>You may also use <code>Type</code> to specify that any class is allowed.</p>"},{"location":"usage/types/#typevar","title":"TypeVar","text":"<p><code>TypeVar</code> is supported either unconstrained, constrained or with a bound.</p>"},{"location":"usage/types/#literal-type","title":"Literal Type","text":"<p>Note</p> <p>This is a new feature of the Python standard library as of Python 3.8; prior to Python 3.8, it requires the typing-extensions package.</p> <p>pydantic supports the use of <code>typing.Literal</code> (or <code>typing_extensions.Literal</code> prior to Python 3.8) as a lightweight way to specify that a field may accept only specific literal values:</p> <p>One benefit of this field type is that it can be used to check for equality with one or more specific values without needing to declare custom validators:</p> <p>With proper ordering in an annotated <code>Union</code>, you can use this to parse types of decreasing specificity:</p>"},{"location":"usage/types/#annotated-types","title":"Annotated Types","text":""},{"location":"usage/types/#namedtuple","title":"NamedTuple","text":""},{"location":"usage/types/#typeddict","title":"TypedDict","text":"<p>Note</p> <p>This is a new feature of the Python standard library as of Python 3.8. Prior to Python 3.8, it requires the typing-extensions package. But required and optional fields are properly differentiated only since Python 3.9. We therefore recommend using typing-extensions with Python 3.8 as well.</p>"},{"location":"usage/types/#pydantic-types","title":"Pydantic Types","text":"<p>pydantic also provides a variety of other useful types:</p> <code>FilePath</code> like <code>Path</code>, but the path must exist and be a file <code>DirectoryPath</code> like <code>Path</code>, but the path must exist and be a directory <code>PastDate</code> like <code>date</code>, but the date should be in the past <code>FutureDate</code> like <code>date</code>, but the date should be in the future <code>EmailStr</code> requires email-validator to be installed; the input string must be a valid email address, and the output is a simple string <code>NameEmail</code> requires email-validator to be installed; the input string must be either a valid email address or in the format <code>Fred Bloggs &lt;fred.bloggs@example.com&gt;</code>, and the output is a <code>NameEmail</code> object which has two properties: <code>name</code> and <code>email</code>. For <code>Fred Bloggs &lt;fred.bloggs@example.com&gt;</code> the name would be <code>\"Fred Bloggs\"</code>; for <code>fred.bloggs@example.com</code> it would be <code>\"fred.bloggs\"</code>. <code>PyObject</code> expects a string and loads the Python object importable at that dotted path; e.g. if <code>'math.cos'</code> was provided, the resulting field value would be the function <code>cos</code> <code>Color</code> for parsing HTML and CSS colors; see Color Type <code>Json</code> a special type wrapper which loads JSON before parsing; see JSON Type <code>PaymentCardNumber</code> for parsing and validating payment cards; see payment cards <code>AnyUrl</code> any URL; see URLs <code>AnyHttpUrl</code> an HTTP URL; see URLs <code>HttpUrl</code> a stricter HTTP URL; see URLs <code>FileUrl</code> a file path URL; see URLs <code>PostgresDsn</code> a postgres DSN style URL; see URLs <code>CockroachDsn</code> a cockroachdb DSN style URL; see URLs <code>AmqpDsn</code> an <code>AMQP</code> DSN style URL as used by RabbitMQ, StormMQ, ActiveMQ etc.; see URLs <code>RedisDsn</code> a redis DSN style URL; see URLs <code>MongoDsn</code> a MongoDB DSN style URL; see URLs <code>KafkaDsn</code> a kafka DSN style URL; see URLs <code>stricturl</code> a type method for arbitrary URL constraints; see URLs <code>UUID1</code> requires a valid UUID of type 1; see <code>UUID</code> above <code>UUID3</code> requires a valid UUID of type 3; see <code>UUID</code> above <code>UUID4</code> requires a valid UUID of type 4; see <code>UUID</code> above <code>UUID5</code> requires a valid UUID of type 5; see <code>UUID</code> above <code>SecretBytes</code> bytes where the value is kept partially secret; see Secrets <code>SecretStr</code> string where the value is kept partially secret; see Secrets <code>IPvAnyAddress</code> allows either an <code>IPv4Address</code> or an <code>IPv6Address</code> <code>IPvAnyInterface</code> allows either an <code>IPv4Interface</code> or an <code>IPv6Interface</code> <code>IPvAnyNetwork</code> allows either an <code>IPv4Network</code> or an <code>IPv6Network</code> <code>NegativeFloat</code> allows a float which is negative; uses standard <code>float</code> parsing then checks the value is less than 0; see Constrained Types <code>NegativeInt</code> allows an int which is negative; uses standard <code>int</code> parsing then checks the value is less than 0; see Constrained Types <code>PositiveFloat</code> allows a float which is positive; uses standard <code>float</code> parsing then checks the value is greater than 0; see Constrained Types <code>PositiveInt</code> allows an int which is positive; uses standard <code>int</code> parsing then checks the value is greater than 0; see Constrained Types <code>conbytes</code> type method for constraining bytes; see Constrained Types <code>condecimal</code> type method for constraining Decimals; see Constrained Types <code>confloat</code> type method for constraining floats; see Constrained Types <code>conint</code> type method for constraining ints; see Constrained Types <code>condate</code> type method for constraining dates; see Constrained Types <code>conlist</code> type method for constraining lists; see Constrained Types <code>conset</code> type method for constraining sets; see Constrained Types <code>confrozenset</code> type method for constraining frozen sets; see Constrained Types <code>constr</code> type method for constraining strs; see Constrained Types"},{"location":"usage/types/#urls","title":"URLs","text":"<p>For URI/URL validation the following types are available:</p> <ul> <li><code>AnyUrl</code>: any scheme allowed, TLD not required, host required</li> <li><code>AnyHttpUrl</code>: scheme <code>http</code> or <code>https</code>, TLD not required, host required</li> <li><code>HttpUrl</code>: scheme <code>http</code> or <code>https</code>, TLD required, host required, max length 2083</li> <li><code>FileUrl</code>: scheme <code>file</code>, host not required</li> <li><code>PostgresDsn</code>: user info required, TLD not required, host required,   as of V.10 <code>PostgresDsn</code> supports multiple hosts. The following schemes are supported:<ul> <li><code>postgres</code></li> <li><code>postgresql</code></li> <li><code>postgresql+asyncpg</code></li> <li><code>postgresql+pg8000</code></li> <li><code>postgresql+psycopg</code></li> <li><code>postgresql+psycopg2</code></li> <li><code>postgresql+psycopg2cffi</code></li> <li><code>postgresql+py-postgresql</code></li> <li><code>postgresql+pygresql</code></li> </ul> </li> <li><code>CockroachDsn</code>: scheme <code>cockroachdb</code>, user info required, TLD not required, host required. Also, its supported DBAPI dialects:<ul> <li><code>cockroachdb+asyncpg</code></li> <li><code>cockroachdb+psycopg2</code></li> </ul> </li> <li><code>AmqpDsn</code>: schema <code>amqp</code> or <code>amqps</code>, user info not required, TLD not required, host not required</li> <li><code>RedisDsn</code>: scheme <code>redis</code> or <code>rediss</code>, user info not required, tld not required, host not required (CHANGED: user info) (e.g., <code>rediss://:pass@localhost</code>)</li> <li><code>MongoDsn</code> : scheme <code>mongodb</code>, user info not required, database name not required, port   not required from v1.6 onwards), user info may be passed without user part (e.g., <code>mongodb://mongodb0.example.com:27017</code>)</li> <li><code>stricturl</code>: method with the following keyword arguments:     - <code>strip_whitespace: bool = True</code>     - <code>min_length: int = 1</code>     - <code>max_length: int = 2 ** 16</code>     - <code>tld_required: bool = True</code>     - <code>host_required: bool = True</code>     - <code>allowed_schemes: Optional[Set[str]] = None</code></li> </ul> <p>Warning</p> <p>In V1.10.0 and v1.10.1 <code>stricturl</code> also took an optional <code>quote_plus</code> argument and URL components were percent encoded in some cases. This feature was removed in v1.10.2, see  #4470 for explanation and more details.</p> <p>The above types (which all inherit from <code>AnyUrl</code>) will attempt to give descriptive errors when invalid URLs are provided:</p> <p>If you require a custom URI/URL type, it can be created in a similar way to the types defined above.</p>"},{"location":"usage/types/#url-properties","title":"URL Properties","text":"<p>Assuming an input URL of <code>http://samuel:pass@example.com:8000/the/path/?query=here#fragment=is;this=bit</code>, the above types export the following properties:</p> <ul> <li><code>scheme</code>: always set - the url scheme (<code>http</code> above)</li> <li><code>host</code>: always set - the url host (<code>example.com</code> above)</li> <li> <p><code>host_type</code>: always set - describes the type of host, either:</p> <ul> <li><code>domain</code>: e.g. <code>example.com</code>,</li> <li><code>int_domain</code>: international domain, see below, e.g. <code>exampl\u00a3e.org</code>,</li> <li><code>ipv4</code>: an IP V4 address, e.g. <code>127.0.0.1</code>, or</li> <li><code>ipv6</code>: an IP V6 address, e.g. <code>2001:db8:ff00:42</code></li> </ul> </li> </ul> <ul> <li><code>user</code>: optional - the username if included (<code>samuel</code> above)</li> <li><code>password</code>: optional - the password if included (<code>pass</code> above)</li> <li><code>tld</code>: optional - the top level domain (<code>com</code> above),   Note: this will be wrong for any two-level domain, e.g. \"co.uk\". You'll need to implement your own list of TLDs   if you require full TLD validation</li> <li><code>port</code>: optional - the port (<code>8000</code> above)</li> <li><code>path</code>: optional - the path (<code>/the/path/</code> above)</li> <li><code>query</code>: optional - the URL query (aka GET arguments or \"search string\") (<code>query=here</code> above)</li> <li><code>fragment</code>: optional - the fragment (<code>fragment=is;this=bit</code> above)</li> </ul> <p>If further validation is required, these properties can be used by validators to enforce specific behaviour:</p>"},{"location":"usage/types/#international-domains","title":"International Domains","text":"<p>\"International domains\" (e.g. a URL where the host or TLD includes non-ascii characters) will be encoded via punycode (see this article for a good description of why this is important):</p> <p>Warning</p>"},{"location":"usage/types/#underscores-in-hostnames","title":"Underscores in Hostnames","text":"<p>In pydantic underscores are allowed in all parts of a domain except the tld. Technically this might be wrong - in theory the hostname cannot have underscores, but subdomains can.</p> <p>To explain this; consider the following two cases:</p> <ul> <li><code>exam_ple.co.uk</code>: the hostname is <code>exam_ple</code>, which should not be allowed since it contains an underscore</li> <li><code>foo_bar.example.com</code> the hostname is <code>example</code>, which should be allowed since the underscore is in the subdomain</li> </ul> <p>Without having an exhaustive list of TLDs, it would be impossible to differentiate between these two. Therefore underscores are allowed, but you can always do further validation in a validator if desired.</p> <p>Also, Chrome, Firefox, and Safari all currently accept <code>http://exam_ple.com</code> as a URL, so we're in good (or at least big) company.</p>"},{"location":"usage/types/#color-type","title":"Color Type","text":"<p>You can use the <code>Color</code> data type for storing colors as per CSS3 specification. Colors can be defined via:</p> <ul> <li>name (e.g. <code>\"Black\"</code>, <code>\"azure\"</code>)</li> <li>hexadecimal value   (e.g. <code>\"0x000\"</code>, <code>\"#FFFFFF\"</code>, <code>\"7fffd4\"</code>)</li> <li>RGB/RGBA tuples (e.g. <code>(255, 255, 255)</code>, <code>(255, 255, 255, 0.5)</code>)</li> <li>RGB/RGBA strings   (e.g. <code>\"rgb(255, 255, 255)\"</code>, <code>\"rgba(255, 255, 255, 0.5)\"</code>)</li> <li>HSL strings   (e.g. <code>\"hsl(270, 60%, 70%)\"</code>, <code>\"hsl(270, 60%, 70%, .5)\"</code>)</li> </ul> <p><code>Color</code> has the following methods:</p> <code>original</code> the original string or tuple passed to <code>Color</code> <code>as_named</code> returns a named CSS3 color; fails if the alpha channel is set or no such color exists unless <code>fallback=True</code> is supplied, in which case it falls back to <code>as_hex</code> <code>as_hex</code> returns a string in the format <code>#fff</code> or <code>#ffffff</code>; will contain 4 (or 8) hex values if the alpha channel is set, e.g. <code>#7f33cc26</code> <code>as_rgb</code> returns a string in the format <code>rgb(&lt;red&gt;, &lt;green&gt;, &lt;blue&gt;)</code>, or <code>rgba(&lt;red&gt;, &lt;green&gt;, &lt;blue&gt;, &lt;alpha&gt;)</code> if the alpha channel is set <code>as_rgb_tuple</code> returns a 3- or 4-tuple in RGB(a) format. The <code>alpha</code> keyword argument can be used to define whether the alpha channel should be included; options: <code>True</code> - always include, <code>False</code> - never include, <code>None</code> (default) - include if set <code>as_hsl</code> string in the format <code>hsl(&lt;hue deg&gt;, &lt;saturation %&gt;, &lt;lightness %&gt;)</code> or <code>hsl(&lt;hue deg&gt;, &lt;saturation %&gt;, &lt;lightness %&gt;, &lt;alpha&gt;)</code> if the alpha channel is set <code>as_hsl_tuple</code> returns a 3- or 4-tuple in HSL(a) format. The <code>alpha</code> keyword argument can be used to define whether the alpha channel should be included; options: <code>True</code> - always include, <code>False</code> - never include, <code>None</code> (the default)  - include if set <p>The <code>__str__</code> method for <code>Color</code> returns <code>self.as_named(fallback=True)</code>.</p> <p>Note</p> <p>the <code>as_hsl*</code> refer to hue, saturation, lightness \"HSL\" as used in html and most of the world, not \"HLS\" as used in Python's <code>colorsys</code>.</p>"},{"location":"usage/types/#secret-types","title":"Secret Types","text":"<p>You can use the <code>SecretStr</code> and the <code>SecretBytes</code> data types for storing sensitive information that you do not want to be visible in logging or tracebacks. <code>SecretStr</code> and <code>SecretBytes</code> can be initialized idempotently or by using <code>str</code> or <code>bytes</code> literals respectively. The <code>SecretStr</code> and <code>SecretBytes</code> will be formatted as either <code>'**********'</code> or <code>''</code> on conversion to json.</p>"},{"location":"usage/types/#json-type","title":"Json Type","text":"<p>You can use <code>Json</code> data type to make pydantic first load a raw JSON string. It can also optionally be used to parse the loaded object into another type base on the type <code>Json</code> is parameterised with:</p>"},{"location":"usage/types/#payment-card-numbers","title":"Payment Card Numbers","text":"<p>The <code>PaymentCardNumber</code> type validates payment cards (such as a debit or credit card).</p> <p><code>PaymentCardBrand</code> can be one of the following based on the BIN:</p> <ul> <li><code>PaymentCardBrand.amex</code></li> <li><code>PaymentCardBrand.mastercard</code></li> <li><code>PaymentCardBrand.visa</code></li> <li><code>PaymentCardBrand.other</code></li> </ul> <p>The actual validation verifies the card number is:</p> <ul> <li>a <code>str</code> of only digits</li> <li>luhn valid</li> <li>the correct length based on the BIN, if Amex, Mastercard or Visa, and between   12 and 19 digits for all other brands</li> </ul>"},{"location":"usage/types/#constrained-types","title":"Constrained Types","text":"<p>The value of numerous common types can be restricted using <code>con*</code> type functions:</p> <p>Where <code>Field</code> refers to the field function.</p>"},{"location":"usage/types/#arguments-to-conlist","title":"Arguments to <code>conlist</code>","text":"<p>The following arguments are available when using the <code>conlist</code> type function</p> <ul> <li><code>item_type: Type[T]</code>: type of the list items</li> <li><code>min_items: int = None</code>: minimum number of items in the list</li> <li><code>max_items: int = None</code>: maximum number of items in the list</li> <li><code>unique_items: bool = None</code>: enforces list elements to be unique</li> </ul>"},{"location":"usage/types/#arguments-to-conset","title":"Arguments to <code>conset</code>","text":"<p>The following arguments are available when using the <code>conset</code> type function</p> <ul> <li><code>item_type: Type[T]</code>: type of the set items</li> <li><code>min_items: int = None</code>: minimum number of items in the set</li> <li><code>max_items: int = None</code>: maximum number of items in the set</li> </ul>"},{"location":"usage/types/#arguments-to-confrozenset","title":"Arguments to <code>confrozenset</code>","text":"<p>The following arguments are available when using the <code>confrozenset</code> type function</p> <ul> <li><code>item_type: Type[T]</code>: type of the frozenset items</li> <li><code>min_items: int = None</code>: minimum number of items in the frozenset</li> <li><code>max_items: int = None</code>: maximum number of items in the frozenset</li> </ul>"},{"location":"usage/types/#arguments-to-conint","title":"Arguments to <code>conint</code>","text":"<p>The following arguments are available when using the <code>conint</code> type function</p> <ul> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>gt: int = None</code>: enforces integer to be greater than the set value</li> <li><code>ge: int = None</code>: enforces integer to be greater than or equal to the set value</li> <li><code>lt: int = None</code>: enforces integer to be less than the set value</li> <li><code>le: int = None</code>: enforces integer to be less than or equal to the set value</li> <li><code>multiple_of: int = None</code>: enforces integer to be a multiple of the set value</li> </ul>"},{"location":"usage/types/#arguments-to-confloat","title":"Arguments to <code>confloat</code>","text":"<p>The following arguments are available when using the <code>confloat</code> type function</p> <ul> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>gt: float = None</code>: enforces float to be greater than the set value</li> <li><code>ge: float = None</code>: enforces float to be greater than or equal to the set value</li> <li><code>lt: float = None</code>: enforces float to be less than the set value</li> <li><code>le: float = None</code>: enforces float to be less than or equal to the set value</li> <li><code>multiple_of: float = None</code>: enforces float to be a multiple of the set value</li> <li><code>allow_inf_nan: bool = True</code>: whether to allows infinity (<code>+inf</code> an <code>-inf</code>) and NaN values, defaults to <code>True</code>,   set to <code>False</code> for compatibility with <code>JSON</code>,   see #3994 for more details, added in V1.10</li> </ul>"},{"location":"usage/types/#arguments-to-condecimal","title":"Arguments to <code>condecimal</code>","text":"<p>The following arguments are available when using the <code>condecimal</code> type function</p> <ul> <li><code>gt: Decimal = None</code>: enforces decimal to be greater than the set value</li> <li><code>ge: Decimal = None</code>: enforces decimal to be greater than or equal to the set value</li> <li><code>lt: Decimal = None</code>: enforces decimal to be less than the set value</li> <li><code>le: Decimal = None</code>: enforces decimal to be less than or equal to the set value</li> <li><code>max_digits: int = None</code>: maximum number of digits within the decimal. it does not include a zero before the decimal point or trailing decimal zeroes</li> <li><code>decimal_places: int = None</code>: max number of decimal places allowed. it does not include trailing decimal zeroes</li> <li><code>multiple_of: Decimal = None</code>: enforces decimal to be a multiple of the set value</li> </ul>"},{"location":"usage/types/#arguments-to-constr","title":"Arguments to <code>constr</code>","text":"<p>The following arguments are available when using the <code>constr</code> type function</p> <ul> <li><code>strip_whitespace: bool = False</code>: removes leading and trailing whitespace</li> <li><code>to_upper: bool = False</code>: turns all characters to uppercase</li> <li><code>to_lower: bool = False</code>: turns all characters to lowercase</li> <li><code>strict: bool = False</code>: controls type coercion</li> <li><code>min_length: int = None</code>: minimum length of the string</li> <li><code>max_length: int = None</code>: maximum length of the string</li> <li><code>curtail_length: int = None</code>: shrinks the string length to the set value when it is longer than the set value</li> <li><code>regex: str = None</code>: regex to validate the string against</li> </ul>"},{"location":"usage/types/#arguments-to-conbytes","title":"Arguments to <code>conbytes</code>","text":"<p>The following arguments are available when using the <code>conbytes</code> type function</p> <ul> <li><code>strip_whitespace: bool = False</code>: removes leading and trailing whitespace</li> <li><code>to_upper: bool = False</code>: turns all characters to uppercase</li> <li><code>to_lower: bool = False</code>: turns all characters to lowercase</li> <li><code>min_length: int = None</code>: minimum length of the byte string</li> <li><code>max_length: int = None</code>: maximum length of the byte string</li> <li><code>strict: bool = False</code>: controls type coercion</li> </ul>"},{"location":"usage/types/#arguments-to-condate","title":"Arguments to <code>condate</code>","text":"<p>The following arguments are available when using the <code>condate</code> type function</p> <ul> <li><code>gt: date = None</code>: enforces date to be greater than the set value</li> <li><code>ge: date = None</code>: enforces date to be greater than or equal to the set value</li> <li><code>lt: date = None</code>: enforces date to be less than the set value</li> <li><code>le: date = None</code>: enforces date to be less than or equal to the set value</li> </ul>"},{"location":"usage/types/#strict-types","title":"Strict Types","text":"<p>You can use the <code>StrictStr</code>, <code>StrictBytes</code>, <code>StrictInt</code>, <code>StrictFloat</code>, and <code>StrictBool</code> types to prevent coercion from compatible types. These types will only pass validation when the validated value is of the respective type or is a subtype of that type. This behavior is also exposed via the <code>strict</code> field of the <code>ConstrainedStr</code>, <code>ConstrainedBytes</code>, <code>ConstrainedFloat</code> and <code>ConstrainedInt</code> classes and can be combined with a multitude of complex validation rules.</p> <p>The following caveats apply:</p> <ul> <li><code>StrictBytes</code> (and the <code>strict</code> option of <code>ConstrainedBytes</code>) will accept both <code>bytes</code>,    and <code>bytearray</code> types.</li> <li><code>StrictInt</code> (and the <code>strict</code> option of <code>ConstrainedInt</code>) will not accept <code>bool</code> types,     even though <code>bool</code> is a subclass of <code>int</code> in Python. Other subclasses will work.</li> <li><code>StrictFloat</code> (and the <code>strict</code> option of <code>ConstrainedFloat</code>) will not accept <code>int</code>.</li> </ul>"},{"location":"usage/types/#bytesize","title":"ByteSize","text":"<p>You can use the <code>ByteSize</code> data type to convert byte string representation to raw bytes and print out human readable versions of the bytes as well.</p> <p>Info</p> <p>Note that <code>1b</code> will be parsed as \"1 byte\" and not \"1 bit\".</p>"},{"location":"usage/types/#custom-data-types","title":"Custom Data Types","text":"<p>You can also define your own custom data types. There are several ways to achieve it.</p>"},{"location":"usage/types/#classes-with-__get_validators__","title":"Classes with <code>__get_validators__</code>","text":"<p>You use a custom class with a classmethod <code>__get_validators__</code>. It will be called to get validators to parse and validate the input data.</p> <p>Tip</p> <p>These validators have the same semantics as in Validators, you can declare a parameter <code>config</code>, <code>field</code>, etc.</p> <p>Similar validation could be achieved using <code>constr(regex=...)</code> except the value won't be formatted with a space, the schema would just include the full pattern and the returned value would be a vanilla string.</p> <p>See schema for more details on how the model's schema is generated.</p>"},{"location":"usage/types/#arbitrary-types-allowed","title":"Arbitrary Types Allowed","text":"<p>You can allow arbitrary types using the <code>arbitrary_types_allowed</code> config in the Model Config.</p>"},{"location":"usage/types/#generic-classes-as-types","title":"Generic Classes as Types","text":"<p>Warning</p> <p>This is an advanced technique that you might not need in the beginning. In most of the cases you will probably be fine with standard pydantic models.</p> <p>You can use Generic Classes as field types and perform custom validation based on the \"type parameters\" (or sub-types) with <code>__get_validators__</code>.</p> <p>If the Generic class that you are using as a sub-type has a classmethod <code>__get_validators__</code> you don't need to use <code>arbitrary_types_allowed</code> for it to work.</p> <p>Because you can declare validators that receive the current <code>field</code>, you can extract the <code>sub_fields</code> (from the generic class type parameters) and validate data with them.</p>"},{"location":"usage/validation_decorator/","title":"Validation decorator","text":"<p>The <code>validate_arguments</code> decorator allows the arguments passed to a function to be parsed and validated using the function's annotations before the function is called. While under the hood this uses the same approach of model creation and initialisation; it provides an extremely easy way to apply validation to your code with minimal boilerplate.</p> <p>In Beta</p> <p>The <code>validate_arguments</code> decorator is in beta, it has been added to pydantic in v1.5 on a provisional basis. It may change significantly in future releases and its interface will not be concrete until v2. Feedback from the community while it's still provisional would be extremely useful; either comment on #1205 or create a new issue.</p> <p>Example of usage:</p>"},{"location":"usage/validation_decorator/#argument-types","title":"Argument Types","text":"<p>Argument types are inferred from type annotations on the function, arguments without a type decorator are considered as <code>Any</code>. Since <code>validate_arguments</code> internally uses a standard <code>BaseModel</code>, all types listed in types can be validated, including pydantic models and custom types. As with the rest of pydantic, types can be coerced by the decorator before they're passed to the actual function:</p> <p>A few notes:</p> <ul> <li>though they're passed as strings, <code>path</code> and <code>regex</code> are converted to a <code>Path</code> object and regex respectively by the decorator</li> <li><code>max</code> has no type annotation, so will be considered as <code>Any</code> by the decorator</li> </ul> <p>Type coercion like this can be extremely helpful but also confusing or not desired, see below for a discussion of <code>validate_arguments</code>'s limitations in this regard.</p>"},{"location":"usage/validation_decorator/#function-signatures","title":"Function Signatures","text":"<p>The decorator is designed to work with functions using all possible parameter configurations and all possible combinations of these:</p> <ul> <li>positional or keyword arguments with or without defaults</li> <li>variable positional arguments defined via <code>*</code> (often <code>*args</code>)</li> <li>variable keyword arguments defined via <code>**</code> (often <code>**kwargs</code>)</li> <li>keyword only arguments - arguments after <code>*,</code></li> <li>positional only arguments - arguments before <code>, /</code> (new in Python 3.8)</li> </ul> <p>To demonstrate all the above parameter types:</p>"},{"location":"usage/validation_decorator/#using-field-to-describe-function-arguments","title":"Using Field to describe function arguments","text":"<p>Field can also be used with <code>validate_arguments</code> to provide extra information about the field and validations. In general it should be used in a type hint with Annotated, unless <code>default_factory</code> is specified, in which case it should be used as the default value of the field:</p> <p>The alias can be used with the decorator as normal.</p>"},{"location":"usage/validation_decorator/#usage-with-mypy","title":"Usage with mypy","text":"<p>The <code>validate_arguments</code> decorator should work \"out of the box\" with mypy since it's defined to return a function with the same signature as the function it decorates. The only limitation is that since we trick mypy into thinking the function returned by the decorator is the same as the function being decorated; access to the raw function or other attributes will require <code>type: ignore</code>.</p>"},{"location":"usage/validation_decorator/#validate-without-calling-the-function","title":"Validate without calling the function","text":"<p>By default, arguments validation is done by directly calling the decorated function with parameters. But what if you wanted to validate them without actually calling the function? To do that you can call the <code>validate</code> method bound to the decorated function.</p>"},{"location":"usage/validation_decorator/#raw-function","title":"Raw function","text":"<p>The raw function which was decorated is accessible, this is useful if in some scenarios you trust your input arguments and want to call the function in the most performant way (see notes on performance below):</p>"},{"location":"usage/validation_decorator/#async-functions","title":"Async Functions","text":"<p><code>validate_arguments</code> can also be used on async functions:</p>"},{"location":"usage/validation_decorator/#custom-config","title":"Custom Config","text":"<p>The model behind <code>validate_arguments</code> can be customised using a config setting which is equivalent to setting the <code>Config</code> sub-class in normal models.</p> <p>Warning</p> <p>The <code>fields</code> and <code>alias_generator</code> properties of <code>Config</code> which allow aliases to be configured are not supported yet with <code>@validate_arguments</code>, using them will raise an error.</p> <p>Configuration is set using the <code>config</code> keyword argument to the decorator, it may be either a config class or a dict of properties which are converted to a class later.</p>"},{"location":"usage/validation_decorator/#limitations","title":"Limitations","text":"<p><code>validate_arguments</code> has been released on a provisional basis without all the bells and whistles, which may be added later, see #1205 for some more discussion of this.</p> <p>In particular:</p>"},{"location":"usage/validation_decorator/#validation-exception","title":"Validation Exception","text":"<p>Currently upon validation failure, a standard pydantic <code>ValidationError</code> is raised, see model error handling.</p> <p>This is helpful since it's <code>str()</code> method provides useful details of the error which occurred and methods like <code>.errors()</code> and <code>.json()</code> can be useful when exposing the errors to end users, however <code>ValidationError</code> inherits from <code>ValueError</code> not <code>TypeError</code> which may be unexpected since Python would raise a <code>TypeError</code> upon invalid or missing arguments. This may be addressed in future by either allow a custom error or raising a different exception by default, or both.</p>"},{"location":"usage/validation_decorator/#coercion-and-strictness","title":"Coercion and Strictness","text":"<p>pydantic currently leans on the side of trying to coerce types rather than raise an error if a type is wrong, see model data conversion and <code>validate_arguments</code> is no different.</p> <p>See #1098 and other issues with the \"strictness\" label for a discussion of this. If pydantic gets a \"strict\" mode in future, <code>validate_arguments</code> will have an option to use this, it may even become the default for the decorator.</p>"},{"location":"usage/validation_decorator/#performance","title":"Performance","text":"<p>We've made a big effort to make pydantic as performant as possible and argument inspect and model creation is only performed once when the function is defined, however there will still be a performance impact to using the <code>validate_arguments</code> decorator compared to calling the raw function.</p> <p>In many situations this will have little or no noticeable effect, however be aware that <code>validate_arguments</code> is not an equivalent or alternative to function definitions in strongly typed languages; it never will be.</p>"},{"location":"usage/validation_decorator/#return-value","title":"Return Value","text":"<p>The return value of the function is not validated against its return type annotation, this may be added as an option in future.</p>"},{"location":"usage/validation_decorator/#config-and-validators","title":"Config and Validators","text":"<p><code>fields</code> and <code>alias_generator</code> on custom <code>Config</code> are not supported, see above.</p> <p>Neither are validators.</p>"},{"location":"usage/validation_decorator/#model-fields-and-reserved-arguments","title":"Model fields and reserved arguments","text":"<p>The following names may not be used by arguments since they can be used internally to store information about the function's signature:</p> <ul> <li><code>v__args</code></li> <li><code>v__kwargs</code></li> <li><code>v__positional_only</code></li> </ul> <p>These names (together with <code>\"args\"</code> and <code>\"kwargs\"</code>) may or may not (depending on the function's signature) appear as fields on the internal pydantic model accessible via <code>.model</code> thus this model isn't especially useful (e.g. for generating a schema) at the moment.</p> <p>This should be fixable in future as the way error are raised is changed.</p>"},{"location":"usage/validators/","title":"Validators","text":"<p>Custom validation and complex relationships between objects can be achieved using the <code>validator</code> decorator.</p> <p>A few things to note on validators:</p> <ul> <li>validators are \"class methods\", so the first argument value they receive is the <code>UserModel</code> class, not an instance   of <code>UserModel</code>.</li> <li>the second argument is always the field value to validate; it can be named as you please</li> <li>you can also add any subset of the following arguments to the signature (the names must match):<ul> <li><code>values</code>: a dict containing the name-to-value mapping of any previously-validated fields</li> <li><code>config</code>: the model config</li> <li><code>field</code>: the field being validated. Type of object is <code>pydantic.fields.ModelField</code>.</li> <li><code>**kwargs</code>: if provided, this will include the arguments above not explicitly listed in the signature</li> </ul> </li> <li>validators should either return the parsed value or raise a <code>ValueError</code>, <code>TypeError</code>, or <code>AssertionError</code>   (<code>assert</code> statements may be used).</li> </ul> <p>Warning</p> <p>If you make use of <code>assert</code> statements, keep in mind that running Python with the <code>-O</code> optimization flag disables <code>assert</code> statements, and validators will stop working.</p> <ul> <li> <p>where validators rely on other values, you should be aware that:</p> <ul> <li>Validation is done in the order fields are defined.   E.g. in the example above, <code>password2</code> has access to <code>password1</code> (and <code>name</code>),   but <code>password1</code> does not have access to <code>password2</code>. See Field Ordering   for more information on how fields are ordered</li> </ul> <ul> <li>If validation fails on another field (or that field is missing) it will not be included in <code>values</code>, hence   <code>if 'password1' in values and ...</code> in this example.</li> </ul> </li> </ul>"},{"location":"usage/validators/#pre-and-per-item-validators","title":"Pre and per-item validators","text":"<p>Validators can do a few more complex things:</p> <p>A few more things to note:</p> <ul> <li>a single validator can be applied to multiple fields by passing it multiple field names</li> <li>a single validator can also be called on all fields by passing the special value <code>'*'</code></li> <li>the keyword argument <code>pre</code> will cause the validator to be called prior to other validation</li> <li>passing <code>each_item=True</code> will result in the validator being applied to individual values   (e.g. of <code>List</code>, <code>Dict</code>, <code>Set</code>, etc.), rather than the whole object</li> </ul>"},{"location":"usage/validators/#subclass-validators-and-each_item","title":"Subclass Validators and <code>each_item</code>","text":"<p>If using a validator with a subclass that references a <code>List</code> type field on a parent class, using <code>each_item=True</code> will cause the validator not to run; instead, the list must be iterated over programmatically.</p>"},{"location":"usage/validators/#validate-always","title":"Validate Always","text":"<p>For performance reasons, by default validators are not called for fields when a value is not supplied. However there are situations where it may be useful or required to always call the validator, e.g. to set a dynamic default value.</p> <p>You'll often want to use this together with <code>pre</code>, since otherwise with <code>always=True</code> pydantic would try to validate the default <code>None</code> which would cause an error.</p>"},{"location":"usage/validators/#reuse-validators","title":"Reuse validators","text":"<p>Occasionally, you will want to use the same validator on multiple fields/models (e.g. to normalize some input data). The \"naive\" approach would be to write a separate function, then call it from multiple decorators.  Obviously, this entails a lot of repetition and boiler plate code. To circumvent this, the <code>allow_reuse</code> parameter has been added to <code>pydantic.validator</code> in v1.2 (<code>False</code> by default):</p> <p>As it is obvious, repetition has been reduced and the models become again almost declarative.</p> <p>Tip</p> <p>If you have a lot of fields that you want to validate, it usually makes sense to define a help function with which you will avoid setting <code>allow_reuse=True</code> over and over again.</p>"},{"location":"usage/validators/#root-validators","title":"Root Validators","text":"<p>Validation can also be performed on the entire model's data.</p> <p>As with field validators, root validators can have <code>pre=True</code>, in which case they're called before field validation occurs (and are provided with the raw input data), or <code>pre=False</code> (the default), in which case they're called after field validation.</p> <p>Field validation will not occur if <code>pre=True</code> root validators raise an error. As with field validators, \"post\" (i.e. <code>pre=False</code>) root validators by default will be called even if prior validators fail; this behaviour can be changed by setting the <code>skip_on_failure=True</code> keyword argument to the validator. The <code>values</code> argument will be a dict containing the values which passed field validation and field defaults where applicable.</p>"},{"location":"usage/validators/#field-checks","title":"Field Checks","text":"<p>On class creation, validators are checked to confirm that the fields they specify actually exist on the model.</p> <p>Occasionally however this is undesirable: e.g. if you define a validator to validate fields on inheriting models. In this case you should set <code>check_fields=False</code> on the validator.</p>"},{"location":"usage/validators/#dataclass-validators","title":"Dataclass Validators","text":"<p>Validators also work with pydantic dataclasses.</p>"}]}